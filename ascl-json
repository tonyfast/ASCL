{
	"@context":{
		"ASCL": {
			"@id": "http://schema.org/itemListElement",
			"@container": "@list"
		},
		"ascl_id":{"@id":"http://schema.org/url","@type":"@id"},
		"title":"http://schema.org/headline",
		"credit":"http://schema.org/creator",
		"abstract":"http://dbpedia.org/page/Abstract",
		"bibcode":"http://dbpedia.org/page/Bibcode",
		"views":"http://schema.org/interactionCount",
		"site_list":{
			"@container":"@set",
			"@id":"http://schema.org/downloadUrl"
		},
		"ref_list":{
			"@container": "@set",
			"@id":"http://schema.org/citation"
		}
	},
	"ASCL":[
		{"ascl_id":"9903.001","title":"LENSKY: Galactic Microlensing Probability","credit":"Nemiroff, Robert J.","abstract":"Given a model for the Galaxy, this program computes the microlensing rate in any direction. Program features include the ability to include the brightness of the lens and to compute the probability of lens detection at any level of lensing amplification. The program limits itself to lensing by single stars of single sources. The program is currently setup to accept input from the Galactic models of Bahcall and Soniera (1982, 1986).\n\nThere are three files needed for LENSKY, the Fortran file lensky.for and two input files: galmod.dsk (15 Megs) and galmod.sph (22 Megs). The zip file available below contains all three files. The program generates output to the file lensky.out. The program is pretty self-explanatory past that. Please contact me if there are any problems at nemiroff@mtu.edu","topic_id":"20392","bibcode":"1999ascl.soft03001N","views":"63","site_list":["http:\/\/asterisk.apod.com\/library\/ASCL\/lensky\/lensky.zip"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1998ApJ...509...39N"]},
		{"ascl_id":"9904.001","title":"BSGMODEL: The Bahcall-Soneira Galaxy Model","credit":"Bahcall, John N.","abstract":"BSGMODEL is used to construct the disk and spheroid components of the Galaxy from which the distribution of visible stars and mass in the Galaxy is calculated. The computer files accessible here are available for export use. The modifications are described in comment lines in the software. The Galaxy model software has been installed and used by different people for a large variety of purposes (see, e. g., the the review \"Star Counts and Galactic Structure'', Ann. Rev. Astron. Ap. 24, 577, 1986 ).","topic_id":"29378","bibcode":"1999ascl.soft04001B","views":"67","site_list":["http:\/\/asterisk.apod.com\/library\/ASCL\/bsgmodel\/model.f"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1980ApJS...44...73B"]},
		{"ascl_id":"9905.001","title":"CONSKY: A Sky CCD Integration Simulation","credit":"Nemiroff, Robert J.; Rafert, J. Bruce","abstract":"This program addresses the question of what resources are needed to produce a continuous data record of the entire sky down to a given limiting visual magnitude. Toward this end, the program simulates a small camera\/telescope or group of small camera\/telescopes collecting light from a large portion of the sky. From a given stellar density derived from a Bahcall - Soneira Galaxy model, the program first converts star densities at visual magnitudes between 5 and 20 to number of sky pixels needed to monitor each star simultaneously. From pixels, the program converts input CCD parameters to needed telescope attributes, needed data storage space, and the length of time needed to accumulate data of photometric quality for stars of each limiting visual magnitude over the whole sky. The program steps though photometric integrations one second at a time and includes the contribution from a bright background, read noise, dark current, and atmospheric absorption.","topic_id":"20404","bibcode":"1999ascl.soft05001N","views":"44","site_list":["http:\/\/asterisk.apod.com\/download\/file.php?id=3369"],"ref_list":false},
		{"ascl_id":"9905.002","title":"ICOSAHEDRON: A package for pixelizing the sphere","credit":"Tegmark, Max","abstract":"What is the best way to pixelize a sphere? This question occurs in many practical applications, for instance when making maps (of the earth or the celestial sphere) and when doing numerical integrals over the sphere. This package consists of source code and documentation for a method which involves inscribing the sphere in a regular icosahedron and then equalizing the pixel areas.","topic_id":"20396","bibcode":"1999ascl.soft05002T","views":"37","site_list":["http:\/\/space.mit.edu\/home\/tegmark\/icosahedron.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1996ApJ...470L..81T"]},
		{"ascl_id":"9906.001","title":"SLOPES: Least-squares linear regression lines for bivariate datasets","credit":"Feigelson, Eric","abstract":"SLOPES computes six least-squares linear regression lines for bivariate datasets of the form (x_i,y_i) with unknown population distributions. Measurement errors, censoring (nondetections) or other complications are not treated. The lines are: the ordinary least-squares regression of y on x, OLS(Y|X); the inverse regression of x on y, OLS(X_Y); the angular bisector of the OLS lines; the orthogonal regression line; the reduced major axis, and the mean-OLS line. The latter four regressions treat the variables symmetrically, while the first two regressions are asymmetrical. Uncertainties for the regression coefficients of each method are estimated via asymptotic formulae, bootstrap resampling, and bivariate normal simulation. These methods, derivation of the regression coefficient uncertainties, and discussions of their use are provided in three papers listed below. The user is encouraged to read and reference these studies.","topic_id":"20384","bibcode":"1999ascl.soft06001F","views":"42","site_list":["http:\/\/www.astro.psu.edu\/statcodes\/","http:\/\/www.astro.psu.edu\/statcodes\/slopes.f"],"ref_list":false},
		{"ascl_id":"9906.002","title":"EXTINCT: A computerized model of large-scale visual interstellar extinction","credit":"Hakkila, Jon; Myers, Jeannette M.; Stidham, Brett J.; Hartmann, Dieter H.","abstract":"The program EXTINCT.FOR is a FORTRAN subroutine summarizing a three-dimensional visual Galactic extinction model, based on a number of published studies. INPUTS: Galactic latitude (degrees), Galactic longitude (degrees), and source distance (kpc). OUTPUTS (magnitudes): Extinction, extinction error, a statistical correction term, and an array containing extinction and extinction error from each subroutine. The model is useful for correcting visual magnitudes of Galactic sources (particularly in statistical models), and has been used to find Galactic extinction of extragalactic sources. The model's limited angular resolution (subroutine-dependent, but with a minimum resolution of roughly 2 degrees) is necessitated by its ability to describe three-dimensional structure.","topic_id":"29300","bibcode":"1999ascl.soft06002H","views":"54","site_list":["http:\/\/asterisk.apod.com\/library\/ASCL\/extinct\/extinct.for"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1997AJ....114.2043H"]},
		{"ascl_id":"9909.001","title":"PMCode: Particle-Mesh Code for Cosmological Simulations","credit":"Klypin, Anatoly; Holtzman, Jon","abstract":"Particle-Mesh (PM) codes are still very useful tools for testing predictions of cosmological models in cases when extra high resolution is not very important. We release for public use a cosmological PM N-body code. The code is very fast and simple. We provide a complete package of routines needed to set initial conditions, to run the code, and to analyze the results. The package allows you to simulate models with numerous combinations of parameters: open\/flat\/closed background, with or without the cosmological constant, different values of the Hubble constant, with or without hot neutrinos, tilted or non-tilted initial spectra, different amount of baryons.","topic_id":"20388","bibcode":"1999ascl.soft09001K","views":"42","site_list":["http:\/\/astro.nmsu.edu\/~aklypin\/PM\/pmcode\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1997astro.ph.12217K"]},
		{"ascl_id":"9909.002","title":"ANGSIZ: A general and practical method for calculating cosmological distances","credit":"Helbig, Phillip; Kayser, Rainer; Schramm, Thomas","abstract":"The calculation of distances is of fundamental importance in extragalactic astronomy and cosmology. However, no practical implementation for the general case has previously been available. We derive a second-order differential equation for the angular size distance valid not only in all homogeneous Friedmann-Lemaitre cosmological models, parametrised by $lambda_{0}$ and $Omega_{0}$, but also in inhomogeneous 'on-average' Friedmann-Lemaitre models, where the inhomogeneity is given by the (in the general case redshift-dependent) parameter $eta$. Since most other distances can be obtained trivially from the angular size distance, and since the differential equation can be efficiently solved numerically, this offers for the first time a practical method for calculating distances in a large class of cosmological models. We also briefly discuss our numerical implementation, which is publicly available.","topic_id":"20411","bibcode":"1999ascl.soft09002H","views":"82","site_list":["http:\/\/www.astro.multivax.de:8001\/phillip\/angsiz_prog\/1_1-1\/aaareadme.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1997A%26A...318..680K"]},
		{"ascl_id":"9909.003","title":"ISIS: A method for optimal image subtraction","credit":"Alard, Christophe; Lupton, Robert","abstract":"ISIS is a complete package to process CCD images using the image Optimal subtraction method (Alard & Lupton 1998, Alard 1999). The ISIS package can find the best kernel solution even in case of kernel variations as a function of position in the image. The relevant computing time is minimal in this case and is only slightly different from finding constant kernel solutions. ISIS includes as well a number of facilities to compute the light curves of variables objects from the subtracted images. The basic routines required to build the reference frame and make the image registration are also provided in the package.","topic_id":"20393","bibcode":"1999ascl.soft09003A","views":"50","site_list":["http:\/\/www2.iap.fr\/users\/alard\/package.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003MNRAS.345..960T"]},
		{"ascl_id":"9909.004","title":"CMBFAST: A microwave anisotropy code","credit":"Seljak, U.; Zaldarriaga, M.","abstract":"CMBFAST is the most extensively used code for computing cosmic microwave background anisotropy, polarization and matter power spectra. This package contains cosmological linear perturbation theory code to compute the evolution of various cosmological matter and radiation components, both today and at high redshift. The code has been tested over a wide range of cosmological parameters. We are continuously testing and updating the code based on suggestions from the cosmological community.","topic_id":"20405","bibcode":"1999ascl.soft09004S","views":"119","site_list":["http:\/\/lambda.gsfc.nasa.gov\/toolbox\/tb_cmbfast_ov.cf","http:\/\/lambda.gsfc.nasa.gov\/toolbox\/web_cmbfast_4.5.1_v2.tar.gz"],"ref_list":false},
		{"ascl_id":"9909.005","title":"BLOCK: A Bayesian block method to analyze structure in photon counting data","credit":"Scargle, Jeffrey D.","abstract":"Bayesian Blocks is a time-domain algorithm for detecting localized structures (bursts), revealing pulse shapes, and generally characterizing intensity variations. The input is raw counting data, in any of three forms: time-tagged photon events, binned counts, or time-to-spill data. The output is the most probable segmentation of the observation into time intervals during which the photon arrival rate is perceptibly constant, <span style=\"font-style: italic\">i.e.<\/span> has no statistically significant variations. The idea is not that the source is deemed to have this discontinuous, piecewise constant form, rather that such an approximate and generic model is often useful. The analysis is based on Bayesian statistics. \r\n\r\nThis code is obsolete and yields approximate results; see <a href=\"http:\/\/ascl.net\/1209.001\">Bayesian Blocks<\/a> instead for an algorithm guaranteeing exact global optimization.","topic_id":"29316","bibcode":"1999ascl.soft09005S","views":"81","site_list":["http:\/\/asterisk.apod.com\/library\/ASCL\/block\/block.zip"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1998ApJ...504..405S"]},
		{"ascl_id":"9910.001","title":"Cloudy: Numerical simulation of plasmas and their spectra","credit":"Ferland, Gary; van Hoof, Peter; Verner, Dima; Verner, Katya; Ferguson, Jason; Hamann, Fred; Kingdon, Jim; Korista, Kirk; Shields, Joe","abstract":"Cloudy is a large-scale spectral synthesis code designed to simulate fully physical conditions within an astronomical plasma and then predict the emitted spectrum. The code is freely available and is widely used in the analysis and interpretation of emission-line spectra.","topic_id":"20407","bibcode":"1999ascl.soft10001F","views":"71","site_list":["http:\/\/www.nublado.org\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000astro.ph..1196V","http:\/\/adsabs.harvard.edu\/abs\/2006PASP..118..920P"]},
		{"ascl_id":"9910.002","title":"SPECTRUM: A stellar spectral synthesis program","credit":"Gray, Richard O.","abstract":"SPECTRUM ((C) Richard O. Gray, 1992-2008) is a stellar spectral synthesis program which  runs on a number of platforms, including most flavors of UNIX and LINUX. It will also run under Windwos 9x\/ME\/NT\/2000\/XP using the Cygwin tools or the distributed Windows binaries. The code for SPECTRUM has been written in the \"C\" language. SPECTRUM computes the LTE synthetic spectrum given a stellar atmosphere model. SPECTRUM can use as input the fully blanketed stellar atmosphere models of Robert Kurucz including the new models of Castelli and Kurucz, but any other stellar atmosphere model which can be cast into the format of Kurucz's models can be used as well. SPECTRUM can be programmed with \"command-line switches\" to give a number of different outputs. In the default mode, SPECTRUM computes the stellar-disk-integrated normalized-intensity spectrum, but in addition, SPECTRUM will compute the absolute monochromatic flux from the stellar atmosphere or the specific intensity from any point on the stellar surface.","topic_id":"20383","bibcode":"1999ascl.soft10002G","views":"51","site_list":["http:\/\/www.appstate.edu\/~grayro\/spectrum\/spectrum.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010A%26A...519A.115H"]},
		{"ascl_id":"9910.003","title":"FASTELL: Fast calculation of a family of elliptical mass gravitational lens models","credit":"Barkana, Rennan","abstract":"Because of their simplicity, axisymmetric mass distributions are often used to model gravitational lenses. Since galaxies are usually observed to have elliptical light distributions, mass distributions with elliptical density contours offer more general and realistic lens models. They are difficult to use, however, since previous studies have shown that the deflection angle (and magnification) in this case can only be obtained by rather expensive numerical integrations. We present a family of lens models for which the deflection can be calculated to high relative accuracy (10-5) with a greatly reduced numerical effort, for small and large ellipticity alike. This makes it easier to use these distributions for modeling individual lenses as well as for applications requiring larger computing times, such as statistical lensing studies. FASTELL is a code to calculate quickly and accurately the lensing deflection and magnification matrix for the softened power-law elliptical mass distribution (SPEMD) lens galaxy model. The SPEMD consists of a softened power-law radial distribution with elliptical isodensity contours.","topic_id":"20399","bibcode":"1999ascl.soft10003B","views":"45","site_list":["http:\/\/wise-obs.tau.ac.il\/~barkana\/codes.html","http:\/\/wise-obs.tau.ac.il\/~barkana\/fastell.f"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004MNRAS.347...59B"]},
		{"ascl_id":"9910.004","title":"COSMICS: Cosmological initial conditions and microwave anisotropy codes","credit":"Bertschinger, Edmund","abstract":"COSMICS is a package of Fortran programs useful for computing transfer functions and microwave background anisotropy for cosmological models, and for generating gaussian random initial conditions for nonlinear structure formation simulations of such models. Four programs are provided: linger_con  and linger_syn integrate the linearized equations of general relativity, matter, and radiation in conformal Newtonian and synchronous gauge, respectively; deltat integrates the photon transfer functions computed by the linger codes to produce photon anisotropy power spectra; and grafic tabulates normalized matter power spectra and produces constrained or unconstrained samples of the matter density field.","topic_id":"20403","bibcode":"1999ascl.soft10004B","views":"64","site_list":["http:\/\/web.mit.edu\/edbert\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1995astro.ph..6070B"]},
		{"ascl_id":"9910.005","title":"XSPEC: An X-ray spectral fitting package","credit":"Arnaud, Keith; Dorman, Ben; Gordon, Craig","abstract":"It has been over a decade since the first paper was published containing results determined using the general X-ray spectral-fitting program XSPEC. Since then XSPEC has become the most widely used program for this purpose, being the de facto standard for the ROSAT and the de jure standard for the ASCA and XTE satellites. Probably the most important features of XSPEC are the large number of theoretical models available and the facilities for adding new models.","topic_id":"19783","bibcode":"1999ascl.soft10005A","views":"62","site_list":["http:\/\/heasarc.gsfc.nasa.gov\/docs\/xanadu\/xspec\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008PASP..120..821N"]},
		{"ascl_id":"9910.006","title":"BHSKY: Visual distortions near a black hole","credit":"Nemiroff, Robert J.","abstract":"BHSKY (copyright 1999 by Robert J. Nemiroff) computes the visual distortion effects visible to an observer traveling around and descending near a non-rotating black hole. The codes are general relativistically accurate and incorporate concepts such as large-angle deflections, image magnifications, multiple imaging, blue-shifting, and the location of the photon sphere. Once star.dat is edited to define the position and orientation of the observer relative to the black hole, bhsky_table should be run to create a table of photon deflection angles. Next bhsky_image reads this table and recomputes the perceived positions of stars in star.num, the Yale Bright Star Catalog. Lastly, bhsky_camera plots these results. The code currently tracks only the two brightest images of each star, and hence becomes noticeably incomplete within 1.1 times the Schwarzschild radius.","topic_id":"20409","bibcode":"1999ascl.soft10006N","views":"78","site_list":["http:\/\/antwrp.gsfc.nasa.gov\/htmltest\/rjn_bht.html","http:\/\/ascl.net\/phpBB3\/download\/file.php?id=8"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1993AmJPh..61..619N"]},
		{"ascl_id":"9910.007","title":"WINGSPAN: A WINdows Gamma-ray SPectral Analysis program","credit":"Preece, Robert D.; Briggs, Michael S.; Mallozzi, Robert S.; Brock, Martin N.","abstract":"WINGSPAN is a program written to analyze spectral data from the Burst and Transient Source Experiment (BATSE) on NASA's Compton Gamma-Ray Observatory. Data files in the FITS (BFITS) format are suitable for input into the program. WINGSPAN can be used to view and manipulate event time histories or count spectra, and also has the capability to perform spectral deconvolution via a standard forward folding model fitting technique (Levenberg-Marquardt algorithm). Although WINGSPAN provides many functions for data manipulation, the program was designed to allow users to easily plug in their own external IDL routines. These external routines have access to all data read from the FITS files, as well as selection intervals created in the main part of WINGSPAN (background intervals and model, etc).","topic_id":"19807","bibcode":"1999ascl.soft10007P","views":"58","site_list":["http:\/\/gammaray.msfc.nasa.gov\/tools\/wingspan\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1999ApL%26C..39..281R"]},
		{"ascl_id":"9910.008","title":"XSTAR: A program for calculating conditions and spectra of photoionized gases","credit":"Kallman, Tim","abstract":"XSTAR is a command-driven, interactive, computer program for calculating the physical conditions and emission spectra of photoionized gases.  It may be applied in a wide variety of astrophysical contexts.  Stripped to essentials, its job may be described simply: A spherical gas shell surrounding a central source of ionizing radiation absorbs some of this radiation and reradiates it in other portions of the spectrum; XSTAR computes the effects on the gas of absorbing this energy, and the spectrum of reradiated light.  The user supplies the shape and strength of the incident continuum, the elemental abundances in the gas, its density or pressure, and its thickness; the code can be directed to return any of a large number of derived quantities, including (but not limited to) the ionization balance and temperature, opacity tables, and emitted line and continuum fluxes.","topic_id":"19597","bibcode":"1999ascl.soft10008K","views":"423","site_list":["http:\/\/heasarc.gsfc.nasa.gov\/docs\/software\/lheasoft\/download.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001ApJS..133..221K"]},
		{"ascl_id":"9910.009","title":"RADPACK: A RADical compression analysis PACKage for fitting to the CMB","credit":"Knox, Lloyd","abstract":"The RADPACK package, written in IDL, contains both data and software. The data are the constraints on the cosmic microwave background (CMB) angular power spectrum from all published data as of 9\/99. A unique aspect of this compilation is that the non-Gaussianity of the uncertainties has been characterized. The most important program in the package, written in the IDL language, is called chisq.pro and calculates $chi^2$, for an input power spectrum, according to the offset log-normal form of Bond, Jaffe and Knox (astro-ph\/9808264). chisq.pro also outputs files that are useful for examining the residuals (the difference between the predictions of the model and the data). There is an sm macro for plotting up the residuals, and a histogram of the residuals. The histogram is actually for the 'whitenend' residuals ---a linear combination of the residuals which leaves them uncorrelated and with unit variance. The expectation is that the whitened residuals will be distributed as a Gaussian with unit variance.","topic_id":"29439","bibcode":"1999ascl.soft10009K","views":"54","site_list":["http:\/\/asterisk.apod.com\/library\/ASCL\/radpack\/radpack.tar.gz"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000ApJ...533...19B","http:\/\/adsabs.harvard.edu\/abs\/2003PhRvD..68h3517K"]},
		{"ascl_id":"9911.001","title":"DUSTY: Radiation transport in a dusty environment","credit":"Ivezic, Zeljko; Nenkova, Maia; Elitzur, Moshe","abstract":"DUSTY solves the problem of radiation transport in a dusty environment. The code can handle both spherical and planar geometries. The user specifies the properties of the radiation source and dusty region, and the code calculates the dust temperature distribution and the radiation field in it. The solution method is  based on a self-consistent equation for the radiative energy density, including dust scattering, absorption and emission, and does not introduce any approximations. The solution is exact to within the specified numerical accuracy. DUSTY has built in optical properties for the most common types of astronomical dust and comes with a library for many other grains. It supports various analytical forms for the density distribution, and can perform a full dynamical calculation for radiatively driven winds around AGB stars. The spectral energy distribution of the source can be specified analytically as either Planckian or broken power-law. In addition, arbitrary dust optical properties, density distributions and external radiation can be entered in user supplied files. Furthermore, the wavelength grid can be modified to accommodate spectral features. A single DUSTY run can process an unlimited number of models, with each input set producing a run of optical depths, as specified. The user controls the detail level of the output, which can include both spectral and imaging properties as well as other quantities of interest.","topic_id":"20400","bibcode":"1999ascl.soft11001I","views":"37","site_list":["http:\/\/www.pa.uky.edu\/~moshe\/dusty\/"],"ref_list":false},
		{"ascl_id":"9911.002","title":"IRAF: Image Reduction and Analysis Facility","credit":"National Optical Astronomy Observatories","abstract":"IRAF includes a broad selection of programs for general image processing and graphics, plus a large number of programs for the reduction and analysis of optical and IR astronomy data. Other external or layered packages are available for applications such as data acquisition or handling data from other observatories and wavelength regimes such as the Hubble Space Telescope (optical), EUVE (extreme ultra-violet), or ROSAT and AXAF (X-ray). These external packages are distributed separately from the main IRAF distribution but can be easily installed. The IRAF system also includes a complete programming environment for scientific applications, which includes a programmable Command Language scripting facility, the IMFORT Fortran\/C programming interface, and the full SPP\/VOS programming environment in which the portable IRAF system and all applications are written.","topic_id":"20394","bibcode":"1999ascl.soft11002N","views":"85","site_list":["http:\/\/iraf.noao.edu\/"],"ref_list":false},
		{"ascl_id":"9911.003","title":"AIPS: Astronomical Image Processing System","credit":"Associated Universities, Inc.","abstract":"AIPS (\"Classic\") is a software package for interactive and batch calibration and editing of astronomical data, typically radio interferometric data. AIPS can be used for the calibration, construction, enhancement, display, and analysis of astronomical images made from data using Fourier synthesis methods. Design and development of the package begin in 1978. AIPS presently consists of over 1,000,000 lines of code and 400,000 lines of documentation, representing over 65 person-years of effort.","topic_id":"20413","bibcode":"1999ascl.soft11003A","views":"201","site_list":["http:\/\/www.aips.nrao.edu\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001astro.ph..6427C"]},
		{"ascl_id":"9911.004","title":"CHIANTI: A database for astrophysical emission line spectroscopy","credit":"Del-Zanna, Giulio; Young, Peter; Dere, Ken; Landini, Massimo; Landi, Enrico; Mason, Helen","abstract":"CHIANTI consists of a critically evaluated set of atomic data necessary to calculate the emission line spectrum of astrophysical plasmas. The data consists of atomic energy levels, atomic radiative data such as wavelengths, weighted oscillator strengths and A values, and electron collisional excitation rates. A set of programs that use these data to calculate the spectrum in a desired wavelength range as a function of temperature and density are also provided. These programs have been written in Interactive Data Language (IDL) and the below linked html document provides a description of these various programs.","topic_id":"20408","bibcode":"1999ascl.soft11004D","views":"60","site_list":["http:\/\/www.chiantidatabase.org\/chianti.html"],"ref_list":false},
		{"ascl_id":"9912.001","title":"SPH_1D: Hierarchical gravity\/SPH treecode for simulations of interacting galaxies","credit":"Olson, Kevin M.; Dorband, John E.","abstract":"We describe a fast tree algorithm for gravitational N-body simulation on SIMD parallel computers. The tree construction uses fast, parallel sorts. The sorted lists are recursively divided along their x, y and z coordinates. This data structure is a completely balanced tree (i.e., each particle is paired with exactly one other particle) and maintains good spatial locality. An implementation of this tree-building algorithm on a 16k processor Maspar MP-1 performs well and constitutes only a small fraction (approximately 15%) of the entire cycle of finding the accelerations. Each node in the tree is treated as a monopole. The tree search and the summation of accelerations also perform well. During the tree search, node data that is needed from another processor is simply fetched. Roughly 55% of the tree search time is spent in communications between processors. We apply the code to two problems of astrophysical interest. The first is a simulation of the close passage of two gravitationally, interacting, disk galaxies using 65,636 particles. We also simulate the formation of structure in an expanding, model universe using 1,048,576 particles. Our code attains speeds comparable to one head of a Cray Y-MP, so single instruction, multiple data (SIMD) type computers can be used for these simulations. The cost\/performance ratio for SIMD machines like the Maspar MP-1 make them an extremely attractive alternative to either vector processors or large multiple instruction, multiple data (MIMD) type parallel computers. With further optimizations (e.g., more careful load balancing), speeds in excess of today's vector processing computers should be possible.","topic_id":"21815","bibcode":"1999ascl.soft12001O","views":"39","site_list":["http:\/\/www.wesman.net\/~wesley\/ucb\/cs184\/second\/README"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1994ApJS...94..117"]},
		{"ascl_id":"9912.002","title":"FTOOLS: A general package of software to manipulate FITS files","credit":"Blackburn, J. K.; Shaw, R. A.; Payne, H. E.; Hayes, J. J. E.; Heasarc","abstract":"FTOOLS, a highly modular collection of utilities for processing and analyzing data in the FITS (Flexible Image Transport System) format, has been developed in support of the HEASARC (High Energy Astrophysics Research Archive Center) at NASA's Goddard Space Flight Center. The FTOOLS package contains many utility programs which perform modular tasks on any FITS image or table, as well as higher-level analysis programs designed specifically for data from current and past high energy astrophysics missions. The utility programs for FITS tables are especially rich and powerful, and provide functions for presentation of file contents, extraction of specific rows or columns, appending or merging tables, binning values in a column or selecting subsets of rows based on a boolean expression. Individual FTOOLS programs can easily be chained together in scripts to achieve more complex operations such as the generation and displaying of spectra or light curves. FTOOLS  development began in 1991 and has produced the main set of data analysis software for the current ASCA and RXTE space missions and for other archival sets of X-ray and gamma-ray data. The FTOOLS software package is supported on most UNIX platforms and on Windows 98\/NT machines. The user interface is controlled by standard parameter files that are very similar to those used by IRAF. The package is self documenting through a stand alone help task called fhelp. Software is written in ANSI C and FORTRAN to provide portability across most computer systems. The data format dependencies between hardware platforms are isolated through the FITSIO  library package.","topic_id":"20398","bibcode":"1999ascl.soft12002B","views":"89","site_list":["http:\/\/heasarc.gsfc.nasa.gov\/docs\/software\/ftools\/ftools_menu.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008A%26A...492..511K"]},
		{"ascl_id":"9912.003","title":"RVSAO 2.0: Digital Redshifts and Radial Velocities","credit":"Kurtz, Michael J.; Mink, Douglas J.","abstract":"RVSAO is a set of programs to obtain redshifts and radial velocities from digital spectra. RVSAO operates in the IRAF (Tody 1986, 1993) environment. The heart of the system is xcsao, which implements the cross-correlation method, and is a direct descendant of the system built by Tonry and Davis (1979). emsao uses intelligent heuristics to search for emission lines in spectra, then fits them to obtain a redshift. sumspec shifts and sums spectra to build templates for cross-correlation. linespec builds synthetic spectra given a list of spectral lines. bcvcorr corrects velocities for the motion of the earth. We discuss in detail the parameters necessary to run xcsao and emsao properly. We discuss the reliability and error associated with xcsao derived redshifts. We develop an internal error estimator, and we show how large, stable surveys can be used to develop more accurate error estimators. We develop a new methodology for building spectral templates for galaxy redshifts. We show how to obtain correlation velocities using emission line templates. Emission line correlations are substantially more efficient than the previous standard technique, automated emission line fitting. We compare the use of RVSAO with new methods, which use Singular Value Decomposition and $chi^2$ fitting techniques.","topic_id":"21816","bibcode":"1999ascl.soft12003K","views":"53","site_list":["http:\/\/tdc-www.harvard.edu\/iraf\/rvsao\/rvsao.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1998PASP..110..934K"]},
		{"ascl_id":"0003.001","title":"GADGET-2: A Code for Cosmological Simulations of Structure Formation","credit":"Springel, Volker","abstract":"The cosmological simulation code GADGET-2, a new massively parallel TreeSPH code, is capable of following a collisionless fluid with the N-body method, and an ideal gas by means of smoothed particle hydrodynamics (SPH). The implementation of SPH manifestly conserves energy and entropy in regions free of dissipation, while allowing for fully adaptive smoothing lengths. Gravitational forces are computed with a hierarchical multipole expansion, which can optionally be applied in the form of a TreePM algorithm, where only short-range forces are computed with the `tree'-method while long-range forces are determined with Fourier techniques. Time integration is based on a quasi-symplectic scheme where long-range and short-range forces can be integrated with different timesteps. Individual and adaptive short-range timesteps may also be employed. The domain decomposition used in the parallelisation algorithm is based on a space-filling curve, resulting in high flexibility and tree force errors that do not depend on the way the domains are cut. The code is efficient in terms of memory consumption and required communication bandwidth. It has been used to compute the first cosmological N-body simulation with more than 10^10 dark matter particles, reaching a homogeneous spatial dynamic range of 10^5 per dimension in a 3D box. It has also been used to carry out very large cosmological SPH simulations that account for radiative cooling and star formation, reaching total particle numbers of more than 250 million. GADGET-2 is publicly released to the research community.","topic_id":"21802","bibcode":"2000ascl.soft03001S","views":"96","site_list":["http:\/\/www.mpa-garching.mpg.de\/gadget\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005MNRAS.364.1105S"]},
		{"ascl_id":"0003.002","title":"SAOImage DS9: A utility for displaying astronomical images in the X11 window environment","credit":"Smithsonian Astrophysical Observatory","abstract":"SAOImage DS9 is an astronomical imaging and data visualization application. DS9 supports FITS images and binary tables, multiple frame buffers, region manipulation, and many scale algorithms and colormaps. It provides for easy communication with external analysis tasks and is highly configurable and extensible via XPA and SAMP. DS9 is a stand-alone application. It requires no installation or support files. Versions of DS9 currently exist for Solaris, Linux, MacOSX, and Windows. All versions and platforms support a consistent set of GUI and functional capabilities. DS9 supports advanced features such as multiple frame buffers, mosaic images, tiling, blinking, geometric markers, colormap manipulation, scaling, arbitrary zoom, rotation, pan, and a variety of coordinate systems. DS9 also supports FTP and HTTP access. The GUI for DS9 is user configurable. GUI elements such as the coordinate display, panner, magnifier, horizontal and vertical graphs, button bar, and colorbar can be configured via menus or the command line. DS9 is a Tk\/Tcl application which utilizes the SAOTk widget set. It also incorporates the X Public Access (XPA) mechanism to allow external processes to access and control its data, GUI functions, and algorithms.","topic_id":"20385","bibcode":"2000ascl.soft03002S","views":"45","site_list":["http:\/\/hea-www.harvard.edu\/RD\/ds9\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003ASPC..295..489J"]},
		{"ascl_id":"0008.001","title":"DDSCAT: The discrete dipole approximation for scattering and absorption of light by irregular particles","credit":"Draine, Bruce T.; Flatau, Piotr J.","abstract":"DDSCAT is a freely available software package which applies the \"discrete dipole approximation\" (DDA) to calculate scattering and absorption of electromagnetic waves by targets with arbitrary geometries and complex refractive index. The DDA approximates the target by an array of polarizable points. DDSCAT.5a requires that these polarizable points be located on a cubic lattice. DDSCAT allows accurate calculations of electromagnetic scattering from targets with \"size parameters\" 2 pi a\/lambda &lt; 15 provided the refractive index m is not large compared to unity (|m-1| &lt; 1). The DDSCAT package is written in Fortran and is highly portable. The program supports calculations for a variety of target geometries (e.g., ellipsoids, regular tetrahedra, rectangular solids, finite cylinders, hexagonal prisms, etc.). Target materials may be both inhomogeneous and anisotropic. It is straightforward for the user to import arbitrary target geometries into the code, and relatively straightforward to add new target generation capability to the package. DDSCAT automatically calculates total cross sections for absorption and scattering and selected elements of the Mueller scattering intensity matrix for specified orientation of the target relative to the incident wave, and for specified scattering directions. This User Guide explains how to use DDSCAT to carry out EM scattering calculations. CPU and memory requirements are described.","topic_id":"20401","bibcode":"2000ascl.soft08001D","views":"55","site_list":["http:\/\/www.astro.princeton.edu\/~draine\/DDSCAT.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008JOSAA..25.2693D"]},
		{"ascl_id":"0008.002","title":"RATRAN: Radiative Transfer and Molecular Excitation in One and Two Dimensions","credit":"Hogerheijde, Michiel; van der Tak, Floris","abstract":"RATRAN is a numerical method and computer code to calculate the radiative transfer and excitation of molecular lines. The approach is based on the Monte Carlo method, and incorporates elements from Accelerated Lambda Iteration. It combines the flexibility of the former with the speed and accuracy of the latter. Convergence problems known to plague Monte Carlo methods at large optical depth (>100) are avoided by separating local contributions to the radiation field from the overall transfer problem. The random nature of the Monte Carlo method serves to verify the independence of the solution to the angular, spatial, and frequency sampling of the radiation field. This allows the method to be used in a wide variety of astrophysical problems without specific adaptations. Moreover, the code can be applied to all atoms or molecules for which collisional rate coefficients are available and any axially symmetric source model. Continuum emission and absorption by dust is explicitly taken into account but scattering is neglected. We expect this program to be an important tool in analyzing data from present and future infrared and (sub-)millimeter telescopes.","topic_id":"21819","bibcode":"2000ascl.soft08002H","views":"71","site_list":["http:\/\/www.sron.rug.nl\/~vdtak\/ratran\/frames.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007astro.ph..2385V"]},
		{"ascl_id":"0011.001","title":"StarFinder: A code for stellar field analysis","credit":"Diolaiti, Emiliano; Bendinelli, Orazio; Bonaccini, Domenico; Close, Laird M.; Currie, Doug G.; Parmeggiani, Gianluigi","abstract":"StarFinder is an IDL code for the deep analysis of stellar fields, designed for Adaptive Optics well-sampled images with high and low Strehl ratio. The Point Spread Function is extracted directly from the frame, to take into account the actual structure of the instrumental response and the atmospheric effects. The code is written in IDL language and organized in the form of a self-contained widget-based application, provided with a series of tools for data visualization and analysis. A description of the method and some applications to Adaptive Optics data are presented.","topic_id":"20382","bibcode":"2000ascl.soft11001D","views":"45","site_list":["http:\/\/cfao.ucolick.org\/software\/starfinder.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000ASPC..216..623D"]},
		{"ascl_id":"0101.001","title":"MILLISEARCH: A Search for Millilensing in BATSE GRB Data","credit":"Nemiroff, Robert J.","abstract":"The millisearch.for code was used to generate a new search for the gravitational lens effects of a significant cosmological d ensity of supermassive compact objects (SCOs) on gamma-ray bursts. No signal attributable to millilensing was found. We inspected the timing data of 774 BATSE-triggered GRBs for evidence of millilensing: repeated peaks similar in light-curve shape and spectra. Our null detection leads us to conclude that, in all candidate universes simulated, Omega<sub>SCO<\/sub> &lt; 0.1 is favored for 10<sup>5<\/sup> &lt; M<sub>SCO<\/sub>\/M<sub>odot<\/sub> &lt; 10<sup>9<\/sup>, while in some universes and mass ranges the density limits are as much as 10 times lower. Therefore, a cosmologically significant population of SCOs near globular cluster mass neither came out of the primordial universe, nor condensed at recombination.","topic_id":"20391","bibcode":"2001ascl.soft01001N","views":"42","site_list":["http:\/\/asterisk.apod.com\/download\/file.php?id=3341"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001PhRvL..86..580N"]},
		{"ascl_id":"0104.001","title":"MLAPM: Simulating Structure Formation from Collisionless Matter","credit":"Knebe, Alexander; Green, Andrew; Binney, James","abstract":"We present a computer code written in C that is designed to simulate structure formation from collisionless matter. The code is purely grid-based and uses a recursively refined Cartesian grid to solve Poisson's equation for the potential, rather than obtaining the potential from a Green's function. Refinements can have arbitrary shapes and in practice closely follow the complex morphology of the density field that evolves. The timestep shortens by a factor two with each successive refinement. It is argued that an appropriate choice of softening length is of great importance and that the softening should be at all points an appropriate multiple of the local inter-particle separation. Unlike tree and P3M codes, multigrid codes automatically satisfy this requirement. We show that at early times and low densities in cosmological simulations, the softening needs to be significantly smaller relative to the inter-particle separation than in virialized regions. Tests of the ability of the code's Poisson solver to recover the gravitational fields of both virialized halos and Zel'dovich waves are presented, as are tests of the code's ability to reproduce analytic solutions for plane-wave evolution. The times required to conduct a LCDM cosmological simulation for various configurations are compared with the times required to complete the same simulation with the ART, AP3M and GADGET codes. The power spectra, halo mass functions and halo-halo correlation functions of simulations conducted with different codes are compared.","topic_id":"20390","bibcode":"2001ascl.soft04001K","views":"43","site_list":["http:\/\/popia.ft.uam.es\/MLAPM\/"],"ref_list":false},
		{"ascl_id":"0104.002","title":"CSENV: A code for the chemistry of CircumStellar ENVelopes","credit":"Mamon, Gary A.; Glassgold, Al","abstract":"CSENV is a code that computes the chemical abundances for a desired set of species as a function of radius in a stationary, non-clumpy, <span style=\"font-weight: bold\">C<\/span>ircum<span style=\"font-weight: bold\">S<\/span>tellar <span style=\"font-weight: bold\">ENV<\/span>elope.  The chemical species can be atoms, molecules, ions, radicals, molecular ions, and\/or their specific quantum states.  Collisional ionization or excitation can be incorporated through the proper chemical channels.  The chemical species interact with one another and can are subject to photo-processes (dissociation of molecules, radicals, and molecular ions as well as ionization of all species). Cosmic ray ionization can be included.  Chemical reaction rates are specified with possible activation temperatures and additional power-law dependences.  Photo-absorption cross-sections vs. wavelength, with appropriate thresholds, can be specified for each species, while for H2+ a photoabsorption cross-section is provided as a function of wavelength and temperature. The photons originate from both the star and the external interstellar medium.  The chemical species are shielded from the photons by circumstellar dust, by other species and by themselves (self-shielding).  Shielding of continuum-absorbing species by these species (self and mutual shielding), line-absorbing species, and dust varies with radial optical depth.  The envelope is spherical by default, but can be made bipolar with an opening solid-angle that varies with radius. In the non-spherical case, no provision is made for photons penetrating the envelope from the sides.  The envelope is subject to a radial outflow (or wind), constant velocity by default, but the wind velocity can be made to vary with radius.  The temperature of the envelope is specified (and thus not computed self-consistently).","topic_id":"20402","bibcode":"2001ascl.soft04002M","views":"41","site_list":["http:\/\/www2.iap.fr\/users\/gam\/software.html"],"ref_list":false},
		{"ascl_id":"0202.001","title":"PopRatio: A program to calculate atomic level populations in astrophysical plasmas","credit":"Silva, A. I.; Viegas, S. M.","abstract":"PopRatio is a Fortran 90 code to calculate atomic level populations in astrophysical plasmas. The program solves the equations of statistical equilibrium considering all possible bound-bound processes: spontaneous, collisional or radiation induced (the later either directly or by fluorescence). There is no limit on the number of levels or in the number of processes that may be taken into account. The program may find a wide range of applicability in astronomical problems, such as interpreting fine-structure absorption lines or collisionally excited emission lines and also in calculating the cooling rates due to collisional excitation.","topic_id":"20387","bibcode":"2002ascl.soft02001S","views":"54","site_list":["http:\/\/nedwww.ipac.caltech.edu\/level5\/Silva\/TOC.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001CoPhC.136..319S"]},
		{"ascl_id":"1004.001","title":"GIM2D: Galaxy IMage 2D","credit":"Simard, Luc","abstract":"GIM2D (Galaxy IMage 2D) is an IRAF\/SPP package written to perform detailed bulge\/disk decompositions of low signal-to-noise images of distant galaxies in a fully automated way. GIM2D takes an input image from HST or ground-based telescopes and outputs a galaxy-subtracted image as well as a catalog of structural parameters.","topic_id":"23409","bibcode":"2010ascl.soft04001S","views":"52","site_list":["https:\/\/www.astrosci.ca\/users\/GIM2D\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005ApJS..157..175K","http:\/\/adsabs.harvard.edu\/abs\/2007ApJ...662..909K"]},
		{"ascl_id":"1007.001","title":"PINTofALE: Package for Interactive Analysis of Line Emission","credit":"Drake, Jeremy J.; Kashyap, Vinay L.","abstract":"PINTofALE was originally developed to analyze spectroscopic data from optically-thin coronal plasmas, though much of the software is sufficiently general to be of use in a much wider range of astrophysical data analyses. It is based on a modular set of IDL tools that interact with an atomic database and with observational data. The tools are designed to allow easy identification of spectral features, measure line fluxes, and carry out detailed modeling. The basic philosophy of the package is to provide access to the innards of atomic line databases, and to have flexible tools to interactively compare with the observed data. It is motivated by the large amount of book-keeping, computation and iterative interaction that is required between the researcher and observational and theoretical data in order to derive astrophysical results. The tools link together transparently and automatically the processes of spectral \"browsing\", feature identification, measurement, and computation and derivation of results. Unlike standard modeling and fitting engines currently in use, PINTofALE opens up the \"black box\" of atomic data required for UV\/X-ray analyses and allows the user full control over the data that are used in any given analysis.","topic_id":"20389","bibcode":"2010ascl.soft07001D","views":"94","site_list":["http:\/\/hea-www.harvard.edu\/PINTofALE\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004AAS...204.7311K"]},
		{"ascl_id":"1007.002","title":"INFALL: A code for calculating the mean initial and final density profiles around a virialized dark matter halo","credit":"Barkana, Rennan","abstract":"Infall is a code for calculating the mean initial and final density profiles around a virialized dark matter halo. The initial profile is derived from the statistics of the initial Gaussian random field, accounting for the problem of peaks within peaks using the extended Press-Schechter model. Spherical collapse then yields the typical density and velocity profiles of the gas and dark matter that surrounds the final, virialized halo. In additional to the mean profile, \u00b11-\u03c3 profiles are calculated and can be used as an estimate of the scatter.","topic_id":"20395","bibcode":"2010ascl.soft07002B","views":"45","site_list":["http:\/\/wise-obs.tau.ac.il\/~barkana\/codes.html"],"ref_list":false},
		{"ascl_id":"1007.003","title":"GEMINI: A toolkit for analytical models of two-point correlations and inhomogeneous structure formation","credit":"Scannapieco, Evan; Barkana, Rennan","abstract":"Gemini is a toolkit for analytical models of two-point correlations and inhomogeneous structure formation. It extends standard Press-Schechter theory to inhomogeneous situations, allowing a realistic, analytical calculation of halo correlations and bias.","topic_id":"20397","bibcode":"2010ascl.soft07003S","views":"50","site_list":["http:\/\/wise-obs.tau.ac.il\/~barkana\/codes.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002ApJ...571..585S"]},
		{"ascl_id":"1007.004","title":"CMBEASY: An object-oriented code for the cosmic microwave background","credit":"Doran, Michael; Seljak, Uros; Zaldarriaga, Matias","abstract":"CMBEASY is a software package for calculating the evolution of density fluctuations in the universe. Most notably, the Cosmic Microwave Background temperature anisotropies. It features a Markov Chain Monte Carlo driver and many routines to compute likelihoods of any given model. It is based on the <a href=\"http:\/\/ascl.net\/9909.004\">CMBFAST<\/a> package by Uros Seljak and Matias Zaldarriaga.","topic_id":"20406","bibcode":"2010ascl.soft07004D","views":"81","site_list":["http:\/\/www.thphys.uni-heidelberg.de\/~robbers\/cmbeasy\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005JCAP...10..011D","http:\/\/adsabs.harvard.edu\/abs\/2004JCAP...09..003D"]},
		{"ascl_id":"1007.005","title":"Arcetri Spectral Code for Thin Plasmas","credit":"Landi, E.; Landini, M.","abstract":"The Arcetri spectral code allows to evaluate the spectrum of the radiation emitted by hot and optically thin plasmas in the spectral range 1 - 2000 Angstroms. The database has been updated including atomic data and radiative and collisional rates to calculate level population and line emissivities for a number of ions of the minor elements; a critical compilation of the electron collision excitation for these elements has been performed. The present version of the program includes the CHIANTI database for the most abundant elements, the minor elements data, and Fe III atomic model, radiative and collisional data.","topic_id":"20410","bibcode":"2010ascl.soft07005L","views":"92","site_list":["http:\/\/www.arcetri.astro.it\/science\/spettro\/spettro.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1998A%26AS..133..411L"]},
		{"ascl_id":"1007.006","title":"AMIGA: Adaptive Mesh Investigations of Galaxy Assembly","credit":"Knebe, Alexander; Doumler, Timur","abstract":"AMIGA is a publicly available adaptive mesh refinement code for (dissipationless) cosmological simulations. It combines an N-body code with an Eulerian grid-based solver for the full set of magnetohydrodynamics (MHD) equations in order to conduct simulations of dark matter, baryons and magnetic fields in a self-consistent way in a fully cosmological setting. Our numerical scheme includes effective methods to ensure proper capturing of shocks and highly supersonic flows and a divergence-free magnetic field. The high accuracy of the code is demonstrated by a number of numerical tests.","topic_id":"20412","bibcode":"2010ascl.soft07006K","views":"97","site_list":["http:\/\/popia.ft.uam.es\/AMIGA\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010MNRAS.403..453D"]},
		{"ascl_id":"1010.001","title":"CFITSIO: A FITS File Subroutine Library","credit":"Pence, William D.","abstract":"CFITSIO is a library of C and Fortran subroutines for reading and writing data files in FITS (Flexible Image Transport System) data format. CFITSIO provides simple high-level routines for reading and writing FITS files that insulate the programmer from the internal complexities of the FITS format. CFITSIO also provides many advanced features for manipulating and filtering the information in FITS files.","topic_id":"21363","bibcode":"2010ascl.soft10001P","views":"146","site_list":["http:\/\/heasarc.gsfc.nasa.gov\/fitsio\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1999ASPC..172..487P"]},
		{"ascl_id":"1010.002","title":"fpack: FITS Image Compression Program","credit":"Seaman, Rob; Pence, William; White, Rick","abstract":"fpack is a utility program for optimally compressing images in the FITS data format. The associated funpack program will restore the compressed file back to its original state. These programs may be run from the host operating system command line and are analogous to the gzip and gunzip utility programs, except that they are specifically optimized for FITS format images and offer a wider choice of compression options.\r\n\r\nfpack uses the tiled image compression convention for storing the compressed images. This convention can in principle support any number of of different compression algorithms; currently GZIP, Rice, Hcompress, and the IRAF pixel list compression algorithms have been implemented.\r\n\r\nThe main advantages of fpack compared to the commonly used technique of externally compressing the whole FITS file with gzip are:\r\n\r\n<ol style=\"list-style-type: decimal\"><li>It is generally faster and offers better compression than gzip.<\/li><li>The FITS header keywords remain uncompressed for fast access.<\/li><li>Each HDU of a multi-extension FITS file is compressed separately, so it is not necessary to uncompress the entire file to read a single image in a multi-extension file.<\/li><li>Dividing the image into tiles before compression enables faster access to small subsections of the image.<\/li><li>The compressed image is itself a valid FITS file and can be manipulated by other general FITS utility software.<\/li><li>Lossy compression can be used for much higher compression in cases where it is not necessary to exactly preserve the original image.<\/li><li>The CHECKSUM keywords are automatically updated to help verify the integrity of the files.<\/li><li>Software that supports the tiled image compression technique can directly read and write the FITS images in their compressed form. <\/li><\/ol>","topic_id":"21365","bibcode":"2010ascl.soft10002S","views":"52","site_list":["http:\/\/heasarc.gsfc.nasa.gov\/fitsio\/fpack\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009PASP..121..414P"]},
		{"ascl_id":"1010.003","title":"AMBER: Data Reduction Software","credit":"Malbet, Fabien; Duvert, Gilles; Millour, Florentin; Le Bouquin, Jean-Baptiste; Mella, Guillaume; Halipr\u00e9, Luc; Chelli, Alain; Lafrasse, Sylvain; Altariba, Evelyne; Zins, G\u00e9rard","abstract":"AMBER data reduction software has an optional graphic interface in a high level language, allowing the user to control the data reduction step by step or in a completely automatic manner. The software has a robust calibration scheme that make use of the full calibration sets available during the night. The output products are standard OI-FITS files, which can be used directly in high level software like model fitting or image reconstruction tools.","topic_id":"21463","bibcode":"2010ascl.soft10003M","views":"90","site_list":["http:\/\/www.jmmc.fr\/data_processing_amber.htm"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010SPIE.7734E.138M"]},
		{"ascl_id":"1010.004","title":"Needatool: A Needlet Analysis Tool for Cosmological Data Processing","credit":"Pietrobon, Davide; Balbi, Amedeo; Cabella, Paolo; Gorski, Krzysztof M.","abstract":"NeedATool (Needlet Analysis Tool) performs data analysis based on needlets, a wavelet rendition powerful for the analysis of fields defined on a sphere. Needlets have been applied successfully to the treatment of astrophysical and cosmological observations, particularly to the analysis of cosmic microwave background (CMB) data. Wavelets have emerged as a useful tool for CMB data analysis, as they combine most of the advantages of both pixel space, where it is easier to deal with partial sky coverage and experimental noise, and the harmonic domain, in which beam treatment and comparison with theoretical predictions are more effective due in large part to their sharp localization.","topic_id":"21488","bibcode":"2010ascl.soft10004P","views":"45","site_list":["http:\/\/www.fisica.uniroma2.it\/~pietrobon\/dp_files\/dp_NeedATool_download.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010ApJ...723....1P"]},
		{"ascl_id":"1010.005","title":"Particle module of Piernik MHD code","credit":"Dr\u0105\u017ckowska, Joanna; Hanasz, Micha\u0142; Kowalik, Kacper","abstract":"Piernik is a multi-fluid grid magnetohydrodynamic (MHD) code based on the Relaxing Total Variation Diminishing (RTVD) conservative scheme. The original code has been extended by addition of dust described within the particle approximation. The dust is now described as a system of interacting particles. The particles can interact with gas, which is described as a fluid. The comparison between the test problem results and the results coming from fluid simulations made with Piernik code shows the most important differences between fluid and particle approximations used to describe dynamical evolution of dust under astrophysical conditions.","topic_id":"21492","bibcode":"2010ascl.soft10005D","views":"52","site_list":["http:\/\/piernik.astri.umk.pl\/"],"ref_list":["http:\/\/citeseerx.ist.psu.edu\/viewdoc\/summary?doi=10.1.1.52.4779"]},
		{"ascl_id":"1010.006","title":"DSPSR: Digital Signal Processing Software for Pulsar Astronomy","credit":"van Straten, W.; Bailes, M.","abstract":"DSPSR, written primarily in C++, is an open-source, object-oriented, digital signal processing software library and application suite for use in radio pulsar astronomy. The library implements an extensive range of modular algorithms for use in coherent dedispersion, filterbank formation, pulse folding, and other tasks. The software is installed and compiled using the standard GNU configure and make system, and is able to read astronomical data in 18 different file formats, including FITS, S2, CPSR, CPSR2, PuMa, PuMa2, WAPP, ASP, and Mark5.","topic_id":"21494","bibcode":"2010ascl.soft10006V","views":"68","site_list":["http:\/\/dspsr.sourceforge.net\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011PASA...28....1V"]},
		{"ascl_id":"1010.007","title":"SPEAR: Stochastic Process Estimation for AGN Reverberations","credit":"Zu, Ying; Kochanek, C. S.; Peterson, Bradley. M.","abstract":"SPEAR is a new approach to reverberation mapping that computes the lags between the AGN continuum and emission line light curves and their statistical confidence limits. It uses a damped random walk model to describe the quasar continuum variability and the ansatz that emission line variability is a scaled, smoothed and displaced version of the continuum. While currently configured only to simultaneously fit light curve means, it includes a general linear parameters formalism to fit more complex trends or calibration offsets. The noise matrix can be modified to allow for correlated errors, and the correlation matrix can be modified to use a different stochastic process. The transfer function model is presently a tophat, but this can be altered by changing the line-continuum covariance matrices. It is also able to cope with some problems in traditional reverberation mapping, such as irregular sampling, correlated errors and seasonal gaps.","topic_id":"21495","bibcode":"2010ascl.soft10007Z","views":"80","site_list":["http:\/\/www.astronomy.ohio-state.edu\/~yingzu\/spear.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ApJ...735...80Z"]},
		{"ascl_id":"1010.008","title":"midIR_sensitivity: Mid-infrared astronomy with METIS","credit":"Kendrew, Sarah; Jolissaint, Laurent; Brandl, Bernhard; Lenzen, Rainer; Pantin, Eric; Glasse, Alistair; Blommaert, Joris; Venema, Lars; Siebenmorgen, Ralf; Molster, Frank","abstract":"midIR_sensitivity is idl code that calculates the sensitivity of a ground-based mid-infrared instrument for astronomy. The code was written for the Phase A study of the instrument METIS (http:\/\/www.strw.leidenuniv.nl\/metis), the Mid-Infrared E-ELT Imager and Spectrograph, for the 42-m European Extremely Large Telescope. The model uses a detailed set of input parameters for site characteristics and atmospheric profiles, optical design, and thermal background. The code and all input parameters are highly tailored for the particular design parameters of the E-ELT and METIS, however, the program is structured in such a way that the parameters can easily be adjusted for a different system, or alternative input files used.","topic_id":"21499","bibcode":"2010ascl.soft10008K","views":"62","site_list":["https:\/\/github.com\/skendrew\/midIR_sensitivity"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010SPIE.7735E.179K"]},
		{"ascl_id":"1407.002","title":"TWODSPEC: Long-slit and optical fiber array spectra extensions for FIGARO","credit":"Wilkins, T. N.; Axon, D. J.","abstract":"TWODSPEC offers programs for the reduction and analysis of long-slit and optical fiber array spectra, implemented as extensions to the FIGARO package (<a href=\"http:\/\/ascl.net\/1203.013\">ascl:1203.013<\/a>). The software are currently distributed as part of the Starlink software collection (<a href=\"http:\/\/ascl.net\/1110.012\">ascl:1110.012<\/a>). These programs are designed to do as much as possible for the user, to assist quick reduction and analysis of data; for example, LONGSLIT can fit multiple Gaussians to line profiles in batch and decides how many components to fit.","topic_id":"33359","bibcode":"2014ascl.soft07002W","views":"183","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1992MNRAS.259..629B","http:\/\/adsabs.harvard.edu\/abs\/1992ASPC...25..427W"]},
		{"ascl_id":"1010.009","title":"ModeCode: Bayesian Parameter Estimation for Inflation","credit":"Mortonson, Michael J.; Peiris, Hiranya V.; Easther, Richard","abstract":"ModeCode is a publicly available code that computes the primordial scalar and tensor power spectra for single field inflationary models. ModeCode solves the inflationary mode equations numerically, avoiding the slow roll approximation. It provides an efficient and robust numerical evaluation of the inflationary perturbation spectrum, and allows the free parameters in the inflationary potential to be estimated within an MCMC computation. ModeCode also allows the estimation of reheating uncertainties once a potential has been specified. It is interfaced with <a href=\"http:\/\/ascl.net\/1102.026\">CAMB<\/a> and <a href=\"http:\/\/ascl.net\/1106.025\">CosmoMC<\/a> to compute cosmic microwave background angular power spectra and perform likelihood analysis and parameter estimation. It can be run as a standalone code as well. Errors in the results from ModeCode contribute negligibly to the error budget for analyses of data from Planck or other next generation experiments.","topic_id":"21505","bibcode":"2010ascl.soft10009M","views":"51","site_list":["http:\/\/zuserver2.star.ucl.ac.uk\/~hiranya\/ModeCode\/ModeCode\/ModeCode.html"],"ref_list":false},
		{"ascl_id":"1010.010","title":"Fast WMAP Likelihood Code and GSR PC Functions","credit":"Dvorkin, Cora; Hu, Wayne","abstract":"We place functional constraints on the shape of the inflaton potential from the cosmic microwave background through a variant of the generalized slow roll approximation that allows large amplitude, rapidly changing deviations from scale-free conditions. Employing a principal component decomposition of the source function G'~3(V'\/V)^2 - 2V''\/V and keeping only those measured to better than 10% results in 5 nearly independent Gaussian constraints that maybe used to test any single-field inflationary model where such deviations are expected. The first component implies &lt; 3% variations at the 100 Mpc scale. One component shows a 95% CL preference for deviations around the 300 Mpc scale at the ~10% level but the global significance is reduced considering the 5 components examined. This deviation also requires a change in the cold dark matter density which in a flat LCDM model is disfavored by current supernova and Hubble constant data and can be tested with future polarization or high multipole temperature data. Its impact resembles a local running of the tilt from multipoles 30-800 but is only marginally consistent with a constant running beyond this range. For this analysis, we have implemented a ~40x faster WMAP7 likelihood method which we have made publicly available.","topic_id":"21506","bibcode":"2010ascl.soft10010D","views":"55","site_list":["http:\/\/background.uchicago.edu\/wmap_fast\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010PhRvD..82d3513D"]},
		{"ascl_id":"1010.011","title":"PSpectRe: A Pseudo-Spectral Code for (P)reheating","credit":"Easther, Richard; Finkel, Hal; Roth, Nathaniel","abstract":"PSpectRe, written in C++, uses Fourier-space pseudo-spectral methods to evolve interacting scalar fields in an expanding universe. The code is optimized for the analysis of parametric resonance in the post-inflationary universe and provides an alternative to finite differencing codes. PSpectRe has both second- (Velocity-Verlet) and fourth-order (Runge-Kutta) time integrators. In some circumstances PSpectRe obtains reliable results while using substantially fewer points than a finite differencing code by computing the post-resonance equation of state. PSpectRe is designed to be easily extended to other problems in early-universe cosmology, including the generation of gravitational waves during phase transitions and pre-inflationary bubble collisions.","topic_id":"21507","bibcode":"2010ascl.soft10011E","views":"50","site_list":["http:\/\/easther.physics.yale.edu\/Richard_Easther\/Download_PSpectRe.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010JCAP...10..025E"]},
		{"ascl_id":"1010.012","title":"glafic: Software Package for Analyzing Gravitational Lensing","credit":"Oguri, Masamune","abstract":"<span style=\"font-style: italic\">glafic<\/span> is a public software package for analyzing gravitational lensing. It offers many features including computations of various lens properties for many mass models, solving the lens equation using an adaptive grid algorithm, simulations of lensed extended images with PSF convolved, and efficient modeling of observed strong lens systems.","topic_id":"21511","bibcode":"2010ascl.soft10012O","views":"56","site_list":["http:\/\/www.slac.stanford.edu\/~oguri\/glafic\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010PASJ...62.1017"]},
		{"ascl_id":"1010.013","title":"AstroGK: Astrophysical Gyrokinetics Code","credit":"Numata, Ryusuke; Howes, Gregory G.; Tatsuno, Tomoya; Barnes, Michael; Dorland, William","abstract":"The gyrokinetic simulation code AstroGK is developed to study fundamental aspects of kinetic plasmas and for applications mainly to astrophysical problems. AstroGK is an Eulerian slab code that solves the electromagnetic Gyrokinetic-Maxwell equations in five-dimensional phase space, and is derived from the existing gyrokinetics code GS2 by removing magnetic geometry effects. Algorithms used in the code are described. The code is benchmarked using linear and nonlinear problems. Serial and parallel performance scalings are also presented.","topic_id":"21514","bibcode":"2010ascl.soft10013N","views":"92","site_list":["http:\/\/www.physics.uiowa.edu\/~ghowes\/astrogk\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010JCoPh.229.9347N"]},
		{"ascl_id":"1010.014","title":"Athena: Grid-based code for astrophysical magnetohydrodynamics (MHD)","credit":"Stone, James M.; Gardiner, Thomas A.; Teuben, Peter; Hawley, John F.; Simon, Jacob B.","abstract":"Athena is a grid-based code for astrophysical magnetohydrodynamics (MHD). It was developed primarily for studies of the interstellar medium, star formation, and accretion flows. The code has been designed to be easily extensible for use with static and adaptive mesh refinement. It combines higher-order Godunov methods with the constrained transport (CT) technique to enforce the divergence-free constraint on the magnetic field. Discretization is based on cell-centered volume-averages for mass, momentum, and energy, and face-centered area-averages for the magnetic field. Novel features of the algorithm include (1) a consistent framework for computing the time- and edge-averaged electric fields used by CT to evolve the magnetic field from the time- and area-averaged Godunov fluxes, (2) the extension to MHD of spatial reconstruction schemes that involve a dimensionally-split time advance, and (3) the extension to MHD of two different dimensionally-unsplit integration methods. Implementation of the algorithm in both C and Fortran95 is detailed, including strategies for parallelization using domain decomposition. Results from a test suite which includes problems in one-, two-, and three-dimensions for both hydrodynamics and MHD are given, not only to demonstrate the fidelity of the algorithms, but also to enable comparisons to other methods. The source code is freely available for download on the web.","topic_id":"21515","bibcode":"2010ascl.soft10014S","views":"126","site_list":["https:\/\/trac.princeton.edu\/Athena\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ApJS..178..137S"]},
		{"ascl_id":"1010.015","title":"Fyris Alpha: Computational Fluid Dynamics Code","credit":"Sutherland, Ralph S.","abstract":"Fyris Alpha is a high resolution, shock capturing, multi-phase, up-wind Godunov method hydrodynamics code that includes a variable equation of state and optional microphysics such as cooling, gravity and multiple tracer variables. The code has been designed and developed for use primarily in astrophysical applications, such as galactic and interstellar bubbles, hypersonic shocks, and a range of jet phenomena. Fyris Alpha boasts both higher performance and more detailed microphysics than its predecessors, with the aim of producing output that is closer to the observational domain, such as emission line fluxes, and eventually, detailed spectral synthesis. Fyris Alpha is approximately 75,000 lines of C code; it encapsulates the split sweep semi-lagrangian remap PPM method used by ppmlr (in turn developed from VH1, Blondin et al. 1998) but with an improved Riemann solver, which is derived from the exact solver of Gottlieb and Groth (1988), a significantly faster solution than previous solvers. It has a number of optimisations that have improved the speed so that additional calculations neeed for multi-phase simulations become practical.","topic_id":"21516","bibcode":"2010ascl.soft10015S","views":"48","site_list":["http:\/\/www.mso.anu.edu.au\/fyris"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010Ap%26SS.327..173S"]},
		{"ascl_id":"1010.016","title":"SpDust\/SpDust.2: Code to Calculate Spinning Dust Spectra","credit":"Ali-Haimoud, Yacine","abstract":"SpDust is an IDL program that evaluates the spinning dust emissivity for user-provided environmental conditions. A new version of the code became available in March, 2010.","topic_id":"21528","bibcode":"2010ascl.soft10016A","views":"44","site_list":["http:\/\/www.sns.ias.edu\/~yacine\/spdust\/spdust.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0812.2904","http:\/\/arxiv.org\/abs\/1003.4732"]},
		{"ascl_id":"1010.017","title":"AOFlagger: RFI Software","credit":"Offringa, A. R.","abstract":"The RFI software presented here can automatically flag data and can be used to analyze the data in a measurement. The purpose of flagging is to mark samples that are affected by interfering sources such as radio stations, airplanes, electrical fences or other transmitting interferers.\n\nThe tools in the package are meant for offline use. The software package contains a graphical interface (\"rfigui\") that can be used to visualize a measurement set and analyze mitigation techniques. It also contains a console flagger (\"rficonsole\") that can execute a script of mitigation functions without the overhead of a graphical environment. All tools were written in C++.\n\nThe software has been tested extensively on low radio frequencies (150 MHz or lower) produced by the WSRT and LOFAR telescopes. LOFAR is the Low Frequency Array that is built in and around the Netherlands. Higher frequencies should work as well. Some of the methods implemented are the SumThreshold, the VarThreshold and the singular value decomposition (SVD) method. Included also are several surface fitting algorithms.\n\nThe software is published under the GNU General Public License version 3.","topic_id":"21529","bibcode":"2010ascl.soft10017O","views":"104","site_list":["http:\/\/www.astro.rug.nl\/rfi-software\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010MNRAS.405..155"]},
		{"ascl_id":"1010.018","title":"Emu CMB: Power spectrum emulator","credit":"Schneider, Michael D.; Holm, Oskar; Knox, Lloyd","abstract":"Emu CMB is a fast emulator the CMB temperature power spectrum based on <a href=\"http:\/\/ascl.net\/1102.026\">CAMB<\/a> (Jan 2010 version). Emu CMB is based on a \"space-filling\" Orthogonal Array Latin Hypercube design in a de-correlated parameter space obtained by using a fiducial WMAP5 CMB Fisher matrix as a rotation matrix.  This design strategy allows for accurate interpolation with small numbers of simulation design points.  The emulator presented here is calibrated with 100 CAMB runs that are interpolated over the design space using a global quadratic polynomial fit.","topic_id":"21533","bibcode":"2010ascl.soft10018S","views":"48","site_list":["http:\/\/www.emucmb.info\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1002.1752"]},
		{"ascl_id":"1010.019","title":"NBSymple: A Double Parallel, Symplectic N-body Code Running on Graphic Processing Units","credit":"Capuzzo-Dolcetta, R.; Mastrobuono-Battisti, A.","abstract":"NBSymple is a numerical code which numerically integrates the equation of motions of N 'particles' interacting via Newtonian gravitation and move in an external galactic smooth field. The force evaluation on every particle is done by mean of direct summation of the contribution of all the other system's particle, avoiding truncation error. The time integration is done with second-order and sixth-order symplectic schemes. NBSymple has been parallelized twice, by mean of the Computer Unified Device Architecture to make the all-pair force evaluation as fast as possible on high-performance Graphic Processing Units NVIDIA TESLA C 1060, while the O(N) computations are distributed on various CPUs by mean of OpenMP Application Program. The code works both in single precision floating point arithmetics or in double precision. The use of single precision allows the use at best of the GPU performances but, of course, limits the precision of simulation in some critical situations. We find a good compromise in using a software reconstruction of double precision for those variables that are most critical for the overall precision of the code.","topic_id":"21534","bibcode":"2010ascl.soft10019C","views":"48","site_list":["http:\/\/astrowww.phys.uniroma1.it\/dolcetta\/nbsymple.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011NewA...16..284C"]},
		{"ascl_id":"1010.020","title":"Libpsht: Algorithms for Efficient Spherical Harmonic Transforms","credit":"Reinecke, Martin","abstract":"Libpsht (or \"library for Performant Spherical Harmonic Transforms\") is a collection of algorithms for efficient conversion between spatial-domain and spectral-domain representations of data defined on the sphere. The package supports transforms of scalars as well as spin-1 and spin-2 quantities, and can be used for a wide range of pixelisations (including HEALPix, GLESP and ECP). It will take advantage of hardware features like multiple processor cores and floating-point vector operations, if available. Even without this additional acceleration, the employed algorithms are among the most efficient (in terms of CPU time as well as memory consumption) currently being used in the astronomical community. \r\n\r\nThe library is written in strictly standard-conforming C90, ensuring portability to many different hard- and software platforms, and allowing straightforward integration with codes written in various programming languages like C, C++, Fortran, Python etc. \r\n\r\nLibpsht is distributed under the terms of the GNU General Public License (GPL) version 2.","topic_id":"21537","bibcode":"2010ascl.soft10020R","views":"60","site_list":["http:\/\/sourceforge.net\/projects\/libpsht\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011A%26A...526A.108R"]},
		{"ascl_id":"1010.021","title":"velfit: A Code for Modeling Non-Circular Flows in Disk Galaxies","credit":"Spekkens, K. J.; Sellwood, J. A.","abstract":"High-quality velocity maps of galaxies frequently exhibit signatures of non-circular streaming motions. <span style=\"font-style: italic\">velfit<\/span> yields results that are more easily interpreted than the commonly used procedure. It can estimate the magnitudes of forced non-circular motions over a broad range of bar strengths from a strongly barred galaxy, through cases of mild bar-like distortions to placing bounds on the shapes of halos in galaxies having extended rotation curves.","topic_id":"21552","bibcode":"2010ascl.soft10021S","views":"56","site_list":["http:\/\/www.physics.rutgers.edu\/~spekkens\/velfit\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007ApJ...664..204S","http:\/\/xxx.lanl.gov\/abs\/0912.5493"]},
		{"ascl_id":"1010.022","title":"GR1D: Open-Source Code for Spherically-Symmetric Stellar Collapse to Neutron Stars and Black Holes","credit":"O'Connor, Evan; Ott, Christian D.","abstract":"GR1D is based on the Eulerian formulation of GR hydrodynamics (GRHD) put forth by Romero-Ibanez-Gourgoulhon and employs radial-gauge, polar-slicing coordinates in which the 3+1 equations simplify substantially. GR1D is intended for the simulation of stellar collapse to neutron stars and black holes and will also serve as a testbed for modeling technology to be incorporated in multi-D GR codes. Its GRHD part is coupled to various finite-temperature microphysical equations of state in tabulated form that we make available with GR1D.","topic_id":"21558","bibcode":"2010ascl.soft10022O","views":"52","site_list":["http:\/\/www.stellarcollapse.org\/codes.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010CQGra..27k4103O"]},
		{"ascl_id":"1010.023","title":"AstroSim: Collaborative Visualization of an Astrophysics Simulation in Second Life","credit":"Nakasone, Arturo; Prendinger, Helmut; Holland, Simon; Hut, Piet; Makino, Jun; Miura, Kenichi","abstract":"AstroSim is a Second Life based prototype application for synchronous collaborative visualization targeted at astronomers.","topic_id":"21559","bibcode":"2010ascl.soft10023N","views":"95","site_list":["http:\/\/sourceforge.net\/projects\/astrosim\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0911.5683"]},
		{"ascl_id":"1010.024","title":"ADAPTSMOOTH: A Code for the Adaptive Smoothing of Astronomical Images","credit":"Zibetti, Stefano","abstract":"ADAPTSMOOTH serves to smooth astronomical images in an adaptive fashion in order to enhance the signal-to-noise ratio (S\/N). The adaptive smoothing scheme allows taking full advantage of the spatially resolved photometric information contained in an image in that at any location the minimal smoothing is applied to reach the requested S\/N. Support is given to match more images on the same smoothing length, such that proper estimates of local colors can be done, with a big potential impact on multi-wavelength studies of extended sources (galaxies, nebulae). Different modes to estimate local S\/N are provided. In addition to classical arithmetic-mean averaging mode, the code can operate in median averaging mode, resulting in a significant enhancement of the final image quality and very accurate flux conservation.","topic_id":"21560","bibcode":"2010ascl.soft10024Z","views":"125","site_list":["http:\/\/www.arcetri.astro.it\/~zibetti\/Software\/ADAPTSMOOTH.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0911.4956"]},
		{"ascl_id":"1010.025","title":"SimFast21: Simulation of the Cosmological 21cm Signal","credit":"Santos, Mario; Ferramacho, Luis; Silva, Marta; Amblard, Alexandre; Cooray, Asantha","abstract":"SimFast 21 generates a simulation of the cosmological 21cm signal. While limited to low spatial resolution, the next generation low-frequency radio interferometers that target 21 cm observations during the era of reionization and prior will have instantaneous fields-of-view that are many tens of square degrees on the sky. Predictions related to various statistical measurements of the 21 cm brightness temperature must then be pursued with numerical simulations of reionization with correspondingly large volume box sizes, of order 1000 Mpc on one side. The authors pursued a semi-numerical scheme to simulate the 21 cm signal during and prior to Reionization by extending a hybrid approach where simulations are performed by first laying down the linear dark matter density field, accounting for the non-linear evolution of the density field based on second-order linear perturbation theory as specified by the Zel'dovich approximation, and then specifying the location and mass of collapsed dark matter halos using the excursion-set formalism. The location of ionizing sources and the time evolving distribution of ionization field is also specified using an excursion-set algorithm. They account for the brightness temperature evolution through the coupling between spin and gas temperature due to collisions, radiative coupling in the presence of Lyman-alpha photons and heating of the intergalactic medium, such as due to a background of X-ray photons. The method is capable of producing the required large volume simulations with adequate resolution in a reasonable time so a large number of realizations can be obtained with variations in assumptions related to astrophysics and background cosmology that govern the 21 cm signal.","topic_id":"21583","bibcode":"2010ascl.soft10025S","views":"62","site_list":["http:\/\/www.simfast21.org\/"],"ref_list":["http:\/\/www.simfast21.org\/"]},
		{"ascl_id":"1010.026","title":"SingLe: A F90-package devoted to Softened Gravity in gaseous discs","credit":"Hur\u00e9, Jean-Marc; Pierens, Arnaud","abstract":"<strong>S<\/strong><small>often<\/small><strong>ingLe<\/strong><small>ngth<\/small>: Because Newton's law of Gravitation diverges as the relative separations |r'-r| tends to zero, it is common to add a positive constant \u03bb also known as the \"softening length\", i.e. : \r\n\r\n<div style=\"text-align: center;\">|r'-r|\u00b2 \u2190 |r'-r|\u00b2 + \u03bb\u00b2.<\/div>\r\n\r\nSingLe determines the appropriate value of this Softening Length \u03bb for a given disc local structure (thickness 2h and vertical stratification \u03c1), in the axially symmetric, flat disc limit, preserving at best the Newtonian character of the gravitational potential and associated forces. Mass density \u03c1(z) is assumed to be locally expandable in the z-direction according to:\r\n\r\n<div style=\"text-align: center;\">\u03c1(z)= \u03c1<sub>0<\/sub>[1 + a<sub>1<\/sub>(z\/h)<sup>2<\/sup>+...+a<sub>q<\/sub> (z\/h)<sup>2q<\/sup>+...+a<sub>N<\/sub> (z\/h)<sup>2 N<\/sup>].<\/div>","topic_id":"21584","bibcode":"2010ascl.soft10026H","views":"138","site_list":["http:\/\/www.obs.u-bordeaux1.fr\/radio\/JMHure\/intro2single.php"],"ref_list":["http:\/\/arxiv.org\/abs\/0909.0369"]},
		{"ascl_id":"1010.027","title":"SNANA: A Public Software Package for Supernova Analysis","credit":"Kessler, Richard; Bernstein, Joseph P.; Cinabro, David; Dilday, Benjamin; Frieman, Joshua A.; Jha, Saurabh; Kuhlmann, Stephen; Miknaitis, Gajus; Sako, Masao; Taylor, Matt; VanderPlas, Jake","abstract":"SNANA is a general analysis package for supernova (SN) light curves that contains a simulation, light curve fitter, and cosmology fitter. The software is designed with the primary goal of using SNe Ia as distance indicators for the determination of cosmological parameters, but it can also be used to study efficiencies for analyses of SN rates, estimate contamination from non-Ia SNe, and optimize future surveys. Several SN models are available within the same software architecture, allowing technical features such as K-corrections to be consistently used among multiple models, and thus making it easier to make detailed comparisons between models. New and improved light-curve models can be easily added. The software works with arbitrary surveys and telescopes and has already been used by several collaborations, leading to more robust and easy-to-use code. This software is not intended as a final product release, but rather it is designed to undergo continual improvements from the community as more is learned about SNe.","topic_id":"21585","bibcode":"2010ascl.soft10027K","views":"57","site_list":["http:\/\/sdssdp62.fnal.gov\/sdsssn\/SNANA-PUBLIC\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009PASP..121.1028K"]},
		{"ascl_id":"1010.028","title":"GALPROP: Code for Cosmic-ray Transport and Diffuse Emission Production","credit":"Strong, A. W.; Moskalenko, I. V.; Porter, T. A.; J\u00f3hannesson, G.; Orlando, E.; Digel, S. W.","abstract":"GALPROP is a numerical code for calculating the propagation of relativistic charged particles and the diffuse emissions produced during their propagation. The GALPROP code incorporates as much realistic astrophysical input as possible together with latest theoretical developments. The code calculates the propagation of cosmic-ray nuclei, antiprotons, electrons and positrons, and computes diffuse \u03b3-rays and synchrotron emission in the same framework. Each run of the code is governed by a configuration file allowing the user to specify and control many details of the calculation. Thus, each run of the code corresponds to a potentially different \"model.\" The code continues to be developed and is available to the scientific community.","topic_id":"21586","bibcode":"2010ascl.soft10028S","views":"52","site_list":["http:\/\/galprop.stanford.edu\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1105.4921"]},
		{"ascl_id":"1010.029","title":"DNEST: Diffusive Nested Sampling","credit":"Brewer, Brendon J.; P\u00e1rtay, Livia B.; Cs\u00e1nyi, G\u00e1bor","abstract":"This code is a general Monte Carlo method based on Nested Sampling (NS) for sampling complex probability distributions and estimating the normalising constant. The method uses one or more particles, which explore a mixture of nested probability distributions, each successive distribution occupying ~e^-1 times the enclosed prior mass of the previous distribution. While NS technically requires independent generation of particles, Markov Chain Monte Carlo (MCMC) exploration fits naturally into this technique. This method can achieve four times the accuracy of classic MCMC-based Nested Sampling, for the same computational effort; equivalent to a factor of 16 speedup. An additional benefit is that more samples and a more accurate evidence value can be obtained simply by continuing the run for longer, as in standard MCMC.","topic_id":"21591","bibcode":"2010ascl.soft10029B","views":"54","site_list":["http:\/\/web.physics.ucsb.edu\/~brewer\/DNest\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0912.2380"]},
		{"ascl_id":"1010.030","title":"CosmicEmu: Cosmic Emulator for the Dark Matter Power Spectrum","credit":"Lawrence, Earl; Heitmann, Katrin; White, Martin; Higdon, David; Wagner, Christian; Habib, Salman; Williams, Brian","abstract":"Many of the most exciting questions in astrophysics and cosmology, including the majority of observational probes of dark energy, rely on an understanding of the nonlinear regime of structure formation. In order to fully exploit the information available from this regime and to extract cosmological constraints, accurate theoretical predictions are needed. Currently such predictions can only be obtained from costly, precision numerical simulations. The \"Coyote Universe'' simulation suite comprises nearly 1,000 N-body simulations at different force and mass resolutions, spanning 38 wCDM cosmologies. This large simulation suite enabled construct of a prediction scheme, or emulator, for the nonlinear matter power spectrum accurate at the percent level out to k~1 h\/Mpc. This is the first cosmic emulator for the dark matter power spectrum.","topic_id":"21609","bibcode":"2010ascl.soft10030L","views":"47","site_list":["http:\/\/www.lanl.gov\/projects\/cosmology\/CosmicEmu\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0912.4490"]},
		{"ascl_id":"1010.031","title":"DimReduce: Nonlinear Dimensionality Reduction of Very Large Datasets with Locally Linear Embedding (LLE) and its Variants","credit":"VanderPlas, J. T.; Connolly, A. J.","abstract":"DimReduce is a C++ package for performing nonlinear dimensionality reduction of very large datasets with Locally Linear Embedding (LLE) and its variants. DimReduce is built for speed, using the optimized linear algebra packages BLAS, LAPACK, and <a href=\"http:\/\/ascl.net\/1311.010\">ARPACK<\/a>. Because of the need for storing very large matrices (1000 by 10000, for our SDSS LLE work), DimReduce is designed to use binary FITS files as inputs and outputs. This means that using the code is a bit more cumbersome. For smaller-scale LLE, where speed of computation is not as much of an issue, the Modular Data Processing toolkit may be a better choice. It is a python toolkit with some LLE functionality, which VanderPlas contributed.","topic_id":"21610","bibcode":"2010ascl.soft10031V","views":"50","site_list":["http:\/\/ssg.astro.washington.edu\/research.shtml?research\/software"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009arXiv0907.2238V"]},
		{"ascl_id":"1010.032","title":"Extreme Deconvolution: Density Estimation using Gaussian Mixtures in the Presence of Noisy, Heterogeneous and Incomplete Data","credit":"Bovy, Jo; Hogg, David W.; Roweis, Sam T.","abstract":"Extreme-deconvolution is a general algorithm to infer a d-dimensional distribution function from a set of heterogeneous, noisy observations or samples. It is fast, flexible, and treats the data's individual uncertainties properly, to get the best description possible for the underlying distribution. It performs well over the full range of density estimation, from small data sets with only tens of samples per dimension, to large data sets with hundreds of thousands of data points.","topic_id":"21620","bibcode":"2010ascl.soft10032B","views":"54","site_list":["http:\/\/code.google.com\/p\/extreme-deconvolution\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1103.3067"]},
		{"ascl_id":"1010.033","title":"GALEV Evolutionary Synthesis Models","credit":"Kotulla, Ralf; Fritze, Uta; Weilbacher, Peter; Anders, Peter","abstract":"GALEV evolutionary synthesis models describe the evolution of stellar populations in general, of star clusters as well as of galaxies, both in terms of resolved stellar populations and of integrated light properties over cosmological timescales of &gt; 13 Gyr from the onset of star formation shortly after the Big Bang until today. \r\n\r\nFor galaxies, GALEV includes a simultaneous treatment of the chemical evolution of the gas and the spectral evolution of the stellar content, allowing for a chemically consistent treatment using input physics (stellar evolutionary tracks, stellar yields and model atmospheres) for a large range of metallicities and consistently account for the increasing initial abundances of successive stellar generations.","topic_id":"21621","bibcode":"2010ascl.soft10033K","views":"42","site_list":["http:\/\/www.galev.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0903.0378"]},
		{"ascl_id":"1010.034","title":"iCosmo: An Interactive Cosmology Package","credit":"Refregier, Alexandre; Amara, Adam; Kitching, Thomas; Rassat, Anais","abstract":"iCosmo is a software package to perform interactive cosmological calculations for the low redshift universe. The computation of distance measures, the matter power spectrum, and the growth factor is supported for any values of the cosmological parameters. It also performs the computation of observables for several cosmological probes such as weak gravitational lensing, baryon acoustic oscillations and supernovae. The associated errors for these observables can be derived for customised surveys, or for pre-set values corresponding to current or planned instruments. The code also allows for the calculation of cosmological forecasts with Fisher matrices which can be manipulated to combine different surveys and cosmological probes. The code is written in the IDL language and thus benefits from the convenient interactive features and scientific library available in this language. iCosmo can also be used as an engine to perform cosmological calculations in batch mode, and forms a convenient evolutive platform for the development of further cosmological modules. With its extensive documentation, it may also serve as a useful resource for teaching and for newcomers in the field of cosmology.","topic_id":"21632","bibcode":"2010ascl.soft10034R","views":"52","site_list":["http:\/\/icosmo.ethz.ch\/Initiative_Web\/Initiative.html","http:\/\/icosmo.pbworks.com\/"],"ref_list":false},
		{"ascl_id":"1010.035","title":"SLR: Stellar Locus Regression","credit":"High, F. W.; Stubbs, C. W.; Rest, A.; Stalder, B.; Challis, P.","abstract":"Stellar Locus Regression (SLR) is a simple way to calibrate colors at the 1-2% level, and magnitudes at the sub-5% level as limited by 2MASS, without the traditional use of standard stars. With SLR, stars in any field are \"standards.\" This is an entirely new way to calibrate photometry. SLR exploits the simple fact that most stars lie along a well defined line in color-color space called the stellar locus. Cross-match point-sources in flattened images taken through different passbands and plot up all color vs color combinations, and you will see the stellar locus with little effort. SLR calibrates colors by fitting these colors to a standard line. Cross-match with 2MASS on top of that, and SLR will deliver calibrated magnitudes as well.","topic_id":"21633","bibcode":"2010ascl.soft10035H","views":"44","site_list":["http:\/\/code.google.com\/p\/stellar-locus-regression\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009AJ....138..110H"]},
		{"ascl_id":"1010.036","title":"Montage: An Astronomical Image Mosaicking Toolkit","credit":"Jacob, Joseph C.; Katz, Daniel S.; Berriman, G. Bruce; Good, John; Laity, Anastasia C.; Deelman, Ewa; Kesselman, Carl; Singh, Gurmeet; Su, Mei-Hui; Prince, Thomas A.; Williams, Roy","abstract":"Montage is an open source code toolkit for assembling Flexible Image Transport System (FITS) images into custom mosaics. It runs on all common Linux\/Unix platforms, on desktops, clusters and computational grids, and supports all World Coordinate System (WCS) projections and common coordinate systems. Montage preserves spatial and calibration fidelity of input images, processes 40 million pixels in up to 32 minutes on 128 nodes on a Linux cluster, and provides independent engines for analyzing the geometry of images on the sky, re-projecting images, rectifying background emission to a common level, and co-adding images. It offers convenient tools for managing and manipulating large image files.","topic_id":"21509","bibcode":"2010ascl.soft10036J","views":"45","site_list":["http:\/\/montage.ipac.caltech.edu\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1005.4454"]},
		{"ascl_id":"1010.037","title":"FastChi: A Fast Chi-squared Technique For Period Search of Irregularly Sampled Data","credit":"Palmer, David M.","abstract":"The Fast Chi-Squared Algorithm is a fast, powerful technique for detecting periodicity. It was developed for analyzing variable stars, but is applicable to many of the other applications where the Fast Fourier Transforms (FFTs) or other periodograms (such as Lomb-Scargle) are currently used. The Fast Chi-squared technique takes a data set (e.g. the brightness of a star measured at many different times during a series of observations) and finds the periodic function that has the best frequency and shape (to an arbitrary number of harmonics) to fit the data. Among its advantages are:\r\n<ul><li>Statistical efficiency: all of the data are used, weighted by their individual error bars, giving a result with a significance calibrated in well-understood Chi-squared statistics. <\/li><li>Sensitivity to harmonic content: many conventional techniques look only at the significance (or the amplitude) of the fundamental sinusoid and discard the power of the higher harmonics. <\/li><li>Insensitivity to the sample timing: you won't find a period of 24 hours just because you take your observations at night. You do not need to window your data. <\/li><li>The frequency search is gridded more tightly than the traditional \"integer number of cycles over the span of observations\", eliminating power loss from peaks that fall between the grid points. <\/li><li>Computational speed: The complexity of the algorithm is O(NlogN), where N is the number of frequencies searched, due to its use of the FFT. <\/li><\/ul>","topic_id":"21673","bibcode":"2010ascl.soft10037P","views":"51","site_list":["http:\/\/public.lanl.gov\/palmer\/fastchi.html"],"ref_list":["http:\/\/lanl.arxiv.org\/abs\/0901.1913"]},
		{"ascl_id":"1010.038","title":"Low Resolution Spectral Templates For AGNs and Galaxies From 0.03 -- 30 microns","credit":"Assef, R. J.; Kochanek, C. S.; Brodwin, M.; Cool, R.; Forman, W.; Gonzalez, A. H.; Hickox, R. C.; Jones, C.; Le Floc'h, E.; Moustakas, J.; Murray, S. S.; Stern, D.","abstract":"We present a set of low resolution empirical SED templates for AGNs and galaxies in the wavelength range from 0.03 to 30 microns based on the multi-wavelength photometric observations of the NOAO Deep-Wide Field Survey Bootes field and the spectroscopic observations of the AGN and Galaxy Evolution Survey. Our training sample is comprised of 14448 galaxies in the redshift range 0&lt;~z&lt;~1 and 5347 likely AGNs in the range 0&lt;~z&lt;~5.58. We use our templates to determine photometric redshifts for galaxies and AGNs. While they are relatively accurate for galaxies, their accuracies for AGNs are a strong function of the luminosity ratio between the AGN and galaxy components. Somewhat surprisingly, the relative luminosities of the AGN and its host are well determined even when the photometric redshift is significantly in error. We also use our templates to study the mid-IR AGN selection criteria developed by Stern et al.(2005) and Lacy et al.(2004). We find that the Stern et al.(2005) criteria suffers from significant incompleteness when there is a strong host galaxy component and at z =~ 4.5, when the broad Halpha emission line is redshifted into the [3.6] band, but that it is little contaminated by low and intermediate redshift galaxies. The Lacy et al.(2004) criterion is not affected by incompleteness at z =~ 4.5 and is somewhat less affected by strong galaxy host components, but is heavily contaminated by low redshift star forming galaxies. Finally, we use our templates to predict the color-color distribution of sources in the upcoming WISE mission and define a color criterion to select AGNs analogous to those developed for IRAC photometry. We estimate that in between 640,000 and 1,700,000 AGNs will be identified by these criteria, but will have serious completeness problems for z &gt;~ 3.4.","topic_id":"21674","bibcode":"2010ascl.soft10038A","views":"50","site_list":["http:\/\/www.astronomy.ohio-state.edu\/~rjassef\/lrt\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1004.5415"]},
		{"ascl_id":"1010.039","title":"Parameter Estimation from Time-Series Data with Correlated Errors: A Wavelet-Based Method and its Application to Transit Light Curves","credit":"Carter, Joshua A.; Winn, Joshua N.","abstract":"We consider the problem of fitting a parametric model to time-series data that are afflicted by correlated noise. The noise is represented by a sum of two stationary Gaussian processes: one that is uncorrelated in time, and another that has a power spectral density varying as $1\/f^gamma$. We present an accurate and fast [O(N)] algorithm for parameter estimation based on computing the likelihood in a wavelet basis. The method is illustrated and tested using simulated time-series photometry of exoplanetary transits, with particular attention to estimating the midtransit time. We compare our method to two other methods that have been used in the literature, the time-averaging method and the residual-permutation method. For noise processes that obey our assumptions, the algorithm presented here gives more accurate results for midtransit times and truer estimates of their uncertainties.","topic_id":"21675","bibcode":"2010ascl.soft10039C","views":"57","site_list":["http:\/\/asterisk.apod.com\/download\/file.php?id=3757"],"ref_list":["http:\/\/arxiv.org\/abs\/0909.0747"]},
		{"ascl_id":"1010.040","title":"Cosmic String Simulations","credit":"Copi, Craig J.; Vachaspati, Tanmay","abstract":"Complicated cosmic string loops will fragment until they reach simple, non-intersecting (\"stable\") configurations. Through extensive numerical study, these attractor loop shapes are characterized including their length, velocity, kink, and cusp distributions. An initial loop containing $M$ harmonic modes will, on average, split into 3M stable loops. These stable loops are approximately described by the degenerate kinky loop, which is planar and rectangular, independently of the number of modes on the initial loop. This is confirmed by an analytic construction of a stable family of perturbed degenerate kinky loops. The average stable loop is also found to have a 40% chance of containing a cusp. This new analytic scheme explicitly solves the string constraint equations.","topic_id":"21677","bibcode":"2010ascl.soft10040C","views":"55","site_list":["http:\/\/www.phys.cwru.edu\/projects\/strings\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1010.4030"]},
		{"ascl_id":"1010.041","title":"FASTLens (FAst STatistics for weak Lensing): Fast Method for Weak Lensing Statistics and Map Making","credit":"Pires, S.; Starck, J.-L.; Amara, A.; Teyssier, R.; Refregier, A.; Fadili, J.","abstract":"The analysis of weak lensing data requires to account for missing data such as masking out of bright stars. To date, the majority of lensing analyses uses the two point-statistics of the cosmic shear field. These can either be studied directly using the two-point correlation function, or in Fourier space, using the power spectrum. The two-point correlation function is unbiased by missing data but its direct calculation will soon become a burden with the exponential growth of astronomical data sets. The power spectrum is fast to estimate but a mask correction should be estimated. Other statistics can be used but these are strongly sensitive to missing data. The solution that is proposed by FASTLens is to properly fill-in the gaps with only NlogN operations, leading to a complete weak lensing mass map from which one can compute straight forwardly and with a very good accuracy any kind of statistics like power spectrum or bispectrum.","topic_id":"21687","bibcode":"2010ascl.soft10041P","views":"51","site_list":["http:\/\/irfu.cea.fr\/Ast\/fastlens.software.php"],"ref_list":["http:\/\/arxiv.org\/abs\/0804.4068"]},
		{"ascl_id":"1010.042","title":"WeightMixer: Hybrid Cross-power Spectrum Estimation","credit":"Lewis, Antony","abstract":"This code, wihch requires <a href=\"http:\/\/healpix.jpl.nasa.gov\/\">HEALPix<\/a> 2.x, allows you to generate power spectrum estimators from WMAP 5-year maps and generate hybrid cross- and auto- power spectrum and covariance from general foreground-cleaned maps. In addition, it allows you to simulate combined maps or combinations of maps for individual detectors and do MPI spherical transforms of arrays of maps, calculate coupling matrices etc. The code includes all of <a href=\"http:\/\/cosmologist.info\/lenspix\">LensPix<\/a> - the MPI framework used for doing spherical transforms (based on HealPix).","topic_id":"21688","bibcode":"2010ascl.soft10042L","views":"52","site_list":["http:\/\/cosmologist.info\/weightmixer\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0804.3865"]},
		{"ascl_id":"1010.043","title":"FSPS: Flexible Stellar Population Synthesis","credit":"Conroy, Charlie; Gunn, James E.","abstract":"FSPS is a flexible SPS package that allows the user to compute simple stellar populations (SSPs) for a range of IMFs and metallicities, and for a variety of assumptions regarding the morphology of the horizontal branch, the blue straggler population, the post--AGB phase, and the location in the HR diagram of the TP-AGB phase.  From these SSPs the user may then generate composite stellar populations (CSPs) for a variety of star formation histories (SFHs) and dust attenuation prescriptions.  Outputs include the \"observed\" spectra and magnitudes of the SSPs and CSPs at arbitrary redshift.  In addition to these fortran routines, several IDL routines are provided that allow easy manipulation of the output. FSPS was designed with the intention that the user would make full use of the provided fortran routines.  However, the full FSPS package is quite large, and requires some time for the user to become familiar with all of the options and syntax.  Some users may only need SSPs for a range of metallicities and IMFs.  For such users, standard SSP sets for several IMFs, evolutionary tracks, and spectral libraries are available here.","topic_id":"21697","bibcode":"2010ascl.soft10043C","views":"65","site_list":["http:\/\/people.ucsc.edu\/~conroy\/FSPS.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0911.3151"]},
		{"ascl_id":"1010.044","title":"MAESTRO: An Adaptive Low Mach Number Hydrodynamics Algorithm for Stellar Flows","credit":"Nonaka, A.; Almgren, A. S.; Bell, J. B.; Lijewski, M. J.; Malone, C. M.; Zingale, M.","abstract":"Many astrophysical phenomena are highly subsonic, requiring specialized numerical methods suitable for long-time integration. In a series of earlier papers we described the development of MAESTRO, a low Mach number stellar hydrodynamics code that can be used to simulate long-time, low-speed flows that would be prohibitively expensive to model using traditional compressible codes. MAESTRO is based on an equation set derived using low Mach number asymptotics; this equation set does not explicitly track acoustic waves and thus allows a significant increase in the time step. MAESTRO is suitable for two- and three-dimensional local atmospheric flows as well as three-dimensional full-star flows. Here, we continue the development of MAESTRO by incorporating adaptive mesh refinement (AMR). The primary difference between MAESTRO and other structured grid AMR approaches for incompressible and low Mach number flows is the presence of the time-dependent base state, whose evolution is coupled to the evolution of the full solution. We also describe how to incorporate the expansion of the base state for full-star flows, which involves a novel mapping technique between the one-dimensional base state and the Cartesian grid, as well as a number of overall improvements to the algorithm. We examine the efficiency and accuracy of our adaptive code, and demonstrate that it is suitable for further study of our initial scientific application, the convective phase of Type Ia supernovae.","topic_id":"23446","bibcode":"2010ascl.soft10044N","views":"49","site_list":["https:\/\/ccse.lbl.gov\/Research\/MAESTRO\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1005.0112","http:\/\/arxiv.org\/abs\/1008.2801","http:\/\/arxiv.org\/abs\/1012.0609"]},
		{"ascl_id":"1010.045","title":"PLUTO: A Code for Flows in Multiple Spatial Dimensions","credit":"Mignone, Andrea; Tzeferacos, P.; Zanni, C.; Tesileanu, O.; Matsakos, T.; Bodo, G.","abstract":"PLUTO is a modular Godunov-type code intended mainly for astrophysical applications and high Mach number flows in multiple spatial dimensions. The code embeds different hydrodynamic modules and multiple algorithms to solve the equations describing Newtonian, relativistic, MHD, or relativistic MHD fluids in Cartesian or curvilinear coordinates. PLUTO is entirely written in the C programming language and can run on either single processor machines or large parallel clusters through the MPI library. A simple user-interface based on the Python scripting language is available to setup a physical problem in a quick and self-explanatory way. Computations may be carried on either static or adaptive (structured) grids, the latter functionality being provided through the Chombo adaptive mesh refinement library.","topic_id":"21742","bibcode":"2010ascl.soft10045M","views":"51","site_list":["http:\/\/plutocode.ph.unito.it\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0701854"]},
		{"ascl_id":"1010.046","title":"indexf: Line-strength Indices in Fully Calibrated FITS Spectra","credit":"Cardiel, Nicolas","abstract":"This program measures line-strength indices in fully calibrated FITS spectra. By \"fully calibrated\" one should understand wavelength and relative flux-calibrated data. Note that the different types of line-strength indices that can be measured with indexf (see below) do not require absolute flux calibration. If even a relative flux-calibration is absent (or deficient), the derived indices should be transformed to an appropriate spectrophotometric system. The program can also compute index errors resulting from the propagation of random errors (e.g. photon statistics, read-out noise). This option is only available if the user provides the error spectrum as an additional input FITS file to indexf. The error spectrum must contain the unbiased standard deviation (and not the variance!) for each pixel of the data spectrum. In addition, indexf also estimates the effect of errors on radial velocity. For this purpose, the program performs Monte Carlo simulations by measuring each index using randomly drawn radial velocities (following a Gaussian distribution of a given standard deviation). If no error file is employed, the program can perform numerical simulations with synthetic error spectra, the latter generated from the original data spectra and assuming randomly generated S\/N ratios.","topic_id":"21699","bibcode":"2010ascl.soft10046C","views":"48","site_list":["http:\/\/www.ucm.es\/info\/Astrof\/software\/indexf\/indexf.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1004.4439","http:\/\/arxiv.org\/abs\/astro-ph\/0607009"]},
		{"ascl_id":"1010.047","title":"ISW and Weak Lensing Likelihood Code","credit":"Ho, Shirley; Hirata, Christopher M.; Padmanabhan, Nikhil; Seljak, Uros; Bahcall, Neta","abstract":"ISW and Weak Lensing Likelihood code is the likelihood code that calculates the likelihood of Integrated Sachs Wolfe and Weak Lensing of Cosmic Microwave Background using the WMAP 3year CMB maps with mass tracers such as 2MASS (2-Micron All Sky Survey), SDSS LRG (Sloan Digital Sky Survey Luminous Red Galaxies), SDSS QSOs (Sloan Digital Sky Survey Quasars) and NVSS (NRAO VLA All Sky Survey) radio sources. The details of the analysis (*thus the likelihood code) can be understood by reading the papers <a href=\"http:\/\/arxiv.org\/abs\/0801.0642\">ISW paper<\/a> and <a href=\"http:\/\/arxiv.org\/abs\/0801.0644\">Weak lensing paper<\/a>. The code does brute force theoretical matter power spectrum and calculations with <a href=\"http:\/\/ascl.net\/1102.026\">CAMB<\/a>. See the paper  for an introduction, descriptions, and typical results from some pre-WMAP data. The code is designed to be integrated into <a href=\"http:\/\/ascl.net\/1106.025\">CosmoMC<\/a>. For further information concerning the integration, see <a href=\"http:\/\/lymanalpha.lbl.gov\/~shirley\/ISW_WL.html#Modification\">Code Modification for integration into COSMOMC<\/a>.","topic_id":"21701","bibcode":"2010ascl.soft10047H","views":"52","site_list":["http:\/\/terapix.phys.cmu.edu\/ISW_WL.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0801.0642","http:\/\/arxiv.org\/abs\/0801.0644"]},
		{"ascl_id":"1010.048","title":"OCTGRAV: Sparse Octree Gravitational N-body Code on Graphics Processing Units","credit":"Gaburov, Evghenii; B\u00e9dorf, Jeroen; Portegies Zwart, Simon","abstract":"Octgrav is a new very fast tree-code which runs on massively parallel Graphical Processing Units (GPU) with NVIDIA CUDA architecture. The algorithms are based on parallel-scan and sort methods. The tree-construction and calculation of multipole moments is carried out on the host CPU, while the force calculation which consists of tree walks and evaluation of interaction list is carried out on the GPU. In this way, a sustained performance of about 100GFLOP\/s and data transfer rates of about 50GB\/s is achieved. It takes about a second to compute forces on a million particles with an opening angle of $\theta approx 0.5$. \r\n\r\nTo test the performance and feasibility, we implemented the algorithms in CUDA in the form of a gravitational tree-code which completely runs on the GPU. The tree construction and traverse algorithms are portable to many-core devices which have support for CUDA or OpenCL programming languages. The gravitational tree-code outperforms tuned CPU code during the tree-construction and shows a performance improvement of more than a factor 20 overall, resulting in a processing rate of more than 2.8 million particles per second. \r\n\r\nThe code has a convenient user interface and is freely available for use.","topic_id":"21704","bibcode":"2010ascl.soft10048G","views":"69","site_list":["http:\/\/castle.strw.leidenuniv.nl\/software\/octgrav.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1106.1900"]},
		{"ascl_id":"1010.049","title":"Gas-momentum-kinetic SZ cross-correlations","credit":"Ho, Shirley; Dedeo, Simon; Spergel, David","abstract":"We present a new method for detecting the missing baryons by generating a template for the kinematic Sunyaev-Zel'dovich effect. The template is computed from the product of a reconstructed velocity field with a galaxy field. We provide maps of such templates constructed from SDSS Data Release 7 spectroscopic data (SDSS VAGC sample) along side with their expected two point correlation functions with CMB temperature anisotropies. Codes of generating such coefficients of the two point correlation function are also released to provide users of the gas-momentum map a way to change the parameters such as cosmological parameters, reionization history, ionization parameters, etc.","topic_id":"21708","bibcode":"2010ascl.soft10049H","views":"45","site_list":["http:\/\/www.astro.princeton.edu\/~shirley\/SZ\/SZ.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0903.2845"]},
		{"ascl_id":"1010.050","title":"LensPerfect: Gravitational Lens Massmap Reconstructions Yielding Exact Reproduction of All Multiple Images","credit":"Coe, D.; Fuselier, E.; Benitez, N.; Broadhurst, T.; Frye, B.; Ford, H.","abstract":"LensPerfect is a new approach to the massmap reconstruction of strong gravitational lenses. Conventional methods iterate over possible lens models which reproduce the observed multiple image positions well but not exactly. LensPerfect only produces solutions which fit all of the data exactly. Magnifications and shears of the multiple images can also be perfectly constrained to match observations.","topic_id":"21709","bibcode":"2010ascl.soft10050C","views":"56","site_list":["http:\/\/www.stsci.edu\/~dcoe\/LensPerfect\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ApJ...681..814C"]},
		{"ascl_id":"1010.051","title":"NEMO: A Stellar Dynamics Toolbox","credit":"Barnes, Joshua; Hut, Piet; Teuben, Peter","abstract":"NEMO is an extendible  Stellar Dynamics Toolbox, following an Open-Source Software model. It has various programs to create, integrate, analyze and visualize N-body and SPH like systems, following the pipe and filter architecture. In addition there are various tools to operate on images, tables and orbits, including FITS files to export\/import to\/from other astronomical data reduction packages. A large growing fraction of NEMO has been contributed by a growing list of authors. The source code consist of a little over 4000 files and a little under 1,000,000 lines of code and documentation, mostly C, and some C++ and Fortran. NEMO development started in 1986 in Princeton (USA) by Barnes, Hut and Teuben. See also ZENO (<a href=\"http:\/\/ascl.net\/1102.027\">ascl:1102.027<\/a>) for the version that Barnes maintains.","topic_id":"21714","bibcode":"2010ascl.soft10051B","views":"955","site_list":["http:\/\/carma.astro.umd.edu\/nemo\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1995ASPC...77..398T"]},
		{"ascl_id":"1010.052","title":"EAZY: A Fast, Public Photometric Redshift Code","credit":"Brammer, Gabriel B.; van Dokkum, Pieter G.; Coppi, Paolo","abstract":"EAZY, Easy and Accurate Zphot from Yale, is a new program for determining photometric redshifts. The program is optimized for cases where spectroscopic redshifts are not available, or only available for a biased subset of the galaxies. The code combines features from various existing codes: it can fit linear combinations of templates, it includes optional flux- and redshift-based priors, and its user interface is modeled on the popular HYPERZ code. A novel feature is that the default template set, as well as the default functional forms of the priors, are not based on (usually highly biased) spectroscopic samples, but on semi-analytical models. Furthermore, template mismatch is addressed by a novel rest-frame template error function. This function gives different wavelength regions different weights, and ensures that the formal redshift uncertainties are realistic. A redshift quality parameter, Q_z, provides a robust estimate of the reliability of the photometric redshift estimate.","topic_id":"21717","bibcode":"2010ascl.soft10052B","views":"49","site_list":["http:\/\/www.astro.yale.edu\/eazy\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1104.2595"]},
		{"ascl_id":"1010.053","title":"Halofitting codes for DGP and Degravitation","credit":"Khoury, J.; Wyman, M.","abstract":"We perform N-body simulations of theories with infinite-volume extra dimensions, such as the Dvali-Gabadadze-Porrati (DGP) model and its higher-dimensional generalizations, where 4D gravity is mediated by massive gravitons. The longitudinal mode of these gravitons mediates an extra scalar force, which we model as a density-dependent modification to the Poisson equation. This enhances gravitational clustering, particularly on scales that have undergone mild nonlinear processing. While the standard non-linear fitting algorithm of Smith et al. overestimates this power enhancement on non-linear scales, we present a modified fitting formula that offers a remarkably good fit to our power spectra. Due to the uncertainty in galaxy bias, our results are consistent with precision power spectrum determinations from galaxy redshift surveys, even for graviton Compton wavelengths as small as 300 Mpc. Our model is sufficiently general that we expect it to capture the phenomenology of a wide class of related higher-dimensional gravity scenarios.","topic_id":"21726","bibcode":"2010ascl.soft10053K","views":"47","site_list":["http:\/\/www.markcwyman.com\/Code\/"],"ref_list":false},
		{"ascl_id":"1010.054","title":"MagnetiCS.c: Cosmic String Loop Evolution and Magnetogenesis","credit":"Battefeld, Diana; Battefeld, Thorsten; Wesley, Daniel H.; Wyman, Mark","abstract":"Large-scale coherent magnetic fields are observed in galaxies and clusters, but their ultimate origin remains a mystery. We reconsider the prospects for primordial magnetogenesis by a cosmic string network. We show that the magnetic flux produced by long strings has been overestimated in the past, and give improved estimates. We also compute the fields created by the loop population, and find that it gives the dominant contribution to the total magnetic field strength on present-day galactic scales. We present numerical results obtained by evolving semi-analytic models of string networks (including both one-scale and velocity-dependent one-scale models) in a Lambda-CDM cosmology, including the forces and torques on loops from Hubble redshifting, dynamical friction, and gravitational wave emission. Our predictions include the magnetic field strength as a function of correlation length, as well as the volume covered by magnetic fields. We conclude that string networks could account for magnetic fields on galactic scales, but only if coupled with an efficient dynamo amplification mechanism.","topic_id":"21727","bibcode":"2010ascl.soft10054B","views":"47","site_list":["http:\/\/www.markcwyman.com\/Code\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0708.2901"]},
		{"ascl_id":"1010.055","title":"SYNOW: A Highly Parameterized Spectrum Synthesis Code for Direct Analysis of SN Spectra","credit":"Parrent, Jerod; Branch, David; Jeffery, David","abstract":"SYNOW is a highly parameterized spectrum synthesis code used primarily for direct (empirical) analysis of SN spectra. The code is based on simple assumptions : spherical symmetry; homologous expansion; a sharp photosphere that emits a blackbody continuous spectrum; and line formation by resonance scattering, treated in the Sobolev approximation. Synow does not do continuum transport, it does not solve rate equations, and it does not calculate ionization ratios. Its main function is to take line multiple scattering into account so that it can be used in an empirical spirit to make line identifications and estimate the velocity at the photosphere (or pseudo-photosphere) and the velocity interval within which each ion is detected. these quantities provide constraints on the composition structure of the ejected matter.","topic_id":"21730","bibcode":"2010ascl.soft10055P","views":"51","site_list":["http:\/\/www.nhn.ou.edu\/~parrent\/synow.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1103.1671"]},
		{"ascl_id":"1010.056","title":"PHOENIX: A General-purpose State-of-the-art Stellar and Planetary Atmosphere Code","credit":"Baron, E.; Chen, Bin; Hauschildt, P. H.","abstract":"PHOENIX is a general-purpose state-of-the-art stellar and planetary atmosphere code. It can calculate atmospheres and spectra of stars all across the HR-diagram including main sequence stars, giants, white dwarfs, stars with winds, TTauri stars, novae, supernovae, brown dwarfs and extrasolar giant planets.","topic_id":"21732","bibcode":"2010ascl.soft10056B","views":"73","site_list":["http:\/\/www.hs.uni-hamburg.de\/EN\/For\/ThA\/phoenix\/index.html"],"ref_list":["http:\/\/ads.ari.uni-heidelberg.de\/abs\/2009A%26A...502.1043J"]},
		{"ascl_id":"1010.057","title":"Tiny Tim: Simulated Hubble Space Telescope PSFs","credit":"Krist, John; Hook, Richard; Stoehr, Felix","abstract":"Tiny Tim generates simulated Hubble Space Telescope point spread functions (PSFs). It is written in C and distributed as source code and runs on a wide variety of UNIX and VMS systems. Tiny Tim includes mirror zonal errors, time dependent aberrations (for the pre-repair instruments), field dependent obscuration patterns (for WF\/PC-1 and WFPC2), and filter passband effects. It can produce a normally sampled or subsampled PSF. Output is a FITS image file.","topic_id":"21739","bibcode":"2010ascl.soft10057K","views":"65","site_list":["http:\/\/www.stsci.edu\/hst\/observatory\/focus\/TinyTim"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1995chst.conf..311K"]},
		{"ascl_id":"1010.058","title":"VINE: A numerical code for simulating astrophysical systems using particles I","credit":"Wetzstein, M.; Nelson, Andrew F.; Naab, T.; Burkert, A.","abstract":"VINE is a particle based astrophysical simulation code. It uses a tree structure to efficiently solve the gravitational N-body problem and Smoothed Particle Hydrodynamics (SPH) to simulate gas dynamical effects. The code has been successfully used for a number of studies on galaxy interactions, galactic dynamics, star formation and planet formation and given the implemented physics, other applications are possible as well.","topic_id":"21740","bibcode":"2010ascl.soft10058W","views":"55","site_list":["http:\/\/www.usm.lmu.de\/people\/mwetz\/Overview.html"],"ref_list":["http:\/\/lanl.arxiv.org\/abs\/0802.4245"]},
		{"ascl_id":"1010.059","title":"CESAM: A Free Code for Stellar Evolution Calculations","credit":"Morel, Pierre; Lebreton, Yveline","abstract":"The Cesam code is a consistent set of programs and routines which perform calculations of 1D quasi-hydrostatic stellar evolution including microscopic diffusion of chemical species and diffusion of angular momentum. The solution of the quasi-static equilibrium is performed by a collocation method based on piecewise polynomials approximations projected on a B-spline basis; that allows stable and robust calculations, and the exact restitution of the solution, not only at grid points, even for the discontinuous variables. Other advantages are the monitoring by only one parameter of the accuracy and its improvement by super-convergence. An automatic mesh refinement has been designed for adjusting the localisations of grid points according to the changes of unknowns. For standard models, the evolution of the chemical composition is solved by stiffly stable schemes of orders up to four; in the convection zones mixing and evolution of chemical are simultaneous. The solution of the diffusion equation employs the Galerkin finite elements scheme; the mixing of chemicals is then performed by a strong turbulent diffusion. A precise restoration of the atmosphere is allowed for.","topic_id":"21741","bibcode":"2010ascl.soft10059M","views":"52","site_list":["http:\/\/www.oca.eu\/cesam\/news.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0801.2019"]},
		{"ascl_id":"1010.060","title":"Pencil: Finite-difference Code for Compressible Hydrodynamic Flows","credit":"Brandenburg, Axel; Dobler, Wolfgang","abstract":"The Pencil code is a high-order finite-difference code for compressible hydrodynamic flows with magnetic fields. It is highly modular and can easily be adapted to different types of problems. The code runs efficiently under MPI on massively parallel shared- or distributed-memory computers, like e.g. large Beowulf clusters. The Pencil code is primarily designed to deal with weakly compressible turbulent flows. To achieve good parallelization, explicit (as opposed to compact) finite differences are used. Typical scientific targets include driven MHD turbulence in a periodic box, convection in a slab with non-periodic upper and lower boundaries, a convective star embedded in a fully nonperiodic box, accretion disc turbulence in the shearing sheet approximation, self-gravity, non-local radiation transfer, dust particle evolution with feedback on the gas, etc. A range of artificial viscosity and diffusion schemes can be invoked to deal with supersonic flows. For direct simulations regular viscosity and diffusion is being used. The code is written in well-commented Fortran90.","topic_id":"21747","bibcode":"2010ascl.soft10060B","views":"43","site_list":["http:\/\/www.nordita.org\/software\/pencil-code\/","http:\/\/code.google.com\/p\/pencil-code\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1005.5301"]},
		{"ascl_id":"1010.061","title":"EyE: Enhance Your Extraction","credit":"Bertin, Emmanuel; Marmo, Chiara","abstract":"In EyE (Enhance Your Extraction) an artificial neural network connected to pixels of a moving window (retina) is trained to associate these input stimuli to the corresponding response in one or several output image(s). The resulting filter can be loaded in <a href=\"http:\/\/ascl.net\/1010.064\">SExtractor<\/a> to operate complex, wildly non-linear filters on astronomical images. Typical applications of EyE include adaptive filtering, feature detection and cosmetic corrections.","topic_id":"21767","bibcode":"2010ascl.soft10061B","views":"48","site_list":["http:\/\/www.astromatic.net\/software\/eye"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001misk.conf..353B"]},
		{"ascl_id":"1010.062","title":"MissFITS: Basic Maintenance and Packaging Tasks on FITS Files","credit":"Marmo, Chiara; Bertin, Emmanuel","abstract":"MissFITS is a program that performs basic maintenance and packaging tasks on FITS files using an optimized FITS library. MissFITS can:\r\n\r\n<ul><li>add, edit, and remove FITS header keywords;<\/li><li>split and join Multi-Extension-FITS (MEF) files;<\/li><li>unpile and pile FITS data-cubes; and, <\/li><li>create, check, and update FITS checksums, using <a href=\"http:\/\/www.adass.org\/adass\/proceedings\/adass94\/seamanr.html\">R. Seaman\u2019s protocol<\/a>. <\/li><\/ul>","topic_id":"21768","bibcode":"2010ascl.soft10062M","views":"42","site_list":["http:\/\/www.astromatic.net\/software\/missfits"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ASPC..394..619M"]},
		{"ascl_id":"1010.063","title":"SCAMP: Automatic Astrometric and Photometric Calibration","credit":"Bertin, Emmanuel","abstract":"Astrometric and photometric calibrations have remained the most tiresome step in the reduction of large imaging surveys. SCAMP has been written to address this problem. The program efficiently computes accurate astrometric and photometric solutions for any arbitrary sequence of FITS images in a completely automatic way. SCAMP is released under the GNU General Public License.","topic_id":"21769","bibcode":"2010ascl.soft10063B","views":"60","site_list":["http:\/\/www.astromatic.net\/software\/scamp"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ASPC..351..112B"]},
		{"ascl_id":"1010.064","title":"SExtractor: Source Extractor","credit":"Bertin, E.; Arnouts, S.","abstract":"This new software optimally detects, de-blends, measures and classifies sources from astronomical images: SExtractor (Source Extractor). A very reliable star\/galaxy separation can be achieved on most images using a neural network trained with simulated images. Salient features of SExtractor include its ability to work on very large images, with minimal human intervention, and to deal with a wide variety of object shapes and magnitudes. It is therefore particularly suited to the analysis of large extragalactic surveys.","topic_id":"21770","bibcode":"2010ascl.soft10064B","views":"83","site_list":["http:\/\/www.astromatic.net\/software\/sextractor"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1996A%26AS..117..393B"]},
		{"ascl_id":"1010.065","title":"Higher Post Newtonian Gravity Calculations","credit":"Chu, Yi-Zen","abstract":"Motivated by experimental probes of general relativity, we adopt methods from perturbative (quantum) field theory to compute, up to certain integrals, the effective lagrangian for its n-body problem. Perturbation theory is performed about a background Minkowski spacetime to O[(v\/c)^4] beyond Newtonian gravity, where v is the typical speed of these n particles in their center of energy frame. For the specific case of the 2 body problem, the major efforts underway to measure gravitational waves produced by in-spiraling compact astrophysical binaries require their gravitational interactions to be computed beyond the currently known O[(v\/c)^7]. We argue that such higher order post-Newtonian calculations must be automated for these field theoretic methods to be applied successfully to achieve this goal. In view of this, we outline an algorithm that would in principle generate the relevant Feynman diagrams to an arbitrary order in v\/c and take steps to develop the necessary software. The Feynman diagrams contributing to the n-body effective action at O[(v\/c)^6] beyond Newton are derived.","topic_id":"21774","bibcode":"2010ascl.soft10065C","views":"63","site_list":["http:\/\/www.stargazing.net\/yizen\/PN.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0812.0012"]},
		{"ascl_id":"1010.066","title":"SkyMaker: Astronomical Image Simulations Made Easy","credit":"Bertin, Emmanuel; Fouqu\u00e9, Pascal","abstract":"SkyMaker is a program that simulates astronomical images. It accepts object lists in ASCII generated by the Stuff program to produce realistic astronomical fields. SkyMaker is part of the <a href=\"http:\/\/www.efigi.org\/\">EFIGI<\/a> development project.","topic_id":"21771","bibcode":"2010ascl.soft10066B","views":"43","site_list":["http:\/\/www.astromatic.net\/software\/skymaker"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009MmSAI..80..422B"]},
		{"ascl_id":"1010.067","title":"Stuff: Simulating \u201cPerfect\u201d Astronomical Catalogues","credit":"Bertin, Emmanuel","abstract":"Stuff is a program that simulates \u201cperfect\u201d astronomical catalogues. It generate object lists in ASCII which can read by the SkyMaker program to produce realistic astronomical fields. Stuff is part of the <a href=\"http:\/\/www.efigi.org\/\">EFIGI<\/a> development project.","topic_id":"21775","bibcode":"2010ascl.soft10067B","views":"41","site_list":["http:\/\/www.astromatic.net\/software\/stuff"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009MmSAI..80..422B"]},
		{"ascl_id":"1010.068","title":"SWarp: Resampling and Co-adding FITS Images Together","credit":"Bertin, Emmanuel","abstract":"SWarp is a program that resamples and co-adds together FITS images using any arbitrary astrometric projection defined in the WCS standard. It operates on pre-reduced images and their weight-maps. Based on the astrometric and photometric calibrations derived at an earlier phase of the pipeline, SWarp re-maps (\"warps\") the pixels to a perfect projection system, and co-adds them in an optimum way, according to their relative weights. SWarp's astrometric engine is based on a customized version of Calabretta's WCSLib 2.6 and supports all of the projections defined in the 2000 version of the WCS proposal.","topic_id":"21772","bibcode":"2010ascl.soft10068B","views":"60","site_list":["http:\/\/www.astromatic.net\/software\/swarp"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002ASPC..281..228B"]},
		{"ascl_id":"1010.069","title":"WeightWatcher: Code to Produce Control Maps","credit":"Marmo, Chiara; Bertin, Emmanuel","abstract":"WeightWatcher is a program that combines weight-maps, flag-maps and polygon data in order to produce control maps which can directly be used in astronomical image-processing packages like <a href=\"http:\/\/ascl.net\/1212.011\">Drizzle<\/a>, <a href=\"http:\/\/ascl.net\/1010.068\">SWarp<\/a> or <a href=\"http:\/\/ascl.net\/1010.064\">SExtractor<\/a>.","topic_id":"21773","bibcode":"2010ascl.soft10069M","views":"56","site_list":["http:\/\/www.astromatic.net\/software\/weightwatcher"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ASPC..394..619M"]},
		{"ascl_id":"1010.070","title":"Fisher.py: Fisher Matrix Manipulation and Confidence Contour Plotting","credit":"Coe, Dan","abstract":"Fisher.py allows you to combine constraints from multiple experiments (e.g., weak lensing + supernovae) and add priors (e.g., a flat universe) simply and easily. Calculate parameter uncertainties and plot confidence ellipses. Fisher matrix expectations for several experiments are included as calculated by myself (time delays) and the Dark Energy Task Force (WL\/SN\/BAO\/CL\/CMB), or provide your own.","topic_id":"21801","bibcode":"2010ascl.soft10070C","views":"47","site_list":["http:\/\/www.stsci.edu\/~dcoe\/Fisher\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0906.4123"]},
		{"ascl_id":"1010.071","title":"WSHAPE: Gravitational Softening and Adaptive Mass Resolution","credit":"Shirokov, Alexander","abstract":"Pairwise forces between particles in cosmological N-body simulations are generally softened to avoid hard collisions. Physically, this softening corresponds to treating the particles as diffuse clouds rather than point masses. For particles of unequal mass (and hence unequal softening length), computing the softened force involves a nontrivial double integral over the volumes of the two particles. We show that Plummer force softening is consistent with this interpretation of softening while spline softening is not. We provide closed-form expressions and numerical implementation for pairwise gravitational force laws for pairs of particles of general softening scales $epsilon_1$ and $epsilon_2$ assuming the commonly used cloud profiles: NGP, CIC, TSC, and PQS. Similarly, we generalize Plummer force law into pairs of particles of general softenings. We relate our expressions to the gaussian, Plummer and spline force softenings known from literature. Our expressions allow possible inclusions of pointlike particles such as stars or supermassive black holes.","topic_id":"21810","bibcode":"2010ascl.soft10071S","views":"58","site_list":["http:\/\/www.gracos.org\/wshape\/"],"ref_list":["http:\/\/lanl.arxiv.org\/abs\/0711.2989"]},
		{"ascl_id":"1010.072","title":"Enzo: AMR Cosmology Application","credit":"O'Shea, Brian W.; Bryan, Greg; Bordner, James; Norman, Michael L.; Abel, Tom; Harkness, Robert; Kritsuk, Alexei","abstract":"Enzo is an adaptive mesh refinement (AMR), grid-based hybrid code (hydro + N-Body) which is designed to do simulations of cosmological structure formation. It uses the algorithms of Berger & Collela to improve spatial and temporal resolution in regions of large gradients, such as gravitationally collapsing objects. The Enzo simulation software is incredibly flexible, and can be used to simulate a wide range of cosmological situations with the available physics packages.\r\n\r\nEnzo has been parallelized using the MPI message-passing library and can run on any shared or distributed memory parallel supercomputer or PC cluster. Simulations using as many as 1024 processors have been successfully carried out on the San Diego Supercomputing Center's Blue Horizon, an IBM SP.","topic_id":"21812","bibcode":"2010ascl.soft10072O","views":"53","site_list":["http:\/\/enzo-project.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0403044"]},
		{"ascl_id":"1010.073","title":"partiview: Immersive 4D Interactive Visualization of Large-Scale Simulations","credit":"Teuben, Peter; Hut, Piet; Levy, Stuart; Makino, Jun; McMillan, Steve; Portegies Zwart, Simon; Shara, Mike; Emmart, Carter","abstract":"In dense clusters a bewildering variety of interactions between stars can be observed, ranging from simple encounters to collisions and other mass-transfer encounters. With faster and special-purpose computers like GRAPE, the amount of data per simulation is now exceeding 1TB. Visualization of such data has now become a complex 4D data-mining problem, combining space and time, and finding interesting events in these large datasets. We have recently starting using the virtual reality simulator, installed in the Hayden Planetarium in the American Museum for Natural History, to tackle some of these problem. partiview is a program that enables you to visualize and animate particle data. partiview runs on relatively simple desktops and laptops, but is mostly compatible with its big brother VirDir.","topic_id":"21813","bibcode":"2010ascl.soft10073T","views":"41","site_list":["http:\/\/carma.astro.umd.edu\/nemo\/amnh\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0101334"]},
		{"ascl_id":"1010.074","title":"StarCrash: 3-d Evolution of Self-gravitating Fluid Systems","credit":"Faber, Joshua; Lombardi, Jamie; Rasio, Fred","abstract":"StarCrash is a parallel fortran code based on Smoothed Particle Hydrodynamics (SPH) techniques to calculate the 3-d evolution of self-gravitating fluid systems. The code in particularly suited to the study of stellar interactions, such as mergers of binary star systems and stellar collisions. The StarCrash code comes with several important features, including:\r\n\r\n    <ul><li>Several routines which construct the initial conditions appropriate to a wide variety of physical systems\r\n    <\/li><li>An efficient parallel neighbor-finding algorithm for calculating hydrodynamic quantities\r\n    <\/li><li>A parallel gravitational field solver based on FFT convolution techniques, which uses the FFTW software libraries\r\n    <\/li><li>Relaxation Techniques for single stars and synchronized binaries\r\n    <\/li><li>Three different artificial viscosity treatments to calculate the thermodynamic evolution of the matter\r\n    <\/li><li>An optional gravitational radiation back-reaction treatment, which calculates the damping force from gravity wave losses to lowest relativistic order in a spatially accurate way<\/li><\/ul>","topic_id":"21811","bibcode":"2010ascl.soft10074F","views":"51","site_list":["http:\/\/ciera.northwestern.edu\/StarCrash\/"],"ref_list":["http:\/\/arxiv.org\/abs\/gr-qc\/0101074"]},
		{"ascl_id":"1010.075","title":"Radex: Fast Non-LTE Analysis of Interstellar Line Spectra","credit":"van der Tak, F. F. S.; Black, J. H.; Sch\u00f6ier, F. L.; Jansen, D. J.; van Dishoeck, E. F.","abstract":"The large quantity and high quality of modern radio and infrared line observations require efficient modeling techniques to infer physical and chemical parameters such as temperature, density, and molecular abundances. Radex calculates the intensities of atomic and molecular lines produced in a uniform medium, based on statistical equilibrium calculations involving collisional and radiative processes and including radiation from background sources. Optical depth effects are treated with an escape probability method. The program makes use of molecular data files maintained in the Leiden Atomic and Molecular Database (<a href=\"http:\/\/ascl.net\/1010.077\">LAMDA<\/a>), which will continue to be improved and expanded. The performance of the program is compared with more approximate and with more sophisticated methods. An Appendix provides diagnostic plots to estimate physical parameters from line intensity ratios of commonly observed molecules. This program should form an important tool in analyzing observations from current and future radio and infrared telescopes.","topic_id":"21817","bibcode":"2010ascl.soft10075V","views":"44","site_list":["http:\/\/www.sron.rug.nl\/~vdtak\/radex\/index.shtml"],"ref_list":false},
		{"ascl_id":"1010.076","title":"Starlab: A Software Environment for Collisional Stellar Dynamics","credit":"Hut, Piet; McMillan, Steve; Makino, Jun; Portegies Zwart, Simon","abstract":"Traditionally, a simulation of a dense stellar system required choosing an initial model, running an integrator, and analyzing the output. Almost all of the effort went into writing a clever integrator that could handle binaries, triples and encounters between various multiple systems efficiently. Recently, the scope and complexity of these simulations has increased dramatically, for three reasons: 1) the sheer size of the data sets, measured in Terabytes, make traditional 'awking and grepping' of a single output file impractical; 2) the addition of stellar evolution data brings qualitatively new challenges to the data reduction; 3) increased realism of the simulations invites realistic forms of 'SOS': Simulations of Observations of Simulations, to be compared directly with observations. We are now witnessing a shift toward the construction of archives as well as tailored forms of visualization including the use of virtual reality simulators and planetarium domes, and a coupling of both with budding efforts in constructing virtual observatories. This review describes these new trends, presenting Starlab as the first example of a full software environment for realistic large-scale simulations of dense stellar systems.","topic_id":"21814","bibcode":"2010ascl.soft10076H","views":"60","site_list":["http:\/\/www.sns.ias.edu\/~starlab\/starlab.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0204431"]},
		{"ascl_id":"1010.077","title":"LAMDA: Leiden Atomic and Molecular Database","credit":"Sch\u00f6ier, Fredrik; van der Tak, Floris; van Dishoeck, Ewine; Black, John","abstract":"LAMDA provides users of radiative transfer codes with the basic atomic and molecular data needed for the excitation calculation. Line data of a number of astrophysically interesting species are summarized, including energy levels, statistical weights, Einstein A-coefficients and collisional rate coefficients. Available collisional data from quantum chemical calculations and experiments are in some cases extrapolated to higher energies. Currently the database contains atomic data for 3 species and molecular data for 28 different species. In addition, several isotopomers and deuterated versions are available. This database should form an important tool in analyzing observations from current and future infrared and (sub)millimetre telescopes. Databases such as these rely heavily on the efforts by the chemical physics community to provide the relevant atomic and molecular data. Further efforts in this direction are strongly encouraged so that the current extrapolations of collisional rate coefficients can be replaced by actual calculations in future releases.\n\n<a href=\"http:\/\/ascl.net\/1010.075\">RADEX<\/a>, a computer program for performing statistical equilibrium calculations is made publicly available as part of the data base.","topic_id":"21818","bibcode":"2010ascl.soft10077S","views":"55","site_list":["http:\/\/www.strw.leidenuniv.nl\/~moldata\/"],"ref_list":["http:\/\/de.arxiv.org\/abs\/astro-ph\/0411110"]},
		{"ascl_id":"1010.078","title":"AstroMD: A Multi Dimensional Visualization and Analysis Toolkit for Astrophysics","credit":"Becciani, U.; Antonuccio-Delogu, V.; Gheller, C.; Calori, L.; Buonomo, F.; Imboden, S.","abstract":"Over the past few years, the role of visualization for scientific purpose has grown up enormously. Astronomy makes an extended use of visualization techniques to analyze data, and scientific visualization has became a fundamental part of modern researches in Astronomy. With the evolution of high performance computers, numerical simulations have assumed a great role in the scientific investigation, allowing the user to run simulation with higher and higher resolution. Data produced in these simulations are often multi-dimensional arrays with several physical quantities. These data are very hard to manage and to analyze efficiently. Consequently the data analysis and visualization tools must follow the new requirements of the research. AstroMD is a tool for data analysis and visualization of astrophysical data and can manage different physical quantities and multi-dimensional data sets. The tool uses virtual reality techniques by which the user has the impression of travelling through a computer-based multi-dimensional model.","topic_id":"21823","bibcode":"2010ascl.soft10078B","views":"95","site_list":["http:\/\/cosmolab.cineca.it\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0006402"]},
		{"ascl_id":"1010.079","title":"Geant4: A Simulation Toolkit for the Passage of Particles through Matter","credit":"Geant4 Collaboration","abstract":"Geant4 is a toolkit for simulating the passage of particles through matter. It includes a complete range of functionality including tracking, geometry, physics models and hits. The physics processes offered cover a comprehensive range, including electromagnetic, hadronic and optical processes, a large set of long-lived particles, materials and elements, over a wide energy range starting, in some cases, from 250eV and extending in others to the TeV energy range. It has been designed and constructed to expose the physics models utilised, to handle complex geometries, and to enable its easy adaptation for optimal use in different sets of applications. The toolkit is the result of a worldwide collaboration of physicists and software engineers. It has been created exploiting software engineering and object-oriented technology and implemented in the C++ programming language. It has been used in applications in particle physics, nuclear physics, accelerator design, space engineering and medical physics.","topic_id":"21827","bibcode":"2010ascl.soft10079G","views":"61","site_list":["http:\/\/geant4.cern.ch\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ITNS...53..270A"]},
		{"ascl_id":"1010.080","title":"GRACOS: Scalable and Load Balanced P3M Cosmological N-body Code","credit":"Shirokov, Alexander; Bertschinger, Edmund","abstract":"The GRACOS (GRAvitational COSmology) code, a parallel implementation of the particle-particle\/particle-mesh (P3M) algorithm for distributed memory clusters, uses a hybrid method for both computation and domain decomposition. Long-range forces are computed using a Fourier transform gravity solver on a regular mesh; the mesh is distributed across parallel processes using a static one-dimensional slab domain decomposition. Short-range forces are computed by direct summation of close pairs; particles are distributed using a dynamic domain decomposition based on a space-filling Hilbert curve. A nearly-optimal method was devised to dynamically repartition the particle distribution so as to maintain load balance even for extremely inhomogeneous mass distributions. Tests using $800^3$ simulations on a 40-processor beowulf cluster showed good load balance and scalability up to 80 processes. There are limits on scalability imposed by communication and extreme clustering which may be removed by extending the algorithm to include adaptive mesh refinement.","topic_id":"21829","bibcode":"2010ascl.soft10080S","views":"43","site_list":["http:\/\/www.gracos.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0505087"]},
		{"ascl_id":"1010.081","title":"MGGPOD: A Monte Carlo Suite for Gamma-Ray Astronomy","credit":"Weidenspointner, G.; Harris, M.; Ferguson, C.; Sturner, S.; Teegarden, B.; Wunderer, C.","abstract":"We have developed MGGPOD, a user-friendly suite of Monte Carlo codes built around the widely used GEANT (Version 3.21) package. The MGGPOD Monte Carlo suite and documentation are publicly available for download. MGGPOD is an ideal tool for supporting the various stages of gamma-ray astronomy missions, ranging from the design, development, and performance prediction through calibration and response generation to data reduction. In particular, MGGPOD is capable of simulating ab initio the physical processes relevant for the production of instrumental backgrounds. These include the build-up and delayed decay of radioactive isotopes as well as the prompt de-excitation of excited nuclei, both of which give rise to a plethora of instrumental gamma-ray background lines in addition to continuum backgrounds.","topic_id":"21828","bibcode":"2010ascl.soft10081W","views":"41","site_list":["http:\/\/www.gamma.mpe-garching.mpg.de\/MEGA\/mggpod.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0406159"]},
		{"ascl_id":"1010.082","title":"FLASH: Adaptive Mesh Hydrodynamics Code for Modeling Astrophysical Thermonuclear Flashes","credit":"Fryxell, B.; Olson, K.; Ricker, P.; Timmes, F. X.; Zingale, M.; Lamb, D. Q.; MacNeice, P.; Rosner, R.; Truran, J. W.; Tufo, H.","abstract":"The FLASH code, currently in its 4th version, is a publicly available high performance application code which has evolved into a modular, extensible software system from a collection of unconnected legacy codes. FLASH consists of inter-operable modules that can be combined to generate different applications. The FLASH architecture allows arbitrarily many alternative implementations of its components to co-exist and interchange with each other. A simple and elegant mechanism exists for customization of code functionality without the need to modify the core implementation of the source. A built-in unit test framework combined with regression tests that run nightly on multiple platforms verify the code.","topic_id":"21830","bibcode":"2010ascl.soft10082F","views":"40","site_list":["http:\/\/flash.uchicago.edu\/site\/flashcode\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000ApJS..131..273F","http:\/\/arxiv.org\/abs\/astro-ph\/0405410"]},
		{"ascl_id":"1010.083","title":"MESA: Modules for Experiments in Stellar Astrophysics","credit":"Paxton, Bill; Bildsten, Lars; Dotter, Aaron; Herwig, Falk; Lesaffre, Pierre; Timmes, Frank","abstract":"Stellar physics and evolution calculations enable a broad range of research in astrophysics. Modules for Experiments in Stellar Astrophysics (MESA) is a suite of open source libraries for a wide range of applications in computational stellar astrophysics. A newly designed 1-D stellar evolution module, MESA star, combines many of the numerical and physics modules for simulations of a wide range of stellar evolution scenarios ranging from very-low mass to massive stars, including advanced evolutionary phases. MESA star solves the fully coupled structure and composition equations simultaneously. It uses adaptive mesh refinement and sophisticated timestep controls, and supports shared memory parallelism based on OpenMP. Independently usable modules provide equation of state, opacity, nuclear reaction rates, and atmosphere boundary conditions. Each module is constructed as a separate Fortran 95 library with its own public interface. Examples include comparisons to other codes and show evolutionary tracks of very low mass stars, brown dwarfs, and gas giant planets; the complete evolution of a 1 Msun star from the pre-main sequence to a cooling white dwarf; the Solar sound speed profile; the evolution of intermediate mass stars through the thermal pulses on the He-shell burning AGB phase; the interior structure of slowly pulsating B Stars and Beta Cepheids; evolutionary tracks of massive stars from the pre-main sequence to the onset of core collapse; stars undergoing Roche lobe overflow; and accretion onto a neutron star.","topic_id":"21831","bibcode":"2010ascl.soft10083P","views":"51","site_list":["http:\/\/mesa.sourceforge.net\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1009.1622"]},
		{"ascl_id":"1010.084","title":"WhiskyMHD: Numerical Code for General Relativistic Magnetohydrodynamics","credit":"Baiotti, Luca; Giacomazzo, Bruno; Hawke, Ian; et al.","abstract":"Whisky is a code to evolve the equations of general relativistic hydrodynamics (GRHD) and magnetohydrodynamics (GRMHD) in 3D Cartesian coordinates on a curved dynamical background. It was originally developed by and for members of the  EU Network on Sources of Gravitational Radiation  and is based on the Cactus Computational Toolkit. Whisky can also implement adaptive mesh refinement (AMR) if compiled together with Carpet.\r\n\r\nWhisky has grown from earlier codes such as GR3D and GRAstro_Hydro, but has been rewritten to take advantage of some of the latest research performed here in the EU. The motivation behind Whisky is to compute gravitational radiation waveforms for systems that involve matter. Examples would include the merger of a binary system containing a neutron star, which are expected to be reasonably common in the universe and expected to produce substantial amounts of radiation. Other possible sources are given in the projects list.","topic_id":"21832","bibcode":"2010ascl.soft10084B","views":"48","site_list":["http:\/\/www.whiskycode.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/gr-qc\/0403029","http:\/\/arxiv.org\/abs\/gr-qc\/0701109"]},
		{"ascl_id":"1010.085","title":"Network Tools for Astronomical Data Retrieval","credit":"Schombert, James","abstract":"The first step in a science project is the acquisition and understanding of the relevant data. The tools range from simple data transfer methods to more complex browser-emulating scripts. When integrated with a defined sample or catalog, these scripts provide seamless techniques to retrieve and store data of varying types. These tools can be used to leapfrog from website to website to acquire multi-wavelength datasets. This project demonstrates the capability to use multiple data websites, in conjunction, to perform the type of calculations once reserved for on-site datasets.","topic_id":"21890","bibcode":"2010ascl.soft10085S","views":"39","site_list":["http:\/\/abyss.uoregon.edu\/~js\/network\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0910.0896"]},
		{"ascl_id":"1011.001","title":"Identikit 1: A Modeling Tool for Interacting Disk Galaxies","credit":"Barnes, Joshua E.; Hibbard, John E.","abstract":"By combining test-particle and self-consistent techniques, we have developed a method to rapidly explore the parameter space of galactic encounters. Our method, implemented in an interactive graphics program, can be used to find the parameters required to reproduce the observed morphology and kinematics of interacting disk galaxies. We test this system on an artificial data-set of 36 equal-mass merging encounters, and show that it is usually possible to reproduce the morphology and kinematics of these encounters and that a good match strongly constrains the encounter parameters.","topic_id":"21886","bibcode":"2010ascl.soft11001B","views":"40","site_list":["http:\/\/www.ifa.hawaii.edu\/faculty\/barnes\/research\/identikit\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0811.3039"]},
		{"ascl_id":"1011.002","title":"DAOSPEC: An Automatic Code for Measuring Equivalent Widths in High-resolution Stellar Spectra","credit":"Stetson, P. B.; Pancino, E.","abstract":"DAOSPEC is a Fortran code for measuring equivalent widths of absorption lines in stellar spectra with minimal human involvement. It works with standard FITS format files and it is designed for use with high resolution (R&gt;15000) and high signal-to-noise-ratio (S\/N&gt;30) spectra that have been binned on a linear wavelength scale. First, we review the analysis procedures that are usually employed in the literature. Next, we discuss the principles underlying DAOSPEC and point out similarities and differences with respect to conventional measurement techniques. Then experiments with artificial and real spectra are discussed to illustrate the capabilities and limitations of DAOSPEC, with special attention given to the issues of continuum placement; radial velocities; and the effects of strong lines and line crowding. Finally, quantitative comparisons with other codes and with results from the literature are also presented.","topic_id":"21887","bibcode":"2010ascl.soft11002S","views":"40","site_list":["http:\/\/www1.cadc-ccda.hia-iha.nrc-cnrc.gc.ca\/community\/STETSON\/daospec\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0811.2932"]},
		{"ascl_id":"1011.003","title":"ZPEG: An Extension of the Galaxy Evolution Model PEGASE.2","credit":"Le Borgne, Damien; Rocca-Volmerange, Brigitte","abstract":"Photometric redshifts are estimated on the basis of template scenarios with the help of the code ZPEG, an extension of the galaxy evolution model PEGASE.2 and available on the PEGASE web site. The spectral energy distribution (SED) templates are computed for nine spectral types including starburst, irregular, spiral and elliptical. Dust, extinction and metal effects are coherently taken into account, depending on evolution scenarios. The sensitivity of results to adding near-infrared colors and IGM absorption is analyzed. A comparison with results of other models without evolution measures the evolution factor which systematically increases the estimated photometric redshift values by $Delta z$ &gt; 0.2 for z &gt; 1.5. Moreover we systematically check that the evolution scenarios match observational standard templates of nearby galaxies, implying an age constraint of the stellar population at z=0 for each type. The respect of this constraint makes it possible to significantly improve the accuracy of photometric redshifts by decreasing the well-known degeneracy problem. The method is applied to the HDF-N sample. From fits on SED templates by a $chi^2$-minimization procedure, not only is the photometric redshift derived but also the corresponding spectral type and the formation redshift $z_for$ when stars first formed. Early epochs of galaxy formation z &gt; 5 are found from this new method and results are compared to faint galaxy count interpretations.","topic_id":"21889","bibcode":"2010ascl.soft11003L","views":"110","site_list":["http:\/\/www2.iap.fr\/pegase\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0202359"]},
		{"ascl_id":"1011.004","title":"MARS: The MAGIC Analysis and Reconstruction Software","credit":"Moralejo, R. A.; Gaug, M.; Carmona, E.; Colin, P.; Delgado, C.; Lombardi, S.; Mazin, D.; Scalzotto, V.; Sitarek, J.; Tescaro, D.","abstract":"With the commissioning of the second MAGIC gamma-ray Cherenkov telescope situated close to MAGIC-I, the standard analysis package of the MAGIC collaboration, MARS, has been upgraded in order to perform the stereoscopic reconstruction of the detected atmospheric showers. MARS is a ROOT-based code written in C++, which includes all the necessary algorithms to transform the raw data recorded by the telescopes into information about the physics parameters of the observed targets. An overview of the methods for extracting the basic shower parameters is presented, together with a description of the tools used in the background discrimination and in the estimation of the gamma-ray source spectra.","topic_id":"21891","bibcode":"2010ascl.soft11004M","views":"41","site_list":["http:\/\/magic.astro.uni-wuerzburg.de\/mars\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0907.0943"]},
		{"ascl_id":"1011.005","title":"Shape of Cosmic String Loops","credit":"Copi, Craig J.; Vachaspati, Tanmay","abstract":"Complicated cosmic string loops will fragment until they reach simple, non-intersecting (\"stable\") configurations. Through extensive numerical study we characterize these attractor loop shapes including their length, velocity, kink, and cusp distributions. We find that an initial loop containing $M$ harmonic modes will, on average, split into 3M stable loops. These stable loops are approximately described by the degenerate kinky loop, which is planar and rectangular, independently of the number of modes on the initial loop. This is confirmed by an analytic construction of a stable family of perturbed degenerate kinky loops. The average stable loop is also found to have a 40% chance of containing a cusp. We examine the properties of stable loops of different lengths and find only slight variation. Finally we develop a new analytic scheme to explicitly solve the string constraint equations.","topic_id":"21911","bibcode":"2010ascl.soft11005C","views":"39","site_list":["http:\/\/www.phys.cwru.edu\/projects\/strings\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1010.4030"]},
		{"ascl_id":"1011.006","title":"DAME: A Web Oriented Infrastructure for Scientific Data Mining & Exploration","credit":"Brescia, Massimo; Longo, Giuseppe; Djorgovski, George S.; Cavuoti, Stefano; D'Abrusco, Raffaele; Donalek, Ciro; di Guido, Alessandro; Fiore, Michelangelo; Garofalo, Mauro; Laurino, Omar; Mahabal, Ashish; Manna, Francesco; Nocella, Alfonso; D'Angelo, Giovanni; Paolillo, Maurizio","abstract":"DAME (DAta Mining & Exploration) is an innovative, general purpose, Web-based, VObs compliant, istributed data mining infrastructure specialized in Massive Data Sets exploration with machine learning methods. Initially fine tuned to deal with astronomical data only, DAME has evolved in a general purpose platform which has found applications also in other domains of human endeavor.","topic_id":"21912","bibcode":"2010ascl.soft11006B","views":"55","site_list":["http:\/\/voneural.na.infn.it\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1010.4843"]},
		{"ascl_id":"1011.007","title":"RAMSES: A new N-body and hydrodynamical code","credit":"Teyssier, Romain","abstract":"A new N-body and hydrodynamical code, called RAMSES, is presented. It has been designed to study structure formation in the universe with high spatial resolution. The code is based on Adaptive Mesh Refinement (AMR) technique, with a tree based data structure allowing recursive grid refinements on a cell-by-cell basis. The N-body solver is very similar to the one developed for the ART code (Kravtsov et al. 97), with minor differences in the exact implementation. The hydrodynamical solver is based on a second-order Godunov method, a modern shock-capturing scheme known to compute accurately the thermal history of the fluid component. The accuracy of the code is carefully estimated using various test cases, from pure gas dynamical tests to cosmological ones. The specific refinement strategy used in cosmological simulations is described, and potential spurious effects associated to shock waves propagation in the resulting AMR grid are discussed and found to be negligible. Results obtained in a large N-body and hydrodynamical simulation of structure formation in a low density LCDM universe are finally reported, with 256^3 particles and 4.1 10^7 cells in the AMR grid, reaching a formal resolution of 8192^3. A convergence analysis of different quantities, such as dark matter density power spectrum, gas pressure power spectrum and individual haloes temperature profiles, shows that numerical results are converging down to the actual resolution limit of the code, and are well reproduced by recent analytical predictions in the framework of the halo model.","topic_id":"21913","bibcode":"2010ascl.soft11007T","views":"61","site_list":["http:\/\/www.ics.uzh.ch\/~teyssier\/ramses\/RAMSES.html","https:\/\/bitbucket.org\/rteyssie\/ramses"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002A%26A...385..337T"]},
		{"ascl_id":"1011.008","title":"Binsim: Visualising Interacting Binaries in 3D","credit":"Hynes, R. I.","abstract":"I have developed a code which allows images to be produced of a variety of interacting binaries for any system parameters. The resulting images are not only helpful in visualising the geometry of a given system but are also helpful in talks and educational work.","topic_id":"21919","bibcode":"2010ascl.soft11008H","views":"105","site_list":["https:\/\/bitbucket.org\/astrobokonon\/binsim-reborn\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0110058"]},
		{"ascl_id":"1011.009","title":"DRAGON: Monte Carlo Generator of Particle Production from a Fragmented Fireball in Ultrarelativistic Nuclear Collisions","credit":"Tomasik, Boris","abstract":"A Monte Carlo generator of the final state of hadrons emitted from an ultrarelativistic nuclear collision is introduced. An important feature of the generator is a possible fragmentation of the fireball and emission of the hadrons from fragments. Phase space distribution of the fragments is based on the blast wave model extended to azimuthally non-symmetric fireballs. Parameters of the model can be tuned and this allows to generate final states from various kinds of fireballs. A facultative output in the OSCAR1999A format allows for a comprehensive analysis of phase-space distributions and\/or use as an input for an afterburner. DRAGON's purpose is to produce artificial data sets which resemble those coming from real nuclear collisions provided fragmentation occurs at hadronisation and hadrons are emitted from fragments without any further scattering. Its name, DRAGON, stands for DRoplet and hAdron GeneratOr for Nuclear collisions. In a way, the model is similar to THERMINATOR, with the crucial difference that emission from fragments is included.","topic_id":"21918","bibcode":"2010ascl.soft11009T","views":"43","site_list":["http:\/\/www.fpv.umb.sk\/~tomasik\/Boris_Tomasik\/Software.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0806.4770"]},
		{"ascl_id":"1011.010","title":"Global Sky Model (GSM): A Model of Diffuse Galactic Radio Emission from 10 MHz to 100 GHz","credit":"de Oliveira-Costa, Angelica; Tegmark, Max; Gaensler, B. M.; Jonas, Justin; Landecker, T. L.; Reich, Patricia","abstract":"Understanding diffuse Galactic radio emission is interesting both in its own right and for minimizing foreground contamination of cosmological measurements. Cosmic Microwave Background experiments have focused on frequencies &gt; 10 GHz, whereas 21 cm tomography of the high redshift universe will mainly focus on &lt; 0.2 GHz, for which less is currently known about Galactic emission. Motivated by this, we present a global sky model derived from all publicly available total power large-area radio surveys, digitized with optical character recognition when necessary and compiled into a uniform format, as well as the new Villa Elisa data extending the 1.4 GHz map to the entire sky. We quantify statistical and systematic uncertainties in these surveys by comparing them with various global multi-frequency model fits. We find that a principal component based model with only three components can fit the 11 most accurate data sets (at 10, 22, 45 & 408 MHz and 1.4, 2.3, 23, 33, 41, 61, 94 GHz) to an accuracy around 1%-10% depending on frequency and sky region. The data compilation and software returning a predicted all-sky map at any frequency from 10 MHz to 100 GHz are publicly available at the link below.","topic_id":"21920","bibcode":"2010ascl.soft11010D","views":"54","site_list":["http:\/\/space.mit.edu\/home\/angelica\/gsm\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0802.1525"]},
		{"ascl_id":"1011.011","title":"turboGL: Accurate Modeling of Weak Lensing","credit":"Kainulainen, Kimmo; Marra, Valerio","abstract":"turboGL is a fast Mathematica code based on a stochastic approach to cumulative weak lensing. It can easily compute the lensing PDF relative to arbitrary halo mass distributions, selection biases, number of observations, halo profiles and evolutions, making it a useful tool to study how lensing depends on cosmological parameters and impact on observations.","topic_id":"21917","bibcode":"2010ascl.soft11011K","views":"48","site_list":["http:\/\/www.turbogl.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1011.0732"]},
		{"ascl_id":"1011.012","title":"DEFROST: A New Code for Simulating Preheating after Inflation","credit":"Frolov, Andrei V.","abstract":"At the end of inflation, dynamical instability can rapidly deposit the energy of homogeneous cold inflaton into excitations of other fields. This process, known as preheating, is rather violent, inhomogeneous and non-linear, and has to be studied numerically. This paper presents a new code for simulating scalar field dynamics in expanding universe written for that purpose. Compared to available alternatives, it significantly improves both the speed and the accuracy of calculations, and is fully instrumented for 3D visualization. We reproduce previously published results on preheating in simple chaotic inflation models, and further investigate non-linear dynamics of the inflaton decay. Surprisingly, we find that the fields do not want to thermalize quite the way one would think. Instead of directly reaching equilibrium, the evolution appears to be stuck in a rather simple but quite inhomogeneous state. In particular, one-point distribution function of total energy density appears to be universal among various two-field preheating models, and is exceedingly well described by a lognormal distribution. It is tempting to attribute this state to scalar field turbulence.","topic_id":"21925","bibcode":"2010ascl.soft11012F","views":"43","site_list":["http:\/\/www.sfu.ca\/physics\/cosmology\/defrost\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0809.4904"]},
		{"ascl_id":"1011.013","title":"EasyLTB: Code for Testing LTB Models against Cosmology\r\nConfronting Lemaitre-Tolman-Bondi Models with Observational Cosmology","credit":"Garcia-Bellido, Juan; Haugboelle, Troels","abstract":"The possibility that we live in a special place in the universe, close to the centre of a large void, seems an appealing alternative to the prevailing interpretation of the acceleration of the universe in terms of a LCDM model with a dominant dark energy component. In this paper we confront the asymptotically flat Lemaitre-Tolman-Bondi (LTB) models with a series of observations, from Type Ia Supernovae to Cosmic Microwave Background and Baryon Acoustic Oscillations data. We propose two concrete LTB models describing a local void in which the only arbitrary functions are the radial dependence of the matter density Omega_M and the Hubble expansion rate H. We find that all observations can be accommodated within 1 sigma, for our models with 4 or 5 independent parameters. The best fit models have a chi^2 very close to that of the LCDM model. We perform a simple Bayesian analysis and show that one cannot exclude the hypothesis that we live within a large local void of an otherwise Einstein-de Sitter model.","topic_id":"21926","bibcode":"2010ascl.soft11013G","views":"45","site_list":["http:\/\/www.phys.au.dk\/~haugboel\/software.shtml"],"ref_list":["http:\/\/arxiv.org\/abs\/0802.1523"]},
		{"ascl_id":"1011.014","title":"CO5BOLD: COnservative COde for the COmputation of COmpressible COnvection in a BOx of L Dimensions with l=2,3","credit":"Freytag, Bernd; Steffen, Matthias; Wedemeyer-B\u00f6hm, Sven; Ludwig, Hans-G\u00fcnter; Leenaarts, Jorrit; Schaffenberger, Werner; Allard, France; Chiavassa, Andrea; H\u00f6fner, Susanne; Kamp, Inga; Steiner, Oskar","abstract":"CO5BOLD - nickname COBOLD - is the short form of \"COnservative COde for the COmputation of COmpressible COnvection in a BOx of L Dimensions with l=2,3''.\r\n\r\nIt is used to model solar and stellar surface convection. For solar-type stars only a small fraction of the stellar surface layers are included in the computational domain. In the case of red supergiants the computational box contains the entire star. Recently, the model range has been extended to sub-stellar objects (brown dwarfs).\r\n\r\nCO5BOLD solves the coupled non-linear equations of compressible hydrodynamics in an external gravity field together with non-local frequency-dependent radiation transport. Operator splitting is applied to solve the equations of hydrodynamics (including gravity), the radiative energy transfer (with a long-characteristics or a short-characteristics ray scheme), and possibly additional 3D (turbulent) diffusion in individual sub steps. The 3D hydrodynamics step is further simplified with directional splitting (usually). The 1D sub steps are performed with a Roe solver, accounting for an external gravity field and an arbitrary equation of state from a table.\r\n\r\nThe radiation transport is computed with either one of three modules:\r\n\r\n<ul><li>MSrad module: It uses long characteristics. The lateral boundaries have to be periodic. Top and bottom can be closed or open (\"solar module'').\r\n<\/li><li>LHDrad module: It uses long characteristics and is restricted to an equidistant grid and open boundaries at all surfaces (old \"supergiant module'').\r\n<\/li><li>SHORTrad module: It uses short characteristics and is restricted to an equidistant grid and open boundaries at all surfaces (new \"supergiant module'').<\/li><\/ul>\r\nThe code was supplemented with an (optional) MHD version [Schaffenberger et al. (2005)] that can treat magnetic fields. There are also modules for the formation and advection of dust available. The current version now contains the treatment of chemical reaction networks, mostly used for the formation of molecules [Wedemeyer-B\u00f6hm et al. (2005)], and hydrogen ionization [Leenaarts & Wedemeyer-B\u00f6hm (2005)], too.\r\n\r\nCO5BOLD is written in Fortran90. The parallelization is done with OpenMP directives.","topic_id":"21940","bibcode":"2010ascl.soft11014F","views":"56","site_list":["http:\/\/www.astro.uu.se\/~bf\/co5bold_main.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0701029"]},
		{"ascl_id":"1011.015","title":"Geokerr: A Fast New Public Code for Computing Photon Orbits in a Kerr Spacetime","credit":"Dexter, Jason; Agol, Eric","abstract":"Relativistic radiative transfer problems require the calculation of photon trajectories in curved spacetime. We present a novel technique for rapid and accurate calculation of null geodesics in the Kerr metric. The equations of motion from the Hamilton-Jacobi equation are reduced directly to Carlson's elliptic integrals, simplifying algebraic manipulations and allowing all coordinates to be computed semi-analytically for the first time. We discuss the method, its implementation in a freely available FORTRAN code, and its application to toy problems from the literature.","topic_id":"21948","bibcode":"2010ascl.soft11015D","views":"37","site_list":["http:\/\/www.astro.washington.edu\/users\/agol\/geokerr\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0903.0620"]},
		{"ascl_id":"1011.016","title":"Non-LTE Models and Theoretical Spectra of Accretion Disks in Active Galactic Nuclei. \r\nIII. Integrated Spectra for Hydrogen-Helium Disks","credit":"Hubeny, Ivan; Agol, Eric; Blaes, Omer; Krolik, Julian","abstract":"We have constructed a grid of non-LTE disk models for a wide range of black hole mass and mass accretion rate, for several values of viscosity parameter alpha, and for two extreme values of the black hole spin: the maximum-rotation Kerr black hole, and the Schwarzschild (non-rotating) black hole. Our procedure calculates self-consistently the vertical structure of all disk annuli together with the radiation field, without any approximations imposed on the optical thickness of the disk, and without any ad hoc approximations to the behavior of the radiation intensity. The total spectrum of a disk is computed by summing the spectra of the individual annuli, taking into account the general relativistic transfer function. The grid covers nine values of the black hole mass between M = 1\/8 and 32 billion solar masses with a two-fold increase of mass for each subsequent value; and eleven values of the mass accretion rate, each a power of 2 times 1 solar mass\/year. The highest value of the accretion rate corresponds to 0.3 Eddington. We show the vertical structure of individual annuli within the set of accretion disk models, along with their local emergent flux, and discuss the internal physical self-consistency of the models. We then present the full disk-integrated spectra, and discuss a number of observationally interesting properties of the models, such as optical\/ultraviolet colors, the behavior of the hydrogen Lyman limit region, polarization, and number of ionizing photons. Our calculations are far from definitive in terms of the input physics, but generally we find that our models exhibit rather red optical\/UV colors. Flux discontinuities in the region of the hydrogen Lyman limit are only present in cool, low luminosity models, while hotter models exhibit blueshifted changes in spectral slope.","topic_id":"21950","bibcode":"2010ascl.soft11016H","views":"48","site_list":["http:\/\/www.physics.ucsb.edu\/~blaes\/habk\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9911317"]},
		{"ascl_id":"1011.017","title":"Occultation and Microlensing","credit":"Agol, Eric","abstract":"Occultation and microlensing are different limits of the same phenomena of one body passing in front of another body. We derive a general exact analytic expression which describes both microlensing and occultation in the case of spherical bodies with a source of uniform brightness and a non-relativistic foreground body. We also compute numerically the case of a source with quadratic limb-darkening. In the limit that the gravitational deflection angle is comparable to the angular size of the foreground body, both microlensing and occultation occur as the objects align. Such events may be used to constrain the size ratio of the lens and source stars, the limb-darkening coefficients of the source star, and the surface gravity of the lens star (if the lens and source distances are known). Application of these results to microlensing during transits in binaries and giant-star microlensing are discussed. These results unify the microlensing and occultation limits and should be useful for rapid model fitting of microlensing, eclipse, and \"microccultation\" events.","topic_id":"21952","bibcode":"2010ascl.soft11017A","views":"42","site_list":["http:\/\/www.astro.washington.edu\/users\/agol\/microccult.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0207228"]},
		{"ascl_id":"1011.018","title":"Transit of a Spherical Planet of a Stellar Chromosphere which is Geometrically Thin","credit":"Schlawin, Everett; Agol, Eric; Walkowicz, Lucianne; Covey, Kevin; Lloyd, James P.","abstract":"Transit light curves for stellar continua have only one minimum and a \"U\" shape. By contrast, transit curves for optically thin chromospheric emission lines can have a \"W\" shape because of stellar limb-brightening. We calculate light curves for an optically thin shell of emission and fit these models to time-resolved observations of Si IV absorption by the planet HD209458b. We find that the best fit Si IV absorption model has R_p,SIV\/R_*= 0.34+0.07-0.12, similar to the Roche lobe of the planet. While the large radius is only at the limit of statistical significance, we develop formulae applicable to transits of all optically thin chromospheric emission lines.","topic_id":"21951","bibcode":"2010ascl.soft11018S","views":"55","site_list":["http:\/\/www.astro.washington.edu\/users\/agol\/chromosphere.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1008.1073"]},
		{"ascl_id":"1011.019","title":"FLY: MPI-2 High Resolution code for LSS Cosmological Simulations","credit":"Becciani, U.; Antonuccio, V.; Comparato, M.","abstract":"Cosmological simulations of structures and galaxies formations have played a fundamental role in the study of the origin, formation and evolution of the Universe. These studies improved enormously with the use of supercomputers and parallel systems and, recently, grid based systems and Linux clusters. Now we present the new version of the tree N-body parallel code FLY that runs on a PC Linux Cluster using the one side communication paradigm MPI-2 and we show the performances obtained. FLY is included in the Computer Physics Communication Program Library. This new version was developed using the Linux Cluster of CINECA, an IBM Cluster with 1024 Intel Xeon Pentium IV 3.0 Ghz. The results show that it is possible to run a 64 Million particle simulation in less than 15 minutes for each timestep, and the code scalability with the number of processors is achieved. This lead us to propose FLY as a code to run very large N-Body simulations with more than $10^{9}$ particles with the higher resolution of a pure tree code.","topic_id":"21999","bibcode":"2010ascl.soft11019B","views":"40","site_list":["http:\/\/www.ct.astro.it\/fly\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0703526"]},
		{"ascl_id":"1011.020","title":"VisIVO: Integrated Tools and Services for Large-Scale Astrophysical Visualization","credit":"Becciani, U.; Costa, A.; Antonuccio-Delogu, V.; Caniglia, G.; Comparato, M.; Gheller, C.; Jin, Z.; Krokos, M.; Massimino, P.","abstract":"VisIVO is an integrated suite of tools and services specifically designed for the Virtual Observatory. This suite constitutes a software framework for effective visual discovery in currently available (and next-generation) very large-scale astrophysical datasets. VisIVO consists of VisiVO Desktop - a stand alone application for interactive visualization on standard PCs, VisIVO Server - a grid-enabled platform for high performance visualization and VisIVO Web - a custom designed web portal supporting services based on the VisIVO Server functionality. The main characteristic of VisIVO is support for high-performance, multidimensional visualization of very large-scale astrophysical datasets. Users can obtain meaningful visualizations rapidly while preserving full and intuitive control of the relevant visualization parameters. This paper focuses on newly developed integrated tools in VisIVO Server allowing intuitive visual discovery with 3D views being created from data tables. VisIVO Server can be installed easily on any web server with a database repository. We discuss briefly aspects of our implementation of VisiVO Server on a computational grid and also outline the functionality of the services offered by VisIVO Web. Finally we conclude with a summary of our work and pointers to future developments.","topic_id":"22000","bibcode":"2010ascl.soft11020B","views":"359","site_list":["http:\/\/visivo.oact.inaf.it:8080\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1005.1837"]},
		{"ascl_id":"1011.021","title":"GRALE: A genetic algorithm for the non-parametric inversion of strong lensing systems","credit":"Liesenborgs, J.; de Rijcke, S.; Dejonghe, H.","abstract":"We present a non-parametric technique to infer the projected-mass distribution of a gravitational lens system with multiple strong-lensed images. The technique involves a dynamic grid in the lens plane on which the mass distribution of the lens is approximated by a sum of basis functions, one per grid cell. We used the projected mass densities of Plummer spheres as basis functions. A genetic algorithm then determines the mass distribution of the lens by forcing images of a single source, projected back onto the source plane, to coincide as well as possible. Averaging several tens of solutions removes the random fluctuations that are introduced by the reproduction process of genomes in the genetic algorithm and highlights those features common to all solutions. Given the positions of the images and the redshifts of the sources and the lens, we show that the mass of a gravitational lens can be retrieved with an accuracy of a few percent and that, if the sources sufficiently cover the caustics, the mass distribution of the gravitational lens can also be reliably retrieved. A major advantage of the algorithm is that it makes full use of the information contained in the radial images, unlike methods that minimise the residuals of the lens equation, and is thus able to accurately reconstruct also the inner parts of the lens.","topic_id":"22002","bibcode":"2010ascl.soft11021L","views":"42","site_list":["http:\/\/research.edm.uhasselt.be\/~jori\/page\/index.php?n=Physics.Grale"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0601124"]},
		{"ascl_id":"1011.022","title":"yt: A Multi-Code Analysis Toolkit for Astrophysical Simulation Data","credit":"Turk, Matthew J.; Smith, Britton D.; Oishi, Jeffrey S.; Skory, Stephen; Skillman, Samuel W.; Abel, Tom; Norman, Michael L.","abstract":"yt is an open source, community-developed astrophysical analysis and visualization toolkit. Originally designed for handling Enzo's structure adaptive mesh refinement (AMR) data, yt has been extended to work with several different simulation methods and simulation codes including Orion, RAMSES, and FLASH. Analysis and visualization with yt are oriented around physically relevant quantities rather than quantities native to astrophysical simulation codes. yt can be used for projections, multivariate volume rendering, multi-dimensional histograms, halo finding, light cone generation and topologically-connected isocontour identification.","topic_id":"22098","bibcode":"2010ascl.soft11022T","views":"87","site_list":["http:\/\/yt-project.org\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ApJS..192....9T"]},
		{"ascl_id":"1011.023","title":"HyRec: A Fast and Highly Accurate Primordial Hydrogen and Helium Recombination Code","credit":"Ali-Ha\u00efmoud, Yacine; Hirata, Christopher M.","abstract":"We present a state-of-the-art primordial recombination code, HyRec, including all the physical effects that have been shown to significantly affect recombination. The computation of helium recombination includes simple analytic treatments of hydrogen continuum opacity in the He I 2 1P - 1 1S line, the He I] 2 3P - 1 1S line, and treats feedback between these lines within the on-the-spot approximation. Hydrogen recombination is computed using the effective multilevel atom method, virtually accounting for an infinite number of excited states. We account for two-photon transitions from 2s and higher levels as well as frequency diffusion in Lyman-alpha with a full radiative transfer calculation. We present a new method to evolve the radiation field simultaneously with the level populations and the free electron fraction. These computations are sped up by taking advantage of the particular sparseness pattern of the equations describing the radiative transfer. The computation time for a full recombination history is ~2 seconds. This makes our code well suited for inclusion in Monte Carlo Markov chains for cosmological parameter estimation from upcoming high-precision cosmic microwave background anisotropy measurements.","topic_id":"22099","bibcode":"2010ascl.soft11023A","views":"42","site_list":["http:\/\/www.sns.ias.edu\/~yacine\/hyrec\/hyrec.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1011.3758"]},
		{"ascl_id":"1101.001","title":"Second-order Tight-coupling Code","credit":"Cyr-Racine, Francis-Yan; Sigurdson, Kris","abstract":"Prior to recombination photons, electrons, and atomic nuclei rapidly scattered and behaved, almost, like a single tightly-coupled photon-baryon plasma. In order to solve the cosmological perturbation equations during that time, Cosmic Microwave Background (CMB) codes use the so-called tight-coupling approximation in which the problematic terms (i.e. the source of the stiffness) are expanded in inverse powers of the Thomson Opacity. Most codes only keep the terms linear in the inverse Thomson Opacity. We have developed a second-order tight-coupling code to test the validity of the usual first-order tight-coupling code. It is based on the publicly available code <a href=\"http:\/\/ascl.net\/1102.026\">CAMB<\/a>.","topic_id":"22558","bibcode":"2011ascl.soft01001C","views":"38","site_list":["http:\/\/www.phas.ubc.ca\/~francis\/Codes.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1012.0569"]},
		{"ascl_id":"1101.002","title":"NDSPMHD Smoothed Particle Magnetohydrodynamics Code","credit":"Price, Daniel J.","abstract":"This paper presents an overview and introduction to Smoothed Particle Hydrodynamics and Magnetohydrodynamics in theory and in practice. Firstly, we give a basic grounding in the fundamentals of SPH, showing how the equations of motion and energy can be self-consistently derived from the density estimate. We then show how to interpret these equations using the basic SPH interpolation formulae and highlight the subtle difference in approach between SPH and other particle methods. In doing so, we also critique several `urban myths' regarding SPH, in particular the idea that one can simply increase the `neighbour number' more slowly than the total number of particles in order to obtain convergence. We also discuss the origin of numerical instabilities such as the pairing and tensile instabilities. Finally, we give practical advice on how to resolve three of the main issues with SPMHD: removing the tensile instability, formulating dissipative terms for MHD shocks and enforcing the divergence constraint on the particles, and we give the current status of developments in this area. Accompanying the paper is the first public release of the NDSPMHD SPH code, a 1, 2 and 3 dimensional code designed as a testbed for SPH\/SPMHD algorithms that can be used to test many of the ideas and used to run all of the numerical examples contained in the paper.","topic_id":"22559","bibcode":"2011ascl.soft01002P","views":"44","site_list":["http:\/\/users.monash.edu.au\/~dprice\/ndspmhd\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1012.1885"]},
		{"ascl_id":"1101.003","title":"IGMtransfer: Intergalactic Radiative Transfer Code","credit":"Laursen, Peter","abstract":"This document describes the publically available numerical code \"IGMtransfer\", capable of performing intergalactic radiative transfer (RT) of light in the vicinity of the Lyman alpha (Lya) line. Calculating the RT in a (possibly adaptively refined) grid of cells resulting from a cosmological simulation, the code returns 1) a \"transmission function\", showing how the intergalactic medium (IGM) affects the Lya line at a given redshift, and 2) the \"average transmission\" of the IGM, making it useful for studying the results of reionization simulations.","topic_id":"22560","bibcode":"2011ascl.soft01003L","views":"36","site_list":["http:\/\/www.dark-cosmology.dk\/~pela\/IGMtransfer.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1012.2886"]},
		{"ascl_id":"1101.004","title":"InterpMC: Caching and Interpolated Likelihoods -- Accelerating Cosmological Monte Carlo Markov Chains","credit":"Bouland, Adam; Easther, Richard; Rosenfeld, Katherine","abstract":"We describe a novel approach to accelerating Monte Carlo Markov Chains. Our focus is cosmological parameter estimation, but the algorithm is applicable to any problem for which the likelihood surface is a smooth function of the free parameters and computationally expensive to evaluate. We generate a high-order interpolating polynomial for the log-likelihood using the first points gathered by the Markov chains as a training set. This polynomial then accurately computes the majority of the likelihoods needed in the latter parts of the chains. We implement a simple version of this algorithm as a patch (InterpMC) to <a href=\"http:\/\/ascl.net\/1106.025\">CosmoMC<\/a> and show that it accelerates parameter estimatation by a factor of between two and four for well-converged chains. The current code is primarily intended as a \"proof of concept\", and we argue that there is considerable room for further performance gains. Unlike other approaches to accelerating parameter fits, we make no use of precomputed training sets or special choices of variables, and InterpMC is almost entirely transparent to the user.","topic_id":"22565","bibcode":"2011ascl.soft01004B","views":"46","site_list":["http:\/\/easther.physics.yale.edu\/Richard_Easther\/Download_InterpMC.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1012.5299"]},
		{"ascl_id":"1101.005","title":"CMHOG: Code for Ideal Compressible Hydrodynamics","credit":"Piner, B. Glenn; Stone, James M.; Teuben, Peter J.","abstract":"CMHOG (Connection Machine Higher Order Godunov) is a code for ideal compressible hydrodynamics based on the Lagrange-plus-remap version of the piecewise parabolic method (PPM) of Colella & Woodward (1984, <span style=\"font-style: italic\">J. Comp. Phys.<\/span>, 74, 1). It works in one-, two- or three-dimensional Cartesian coordinates with either an adiabatic or isothermal equation of state. A limited amount of extra physics has been added using operator splitting, including optically-thin radiative cooling, and chemistry for combustion simulations.","topic_id":"22624","bibcode":"2011ascl.soft01005P","views":"53","site_list":["http:\/\/www.astro.princeton.edu\/~jstone\/cmhog.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1995ApJ...449..508P"]},
		{"ascl_id":"1101.006","title":"NIRVANA: A Numerical Tool for Astrophysical Gas Dynamics","credit":"Ziegler, U.","abstract":"The NIRVANA code is capable of the simulation of multi-scale self-gravitational magnetohydrodynamics problems in three space dimensions employing the technique of adaptive mesh refinement. The building blocks of NIRVANA are (i) a fully conservative, divergence-free Godunov-type central scheme for the solution of the equations of magnetohydrodynamics; (ii) a block-structured mesh refinement algorithm which automatically adds and removes elementary grid blocks whenever necessary to achieve adequate resolution and; (iii) an adaptive mesh Poisson solver based on multigrid philosophy which incorporates the so-called elliptic matching condition to keep the gradient of the gravitational potential continous at fine\/coarse mesh interfaces.","topic_id":"22635","bibcode":"2011ascl.soft01006Z","views":"49","site_list":["http:\/\/nirvana-code.aip.de\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005A%26A...435..385Z"]},
		{"ascl_id":"1101.007","title":"Galaxia: A Code to Generate a Synthetic Survey of the Milky Way","credit":"Sharma, Sanjib; Bland-Hawthorn, Joss; Johnston, Kathryn V.; Binney, James","abstract":"We present here a fast code for creating a synthetic survey of the Milky Way. Given one or more color-magnitude bounds, a survey size and geometry, the code returns a catalog of stars in accordance with a given model of the Milky Way. The model can be specified by a set of density distributions or as an N-body realization. We provide fast and efficient algorithms for sampling both types of models. As compared to earlier sampling schemes which generate stars at specified locations along a line of sight, our scheme can generate a continuous and smooth distribution of stars over any given volume. The code is quite general and flexible and can accept input in the form of a star formation rate, age metallicity relation, age velocity dispersion relation and analytic density distribution functions. Theoretical isochrones are then used to generate a catalog of stars and support is available for a wide range of photometric bands. As a concrete example we implement the Besancon Milky Way model for the disc. For the stellar halo we employ the simulated stellar halo N-body models of Bullock & Johnston (2005). In order to sample N-body models, we present a scheme that disperses the stars spawned by an N-body particle, in such a way that the phase space density of the spawned stars is consistent with that of the N-body particles. The code is ideally suited to generating synthetic data sets that mimic near future wide area surveys such as GAIA, LSST and HERMES. As an application we study the prospect of identifying structures in the stellar halo with a simulated GAIA survey.","topic_id":"22700","bibcode":"2011ascl.soft01007S","views":"37","site_list":["http:\/\/galaxia.sourceforge.net\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1101.3561"]},
		{"ascl_id":"1101.008","title":"CRASH: A Block-Adaptive-Mesh Code for Radiative Shock Hydrodynamics","credit":"van der Holst, B.; Toth, G.; Sokolov, I. V.; Powell, K. G.; Holloway, J. P.; Myra, E. S.; Stout, Q.; Adams, M. L.; Morel, J. E.; Drake, R. P.","abstract":"We describe the CRASH (Center for Radiative Shock Hydrodynamics) code, a block adaptive mesh code for multi-material radiation hydrodynamics. The implementation solves the radiation diffusion model with the gray or multigroup method and uses a flux limited diffusion approximation to recover the free-streaming limit. The electrons and ions are allowed to have different temperatures and we include a flux limited electron heat conduction. The radiation hydrodynamic equations are solved in the Eulerian frame by means of a conservative finite volume discretization in either one, two, or three-dimensional slab geometry or in two-dimensional cylindrical symmetry. An operator split method is used to solve these equations in three substeps: (1) solve the hydrodynamic equations with shock-capturing schemes, (2) a linear advection of the radiation in frequency-logarithm space, and (3) an implicit solve of the stiff radiation diffusion, heat conduction, and energy exchange. We present a suite of verification test problems to demonstrate the accuracy and performance of the algorithms. The CRASH code is an extension of the Block-Adaptive Tree Solarwind Roe Upwind Scheme (BATS-R-US) code with this new radiation transfer and heat conduction library and equation-of-state and multigroup opacity solvers. Both CRASH and BATS-R-US are part of the publicly available Space Weather Modeling Framework (SWMF).","topic_id":"22713","bibcode":"2011ascl.soft01008V","views":"50","site_list":["http:\/\/csem.engin.umich.edu\/swmf\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1101.3758"]},
		{"ascl_id":"1101.009","title":"MasQU: Finite Differences on Masked Irregular Stokes Q,U Grids","credit":"Bowyer, Jude; Jaffe, Andrew H.; Novikov, Dmitri I.","abstract":"The detection of B-mode polarization in the CMB is one of the most important outstanding tests of inflationary cosmology. One of the necessary steps for extracting polarization information in the CMB is reducing contamination from so-called \"ambiguous modes\" on a masked sky, which contain leakage from the larger E-mode signal. This can be achieved by utilising derivative operators on the real-space Stokes Q and U parameters. This paper presents an algorithm and a software package to perform this procedure on the nearly full sky, i.e., with projects such as the Planck Surveyor and future satellites in mind; in particular, the package can perform finite differences on masked, irregular grids and is applied to a semi-regular spherical pixellization, the HEALPix grid. The formalism reduces to the known finite-difference solutions in the case of a regular grid. We quantify full-sky improvements on the possible bounds on the CMB B-mode signal. We find that in the specific case of E and B-mode separation, there exists a \"pole problem\" in our formalism which produces signal contamination at very low multipoles l. Several solutions to the \"pole problem\" are presented; one proposed solution facilitates a calculation of a general Gaussian quadrature scheme, which finds application in calculating accurate harmonic coefficients on the HEALPix sphere. Nevertheless, on a masked sphere the software represents a considerable reduction in B-mode noise from limited sky coverage.","topic_id":"22783","bibcode":"2011ascl.soft01009B","views":"39","site_list":["j.bowyer07@imperial.ac.uk"],"ref_list":["http:\/\/arxiv.org\/abs\/1101.0520"]},
		{"ascl_id":"1101.010","title":"TOPCAT: Tool for OPerations on Catalogues And Tables","credit":"Taylor, Mark","abstract":"TOPCAT is an interactive graphical viewer and editor for tabular data. Its aim is to provide most of the facilities that astronomers need for analysis and manipulation of source catalogues and other tables, though it can be used for non-astronomical data as well. It understands a number of different astronomically important formats (including FITS and VOTable) and more formats can be added.\r\n\r\nIt offers a variety of ways to view and analyse tables, including a browser for the cell data themselves, viewers for information about table and column metadata, and facilities for 1-, 2-, 3- and higher-dimensional visualisation, calculating statistics and joining tables using flexible matching algorithms. Using a powerful and extensible Java-based expression language new columns can be defined and row subsets selected for separate analysis. Table data and metadata can be edited and the resulting modified table can be written out in a wide range of output formats.\r\n\r\nIt is a stand-alone application which works quite happily with no network connection. However, because it uses Virtual Observatory (VO) standards, it can cooperate smoothly with other tools in the VO world and beyond, such as VODesktop, Aladin and ds9. Between 2006 and 2009 TOPCAT was developed within the AstroGrid project, and is offered as part of a standard suite of applications on the AstroGrid web site, where you can find information on several other VO tools.\r\n\r\nThe program is written in pure Java and available under the GNU General Public Licence. It has been developed in the UK within the <a href=\"http:\/\/ascl.net\/1110.012\">Starlink<\/a> and AstroGrid projects, and under PPARC and STFC grants. Its underlying table processing facilities are provided by STIL.","topic_id":"22788","bibcode":"2011ascl.soft01010T","views":"95","site_list":["http:\/\/www.star.bristol.ac.uk\/~mbt\/topcat\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1009.3466"]},
		{"ascl_id":"1102.001","title":"N-MODY: A Code for Collisionless N-body Simulations in Modified Newtonian Dynamics","credit":"Londrillo, Pasquale; Nipoti, Carlo","abstract":"N-MODY is a parallel particle-mesh code for collisionless N-body simulations in modified Newtonian dynamics (MOND). N-MODY is based on a numerical potential solver in spherical coordinates that solves the non-linear MOND field equation, and is ideally suited to simulate isolated stellar systems. N-MODY can be used also to compute the MOND potential of arbitrary static density distributions. A few applications of N-MODY indicate that some astrophysically relevant dynamical processes are profoundly different in MOND and in Newtonian gravity with dark matter.","topic_id":"22801","bibcode":"2011ascl.soft02001L","views":"41","site_list":["http:\/\/urania.bo.astro.it\/nipoti\/astrophysics\/codes\/nmody.htm"],"ref_list":["http:\/\/arxiv.org\/abs\/0803.4456","http:\/\/arxiv.org\/abs\/0811.2878v1"]},
		{"ascl_id":"1102.002","title":"PBL: Particle-Based Lensing for Gravitational Lensing Mass Reconstructions of Galaxy Clusters","credit":"Deb, Sanghamitra; Goldberg, David M.; Ramdass, Vede J.","abstract":"We present Particle-Based Lensing (PBL), a new technique for gravitational lensing mass reconstructions of galaxy clusters. Traditionally, most methods have employed either a finite inversion or gridding to turn observational lensed galaxy ellipticities into an estimate of the surface mass density of a galaxy cluster. We approach the problem from a different perspective, motivated by the success of multi-scale analysis in smoothed particle hydrodynamics. In PBL, we treat each of the lensed galaxies as a particle and then reconstruct the potential by smoothing over a local kernel with variable smoothing scale. In this way, we can tune a reconstruction to produce constant signal-noise throughout, and maximally exploit regions of high information density. \r\n\r\nPBL is designed to include all lensing observables, including multiple image positions and fluxes from strong lensing, as well as weak lensing signals including shear and flexion. In this paper, however, we describe a shear-only reconstruction, and apply the method to several test cases, including simulated lensing clusters, as well as the well-studied ``Bullet Cluster'' (1E0657-56). In the former cases, we show that PBL is better able to identify cusps and substructures than are grid-based reconstructions, and in the latter case, we show that PBL is able to identify substructure in the Bullet Cluster without even exploiting strong lensing measurements.","topic_id":"22822","bibcode":"2011ascl.soft02002D","views":"42","site_list":["http:\/\/www.physics.drexel.edu\/~deb\/PBL.htm"],"ref_list":["http:\/\/arxiv.org\/abs\/0802.0004"]},
		{"ascl_id":"1102.003","title":"GRAVLENS: Computational Methods for Gravitational Lensing","credit":"Keeton, Charles R.","abstract":"Modern applications of strong gravitational lensing require the ability to use precise and varied observational data to constrain complex lens models. Two sets of computational methods for lensing calculations are discussed. The first is a new algorithm for solving the lens equation for general mass distributions. This algorithm makes it possible to apply arbitrarily complicated models to observed lenses. The second is an evaluation of techniques for using observational data including positions, fluxes, and time delays of point-like images, as well as maps of extended images, to constrain models of strong lenses. The techniques presented here are implemented in a flexible and user-friendly software package called gravlens, which is made available to the community.","topic_id":"22824","bibcode":"2011ascl.soft02003K","views":"76","site_list":["http:\/\/www.physics.rutgers.edu\/~keeton\/gravlens\/"],"ref_list":["http:\/\/xxx.lanl.gov\/abs\/astro-ph\/0102340"]},
		{"ascl_id":"1102.004","title":"LENSTOOL: A Gravitational Lensing Software for Modeling Mass Distribution of Galaxies and Clusters (strong and weak regime)","credit":"Kneib, Jean-Paul; Bonnet, Henri; Golse, Ghyslain; Sand, David; Jullo, Eric; Marshall, Phil","abstract":"We describe a procedure for modelling strong lensing galaxy clusters with parametric methods, and to rank models quantitatively using the Bayesian evidence. We use a publicly available Markov chain Monte-Carlo (MCMC) sampler ('Bayesys'), allowing us to avoid local minima in the likelihood functions. To illustrate the power of the MCMC technique, we simulate three clusters of galaxies, each composed of a cluster-scale halo and a set of perturbing galaxy-scale subhalos. We ray-trace three light beams through each model to produce a catalogue of multiple images, and then use the MCMC sampler to recover the model parameters in the three different lensing configurations. We find that, for typical Hubble Space Telescope (HST)-quality imaging data, the total mass in the Einstein radius is recovered with ~1-5% error according to the considered lensing configuration. However, we find that the mass of the galaxies is strongly degenerated with the cluster mass when no multiple images appear in the cluster centre. The mass of the galaxies is generally recovered with a 20% error, largely due to the poorly constrained cut-off radius. Finally, we describe how to rank models quantitatively using the Bayesian evidence. We confirm the ability of strong lensing to constrain the mass profile in the central region of galaxy clusters in this way. Ultimately, such a method applied to strong lensing clusters with a very large number of multiple images may provide unique geometrical constraints on cosmology.","topic_id":"22825","bibcode":"2011ascl.soft02004K","views":"72","site_list":["http:\/\/projets.lam.fr\/projects\/lenstool\/wiki"],"ref_list":["http:\/\/arxiv.org\/abs\/0706.0048"]},
		{"ascl_id":"1102.005","title":"MRLENS: Multi-Resolution methods for gravitational LENSing","credit":"Starck, Jean-Luc; Pires, Sandrine; Refregier, Alexandre","abstract":"The MRLENS package offers a new method for the reconstruction of weak lensing mass maps. It uses the multiscale entropy concept, which is based on wavelets, and the False Discovery Rate which allows us to derive robust detection levels in wavelet space. We show that this new restoration approach outperforms several standard techniques currently used for weak shear mass reconstruction. This method can also be used to separate E and B modes in the shear field, and thus test for the presence of residual systematic effects. We concentrate on large blind cosmic shear surveys, and illustrate our results using simulated shear maps derived from N-Body Lambda-CDM simulations with added noise corresponding to both ground-based and space-based observations.","topic_id":"22835","bibcode":"2011ascl.soft02005S","views":"36","site_list":["http:\/\/irfu.cea.fr\/Phocea\/Vie_des_labos\/Ast\/ast_visu.php?id_ast=878"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0503373"]},
		{"ascl_id":"1102.006","title":"NBODY Codes: Numerical Simulations of Many-body (N-body) Gravitational Interactions","credit":"Aarseth, Sverre J.","abstract":"I review the development of direct N-body codes at Cambridge over nearly 40 years, highlighting the main stepping stones. The first code (NBODY1) was based on the simple concepts of a force polynomial combined with individual time steps, where numerical problems due to close encounters were avoided by a softened potential. Fortuitously, the elegant Kustaanheimo-Stiefel two-body regularization soon permitted small star clusters to be studied (NBODY3). Subsequent extensions to unperturbed three-body and four-body regularization proved beneficial in dealing with multiple interactions. Investigations of larger systems became possible with the Ahmad-Cohen neighbor scheme which was used more than 20 years ago for expanding universe models of 4000 galaxies (NBODY2). Combining the neighbor scheme with the regularization procedures enabled more realistic star clusters to be considered (NBODY5). After a period of simulations with no apparent technical progress, chain regularization replaced the treatment of compact subsystems (NBODY3, NBODY5). More recently, the Hermite integration method provided a major advance and has been implemented on the special-purpose HARP computers (NBODY4) together with an alternative version for workstations and supercomputers (NBODY6). These codes also include a variety of algorithms for stellar evolution based on fast lookup functions. The treatment of primordial binaries contains efficient procedures for chaotic two-body motion as well as tidal circularization, and special attention is paid to hierarchical systems and their stability. This family of N-body codes constitutes a powerful tool for dynamical simulations which is freely available to the astronomical community, and the massive effort owes much to collaborators.","topic_id":"22834","bibcode":"2011ascl.soft02006A","views":"46","site_list":["http:\/\/www.ast.cam.ac.uk\/~sverre\/web\/pages\/nbody.htm"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1999PASP..111.1333A","http:\/\/arxiv.org\/abs\/astro-ph\/0008441"]},
		{"ascl_id":"1102.007","title":"PixeLens: A Portable Modeler of Lensed Quasars","credit":"Saha, Prasenjit; Williams, Liliya L. R.","abstract":"We introduce and implement two novel ideas for modeling lensed quasars. The first is to require different lenses to agree about H<sub>0<\/sub>. This means that some models for one lens can be ruled out by data on a different lens. We explain using two worked examples. One example models 1115+080 and 1608+656 (time-delay quadruple systems) and 1933+503 (a prospective time-delay system) all together, yielding time-delay predictions for the third lens and a 90% confidence estimate of H<sub>0<\/sub><sup>-1<\/sup>=14.6+9.4-1.7 Gyr (H<sub>0<\/sub>=67+9-26 km s<sup>-1<\/sup> Mpc<sup>-1<\/sup>) assuming \u2126M=0.3 and \u2126<sub>\u039b<\/sub>=0.7. The other example models the time-delay doubles 1520+530, 1600+434, 1830-211, and 2149-275, which gives H<sub>0<\/sub><sup>-1<\/sup>=14.5+3.3-1.5 Gyr (H<sub>0<\/sub>=67+8-13 km s<sup>-1<\/sup> Mpc<sup>-1<\/sup>). Our second idea is to write the modeling software as a highly interactive Java applet, which can be used both for coarse-grained results inside a browser and for fine-grained results on a workstation. Several obstacles come up in trying to implement a numerically intensive method thus, but we overcome them.","topic_id":"22836","bibcode":"2011ascl.soft02007S","views":"109","site_list":["http:\/\/www.qgd.uzh.ch\/projects\/pixelens\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0402135","http:\/\/adsabs.harvard.edu\/abs\/2008ApJ...679...17C"]},
		{"ascl_id":"1102.008","title":"PMFAST: Towards Optimal Parallel PM N-body Codes","credit":"Merz, Hugh; Pen, Ue-Li; Trac, Hy","abstract":"We present a new parallel PM N-body code named PMFAST that is cost-effective and memory-efficient. PMFAST is based on a two-level mesh gravity solver where the gravitational forces are separated into long and short range components. The decomposition scheme minimizes communication costs and allows tolerance for slow networks. The code approaches optimality in several dimensions. The force computations are local and exploit highly optimized vendor FFT libraries. It features minimal memory overhead, with the particle positions and velocities being the main cost. The code features support for distributed and shared memory parallelization through the use of MPI and OpenMP, respectively.\r\n\r\nThe current release version uses two grid levels on a slab decomposition, with periodic boundary conditions for cosmological applications. Open boundary conditions could be added with little computational overhead. We present timing information and results from a recent cosmological production run of the code using a 3712^3 mesh with 6.4 x 10^9 particles.","topic_id":"22833","bibcode":"2011ascl.soft02008M","views":"41","site_list":["http:\/\/www.cita.utoronto.ca\/~merz\/pmfast\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0402443"]},
		{"ascl_id":"1102.009","title":"AHF: Amiga&#39;s Halo Finder","credit":"Knollmann, Steffen R.; Knebe, Alexander","abstract":"Cosmological simulations are the key tool for investigating the different processes involved in the formation of the universe from small initial density perturbations to galaxies and clusters of galaxies observed today. The identification and analysis of bound objects, halos, is one of the most important steps in drawing useful physical information from simulations. In the advent of larger and larger simulations, a reliable and parallel halo finder, able to cope with the ever-increasing data files, is a must. In this work we present the freely available MPI parallel halo finder AHF. We provide a description of the algorithm and the strategy followed to handle large simulation data. We also describe the parameters a user may choose in order to influence the process of halo finding, as well as pointing out which parameters are crucial to ensure untainted results from the parallel approach. Furthermore, we demonstrate the ability of AHF to scale to high-resolution simulations.","topic_id":"22837","bibcode":"2011ascl.soft02009K","views":"100","site_list":["http:\/\/popia.ft.uam.es\/AMIGA\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0904.3662"]},
		{"ascl_id":"1102.010","title":"SEREN: A SPH code for star and planet formation simulations","credit":"Hubber, David; Batty, Chris; McLeod, Andrew; Whitworth, Anthony; Bisbas, Thomas; Stamatellos, Dimitrios; Walch, Stefanie; Rawiraswattana, Krisada; Goodwin, Simon","abstract":"SEREN is an astrophysical Smoothed Particle Hydrodynamics code designed to investigate star and planet formation problems using self-gravitating hydrodynamics simulations of molecular clouds, star-forming cores, and protostellar disks.\n\nSEREN is written in Fortran 95\/2003 with a modular philosophy for adding features into the code. Each feature can be easily activated or deactivated by way of setting options in the Makefile before compiling the code. This has the added benefit of allowing unwanted features to be removed at the compilation stage resulting in a smaller and faster executable program. SEREN is written with OpenMP directives to allow parallelization on shared-memory architecture.","topic_id":"22845","bibcode":"2011ascl.soft02010H","views":"46","site_list":["http:\/\/dhubber.github.io\/seren\/seren.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011A%26A...529A..27H"]},
		{"ascl_id":"1102.011","title":"Identikit 2: An Algorithm for Reconstructing Galactic Collisions","credit":"Barnes, Joshua E.","abstract":"Using a combination of self-consistent and test-particle techniques, Identikit 1 provided a way to vary the initial geometry of a galactic collision and instantly visualize the outcome. Identikit 2 uses the same techniques to define a mapping from the current morphology and kinematics of a tidal encounter back to the initial conditions. By requiring that various regions along a tidal feature all originate from a single disc with a unique orientation, this mapping can be used to derive the initial collision geometry. In addition, Identikit 2 offers a robust way to measure how well a particular model reproduces the morphology and kinematics of a pair of interacting galaxies. A set of eight self-consistent simulations is used to demonstrate the algorithm's ability to search a ten-dimensional parameter space and find near-optimal matches; all eight systems are successfully reconstructed.","topic_id":"22846","bibcode":"2011ascl.soft02011B","views":"36","site_list":["http:\/\/www.ifa.hawaii.edu\/faculty\/barnes\/research\/identikit\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1101.5671"]},
		{"ascl_id":"1102.012","title":"CPROPS: Bias-free Measurement of Giant Molecular Cloud Properties","credit":"Rosolowsky, Erik; Leroy, Adam","abstract":"CPROPS, written in IDL, processes FITS data cubes containing molecular line emission and returns the properties of molecular clouds contained within it. Without corrections for the effects of beam convolution and sensitivity to GMC properties, the resulting properties may be severely biased. This is particularly true for extragalactic observations, where resolution and sensitivity effects often bias measured values by 40% or more. We correct for finite spatial and spectral resolutions with a simple deconvolution and we correct for sensitivity biases by extrapolating properties of a GMC to those we would expect to measure with perfect sensitivity. The resulting method recovers the properties of a GMC to within 10% over a large range of resolutions and sensitivities, provided the clouds are marginally resolved with a peak signal-to-noise ratio greater than 10. We note that interferometers systematically underestimate cloud properties, particularly the flux from a cloud. The degree of bias depends on the sensitivity of the observations and the (u,v) coverage of the observations. In the Appendix to the paper we present a conservative, new decomposition algorithm for identifying GMCs in molecular-line observations. This algorithm treats the data in physical rather than observational units, does not produce spurious clouds in the presence of noise, and is sensitive to a range of morphologies. As a result, the output of this decomposition should be directly comparable among disparate data sets.\r\n\r\nThe CPROPS package contains within it a distribution of the <a href=\"http:\/\/ascl.net\/1107.014\">CLUMPFIND<\/a> code written by Jonathan Williams and described in <a href=\"http:\/\/adsabs.harvard.edu\/abs\/1994ApJ...428..693W\">Williams, de Geus, and Blitz<\/a>(1994). The package is available as a <a href=\"http:\/\/www.ifa.hawaii.edu\/~jpw\/page16\/page4\/page4.html\">stand alone package<\/a>. If you make use of the CLUMPFIND functionality in the CPROPS package for a publication, please cite Jonathan's original article.","topic_id":"22867","bibcode":"2011ascl.soft02012R","views":"48","site_list":["https:\/\/people.ok.ubc.ca\/erosolo\/cprops\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0601706"]},
		{"ascl_id":"1102.013","title":"Cactus: HPC infrastructure and programming tools","credit":"Collaborative Effort","abstract":"Cactus provides computational scientists and engineers with a collaborative, modular and portable programming environment for parallel high performance computing. Cactus can make use of many other technologies for HPC, such as Samrai, HDF5, PETSc and PAPI, and several application domains such as numerical relativity, computational fluid dynamics and quantum gravity are developing open community toolkits for Cactus.","topic_id":"22893","bibcode":"2011ascl.soft02013C","views":"64","site_list":["http:\/\/cactuscode.org\/"],"ref_list":["http:\/\/xxx.lanl.gov\/abs\/gr-qc\/0210006"]},
		{"ascl_id":"1102.014","title":"Einstein Toolkit for Relativistic Astrophysics","credit":"Collaborative Effort","abstract":"The Einstein Toolkit is a collection of software components and tools for simulating and analyzing general relativistic astrophysical systems. Such systems include gravitational wave space-times, collisions of compact objects such as black holes or neutron stars, accretion onto compact objects, core collapse supernovae and Gamma-Ray Bursts.\r\n\r\nThe Einstein Toolkit builds on numerous software efforts in the numerical relativity community including CactusEinstein, Whisky, and Carpet. The Einstein Toolkit currently uses the Cactus Framework as the underlying computational infrastructure that provides large-scale parallelization, general computational components, and a model for collaborative, portable code development.","topic_id":"22894","bibcode":"2011ascl.soft02014C","views":"41","site_list":["http:\/\/einsteintoolkit.org\/","http:\/\/einsteintoolkit.org\/documentation\/licenses\/"],"ref_list":["http:\/\/www.cct.lsu.edu\/~eschnett\/doc\/Karlsruhe-2008-CBHPC-EinsteinToolkit.pdf"]},
		{"ascl_id":"1102.015","title":"PMFASTIC: Initial condition generator for PMFAST","credit":"Merz, Hugh; Pen, Ue-Li; Trac, Hy","abstract":"PMFASTIC is a parallel initial condition generator, a slab decomposition Fortran 90 parallel cosmological initial condition generator for use with PMFAST. Files required for generating initial dark matter particle distributions and instructions are included, however one would require <a href=\"http:\/\/ascl.net\/9909.004\">CMBFAST<\/a> to create alternative transfer functions.","topic_id":"22896","bibcode":"2011ascl.soft02015M","views":"41","site_list":["http:\/\/www.cita.utoronto.ca\/~merz\/pmfast\/ic\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0402443"]},
		{"ascl_id":"1102.016","title":"HERACLES: 3D Hydrodynamical Code to Simulate Astrophysical Fluid Flows","credit":"Audit, Edouard; Gonz\u00e1lez, Matthias; Vaytet, Neil; Fromang, Sebastien; Hennebelle, Patrick; Teyssier, Romain; Tremblin, Pascal; Thooris, Bruno","abstract":"HERACLES is a 3D hydrodynamical code used to simulate astrophysical fluid flows. It uses a finite volume method on fixed grids to solve the equations of hydrodynamics, MHD, radiative transfer and gravity. This software is developed at the Service d'Astrophysique, CEA\/Saclay as part of the COAST project and is registered under the CeCILL license. HERACLES simulates astrophysical fluid flows using a grid based Eulerian finite volume Godunov method. It is capable of simulating pure hydrodynamical flows, magneto-hydrodynamic flows, radiation hydrodynamic flows (using either flux limited diffusion or the M1 moment method), self-gravitating flows using a Poisson solver or all of the above. HERACLES uses cartesian, spherical and cylindrical grids.","topic_id":"22910","bibcode":"2011ascl.soft02016A","views":"38","site_list":["http:\/\/irfu.cea.fr\/Projets\/Site_heracles\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007A%26A...464..429G"]},
		{"ascl_id":"1102.017","title":"FARGO: Fast Advection in Rotating Gaseous Objects","credit":"Masset, Frederic","abstract":"FARGO is an efficient and simple modification of the standard transport algorithm used in explicit eulerian fixed polar grid codes, aimed at getting rid of the average azimuthal velocity when applying the Courant condition. This results in a much larger timestep than the usual procedure, and it is particularly well-suited to the description of a Keplerian disk where one is traditionally limited by the very demanding Courant condition on the fast orbital motion at the inner boundary. In this modified algorithm, the timestep is limited by the perturbed velocity and by the shear arising from the differential rotation. The speed-up resulting from the use of the FARGO algorithm is problem dependent. In the example presented in the code paper below, which shows the evolution of a Jupiter sized protoplanet embedded in a minimum mass protoplanetary nebula, the FARGO algorithm is about an order of magnitude faster than a traditional transport scheme, with a much smaller numerical diffusivity.","topic_id":"22911","bibcode":"2011ascl.soft02017M","views":"40","site_list":["http:\/\/fargo.in2p3.fr\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9910390"]},
		{"ascl_id":"1102.018","title":"Karma: Visualisation Test-Bed Toolkit","credit":"Gooch, Richard","abstract":"Karma is a toolkit for interprocess communications, authentication, encryption, graphics display, user interface and manipulating the Karma network data structure. It contains KarmaLib (the structured libraries and API) and a large number of modules (applications) to perform many standard tasks. A suite of visualisation tools are distributed with the library.","topic_id":"22912","bibcode":"2011ascl.soft02018G","views":"37","site_list":["http:\/\/www.atnf.csiro.au\/computing\/software\/karma\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1996ASPC..101...80G"]},
		{"ascl_id":"1102.019","title":"HOP: A Group-finding Algorithm for N-body Simulations","credit":"Eisenstein, Daniel; Hut, Piet","abstract":"We describe a new method (HOP) for identifying groups of particles in N-body simulations. Having assigned to every particle an estimate of its local density, we associate each particle with the densest of the Nh particles nearest to it. Repeating this process allows us to trace a path, within the particle set itself, from each particle in the direction of increasing density. The path ends when it reaches a particle that is its own densest neighbor; all particles reaching the same such particle are identified as a group. Combined with an adaptive smoothing kernel for finding the densities, this method is spatially adaptive, coordinate-free, and numerically straight-forward. One can proceed to process the output by truncating groups at a particular density contour and combining groups that share a (possibly different) density contour. While the resulting algorithm has several user-chosen parameters, we show that the results are insensitive to most of these, the exception being the outer density cutoff of the groups.","topic_id":"22913","bibcode":"2011ascl.soft02019E","views":"43","site_list":["https:\/\/www.cfa.harvard.edu\/~deisenst\/hop\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9712200"]},
		{"ascl_id":"1102.020","title":"SKID: Finding Gravitationally Bound Groups in N-body Simulations","credit":"N-Body Shop","abstract":"SKID finds gravitationally bound groups in N-body simulations. The SKID program will group different types of particles depending on the type of input binary file. This could be either dark matter particles, gas particles, star particles or gas and star particles depending on what is in the input <span style=\"font-style: italic\">tipsy<\/span> binary file. Once groups with at least a certain minimum number of members have been determined, SKID will remove particles which are not bound to the group. SKID must use the original positions of all the particles to determine whether or not particles are bound. This procedure which we call unbinding, is again dependent on the type of grouping we are dealing with. There are two cases, one for dark matter only or star particles only (case 1 unbinding), the other for inputs including gas (also stars in a dark matter environment this is case 2 unbinding). \r\n\r\nSkid version 1.3 is a much improved version of the old denmax-1.1 version. The new name was given to avoid confusion with the DENMAX program of Gelb & Bertschinger, and although it is based on the same idea it represents a substantial evolution in the method.","topic_id":"22914","bibcode":"2011ascl.soft02020N","views":"42","site_list":["http:\/\/www-hpcc.astro.washington.edu\/tools\/skid.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9612007"]},
		{"ascl_id":"1102.021","title":"DIRT: Dust InfraRed Toolbox","credit":"Pound, M. W.; Wolfire, M. G.; Mundy, L. G.; Teuben, P. J.; Lord, S.","abstract":"DIRT is a Java applet for modelling astrophysical processes in circumstellar dust shells around young and evolved stars. With DIRT, you can: \r\n\r\n<ul><li>select and display over 500,000 pre-run model spectral energy distributions (SEDs) <\/li><li>find the best-fit model to your data set <\/li><li>account for beam size in model fitting <\/li><li>manipulate data and models with an interactive viewer <\/li><li>display gas and dust density and temperature profiles <\/li><li>display model intensity profiles at various wavelengths<\/li><\/ul>","topic_id":"22943","bibcode":"2011ascl.soft02021P","views":"44","site_list":["http:\/\/dustem.astro.umd.edu\/dirt\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000ASPC..216..628P"]},
		{"ascl_id":"1102.022","title":"PDRT: Photo Dissociation Region Toolbox","credit":"Pound, M. W.; Wolfire, M. G.","abstract":"Ultraviolet photons from O and B stars strongly influence the structure and emission spectra of the interstellar medium. The UV photons energetic enough to ionize hydrogen (h\u03bd &gt; 13.6 eV) will create the H II region around the star, but lower energy UV photons escape. These far-UV photons (6 eV &lt; h\u03bd &lt; 13.6 eV) are still energetic enough to photodissociate molecules and to ionize low ionization-potential atoms such as carbon, silicon, and sulfur. They thus create a photodissociation region (PDR) just outside the H II region. In aggregate, these PDRs dominates the heating and cooling of the neutral interstellar medium.\n\nAs part of the Web Infrared Tool Shed (WITS {http:\/\/dustem.astro.umd.edu}) we have developed a web tool, called the PDR Toolbox, that allows users to determine the physical parameters of a PDR from a set of spectral line observations. Typical observations of both Galactic and extragalactic PDRs come from ground-based millimeter and submillimeter telescopes such as CARMA or the CSO, or space-based telescopes such as Spitzer, ISO, SOFIA, and Herschel. Given a set of observations of spectral line intensities, PDR Toolbox will compute best-fit FUV incident intensity and cloud density based on our published models of PDR emission.","topic_id":"22944","bibcode":"2011ascl.soft02022P","views":"38","site_list":["http:\/\/dustem.astro.umd.edu\/pdrt\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ASPC..394..654P"]},
		{"ascl_id":"1102.023","title":"21cmFAST: A Fast, Semi-Numerical Simulation of the High-Redshift 21-cm Signal","credit":"Mesinger, Andrei; Furlanetto, Steven; Cen, Renyue","abstract":"21cmFAST is a powerful semi-numeric modeling tool designed to efficiently simulate the cosmological 21-cm signal. The code generates 3D realizations of evolved density, ionization, peculiar velocity, and spin temperature fields, which it then combines to compute the 21-cm brightness temperature. Although the physical processes are treated with approximate methods, the results were compared to a state-of-the-art large-scale hydrodynamic simulation, and the findings indicate good agreement on scales pertinent to the upcoming observations (&gt;~ 1 Mpc). The power spectra from 21cmFAST agree with those generated from the numerical simulation to within 10s of percent, down to the Nyquist frequency. Results were shown from a 1 Gpc simulation which tracks the cosmic 21-cm signal down from z=250, highlighting the various interesting epochs. Depending on the desired resolution, 21cmFAST can compute a redshift realization on a single processor in just a few minutes. The code is fast, efficient, customizable and publicly available, making it a useful tool for 21-cm parameter studies.","topic_id":"22945","bibcode":"2011ascl.soft02023M","views":"170","site_list":["http:\/\/homepage.sns.it\/mesinger\/DexM___21cmFAST.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1003.3878"]},
		{"ascl_id":"1102.024","title":"DiFX2: A more flexible, efficient, robust and powerful software correlator","credit":"Deller, A. T.; Brisken, W. F.; Phillips, C. J.; Morgan, J.; Alef, W.; Cappallo, R.; Middelberg, E.; Romney, J.; Rottmann, H.; Tingay, S. J.; Wayth, R.","abstract":"Software correlation, where a correlation algorithm written in a high-level language such as C++ is run on commodity computer hardware, has become increasingly attractive for small to medium sized and\/or bandwidth constrained radio interferometers. In particular, many long baseline arrays (which typically have fewer than 20 elements and are restricted in observing bandwidth by costly recording hardware and media) have utilized software correlators for rapid, cost-effective correlator upgrades to allow compatibility with new, wider bandwidth recording systems and improve correlator flexibility. The DiFX correlator, made publicly available in 2007, has been a popular choice in such upgrades and is now used for production correlation by a number of observatories and research groups worldwide. Here we describe the evolution in the capabilities of the DiFX correlator over the past three years, including a number of new capabilities, substantial performance improvements, and a large amount of supporting infrastructure to ease use of the code. New capabilities include the ability to correlate a large number of phase centers in a single correlation pass, the extraction of phase calibration tones, correlation of disparate but overlapping sub-bands, the production of rapidly sampled filterbank and kurtosis data at minimal cost, and many more. The latest version of the code is at least 15% faster than the original, and in certain situations many times this value. Finally, we also present detailed test results validating the correctness of the new code.","topic_id":"22968","bibcode":"2011ascl.soft02024D","views":"46","site_list":["http:\/\/cira.ivec.org\/dokuwiki\/doku.php\/difx\/installation"],"ref_list":["http:\/\/arxiv.org\/abs\/1101.0885"]},
		{"ascl_id":"1102.025","title":"LensPix: Fast MPI full sky transforms for HEALPix","credit":"Lewis, Antony","abstract":"Modelling of the weak lensing of the CMB will be crucial to obtain correct cosmological parameter constraints from forthcoming precision CMB anisotropy observations. The lensing affects the power spectrum as well as inducing non-Gaussianities. We discuss the simulation of full sky CMB maps in the weak lensing approximation and describe a fast numerical code. The series expansion in the deflection angle cannot be used to simulate accurate CMB maps, so a pixel remapping must be used. For parameter estimation accounting for the change in the power spectrum but assuming Gaussianity is sufficient to obtain accurate results up to Planck sensitivity using current tools. A fuller analysis may be required to obtain accurate error estimates and for more sensitive observations. We demonstrate a simple full sky simulation and subsequent parameter estimation at Planck-like sensitivity.","topic_id":"22969","bibcode":"2011ascl.soft02025L","views":"38","site_list":["http:\/\/cosmologist.info\/lenspix\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0502469"]},
		{"ascl_id":"1102.026","title":"CAMB: Code for Anisotropies in the Microwave Background","credit":"Lewis, Antony; Challinor, Anthony","abstract":"We present a fully covariant and gauge-invariant calculation of the evolution of anisotropies in the cosmic microwave background (CMB) radiation. We use the physically appealing covariant approach to cosmological perturbations, which ensures that all variables are gauge-invariant and have a clear physical interpretation. We derive the complete set of frame-independent, linearised equations describing the (Boltzmann) evolution of anisotropy and inhomogeneity in an almost Friedmann-Robertson-Walker (FRW) cold dark matter (CDM) universe. These equations include the contributions of scalar, vector and tensor modes in a unified manner. Frame-independent equations for scalar and tensor perturbations, which are valid for any value of the background curvature, are obtained straightforwardly from the complete set of equations. We discuss the scalar equations in detail, including the integral solution and relation with the line of sight approach, analytic solutions in the early radiation dominated era, and the numerical solution in the standard CDM model. Our results confirm those obtained by other groups, who have worked carefully with non-covariant methods in specific gauges, but are derived here in a completely transparent fashion.","topic_id":"22970","bibcode":"2011ascl.soft02026L","views":"114","site_list":["http:\/\/camb.info\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1101.2234"]},
		{"ascl_id":"1102.027","title":"ZENO: N-body and SPH Simulation Codes","credit":"Barnes, Joshua E.","abstract":"The ZENO software package integrates N-body and SPH simulation codes with a large array of programs to generate initial conditions and analyze numerical simulations. Written in C, the ZENO system is portable between Mac, Linux, and Unix platforms. It is in active use at the Institute for Astronomy (IfA), at NRAO, and possibly elsewhere.\r\n\r\nZeno programs can perform a wide range of simulation and analysis tasks. While many of these programs were first created for specific projects, they embody algorithms of general applicability and embrace a modular design strategy, so existing code is easily applied to new tasks. Major elements of the system include:\r\n<ul><li>Structured data file utilities facilitate basic operations on binary data, including import\/export of ZENO data to other systems.<\/li><li>Snapshot generation routines create particle distributions with various properties. Systems with user-specified density profiles can be realized in collisionless or gaseous form; multiple spherical and disk components may be set up in mutual equilibrium.<\/li><li>Snapshot manipulation routines permit the user to sift, sort, and combine particle arrays, translate and rotate particle configurations, and assign new values to data fields associated with each particle.<\/li><li>Simulation codes include both pure N-body and combined N-body\/SPH programs:\r\n<ul><li>Pure N-body codes are available in both uniprocessor and parallel versions.<\/li><li>SPH codes offer a wide range of options for gas physics, including isothermal, adiabatic, and radiating models. <\/li><\/ul><\/li><li>Snapshot analysis programs calculate temporal averages, evaluate particle statistics, measure shapes and density profiles, compute kinematic properties, and identify and track objects in particle distributions.<\/li><li>Visualization programs generate interactive displays and produce still images and videos of particle distributions; the user may specify arbitrary color schemes and viewing transformations. <\/li><\/ul>","topic_id":"22971","bibcode":"2011ascl.soft02027B","views":"72","site_list":["http:\/\/www.ifa.hawaii.edu\/faculty\/barnes\/zeno\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.423.3134F"]},
		{"ascl_id":"1102.028","title":"ZEUS-MP\/2: Computational Fluid Dynamics Code","credit":"Hayes, John C.; Norman, Michael L.; Fiedler, Robert A.; Bordner, James O.; Li, Pak Shing; Clark, Stephen E.; Ud-Doula, Asif; Mac Low, Mordecai-Mark","abstract":"ZEUS-MP is a multiphysics, massively parallel, message-passing implementation of the ZEUS code. ZEUS-MP offers an MHD algorithm that is better suited for multidimensional flows than the ZEUS-2D module by virtue of modifications to the method of characteristics scheme first suggested by Hawley & Stone. This MHD module is shown to compare quite favorably to the TVD scheme described by Ryu et al. ZEUS-MP is the first publicly available ZEUS code to allow the advection of multiple chemical (or nuclear) species. Radiation hydrodynamic simulations are enabled via an implicit flux-limited radiation diffusion (FLD) module. The hydrodynamic, MHD, and FLD modules can be used, singly or in concert, in one, two, or three space dimensions. In addition, so-called 1.5D and 2.5D grids, in which the \"half-D'' denotes a symmetry axis along which a constant but nonzero value of velocity or magnetic field is evolved, are supported. Self-gravity can be included either through the assumption of a GM\/r potential or through a solution of Poisson's equation using one of three linear solver packages (conjugate gradient, multigrid, and FFT) provided for that purpose. Point-mass potentials are also supported.\r\n\r\nBecause ZEUS-MP is designed for large simulations on parallel computing platforms, considerable attention is paid to the parallel performance characteristics of each module in the code. Strong-scaling tests involving pure hydrodynamics (with and without self-gravity), MHD, and RHD are performed in which large problems (2563 zones) are distributed among as many as 1024 processors of an IBM SP3. Parallel efficiency is a strong function of the amount of communication required between processors in a given algorithm, but all modules are shown to scale well on up to 1024 processors for the chosen fixed problem size.","topic_id":"22897","bibcode":"2011ascl.soft02028H","views":"73","site_list":["http:\/\/www.netpurgatory.com\/zeusmp.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ApJS..165..188H"]},
		{"ascl_id":"1103.001","title":"Difmap: Synthesis Imaging of Visibility Data","credit":"Shepherd, Martin","abstract":"Difmap is a program developed for synthesis imaging of visibility data from interferometer arrays of radio telescopes world-wide. Its prime advantages over traditional packages are its emphasis on interactive processing, speed, and the use of Difference mapping techniques.","topic_id":"23068","bibcode":"2011ascl.soft03001S","views":"42","site_list":["ftp:\/\/ftp.astro.caltech.edu\/pub\/difmap\/difmap.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9907184","http:\/\/arxiv.org\/abs\/astro-ph\/0612618"]},
		{"ascl_id":"1103.002","title":"PGPLOT: Device-independent Graphics Package for Simple Scientific Graphs","credit":"Pearson, Tim","abstract":"The PGPLOT Graphics Subroutine Library is a Fortran- or C-callable, device-independent graphics package for making simple scientific graphs. It is intended for making graphical images of publication quality with minimum effort on the part of the user. For most applications, the program can be device-independent, and the output can be directed to the appropriate device at run time.\n\nThe PGPLOT library consists of two major parts: a device-independent part and a set of device-dependent \"device handler\" subroutines for output on various terminals, image displays, dot-matrix printers, laser printers, and pen plotters. Common file formats supported include PostScript and GIF.\n\nPGPLOT itself is written mostly in standard Fortran-77, with a few non-standard, system-dependent subroutines. PGPLOT subroutines can be called directly from a Fortran-77 or Fortran-90 program. A C binding library (cpgplot) and header file (cpgplot.h) are provided that allow PGPLOT to be called from a C or C++ program; the binding library handles conversion between C and Fortran argument-passing conventions.","topic_id":"23069","bibcode":"2011ascl.soft03002P","views":"123","site_list":["http:\/\/www.astro.caltech.edu\/~tjp\/pgplot\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0404070"]},
		{"ascl_id":"1103.003","title":"S2PLOT: Three-dimensional (3D) Plotting Library","credit":"Barnes, D. G.; Fluke, C. J.; Bourke, P. D.; Parry, O. T.","abstract":"We present a new, three-dimensional (3D) plotting library with advanced features, and support for standard and enhanced display devices. The library - S2PLOT - is written in C and can be used by C, C++ and FORTRAN programs on GNU\/Linux and Apple\/OSX systems. S2PLOT draws objects in a 3D (x,y,z) Cartesian space and the user interactively controls how this space is rendered at run time. With a PGPLOT inspired interface, S2PLOT provides astronomers with elegant techniques for displaying and exploring 3D data sets directly from their program code, and the potential to use stereoscopic and dome display devices. The S2PLOT architecture supports dynamic geometry and can be used to plot time-evolving data sets, such as might be produced by simulation codes. In this paper, we introduce S2PLOT to the astronomical community, describe its potential applications, and present some example uses of the library.","topic_id":"23070","bibcode":"2011ascl.soft03003B","views":"45","site_list":["http:\/\/astronomy.swin.edu.au\/s2plot"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0608245"]},
		{"ascl_id":"1103.004","title":"SPLASH: An Interactive Visualization Tool for Smoothed Particle Hydrodynamics Simulations","credit":"Price, Daniel J.","abstract":"SPLASH (formerly SUPERSPHPLOT) is a visualization tool for output from (astrophysical) simulations using the Smoothed Particle Hydrodynamics (SPH) method in one, two and three dimensions. It is written in Fortran 90 and utilises the PGPLOT graphics subroutine library to do the actual plotting. It is based around a command-line menu structure but utilises the interactive capabilities of PGPLOT to manipulate data interactively in the plotting window.\r\n\r\nSPLASH is a fully interactive program; visualizations can be changed rapidly at the touch of a button (e.g. zooming, rotating, shifting cross section positions etc). Data is read directly from the code dump format giving rapid access to results and the visualization is advanced forwards and backwards through timesteps by single keystrokes. SPLASH uses the SPH kernel to render plots of not only density but other physical quantities, giving a smooth representation of the data.","topic_id":"23071","bibcode":"2011ascl.soft03004P","views":"38","site_list":["http:\/\/users.monash.edu.au\/~dprice\/splash\/"],"ref_list":["http:\/\/www.publish.csiro.au\/?paper=AS07022"]},
		{"ascl_id":"1103.005","title":"Splotch: Ray Tracer to Visualize SPH Simulations","credit":"Dolag, Klaus; Reinecke, Martin; Gheller, Claudio; Rivi, Marzia; Krokos, Mel; Jin, Zhefan","abstract":"Splotch is a light and fast, publicly available, ray-tracer software tool which supports the effective visualization of cosmological simulations data. The algorithm it relies on is designed to deal with point-like data, optimizing the ray-tracing calculation by ordering the particles as a function of their 'depth', defined as a function of one of the coordinates or other associated parameters. Realistic three-dimensional impressions are reached through a composition of the final colour in each pixel properly calculating emission and absorption of individual volume elements.","topic_id":"23072","bibcode":"2011ascl.soft03005D","views":"49","site_list":["http:\/\/www.mpa-garching.mpg.de\/~kdolag\/Splotch\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008NJPh...10l5006D"]},
		{"ascl_id":"1103.006","title":"GLESP 2.0: Gauss-Legendre Sky Pixelization for CMB Analysis","credit":"Doroshkevich, A. G.; Naselsky, P. D.; Verkhodanov, O. V.; Novikov, D. I.; Turchaninov, V. I.; Novikov, I. D.; Christensen, P. R.; Chiang, L.-Y.","abstract":"GLESP is a pixelization scheme for the cosmic microwave background (CMB) radiation maps. This scheme is based on the Gauss-Legendre polynomials zeros and allows one to create strict orthogonal expansion of the map.","topic_id":"23073","bibcode":"2011ascl.soft03006D","views":"31","site_list":["http:\/\/www.glesp.nbi.dk\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0501494","http:\/\/arxiv.org\/abs\/astro-ph\/0305537"]},
		{"ascl_id":"1103.007","title":"VisIt: Interactive Parallel Visualization and Graphical Analysis Tool","credit":"Department Of Energy (DOE) Advanced Simulation and Computing Initiative (ASCI)","abstract":"VisIt is a free interactive parallel visualization and graphical analysis tool for viewing scientific data on Unix and PC platforms. Users can quickly generate visualizations from their data, animate them through time, manipulate them, and save the resulting images for presentations. VisIt contains a rich set of visualization features so that you can view your data in a variety of ways. It can be used to visualize scalar and vector fields defined on two- and three-dimensional (2D and 3D) structured and unstructured meshes. VisIt was designed to handle very large data set sizes in the terascale range and yet can also handle small data sets in the kilobyte range. See the table below for more details about the tool\u2019s features.\r\n\r\nVisIt was developed by the Department of Energy (DOE) Advanced Simulation and Computing Initiative (ASCI) to visualize and analyze the results of terascale simulations. It was developed as a framework for adding custom capabilities and rapidly deploying new visualization technologies. Although the primary driving force behind the development of VisIt was for visualizing terascale data, it is also well suited for visualizing data from typical simulations on desktop systems.","topic_id":"23074","bibcode":"2011ascl.soft03007D","views":"44","site_list":["https:\/\/wci.llnl.gov\/codes\/visit\/home.html"],"ref_list":["http:\/\/www.visitusers.org\/index.php?title=Projects_that_use_VisIt"]},
		{"ascl_id":"1103.008","title":"Parallel HOP: A Scalable Halo Finder for Massive Cosmological Data Sets","credit":"Skory, Stephen; Turk, Matthew J.; Norman, Michael L.; Coil, Alison L.","abstract":"Modern N-body cosmological simulations contain billions ($10^9$) of dark matter particles. These simulations require hundreds to thousands of gigabytes of memory, and employ hundreds to tens of thousands of processing cores on many compute nodes. In order to study the distribution of dark matter in a cosmological simulation, the dark matter halos must be identified using a halo finder, which establishes the halo membership of every particle in the simulation. The resources required for halo finding are similar to the requirements for the simulation itself. In particular, simulations have become too extensive to use commonly-employed halo finders, such that the computational requirements to identify halos must now be spread across multiple nodes and cores. Here we present a scalable-parallel halo finding method called Parallel HOP for large-scale cosmological simulation data. Based on the halo finder HOP, it utilizes MPI and domain decomposition to distribute the halo finding workload across multiple compute nodes, enabling analysis of much larger datasets than is possible with the strictly serial or previous parallel implementations of HOP. We provide a reference implementation of this method as a part of the toolkit yt, an analysis toolkit for Adaptive Mesh Refinement (AMR) data that includes complementary analysis modules. Additionally, we discuss a suite of benchmarks that demonstrate that this method scales well up to several hundred tasks and datasets in excess of $2000^3$ particles. The Parallel HOP method and our implementation can be readily applied to any kind of N-body simulation data and is therefore widely applicable. Parallel HOP is part of <a href=http:\/\/ascl.net\/1011.022>yt<\/a>.","topic_id":"23079","bibcode":"2011ascl.soft03008S","views":"47","site_list":["http:\/\/yt.enzotools.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1001.3411"]},
		{"ascl_id":"1103.009","title":"SPHRAY: A Smoothed Particle Hydrodynamics Ray Tracer for Radiative Transfer","credit":"Altay, Gabriel; Croft, Rupert A. C.; Pelupessy, Inti","abstract":"SPHRAY, a Smoothed Particle Hydrodynamics (SPH) ray tracer, is designed to solve the 3D, time dependent, radiative transfer (RT) equations for arbitrary density fields. The SPH nature of SPHRAY makes the incorporation of separate hydrodynamics and gravity solvers very natural. SPHRAY relies on a Monte Carlo (MC) ray tracing scheme that does not interpolate the SPH particles onto a grid but instead integrates directly through the SPH kernels. Given initial conditions and a description of the sources of ionizing radiation, the code will calculate the non-equilibrium ionization state (HI, HII, HeI, HeII, HeIII, e) and temperature (internal energy\/entropy) of each SPH particle. The sources of radiation can include point like objects, diffuse recombination radiation, and a background field from outside the computational volume. The MC ray tracing implementation allows for the quick introduction of new physics and is parallelization friendly. A quick Axis Aligned Bounding Box (AABB) test taken from computer graphics applications allows for the acceleration of the raytracing component. We present the algorithms used in SPHRAY and verify the code by performing all the test problems detailed in the recent Radiative Transfer Comparison Project of Iliev et. al. The Fortran 90 source code for SPHRAY and example SPH density fields are made available online.","topic_id":"23080","bibcode":"2011ascl.soft03009A","views":"49","site_list":["http:\/\/code.google.com\/p\/sphray\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0802.3698"]},
		{"ascl_id":"1103.010","title":"Hydra: A Parallel Adaptive Grid Code","credit":"Couchman, Hugh; Pearce, Frazer; Thomas, Peter","abstract":"We describe the first parallel implementation of an adaptive particle-particle, particle-mesh code with smoothed particle hydrodynamics. Parallelisation of the serial code, \"Hydra,\" is achieved by using CRAFT, a Cray proprietary language which allows rapid implementation of a serial code on a parallel machine by allowing global addressing of distributed memory.\r\n\r\nThe collisionless variant of the code has already completed several 16.8 million particle cosmological simulations on a 128 processor Cray T3D whilst the full hydrodynamic code has completed several 4.2 million particle combined gas and dark matter runs. The efficiency of the code now allows parameter-space explorations to be performed routinely using $64^3$ particles of each species. A complete run including gas cooling, from high redshift to the present epoch requires approximately 10 hours on 64 processors.","topic_id":"23084","bibcode":"2011ascl.soft03010C","views":"95","site_list":["http:\/\/coho.mcmaster.ca\/hydra\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9703183","http:\/\/arxiv.org\/abs\/astro-ph\/9603116"]},
		{"ascl_id":"1103.011","title":"AP3M: Adaptive Particle-particle, Particle-mesh Code","credit":"Couchman, Hugh; Pearce, Frazer; Thomas, Peter","abstract":"AP<sup>3<\/sup>M is an adaptive particle-particle, particle-mesh code. It is older than <a href=\"http:\/\/ascl.net\/1103.010\">Hydra<\/a> (ascl:1103.010) but faster and more memory-efficient for dark-matter only calculations. The Adaptive P<sup>3<\/sup>M technique (AP<sup>3<\/sup>M) is built around the standard P<sup>3<\/sup>M algorithm. AP<sup>3<\/sup>M produces fully equivalent forces to P<sup>3<\/sup>M but represents a more efficient implementation of the force splitting idea of P<sup>3<\/sup>M. The AP<sup>3<\/sup>M program may be used in any of the three modes with an appropriate choice of input parameter.","topic_id":"23085","bibcode":"2011ascl.soft03011C","views":"99","site_list":["http:\/\/coho.mcmaster.ca\/hydra\/ap3m\/ap3m.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9708066"]},
		{"ascl_id":"1103.012","title":"Pyflation: Second Order Perturbations During Inflation Beyond Slow-roll","credit":"Huston, Ian","abstract":"Pyflation is a Python package for calculating cosmological perturbations during an inflationary expansion of the universe. The modules in the pyflation Python package can be used to run simulations of different scalar field models of the early universe. The main classes are contained in the cosmomodels module and include simulations of background fields and first order and second order perturbations. The sourceterm package contains modules required for the computation of the term required for the evolution of second order perturbations.\r\n\r\nAlongside the Python package, the bin directory contains Python scripts which can run first and second order simulations. A helper script called pyflation-qsubstart.py sets up a full second order run (including background, first order and source calculations) to be used on queueing system which contains the qsub executable (e.g. a Rocks cluster).","topic_id":"23102","bibcode":"2011ascl.soft03012H","views":"34","site_list":["http:\/\/pyflation.ianhuston.net\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1103.0912"]},
		{"ascl_id":"1103.014","title":"ParaView: Data Analysis and Visualization Application","credit":"Numerous","abstract":"ParaView is an open-source, multi-platform data analysis and visualization application. ParaView users can quickly build visualizations to analyze their data using qualitative and quantitative techniques. The data exploration can be done interactively in 3D or programmatically using ParaView's batch processing capabilities.\r\n\r\nParaView was developed to analyze extremely large datasets using distributed memory computing resources. It can be run on supercomputers to analyze datasets of terascale as well as on laptops for smaller data.","topic_id":"23132","bibcode":"2011ascl.soft03014N","views":"34","site_list":["http:\/\/www.paraview.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0706.1270"]},
		{"ascl_id":"1103.015","title":"Cloudy_3D: Quick Pseudo-3D Photoionization Code","credit":"Morisset, Christophe","abstract":"We developed a new quick pseudo-3D photoionization code based on Cloudy (G. Ferland) and IDL (RSI) tools. The code is running the 1D photoionization code Cloudy various times, changing at each run the input parameters (e.g. inner radius, density law) according to an angular law describing the morphology of the object. Then a cube is generated by interpolating the outputs of Cloudy. In each cell of the cube, the physical conditions (electron temperature and density, ionic fractions) and the emissivities of lines are determined. Associated tools (VISNEB and VELNEB_3D) are used to rotate the nebula and to compute surface brightness maps and emission line profiles, given a velocity law and taking into account the effect of the thermal broadening and eventually the turbulence. Integrated emission line profiles are computed, given aperture shapes and positions (seeing and instrumental width effects are included). The main advantage of this tool is the short time needed to compute a model (a few tens minutes).","topic_id":"23142","bibcode":"2011ascl.soft03015M","views":"54","site_list":["http:\/\/sites.google.com\/site\/cloudy3d\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0605400"]},
		{"ascl_id":"1104.001","title":"TomograPy: A Fast, Instrument-Independent, Solar Tomography Software","credit":"Barbey, Nicolas; Guennou, Chlo\u00e9; Auch\u00e8re, Fr\u00e9d\u00e9ric","abstract":"TomograPy is an open-source software freely available on the Python Package Index that can perform fast tomographic inversions that scale linearly with the number of measurements, linearly with the length of the reconstruction cube (and not the number of voxels) and linearly with the number of cores and can use data from different sources and with a variety of physical models. For performance, TomograPy uses a parallelized-projection algorithm. It relies on the World Coordinate System standard to manage various data sources. A variety of inversion algorithms are provided to perform the tomographic-map estimation. A test suite is provided along with the code to ensure software quality. Since it makes use of the Siddon algorithm it is restricted to rectangular parallelepiped voxels but the spherical geometry of the corona can be handled through proper use of priors.","topic_id":"23290","bibcode":"2011ascl.soft04001B","views":"39","site_list":["http:\/\/nbarbey.github.com\/TomograPy\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1103.5904"]},
		{"ascl_id":"1104.002","title":"AstroBEAR: Adaptive Mesh Refinement Code for Ideal Hydrodynamics & Magnetohydrodynamics","credit":"Cunningham, Andrew J.; Frank, Adam; Varniere, Peggy; Mitran, Sorin; Jones, Thomas W.","abstract":"AstroBEAR is a modular hydrodynamic & magnetohydrodynamic code environment designed for a variety of astrophysical applications. It uses the <a href=\"http:\/\/ascl.net\/1104.013\">BEARCLAW<\/a> package, a multidimensional, Eulerian computational code used to solve hyperbolic systems of equations. AstroBEAR allows adaptive-mesh-refinment (AMR) simulations in 2, 2.5 (i.e., cylindrical), and 3 dimensions, in either cartesian or curvilinear coordinates. Parallel applications are supported through the MPI architecture. AstroBEAR is written in Fortran 90\/95 using standard libraries.\n\nAstroBEAR supports hydrodynamic (HD) and magnetohydrodynamic (MHD) applications using a variety of spatial and temporal methods. MHD simulations are kept divergence-free via the constrained transport (CT) methods of Balsara & Spicer. Three different equation of state environments are available: ideal gas, gas with differing isentropic \u03b3, and the analytic Thomas-Fermi formulation of A.R. Bell [2]. Current work is being done to develop a more advanced real gas equation of state.","topic_id":"23292","bibcode":"2011ascl.soft04002C","views":"103","site_list":["https:\/\/astrobear.pas.rochester.edu\/trac"],"ref_list":["http:\/\/arxiv.org\/abs\/0710.0424"]},
		{"ascl_id":"1104.003","title":"Starburst99: Synthesis Models for Galaxies with Active Star Formation","credit":"Leitherer, Claus; Schaerer, Daniel; Goldader, Jeff; Gonzalez-Delgado, Rosa; Robert, Carmelle; Foo Kune, Denis; de Mello, Duilia; Devost, Daniel; Heckman, Timothy M.; Aloisi, Alessandra; Martins, Lucimara; Vazquez, Gerardo","abstract":"Starburst99 is a comprehensive set of model predictions for spectrophotometric and related properties of galaxies with active star formation. The models are presented in a homogeneous way for five metallicities between Z = 0.040 and 0.001 and three choices of the initial mass function. The age coverage is 10^6 to 10^9 yr. Spectral energy distributions are used to compute colors and other quantities.","topic_id":"23300","bibcode":"2011ascl.soft04003L","views":"36","site_list":["http:\/\/www.stsci.edu\/science\/starburst99\/docs\/default.htm"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9902334"]},
		{"ascl_id":"1104.004","title":"MASSCLEAN: MASSive CLuster Evolution and ANalysis Package","credit":"Popescu, Bogdan; Hanson, M. M.","abstract":"MASSCLEAN is a sophisticated and robust stellar cluster image and photometry simulation package. This package is able to create color-magnitude diagrams and standard FITS images in any of the traditional optical and near-infrared bands based on cluster characteristics input by the user, including but not limited to distance, age, mass, radius and extinction. At the limit of very distant, unresolved clusters, we have checked the integrated colors created in MASSCLEAN against those from other simple stellar population (SSP) models with consistent results. Because the algorithm populates the cluster with a discrete number of tenable stars, it can be used as part of a Monte Carlo Method to derive the probabilistic range of characteristics (integrated colors, for example) consistent with a given cluster mass and age.","topic_id":"23301","bibcode":"2011ascl.soft04004P","views":"36","site_list":["http:\/\/www.physics.uc.edu\/~popescu\/index_lsst_info"],"ref_list":["http:\/\/arxiv.org\/abs\/0909.1113","http:\/\/arxiv.org\/abs\/0811.4210"]},
		{"ascl_id":"1104.005","title":"GALAXEV: Evolutionary Stellar Population Synthesis Models","credit":"Bruzual, Gustavo; Charlot, St\u00e9phane","abstract":"GALAXEV is a library of evolutionary stellar population synthesis models computed using the new isochrone synthesis code of Bruzual & Charlot (2003). This code allows one to computes the spectral evolution of stellar populations in wide ranges of ages and metallicities at a resolution of 3 \u00c5 across the whole wavelength range from 3200 \u00c5 to 9500 \u00c5, and at lower resolution outside this range.","topic_id":"23302","bibcode":"2011ascl.soft04005B","views":"46","site_list":["http:\/\/www2.iap.fr\/users\/charlot\/bc2003\/galaxev_download.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1010.4376"]},
		{"ascl_id":"1104.006","title":"LECTOR: Line-strengths in One-dimensional ASCII Spectra","credit":"Vazdekis, Alexandre","abstract":"LECTOR is a Fortran 77 code that measures line-strengths in one dimensional ascii spectra. The code returns the values of the Lick indices as well as those of Vazdekis & Arimoto 1999, Vazdekis et al. 2001, Rose 1994, Jones & Worthey 1995 and Cenarro et al. 2001. The code measures as many indices as you wish if the limits of two pseudocontinua (at each side of the feature) and the feature itself (i.e. Lick-style index definition) are provided. The Lick-style indices could be either expressed in pseudo-equivalent widths or in magnitudes. If requested the program provides index error estimates on the basis of photon statistics.","topic_id":"23311","bibcode":"2011ascl.soft04006V","views":"33","site_list":["http:\/\/www.iac.es\/galeria\/vazdekis\/vazdekis_software.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1004.4439","http:\/\/arxiv.org\/abs\/astro-ph\/0607009"]},
		{"ascl_id":"1104.007","title":"ULySS: A Full Spectrum Fitting Package","credit":"Koleva, Mina; Prugniel, Philippe; Bouchard, Antoine; Wu, Yue","abstract":"ULySS (University of Lyon Spectroscopic Analysis Software) is an open-source software package written in the GDL\/IDL language to analyze astronomical data. ULySS fits a spectrum with a linear combination of non-linear components convolved with a line-of-sight velocity distribution (LOSVD) and multiplied by a polynomial continuum. ULySS is used to study stellar populations of galaxies and star clusters and atmospheric parameters of stars.","topic_id":"23312","bibcode":"2011ascl.soft04007K","views":"54","site_list":["http:\/\/ulyss.univ-lyon1.fr\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0903.2979","http:\/\/arxiv.org\/abs\/1004.4439","http:\/\/arxiv.org\/abs\/astro-ph\/0607009"]},
		{"ascl_id":"1104.008","title":"Rmodel: Determining Stellar Population Parameters","credit":"Cardiel, Nicolas","abstract":"This program determines stellar population parameters (e.g. age, metallicity, IMF slope,...), using as input a pair of line-strength indices, through the interpolation in SSP model predictions. Both linear and bivariate fits are computed to perform the interpolation.","topic_id":"23313","bibcode":"2011ascl.soft04008C","views":"33","site_list":["http:\/\/www.ucm.es\/info\/Astrof\/software\/rmodel\/rmodel.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0306560","http:\/\/arxiv.org\/abs\/1004.4439","http:\/\/arxiv.org\/abs\/astro-ph\/0607009"]},
		{"ascl_id":"1104.009","title":"r-Java: An r-process Code and Graphical User Interface for Heavy-Element Nucleosynthesis","credit":"Charignon, Camille; Kostka, Mathew; Konin, Nico; Jaikumar, Prashanth; Ouyed, Rachid","abstract":"We present r-Java, an r-process code for open use, that performs r-process nucleosynthesis calculations. Equipped with a simple graphical user interface, r-Java is capable of carrying out nuclear statistical equilibrium (NSE) as well as static and dynamic r-process calculations for a wide range of input parameters. In this introductory paper, we present the motivation and details behind r-Java, and results from our static and dynamic simulations. Static simulations are explored for a range of neutron irradiation and temperatures. Dynamic simulations are studied with a parameterized expansion formula. Our code generates the resulting abundance pattern based on a general entropy expression that can be applied to degenerate as well as non-degenerate matter, allowing us to track the rapid density and temperature evolution of the ejecta during the initial stages of ejecta expansion. At present, our calculations are limited to the waiting-point approximation.","topic_id":"23361","bibcode":"2011ascl.soft04009C","views":"35","site_list":["http:\/\/quarknova.ucalgary.ca\/software\/rJava\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1104.0340"]},
		{"ascl_id":"1104.010","title":"GALFIT: Detailed Structural Decomposition of Galaxy Images","credit":"Peng, Chien Y.; Ho, Luis C.; Impey, Chris D.; Rix, Hans-Walter","abstract":"GALFIT is a two-dimensional (2-D) fitting algorithm designed to extract structural components from galaxy images, with emphasis on closely modeling light profiles of spatially well-resolved, nearby galaxies observed with the Hubble Space Telescope. The algorithm improves on previous techniques in two areas: 1.) by being able to simultaneously fit a galaxy with an arbitrary number of components, and 2.) with optimization in computation speed, suited for working on large galaxy images. 2-D models such as the \"Nuker'' law, the Sersic (de Vaucouleurs) profile, an exponential disk, and Gaussian or Moffat functions are used. The azimuthal shapes are generalized ellipses that can fit disky and boxy components. Many galaxies with complex isophotes, ellipticity changes, and position-angle twists can be modeled accurately in 2-D. When examined in detail, even simple-looking galaxies generally require at least three components to be modeled accurately rather than the one or two components more often employed. This is illustrated by way of seven case studies, which include regular and barred spiral galaxies, highly disky lenticular galaxies, and elliptical galaxies displaying various levels of complexities. A useful extension of this algorithm is to accurately extract nuclear point sources in galaxies.","topic_id":"23408","bibcode":"2011ascl.soft04010P","views":"63","site_list":["http:\/\/users.obs.carnegiescience.edu\/peng\/work\/galfit\/galfit.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0204182","http:\/\/arxiv.org\/abs\/0704.2601","http:\/\/arxiv.org\/abs\/0912.0731"]},
		{"ascl_id":"1104.011","title":"DAOPHOT: Crowded-field Stellar Photometry Package","credit":"Stetson, Peter B.","abstract":"The DAOPHOT program exploits the capability of photometrically linear image detectors to perform stellar photometry in crowded fields. Raw CCD images are prepared prior to analysis, and following the obtaining of an initial star list with the FIND program, synthetic aperture photometry is performed on the detected objects with the PHOT routine. A local sky brightness and a magnitude are computed for each star in each of the specified stellar apertures, and for crowded fields, the empirical point-spread function must then be obtained for each data frame. The GROUP routine divides the star list for a given frame into optimum subgroups, and then the NSTAR routine is used to obtain photometry for all the stars in the frame by means of least- squares profile fits.","topic_id":"23410","bibcode":"2011ascl.soft04011S","views":"51","site_list":["http:\/\/www.star.bris.ac.uk\/~mbt\/daophot\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1987PASP...99..191S"]},
		{"ascl_id":"1104.012","title":"CHIWEI: A Code of Goodness of Fit Tests for Weighted and Unweighed Histograms","credit":"Gagunashvili, Nikolai","abstract":"A self-contained Fortran-77 program for goodness of fit tests for histograms with weighted entries as well as with unweighted entries is presented. The code calculates test statistic for case of histogram with normalized weights of events and for case of unnormalized weights of events.","topic_id":"23728","bibcode":"2011ascl.soft04012G","views":"52","site_list":["http:\/\/asterisk.apod.com\/download\/file.php?id=2978"],"ref_list":["http:\/\/arxiv.org\/abs\/1104.3733"]},
		{"ascl_id":"1104.013","title":"BEARCLAW: Boundary Embedded Adative Refinement Conservation LAW package","credit":"Mitran, Sorin","abstract":"The BEARCLAW package is a multidimensional, Eulerian AMR-capable computational code written in Fortran to solve hyperbolic systems for astrophysical applications. It is part of <a href=\"http:\/\/ascl.net\/1104.002\">AstroBEAR<\/a>, a hydrodynamic & magnetohydrodynamic code environment designed for a variety of astrophysical applications which allows simulations in 2, 2.5 (i.e., cylindrical), and 3 dimensions, in either cartesian or curvilinear coordinates.","topic_id":"23551","bibcode":"2011ascl.soft04013M","views":"83","site_list":["http:\/\/mitran-lab.amath.unc.edu:8084\/redmine\/projects\/bearclaw\/wiki","http:\/\/mitran.web.unc.edu\/codes\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0710.0424"]},
		{"ascl_id":"1104.014","title":"A Correction to the Standard Galactic Reddening Map: Passive Galaxies as Standard Crayons","credit":"Peek, J. E. G.; Graves, Genevieve J.","abstract":"We present corrections to the Schlegel, Finkbeiner, Davis (SFD98) reddening maps over the Sloan Digital Sky Survey northern Galactic cap area. To find these corrections, we employ what we dub the \"standard crayon\" method, in which we use passively evolving galaxies as color standards by which to measure deviations from the reddening map. We select these passively evolving galaxies spectroscopically, using limits on the H alpha and O II equivalent widths to remove all star-forming galaxies from the SDSS main galaxy catalog. We find that by correcting for known reddening, redshift, color-magnitude relation, and variation of color with environmental density, we can reduce the scatter in color to below 3% in the bulk of the 151,637 galaxies we select. Using these galaxies we construct maps of the deviation from the SFD98 reddening map at 4.5 degree resolution, with 1-sigma error of ~ 1.5 millimagnitudes E(B-V). We find that the SFD98 maps are largely accurate with most of the map having deviations below 3 millimagnitudes E(B-V), though some regions do deviate from SFD98 by as much as 50%. The maximum deviation found is 45 millimagnitudes in E(B-V), and spatial structure of the deviation is strongly correlated with the observed dust temperature, such that SFD98 underpredicts reddening in regions of low dust temperature. The maps of these deviations, as well as their errors, are made available to the scientific community as supplemental correction to SFD98 at the URL below.","topic_id":"23555","bibcode":"2011ascl.soft04014P","views":"79","site_list":["http:\/\/www.astro.columbia.edu\/~jpeek\/dust.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1006.3310"]},
		{"ascl_id":"1105.001","title":"STILTS: Starlink Tables Infrastructure Library Tool Set","credit":"Taylor, Mark","abstract":"The STIL Tool Set is a set of command-line tools based on STIL, the Starlink Tables Infrastructure Library. It deals with the processing of tabular data; the package has been designed for, but is not restricted to, astronomical tables such as object catalogues. Some of the tools are generic and can work with multiple formats (including FITS, VOTable, CSV, SQL and ASCII), and others are specific to the VOTable format. In some ways, STILTS forms the command-line counterpart of the GUI table analysis tool TOPCAT. The package is robust, fully documented, and designed for efficiency, especially with very large datasets. \r\n\r\nFacilities offered include:\r\n\r\n<ul><li>format conversion<\/li><li>crossmatching<\/li><li>plotting<\/li><li>column calculation and rearrangement<\/li><li>row selections<\/li><li>data and metadata manipulation and display<\/li><li>sorting<\/li><li>statistical calculations<\/li><li>histogram calculation<\/li><li>data validation<\/li><li>VO service access<\/li><\/ul>A powerful and extensible expression language is used for specifying data calculations. These facilities can be put together in very flexible and efficient ways. For tasks in which the data can be streamed, the size of table STILTS can process is effectively unlimited. For other tasks, million-row tables usually do not present a problem. STILTS is written in pure Java (J2SE1.5 or later), and can be run from the command line or from Jython, or embedded into java applications. It is released under the GPL.","topic_id":"23562","bibcode":"2011ascl.soft05001T","views":"76","site_list":["http:\/\/www.star.bristol.ac.uk\/~mbt\/stilts\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009ASPC..411..510T","http:\/\/adsabs.harvard.edu\/abs\/2006ASPC..351..666T"]},
		{"ascl_id":"1105.002","title":"PACCE: Perl Algorithm to Compute Continuum and Equivalent Widths","credit":"Riffel, Rog\u00e9rio; Borges Vale, Tib\u00e9rio","abstract":"We present Perl Algorithm to Compute continuum and Equivalent Widths (pacce). We describe the methods used in the computations and the requirements for its usage. We compare the measurements made with pacce and \"manual\" ones made using iraf splot task. These tests show that for SSP models the equivalent widths strengths are very similar (differences &lt;0.2A) for both measurements. In real stellar spectra, the correlation between both values is still very good, but with differences of up to 0.5A. pacce is also able to determine mean continuum and continuum at line center values, which are helpful in stellar population studies. In addition, it is also able to compute the uncertainties in the equivalent widths using photon statistics.","topic_id":"23587","bibcode":"2011ascl.soft05002R","views":"39","site_list":["http:\/\/www.if.ufrgs.br\/~riffel\/software.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1105.0318"]},
		{"ascl_id":"1105.003","title":"The DTFE public software: The Delaunay Tessellation Field Estimator code","credit":"Cautun, Marius C.; van de Weygaert, Rien","abstract":"We present the DTFE public software, a code for reconstructing fields from a discrete set of samples\/measurements using the maximum of information contained in the point distribution. The code is written in C++ using the CGAL library and is parallelized using OpenMP. The software was designed for the analysis of cosmological data but can be used in other fields where one must interpolate quantities given at a discrete point set. The software comes with a wide suite of options to facilitate the analysis of 2- and 3-dimensional data and of both numerical simulations and galaxy redshift surveys. For comparison purposes, the code also implements the TSC and SPH grid interpolation methods. The code comes with an extensive user guide detailing the program options, examples and the inner workings of the code.","topic_id":"23588","bibcode":"2011ascl.soft05003C","views":"37","site_list":["http:\/\/www.astro.rug.nl\/~voronoi\/DTFE\/dtfe.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1105.0370"]},
		{"ascl_id":"1105.004","title":"SLiM: A Code for the Simulation of Wave Propagation through an Inhomogeneous, Magnetised Solar Atmosphere","credit":"Cameron, R.; Gizon, L.; Daiffallah, K.","abstract":"The semi-spectral linear MHD (SLiM) code follows the interaction of linear waves through an inhomogeneous three-dimensional solar atmosphere. The background model allows almost arbitrary perturbations of density, temperature, sound speed as well as magnetic and velocity fields. The code is useful in understanding the helioseismic signatures of various solar features, including sunspots.","topic_id":"23633","bibcode":"2011ascl.soft05004C","views":"58","site_list":["http:\/\/www.mps.mpg.de\/projects\/seismo\/NA4\/MODEL\/SLiM.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1002.2344"]},
		{"ascl_id":"1105.005","title":"ChaNGa: Charm N-body GrAvity solver","credit":"N-Body Shop","abstract":"ChaNGa (Charm N-body GrAvity solver) is a code to perform collisionless N-body simulations. It can perform cosmological simulations with periodic boundary conditions in comoving coordinates or simulations of isolated stellar systems. It also can include hydrodynamics using the Smooth Particle Hydrodynamics (SPH) technique. It uses a Barnes-Hut tree to calculate gravity, with hexadecapole expansion of nodes and Ewald summation for periodic forces. Timestepping is done with a leapfrog integrator with individual timesteps for each particle.","topic_id":"23634","bibcode":"2011ascl.soft05005N","views":"63","site_list":["http:\/\/www-hpcc.astro.washington.edu\/tools\/changa.html"],"ref_list":["http:\/\/www.computer.org\/portal\/web\/csdl\/doi\/10.1109\/SC.2010.49"]},
		{"ascl_id":"1105.006","title":"SPARC: Seismic Propagation through Active Regions and Convection","credit":"Hanasoge, Shravan M.","abstract":"The Seismic Propagation through Active Regions and Convection (SPARC) code was developed by S. Hanasoge. The acoustic wavefield in SPARC is simulated by numerically solving the linearised 3-D Euler equations in Cartesian geometry (e.g., see Hanasoge, Duvall and Couvidat (2007)). Spatial derivatives are calculated using sixth-order compact finite differences (Lele,1992) and time evolution is achieved through the repeated application of an optimized second-order five-stage Runge-Kutta scheme (Hu, 1996). Periodic horizontal boundaries are used.","topic_id":"23635","bibcode":"2011ascl.soft05006H","views":"45","site_list":["http:\/\/www.mps.mpg.de\/projects\/seismo\/sparc\/"],"ref_list":["http:\/\/www.mps.mpg.de\/projects\/seismo\/sparc\/noise_sub.pdf"]},
		{"ascl_id":"1105.007","title":"Sunspot Models","credit":"Khomenko, E.","abstract":"This IDL code creates a thick magneto-static structure with parameters of a typical sunspot in a solar like photosphere - chromosphere. The variable parameters are field strength on the axis, radius, and Wilson depression (displacement of the atmosphere on the axis with respect to the field-free atmosphere). Output are magnetic field vector, pressure and density distributions with radius and height. The structure has azimuthal symmetry. The codes are relatively self explanatory and the download packages contain README files.","topic_id":"23636","bibcode":"2011ascl.soft05007K","views":"47","site_list":["http:\/\/www.mps.mpg.de\/projects\/seismo\/NA4\/MODEL\/khomenko.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ApJ...689.1379K"]},
		{"ascl_id":"1105.008","title":"Flux Tube Model","credit":"Steiner, O.","abstract":"This Fortran code computes magnetohydrostatic flux tubes and sheets according to the method of Steiner, Pneuman, & Stenflo (1986) A&A 170, 126-137. The code has many parameters contained in one input file that are easily modified. Extensive documentation is provided in README files.","topic_id":"23637","bibcode":"2011ascl.soft05008S","views":"44","site_list":["http:\/\/www.mps.mpg.de\/projects\/seismo\/NA4\/MODEL\/steiner.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1986A%26A...170..126S"]},
		{"ascl_id":"1105.009","title":"Ray Tracing Codes: run_tau, run_raypath, and ray_kernel","credit":"Birch, Aaron","abstract":"Time-distance helioseismology aims to measure and interpret the travel times of waves propagating between two points located on the solar surface. The travel times are then inverted to infer sub-surface properties that are encoded in the measurements. The trajectory of the waves generally follows that of the infinite-frequency ray path, although they are sensitive to perturbations off of this path. Finite-frequency sensitivity kernels are thus needed to give more accurate inversion results.\n\nRay tracing codes calculate travel time kernels for a ray. There are three main codes which calculate the group time as a function of distance, the ray paths as well as the phase and group times along the path, and the ray kernels for the sound speed squared.","topic_id":"23643","bibcode":"2011ascl.soft05009B","views":"42","site_list":["http:\/\/www.mps.mpg.de\/projects\/seismo\/NA4\/MODEL\/travel_time.html"],"ref_list":["http:\/\/www.mps.mpg.de\/projects\/seismo\/software\/BIRCH\/dissertation\/"]},
		{"ascl_id":"1105.010","title":"CASTRO: Multi-dimensional Eulerian AMR Radiation-hydrodynamics Code","credit":"Center For Computational Sciences; Entineering (Berkeley); Howell, Louis; Singer, Mike","abstract":"CASTRO is a multi-dimensional Eulerian AMR radiation-hydrodynamics code that includes stellar equations of state, nuclear reaction networks, and self-gravity. Initial target applications for CASTRO include Type Ia and Type II supernovae. CASTRO supports calculations in 1-d, 2-d and 3-d Cartesian coordinates, as well as 1-d spherical and 2-d cylindrical (r-z) coordinate systems. Time integration of the hydrodynamics equations is based on an unsplit version of the the piecewise parabolic method (PPM) with new limiters that avoid reducing the accuracy of the scheme at smooth extrema. CASTRO can follow an arbitrary number of isotopes or elements. The atomic weights and amounts of these elements are used to calculate the mean molecular weight of the gas required by the equation of state. CASTRO supports several different approaches to solving for self-gravity. The most general is a full Poisson solve for the gravitational potential. CASTRO also supports a monopole approximation for gravity, and a constant gravity option is also available. The CASTRO software is written in C++ and Fortran, and is based on the BoxLib software framework developed by CCSE.","topic_id":"23677","bibcode":"2011ascl.soft05010C","views":"48","site_list":["https:\/\/ccse.lbl.gov\/Research\/CASTRO\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1008.2801","http:\/\/arxiv.org\/abs\/1105.2466"]},
		{"ascl_id":"1105.011","title":"Ganalyzer: A tool for automatic galaxy image analysis","credit":"Shamir, Lior","abstract":"We describe Ganalyzer, a model-based tool that can automatically analyze and classify galaxy images. Ganalyzer works by separating the galaxy pixels from the background pixels, finding the center and radius of the galaxy, generating the radial intensity plot, and then computing the slopes of the peaks detected in the radial intensity plot to measure the spirality of the galaxy and determine its morphological class. Unlike algorithms that are based on machine learning, Ganalyzer is based on measuring the spirality of the galaxy, a task that is difficult to perform manually, and in many cases can provide a more accurate analysis compared to manual observation. Ganalyzer is simple to use, and can be easily embedded into other image analysis applications. Another advantage is its speed, which allows it to analyze ~10,000,000 galaxy images in five days using a standard modern desktop computer. These capabilities can make Ganalyzer a useful tool in analyzing large datasets of galaxy images collected by autonomous sky surveys such as SDSS, LSST or DES.","topic_id":"23720","bibcode":"2011ascl.soft05011S","views":"40","site_list":["http:\/\/vfacstaff.ltu.edu\/lshamir\/downloads\/ganalyzer\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1105.3214"]},
		{"ascl_id":"1105.012","title":"Stagger: MHD Method for Modeling Star Formation","credit":"Galsgaard, Klaus","abstract":"Stagger is an astrophysical MHD code actively used to model star formation. It is equipped with a multi-frequency radiative transfer module and a comprehensive equation of state module that includes a large number of atomic and molecular species, to be able to compute realistic 3-D models of the near-surface layers of stars. The current version of the code allows a discretization that explicitly conserves mass, momentum, energy, and magnetic flux. The tensor formulation of the viscosity ensures that the viscous force is insensitive to the coordinate system orientation, thereby avoiding artificial grid-alignment.","topic_id":"23733","bibcode":"2011ascl.soft05012G","views":"53","site_list":["http:\/\/comp.astro.ku.dk\/Twiki\/view\/CompAstro\/StaggerCode"],"ref_list":["http:\/\/arxiv.org\/abs\/0907.0587","http:\/\/adsabs.harvard.edu\/abs\/2007ApJ...661..972P"]},
		{"ascl_id":"1105.013","title":"CAMB Sources: Number Counts, Lensing & Dark-age 21cm Power Spectra\r\nThe linear power spectrum of observed source number counts","credit":"Challinor, Anthony; Lewis, Antony","abstract":"We relate the observable number of sources per solid angle and redshift to the underlying proper source density and velocity, background evolution and line-of-sight potentials. We give an exact result in the case of linearized perturbations assuming general relativity. This consistently includes contributions of the source density perturbations and redshift distortions, magnification, radial displacement, and various additional linear terms that are small on sub-horizon scales. In addition we calculate the effect on observed luminosities, and hence the result for sources observed as a function of flux, including magnification bias and radial-displacement effects. We give the corresponding linear result for a magnitude-limited survey at low redshift, and discuss the angular power spectrum of the total count distribution. We also calculate the cross-correlation with the CMB polarization and temperature including Doppler source terms, magnification, redshift distortions and other velocity effects for the sources, and discuss why the contribution of redshift distortions is generally small. Finally we relate the result for source number counts to that for the brightness of line radiation, for example 21-cm radiation, from the sources.","topic_id":"23769","bibcode":"2011ascl.soft05013C","views":"53","site_list":["http:\/\/camb.info\/sources\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1105.5292"]},
		{"ascl_id":"1105.014","title":"PSRCHIVE: Development Library for the Analysis of Pulsar Astronomical Data","credit":"van Straten, Willem; Demorest, Paul; Khoo, Jonathan; Keith, Mike; Hotan, Aidan; et al.","abstract":"PSRCHIVE is an Open Source C++ development library for the analysis of pulsar astronomical data. It implements an extensive range of algorithms for use in pulsar timing, polarimetric calibration, single-pulse analyses, RFI mitigation, scintillation studies, etc. These tools are utilized by a powerful suite of user-end programs that come with the library.","topic_id":"23816","bibcode":"2011ascl.soft05014V","views":"45","site_list":["http:\/\/psrchive.sourceforge.net"],"ref_list":["http:\/\/www.publish.csiro.au\/?paper=AS04022","http:\/\/arxiv.org\/abs\/0912.1662"]},
		{"ascl_id":"1106.001","title":"AlterBBN: A program for calculating the BBN abundances of the elements in alternative cosmologies","credit":"Arbey, Alexandre","abstract":"We describe AlterBBN, a public C program for evaluating the abundances of the elements generated by Big-Bang nucleosynthesis (BBN). This program enables the user to compute the abundances of the elements in the standard model of cosmology, and additionally provides possibilities to alter the assumptions of the cosmological model in order to study their consequences on the abundances of the elements. In particular the baryon-to-photon ratio and the effective number of neutrinos, as well as the expansion rate and the entropy content of the Universe during BBN can be modified in AlterBBN. Such features allow the user to test the cosmological models by confronting them to BBN constraints.","topic_id":"23897","bibcode":"2011ascl.soft06001A","views":"68","site_list":["http:\/\/superiso.in2p3.fr\/relic\/alterbbn"],"ref_list":["http:\/\/arxiv.org\/abs\/1106.1363"]},
		{"ascl_id":"1106.002","title":"PHOEBE: PHysics Of Eclipsing BinariEs","credit":"Prsa, Andrej; Matijevic, Gal; Latkovic, Olivera; Vilardell, Francesc; Wils, Patrick","abstract":"PHOEBE (PHysics Of Eclipsing BinariEs) is a modeling package for eclipsing binary stars, built on top of the widely used WD program (Wilson & Devinney 1971). This introductory paper overviews most important scientific extensions (incorporating observational spectra of eclipsing binaries into the solution-seeking process, extracting individual temperatures from observed color indices, main-sequence constraining and proper treatment of the reddening), numerical innovations (suggested improvements to WD's Differential Corrections method, the new Nelder & Mead's downhill Simplex method) and technical aspects (back-end scripter structure, graphical user interface). While PHOEBE retains 100% WD compatibility, its add-ons are a powerful way to enhance WD by encompassing even more physics and solution reliability.","topic_id":"23919","bibcode":"2011ascl.soft06002P","views":"55","site_list":["http:\/\/phoebe.fmf.uni-lj.si\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0503361"]},
		{"ascl_id":"1106.003","title":"PLplot: Cross-platform Software Package for Scientific Plots","credit":"Many Developers","abstract":"PLplot is a cross-platform software package for creating scientific plots. To help accomplish that task it is organized as a core C library, language bindings for that library, and device drivers which control how the plots are presented in non-interactive and interactive plotting contexts. The PLplot core library can be used to create standard x-y plots, semi-log plots, log-log plots, contour plots, 3D surface plots, mesh plots, bar charts and pie charts. Multiple graphs (of the same or different sizes) may be placed on a single page, and multiple pages are allowed for those device formats that support them. PLplot has core support for Unicode. This means for our many Unicode-aware devices that plots can be labelled using the enormous selection of Unicode mathematical symbols. A large subset of our Unicode-aware devices also support complex text layout (CTL) languages such as Arabic, Hebrew, and Indic and Indic-derived CTL scripts such as Devanagari, Thai, Lao, and Tibetan. PLplot device drivers support a number of different file formats for non-interactive plotting and a number of different platforms that are suitable for interactive plotting. It is easy to add new device drivers to PLplot by writing a small number of device dependent routines.","topic_id":"23920","bibcode":"2011ascl.soft06003M","views":"35","site_list":["http:\/\/plplot.sourceforge.net\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004ASPC..314..517S"]},
		{"ascl_id":"1106.004","title":"E3D: The Euro3D Visualization Tool","credit":"S\u00e1nchez, Sebasti\u00e1n F.","abstract":"E3D is a package of tools for the analysis and visualization of IFS data. It is capable of reading, writing, and visualizing reduced data from 3D spectrographs of any kind.","topic_id":"23921","bibcode":"2011ascl.soft06004S","views":"46","site_list":["http:\/\/www.aip.de\/Euro3D\/E3D\/"],"ref_list":["http:\/\/de.arxiv.org\/abs\/astro-ph\/0310677v1"]},
		{"ascl_id":"1106.005","title":"R3D: Reduction Package for Integral Field Spectroscopy","credit":"S\u00e1nchez, Sebasti\u00e1n. F.","abstract":"R3D was developed to reduce fiber-based integral field spectroscopy (IFS) data. The package comprises a set of command-line routines adapted for each of these steps, suitable for creating pipelines. The routines have been tested against simulations, and against real data from various integral field spectrographs (PMAS, PPAK, GMOS, VIMOS and INTEGRAL). Particular attention is paid to the treatment of cross-talk.\r\n\r\nR3D unifies the reduction techniques for the different IFS instruments to a single one, in order to allow the general public to reduce different instruments data in an homogeneus, consistent and simple way. Although still in its prototyping phase, it has been proved to be useful to reduce PMAS (both in the Larr and the PPAK modes), VIMOS and INTEGRAL data. The current version has been coded in Perl, using PDL, in order to speed-up the algorithm testing phase. Most of the time critical algorithms have been translated to C[float=][\/float], and it is our intention to translate all of them. However, even in this phase R3D is fast enough to produce valuable science frames in reasonable time.","topic_id":"23929","bibcode":"2011ascl.soft06005S","views":"41","site_list":["http:\/\/www.caha.es\/sanchez\/r3d\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006AN....327..850S","http:\/\/adsabs.harvard.edu\/abs\/2007MNRAS.378..416V"]},
		{"ascl_id":"1106.006","title":"MECI: A Method for Eclipsing Component Identification","credit":"Devor, Jonathan; Charbonneau, David","abstract":"We describe an automated method for assigning the most probable physical parameters to the components of an eclipsing binary, using only its photometric light curve and combined colors. With traditional methods, one attempts to optimize a multi-parameter model over many iterations, so as to minimize the chi-squared value. We suggest an alternative method, where one selects pairs of coeval stars from a set of theoretical stellar models, and compares their simulated light curves and combined colors with the observations. This approach greatly reduces the parameter space over which one needs to search, and allows one to estimate the components' masses, radii and absolute magnitudes, without spectroscopic data. We have implemented this method in an automated program using published theoretical isochrones and limb-darkening coefficients. Since it is easy to automate, this method lends itself to systematic analyses of datasets consisting of photometric time series of large numbers of stars, such as those produced by OGLE, MACHO, TrES, HAT, and many others surveys.","topic_id":"23931","bibcode":"2011ascl.soft06006D","views":"36","site_list":["https:\/\/www.cfa.harvard.edu\/~jdevor\/MECI\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0609588"]},
		{"ascl_id":"1106.007","title":"MIRIAD: Multi-channel Image Reconstruction, Image Analysis, and Display","credit":"Sault, R. J.; Teuben, P. J.; Wright, M. C. H.","abstract":"MIRIAD is a radio interferometry data-reduction package, designed for taking raw visibility data through calibration to the image analysis stage. It has been designed to handle any interferometric array, with working examples for BIMA, CARMA, SMA, WSRT, and ATCA. A separate version for ATCA is available, which differs in a few minor ways from the CARMA version.","topic_id":"23932","bibcode":"2011ascl.soft06007S","views":"40","site_list":["http:\/\/carma.astro.umd.edu\/miriad\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0612759"]},
		{"ascl_id":"1106.008","title":"GRAFIC-2: Multiscale Gaussian Random Fields for Cosmological Simulations","credit":"Bertschinger, Edmund","abstract":"This paper describes the generation of initial conditions for numerical simulations in cosmology with multiple levels of resolution, or multiscale simulations. We present the theory of adaptive mesh refinement of Gaussian random fields followed by the implementation and testing of a computer code package performing this refinement called GRAFIC-2.","topic_id":"23937","bibcode":"2011ascl.soft06008B","views":"55","site_list":["http:\/\/web.mit.edu\/~edbert\/grafic-2.101.tar.gz"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0103301"]},
		{"ascl_id":"1106.009","title":"PARAMESH V4.1: Parallel Adaptive Mesh Refinement","credit":"MacNeice, Peter; Olson, Kevin M.; Mobarry, Clark; de Fainchtein, Rosalinda; Packer, Charles","abstract":"PARAMESH is a package of Fortran 90 subroutines designed to provide an application developer with an easy route to extend an existing serial code which uses a logically cartesian structured mesh into a parallel code with adaptive mesh refinement (AMR). Alternatively, in its simplest use, and with minimal effort, it can operate as a domain decomposition tool for users who want to parallelize their serial codes, but who do not wish to use adaptivity.\n\nThe package builds a hierarchy of sub-grids to cover the computational domain, with spatial resolution varying to satisfy the demands of the application. These sub-grid blocks form the nodes of a tree data-structure (quad-tree in 2D or oct-tree in 3D). Each grid block has a logically cartesian mesh. The package supports 1, 2 and 3D models. PARAMESH is released under the <a href=\"http:\/\/www.physics.drexel.edu\/~olson\/paramesh-doc\/Users_manual\/users_agreement.html\">NASA-wide Open-Source software license<\/a>.","topic_id":"23940","bibcode":"2011ascl.soft06009M","views":"52","site_list":["http:\/\/sourceforge.net\/projects\/paramesh\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000CoPhC.126..330M"]},
		{"ascl_id":"1106.010","title":"MAGPHYS: Multi-wavelength Analysis of Galaxy Physical Properties","credit":"da Cunha, Elisabete; Charlot, St\u00e9phane","abstract":"MAGPHYS is a self-contained, user-friendly model package to interpret observed spectral energy distributions of galaxies in terms of galaxy-wide physical parameters pertaining to the stars and the interstellar medium. MAGPHYS is optimized to derive statistical constraints of fundamental parameters related to star formation activity and dust content (e.g. star formation rate, stellar mass, dust attenuation, dust temperatures) of large samples of galaxies using a wide range of multi-wavelength observations. A Bayesian approach is used to interpret the SEDs all the way from the ultraviolet\/optical to the far-infrared.","topic_id":"23962","bibcode":"2011ascl.soft06010D","views":"48","site_list":["http:\/\/www.iap.fr\/magphys\/magphys\/MAGPHYS.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008MNRAS.388.1595D"]},
		{"ascl_id":"1106.011","title":"DRAGON: Galactic Cosmic Ray Diffusion Code","credit":"Maccione, Luca; Evoli, Carmelo; Gaggero, Daniele; Grasso, Dario","abstract":"DRAGON adopts a second-order Cranck-Nicholson scheme with Operator Splitting and time overrelaxation to solve the diffusion equation. This provides a fast solution that is accurate enough for the average user. Occasionally, users may want to have very accurate solutions to their problem. To enable this feature, users may get close to the accurate solution by using the fast method, and then switch to a more accurate solution scheme featuring the Alternating-Direction-Implicit (ADI) Cranck-Nicholson scheme.","topic_id":"23974","bibcode":"2011ascl.soft06011M","views":"52","site_list":["http:\/\/www.dragonproject.org\/Home.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0909.4548","http:\/\/arxiv.org\/abs\/1010.0174"]},
		{"ascl_id":"1106.012","title":"SLUG: Stochastically Lighting Up Galaxies","credit":"da Silva, Robert L.; Fumagalli, Michele; Krumholz, Mark","abstract":"The effects of stochasticity on the luminosities of stellar populations are an often neglected but crucial element for understanding populations in the low mass or low star formation rate regime. To address this issue, we present SLUG, a new code to \"Stochastically Light Up Galaxies\". SLUG synthesizes stellar populations using a Monte Carlo technique that treats stochastic sampling properly including the effects of clustering, the stellar initial mass function, star formation history, stellar evolution, and cluster disruption. This code produces many useful outputs, including i) catalogs of star clusters and their properties, such as their stellar initial mass distributions and their photometric properties in a variety of filters, ii) two dimensional histograms of color-magnitude diagrams of every star in the simulation, iii) and the photometric properties of field stars and the integrated photometry of the entire simulated galaxy. After presenting the SLUG algorithm in detail, we validate the code through comparisons with starburst99 in the well-sampled regime, and with observed photometry of Milky Way clusters. Finally, we demonstrate the SLUG's capabilities by presenting outputs in the stochastic regime.","topic_id":"23979","bibcode":"2011ascl.soft06012D","views":"39","site_list":["http:\/\/sites.google.com\/site\/runslug\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1106.3072"]},
		{"ascl_id":"1106.013","title":"MGCAMB: Modification of Growth with CAMB","credit":"Hojjati, A.; Zhao, G.-B.; Pogosian, L.; Silvestri, A.","abstract":"<a href=\"http:\/\/ascl.net\/1102.026\">CAMB<\/a> is a public Fortran 90 code written by Antony Lewis and Anthony Challinor for evaluating cosmological observables. MGCAMB is a modified version of CAMB in which the linearized Einstein equations of General Relativity (GR) are modified. MGCAMB can also be used in <a href=\"http:\/\/ascl.net\/1106.025\">CosmoMC<\/a> to fit different modified-gravity (MG) models to data.","topic_id":"24256","bibcode":"2011ascl.soft06013H","views":"47","site_list":["http:\/\/www.sfu.ca\/~aha25\/MGCAMB.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0809.3791","http:\/\/arxiv.org\/abs\/1106.4543"]},
		{"ascl_id":"1106.014","title":"Transit Analysis Package (TAP and autoKep): IDL Graphical User Interfaces for Extrasolar Planet Transit Photometry","credit":"Gazak, J. Zachary; Johnson, John A.; Tonry, John; Eastman, Jason; Mann, Andrew W.; Agol, Eric","abstract":"We present an IDL graphical user interface-driven software package designed for the analysis of extrasolar planet transit light curves. The Transit Analysis Package (TAP) software uses Markov Chain Monte Carlo (MCMC) techniques to fit light curves using the analytic model of Mandel and Agol (2002). The package incorporates a wavelet based likelihood function developed by Carter and Winn (2009) which allows the MCMC to assess parameter uncertainties more robustly than classic chi-squared methods by parameterizing uncorrelated \"white\" and correlated \"red\" noise. The software is able to simultaneously analyze multiple transits observed in different conditions (instrument, filter, weather, etc). The graphical interface allows for the simple execution and interpretation of Bayesian MCMC analysis tailored to a user's specific data set and has been thoroughly tested on ground-based and Kepler photometry. AutoKep provides a similar GUI for the preparation of Kepler MAST archive data for analysis by TAP or any other analysis software. This paper describes the software release and provides instructions for its use.","topic_id":"24262","bibcode":"2011ascl.soft06014G","views":"1416","site_list":["http:\/\/ifa.hawaii.edu\/users\/zgazak\/IfA\/TAP.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1102.1036"]},
		{"ascl_id":"1106.015","title":"OrbFit: Software to Determine Orbits of Asteroids","credit":"Orbfit Consortium","abstract":"OrbFit is a software system allowing one to compute the orbits of asteroids starting from the observations, to propagate these orbits, and to compute predictions on the future (and past) position on the celestial sphere. It is a tool to be used to find a well known asteroid, to recover a lost one, to attribute a small group of observations, to identify two orbits with each other, to study the future (and\/or past) close approaches to Earth, thus to assess the risk of an impact, and more.","topic_id":"24271","bibcode":"2011ascl.soft06015O","views":"47","site_list":["http:\/\/adams.dm.unipi.it\/~orbmaint\/orbfit\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007CoSka..37...69W"]},
		{"ascl_id":"1106.016","title":"Nightfall: Animated Views of Eclipsing Binary Stars","credit":"Wichmann, Rainer","abstract":"Nightfall is an astronomy application for fun, education, and science. It can produce animated views of eclipsing binary stars, calculate synthetic lightcurves and radial velocity curves, and eventually determine the best-fit model for a given set of observational data of an eclipsing binary star system. \r\n\r\nNightfall comes with a user guide, and a set of observational data for several eclipsing binary star systems.","topic_id":"24272","bibcode":"2011ascl.soft06016W","views":"44","site_list":["http:\/\/www.hs.uni-hamburg.de\/DE\/Ins\/Per\/Wichmann\/Nightfall.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1105.4176"]},
		{"ascl_id":"1106.017","title":"CAOS: Code for Adaptive Optics Systems","credit":"Carbillet, M.; Verinaud, C.; Femenia, B.; Riccardi, A.; Fini, L.","abstract":"The CAOS \"system\" (where CAOS stands for Code for Adaptive Optics Systems) is properly said a Problem Solving Environment (PSE). It is essentially composed of a graphical programming interface (the CAOS Application Builder) which can load different packages (set of modules). Current publicly distributed packages are the Software Package CAOS (the original adaptive optics package), the Software Package AIRY (an image-reconstruction-oriented package - AIRY stands for Astronomical Image Restoration with interferometrY), the Software Package PAOLAC (a simple CAOS interface for the analytic IDL code PAOLA developed by Laurent Jolissaint - PAOLAC stands for PAOLA within Caos), and a couple of private packages (not publicly distributed but restricted to the corresponding consortia): SPHERE (especially developed for the VLT planet finder SPHERE), and AIRY-LN (a specialized version of AIRY for the LBT instrument LINC-NIRVANA). Another package is also being developed: MAOS (that stands for Multiconjugate Adaptive Optics Simulations), developed for multi-reference multiconjugate AO studies purpose but still in a beta-version form.","topic_id":"24274","bibcode":"2011ascl.soft06017C","views":"88","site_list":["http:\/\/www-n.oca.eu\/caos\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004SPIE.5490..637C"]},
		{"ascl_id":"1106.018","title":"CMB B-modes from Faraday Rotation","credit":"Pogosian, Levon; Yadav, Amit; Ng, Bess; Vachaspati, Tanmay","abstract":"This code is a quick and exact calculator of B-mode angular spectrum due to Faraday rotation by stochastic magnetic fields. Faraday rotation induced B-modes can provide a distinctive signature of primordial magnetic fields because of their characteristic frequency dependence and because they are only weakly damped on small scales, allowing them to dominate B-modes from other sources. By numerically solving the full CMB radiative transport equations, we study the B-mode power spectrum induced by stochastic magnetic fields that have significant power on scales smaller than the thickness of the last scattering surface. Constraints on the magnetic field energy density and inertial scale are derived from WMAP 7-year data, and are stronger than the big bang nucleosynthesis (BBN) bound for a range of parameters. Observations of the CMB polarization at smaller angular scales are crucial to provide tighter constraints or a detection.","topic_id":"24281","bibcode":"2011ascl.soft06018P","views":"49","site_list":["http:\/\/www.sfu.ca\/~levon\/faraday.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1106.1438"]},
		{"ascl_id":"1106.019","title":"Application of Compressive Sampling to Radio Astronomy I: Deconvolution","credit":"Li, Feng; Brown, Shea; Cornwell, Tim J.; de Hoog, Frank","abstract":"Compressive sampling is a new paradigm for sampling, based on sparseness of signals or signal representations. It is much less restrictive than Nyquist-Shannon sampling theory and thus explains and systematises the widespread experience that methods such as the H\u00f6gbom CLEAN can violate the Nyquist-Shannon sampling requirements. In this paper, a CS-based deconvolution method for extended sources is introduced. This method can reconstruct both point sources and extended sources (using the isotropic undecimated wavelet transform as a basis function for the reconstruction step). We compare this CS-based deconvolution method with two CLEAN-based deconvolution methods: the H\u00f6gbom CLEAN and the multiscale CLEAN. This new method shows the best performance in deconvolving extended sources for both uniform and natural weighting of the sampled visibilities. Both visual and numerical results of the comparison are provided.","topic_id":"24282","bibcode":"2011ascl.soft06019L","views":"75","site_list":["http:\/\/code.google.com\/p\/csra\/downloads\/list"],"ref_list":["http:\/\/arxiv.org\/abs\/1106.1711"]},
		{"ascl_id":"1106.020","title":"CLASS: Cosmic Linear Anisotropy Solving System","credit":"Blas, Diego; Lesgourgues, Julien; Tram, Thomas","abstract":"Boltzmann codes are used extensively by several groups for constraining cosmological parameters with Cosmic Microwave Background and Large Scale Structure data. This activity is computationally expensive, since a typical project requires from 10'000 to 100'000 Boltzmann code executions. The newly released code CLASS (Cosmic Linear Anisotropy Solving System) incorporates improved approximation schemes leading to a simultaneous gain in speed and precision. We describe here the three approximations used by CLASS for basic LambdaCDM models, namely: a baryon-photon tight-coupling approximation which can be set to first order, second order or to a compromise between the two; an ultra-relativistic fluid approximation which had not been implemented in public distributions before; and finally a radiation streaming approximation taking reionisation into account.","topic_id":"24283","bibcode":"2011ascl.soft06020B","views":"65","site_list":["http:\/\/class-code.net\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1104.2933","http:\/\/arxiv.org\/abs\/1106.2607"]},
		{"ascl_id":"1106.021","title":"StringFast: Fast Code to Compute CMB Power Spectra induced by Cosmic Strings","credit":"Foreman, Simon; Moss, Adam; Scott, Douglas","abstract":"StringFast implements a method for efficient computation of the C_l spectra induced by a network of strings, which is fast enough to be used in Markov Chain Monte Carlo analyses of future data. This code allows the user to calculate TT, EE, and BB power spectra (scalar [for TT and EE], vector, and tensor modes) for \"wiggly\" cosmic strings. StringFast uses the output of the public code <a href=\"http:\/\/ascl.net\/1106.023\">CMBACT<\/a>. The properties of the strings are described by four parameters:\n\n<ul><li>G\u03bc: dimensionless string tension<\/li><li>v: rms transverse velocity (as fraction of c)<\/li><li>\u03b1: \"wiggliness\"<\/li><li>\u03be: comoving correlation length of the string network <\/li><\/ul>It is written as a Fortran 90 module.","topic_id":"24284","bibcode":"2011ascl.soft06021F","views":"42","site_list":["http:\/\/www.astro.ubc.ca\/people\/scott\/stringfast.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1106.4018"]},
		{"ascl_id":"1106.022","title":"MPI-Defrost: Extension of Defrost to MPI-based Cluster Environment","credit":"Amin, Mustafa A.; Easther, Richard; Finkel, Hal","abstract":"MPI-Defrost extends Frolov\u2019s Defrost to an MPI-based cluster environment.  This version has been restricted to a single field. Restoring two-field support should be straightforward, but will require some code changes. Some output options may also not be fully supported under MPI.\r\n\r\nThis code was produced to support our own work, and has been made available for the benefit of anyone interested in either oscillon simulations or an MPI capable version of Defrost, and it is provided on an \"as-is\" basis.  Andrei Frolov is the primary developer of Defrost and we thank him for placing his work under the GPL (GNU Public License), and thus allowing us to distribute this modified version.","topic_id":"24286","bibcode":"2011ascl.soft06022A","views":"30","site_list":["http:\/\/easther.physics.yale.edu\/Richard_Easther\/Download_MPI-Defrost.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1009.2505"]},
		{"ascl_id":"1106.023","title":"CMBACT: CMB from ACTive sources","credit":"Pogosian, Levon; Vachaspati, Tanmay","abstract":"This code is based on the cosmic string model described in this paper  by Pogosian and Vachaspati, as well as on the <a href=\"http:\/\/ascl.net\/9909.004\">CMBFAST<\/a> code created by Uros Seljak and Matias Zaldarriaga. It contains an integrator for the vector contribution to the CMB temperature and polarization. The code is reconfigured to make it easier to use with or without active sources. To produce inflationary CMB spectra one simply sets the string tension to zero (gmu=0.0d0). For a non-zero value of tension only the string contribution is calculated.\r\n\r\nAn option is added to randomize the directions of velocities of consolidated segments as they evolve in time. In the original segment model, which is still the default version (irandomv=0), each segment is given a random velocity initially, but then continues to move in a straight line for the rest of its life. The new option (irandomv=1) allows to additionally randomize velocities of each segment at roughly each Hubble time. However, the merits of this new option are still under investigation. The default version (irandomv=0) is strongly recommended, since it actually gives reasonable unequal time correlators. For each Fourier mode, k, the string stress-energy components are now evaluated on a time grid sufficiently fine for that k.","topic_id":"24290","bibcode":"2011ascl.soft06023P","views":"60","site_list":["http:\/\/www.sfu.ca\/~levon\/cmbact.html"],"ref_list":["http:\/\/xxx.lanl.gov\/abs\/astro-ph\/9903361","http:\/\/xxx.lanl.gov\/abs\/astro-ph\/0604141"]},
		{"ascl_id":"1106.024","title":"ELMAG: Simulation of Electromagnetic Cascades","credit":"Kachelriess, M.; Ostapchenko, S.; Tomas, R.","abstract":"A Monte Carlo program for the simulation of electromagnetic cascades initiated by high-energy photons and electrons interacting with extragalactic background light (EBL) is presented. Pair production and inverse Compton scattering on EBL photons as well as synchrotron losses and deflections of the charged component in extragalactic magnetic fields (EGMF) are included in the simulation. Weighted sampling of the cascade development is applied to reduce the number of secondary particles and to speed up computations. As final result, the simulation procedure provides the energy, the observation angle, and the time delay of secondary cascade particles at the present epoch. Possible applications are the study of TeV blazars and the influence of the EGMF on their spectra or the calculation of the contribution from ultrahigh energy cosmic rays or dark matter to the diffuse extragalactic gamma-ray background. As an illustration, we present results for deflections and time-delays relevant for the derivation of limits on the EGMF.","topic_id":"24291","bibcode":"2011ascl.soft06024K","views":"58","site_list":["http:\/\/elmag.sourceforge.net\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1106.5508"]},
		{"ascl_id":"1106.025","title":"CosmoMC: Cosmological MonteCarlo","credit":"Lewis, Antony; Bridle, Sarah","abstract":"We present a fast Markov Chain Monte-Carlo exploration of cosmological parameter space. We perform a joint analysis of results from recent CMB experiments and provide parameter constraints, including sigma_8, from the CMB independent of other data. We next combine data from the CMB, HST Key Project, 2dF galaxy redshift survey, supernovae Ia and big-bang nucleosynthesis. The Monte Carlo method allows the rapid investigation of a large number of parameters, and we present results from 6 and 9 parameter analyses of flat models, and an 11 parameter analysis of non-flat models. Our results include constraints on the neutrino mass (m_nu &lt; 0.3eV), equation of state of the dark energy, and the tensor amplitude, as well as demonstrating the effect of additional parameters on the base parameter constraints. In a series of appendices we describe the many uses of importance sampling, including computing results from new data and accuracy correction of results generated from an approximate method. We also discuss the different ways of converting parameter samples to parameter constraints, the effect of the prior, assess the goodness of fit and consistency, and describe the use of analytic marginalization over normalization parameters.","topic_id":"24293","bibcode":"2011ascl.soft06025L","views":"81","site_list":["http:\/\/cosmologist.info\/cosmomc\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0205436"]},
		{"ascl_id":"1106.026","title":"RECFAST: Calculate the Recombination History of the Universe","credit":"Seager, Sara; Sasselov, Dimitar D.; Scott, Douglas","abstract":"We have developed an improved recombination calculation of H, HeI, and HeII in the early Universe which involves a line-by-line treatment of each atomic level. We find two major differences compared with previous calculations. Firstly, the ionization fraction x_e is approximately 10% smaller for redshifts <~800, due to non-equilibrium processes in the excited states of H. Secondly, HeI recombination is much slower than previously thought, and is delayed until just before H recombines. We describe the basic physics behind the new results and present a simple way to reproduce our calculation. This should enable fast computation of the ionization history (and quantities such as the power spectrum of CMB anisotropies which depend on it) for arbitrary cosmologies, without the need to consider the hundreds of atomic levels used in our complete model.","topic_id":"24301","bibcode":"2011ascl.soft06026S","views":"44","site_list":["http:\/\/www.astro.ubc.ca\/people\/scott\/recfast.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9909275"]},
		{"ascl_id":"1107.001","title":"SNID: Supernova Identification","credit":"Blondin, St\u00e9phane; Tonry, John L.","abstract":"We present an algorithm to identify the type of an SN spectrum and to determine its redshift and age. This algorithm, based on the correlation techniques of Tonry & Davis, is implemented in the Supernova Identification (SNID) code. It is used by members of ongoing high-redshift SN searches to distinguish between type Ia and type Ib\/c SNe, and to identify \"peculiar\" SNe Ia. We develop a diagnostic to quantify the quality of a correlation between the input and template spectra, which enables a formal evaluation of the associated redshift error. Furthermore, by comparing the correlation redshifts obtained using SNID with those determined from narrow lines in the SN host galaxy spectrum, we show that accurate redshifts (with a typical error less than 0.01) can be determined for SNe Ia without a spectrum of the host galaxy. Last, the age of an input spectrum is determined with a typical 3-day accuracy, shown here by using high-redshift SNe Ia with well-sampled light curves. The success of the correlation technique confirms the similarity of some SNe Ia at low and high redshifts. The SNID code, which is available to the community, can also be used for comparative studies of SN spectra, as well as comparisons between data and models.","topic_id":"24326","bibcode":"2011ascl.soft07001B","views":"43","site_list":["http:\/\/people.lam.fr\/blondin.stephane\/software\/snid\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0709.4488"]},
		{"ascl_id":"1107.002","title":"GIBIS: Gaia Instrument and Basic Image Simulator","credit":"Babusiaux, Carine; Sartoretti, Paola; Leclerc, Nicolas; Ch\u00e9reau, Fabien","abstract":"GIBIS is a pixel-level simulator of the Gaia mission. It is intended to simulate how the Gaia instruments will observe the sky, using realistic simulations of the astronomical sources and of the instrumental properties. It is a branch of the global Gaia Simulator under development within the Gaia DPAC CU2 Group (Data Simulations). Access is currently restricted to Gaia DPAC teams.","topic_id":"24327","bibcode":"2011ascl.soft07002B","views":"38","site_list":["http:\/\/gibis.cnes.fr\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005ESASP.576..417B","http:\/\/arxiv.org\/abs\/1107.0210"]},
		{"ascl_id":"1107.003","title":"FITSManager: Management of Personal Astronomical Data","credit":"Cui, Chenzhou; Fan, Dongwei; Zhao, Yongheng; Kembhavi, Ajit; He, Boliang; Cao, Zihuang; Li, Jian; Nandrekar, Deoyani","abstract":"With the increase of personal storage capacity, it is easy to find hundreds to thousands of FITS files in the personal computer of an astrophysicist. Because Flexible Image Transport System (FITS) is a professional data format initiated by astronomers and used mainly in the small community, data management toolkits for FITS files are very few. Astronomers need a powerful tool to help them manage their local astronomical data. Although Virtual Observatory (VO) is a network oriented astronomical research environment, its applications and related technologies provide useful solutions to enhance the management and utilization of astronomical data hosted in an astronomer's personal computer. FITSManager is such a tool to provide astronomers an efficient management and utilization of their local data, bringing VO to astronomers in a seamless and transparent way. FITSManager provides fruitful functions for FITS file management, like thumbnail, preview, type dependent icons, header keyword indexing and search, collaborated working with other tools and online services, and so on. The development of the FITSManager is an effort to fill the gap between management and analysis of astronomical data.","topic_id":"24328","bibcode":"2011ascl.soft07003C","views":"33","site_list":["http:\/\/fm.china-vo.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1106.4847"]},
		{"ascl_id":"1107.004","title":"Flexible DM-NRG","credit":"Legeza, \u00d6rs; Moca, Pascu; T\u00f3th, Anna; Weymann, Ireneusz; Zar\u00e1nd, Gergely","abstract":"This code combines the spectral sum-conserving methods of Weichselbaum and von Delft and of Peters, Pruschke and Anders (both relying upon the complete basis set construction of Anders and Schiller) with the use of non-Abelian symmetries in a flexible manner: Essentially any non-Abelian symmetry can be taught to the code, and any number of such symmetries can be used throughout the computation for any density of states, and to compute any local operators' correlation function's real and imaginary parts or any thermodynamical expectation value. The code works both at zero and finite temperatures.","topic_id":"24343","bibcode":"2011ascl.soft07004L","views":"35","site_list":["http:\/\/www.phy.bme.hu\/~dmnrg\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0802.4332"]},
		{"ascl_id":"1107.005","title":"Sherpa: CIAO Modeling and Fitting Package","credit":"Freeman, Peter; Nguyen, Dan; Doe, Stephen; Siemiginowska, Aneta","abstract":"Sherpa is the CIAO modeling and fitting application made available by the Chandra X-ray Center (CXC). It can be used for analysis of images, spectra and time series from many telescopes, including optical telescopes such as Hubble. Sherpa is flexible, modular and extensible. It has an IPython user interface and it is also an importable Python module. Sherpa models, optimization and statistic functions are available via both C++ and Python for software developers wishing to link such functions directly to their own compiled code.\r\n\r\nThe CIAO 4.3 Sherpa release supports fitting of 1-D X-ray spectra from Chandra and other X-ray missions, as well as 1-D non-X-ray data, including ASCII data arrays, radial profiles, and lightcurves. The options for grating data analysis include fitting the spectrum with multiple response files required for overlapping orders in LETG observations. Modeling of 2-D spatial data is fully supported, including the PSF and exposure maps. User specified models can be added to Sherpa with advanced \"user model\" functionality.","topic_id":"24345","bibcode":"2011ascl.soft07005F","views":"48","site_list":["http:\/\/cxc.cfa.harvard.edu\/sherpa\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001SPIE.4477...76F"]},
		{"ascl_id":"1107.006","title":"AIRES: AIRshower Extended Simulations","credit":"Cillis, A. N.; Sciutto, S. J.","abstract":"The objective of this work is to report on the influence of muon interactions on the development of air showers initiated by astroparticles. We make a comparative study of the different theoretical approaches to muon bremsstrahlung and muonic pair production interactions. A detailed algorithm that includes all the relevant characteristics of such processes has been implemented in the AIRES air shower simulation system. We have simulated ultra high energy showers in different conditions in order to measure the influence of these muonic electromagnetic interactions. We have found that during the late stages of the shower development (well beyond the shower maximum) many global observables are significantly modified in relative terms when the mentioned interactions are taken into account. This is most evident in the case of the electromagnetic component of very inclined showers. On the other hand, our simulations indicate that the studied processes do not induce significant changes either in the position of the shower maximum or the structure of the shower front surface.","topic_id":"24358","bibcode":"2011ascl.soft07006C","views":"69","site_list":["http:\/\/www2.fisica.unlp.edu.ar\/auger\/aires\/eg_Aires.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1005.0552"]},
		{"ascl_id":"1107.007","title":"AMUSE: Astrophysical Multipurpose Software Environment","credit":"Portegies Zwart, Simon","abstract":"AMUSE is an open source software framework for large-scale simulations in astrophysics, in which existing codes for gravitational dynamics, stellar evolution, hydrodynamics and radiative transport can be easily coupled and placed in the appropriate observational context.","topic_id":"24392","bibcode":"2011ascl.soft07007P","views":"95","site_list":["http:\/\/www.amusecode.org\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013CoPhC.183..456P","http:\/\/adsabs.harvard.edu\/abs\/2011AAS...21813310W"]},
		{"ascl_id":"1107.008","title":"STARS: A Stellar Evolution Code","credit":"Eggleton, P. P.; Tout, Christopher; Pols, Onno; Izzard, Rob; Eldridge, John; Lesaffre, Pierre; Stancliffe, Richard; Church, Ross; Lau, Herbert","abstract":"We have developed a detailed stellar evolution code capable of following the simultaneous evolution of both stars in a binary system, together with their orbital properties. To demonstrate the capabilities of the code we investigate potential progenitors for the Type IIb supernova 1993J, which is believed to have been an interacting binary system prior to its primary exploding. We use our detailed binary stellar evolution code to model this system to determine the possible range of primary and secondary masses that could have produced the observed characteristics of this system, with particular reference to the secondary. Using the luminosities and temperatures for both stars (as determined by Maund et al. 2004) and the remaining mass of the hydrogen envelope of the primary at the time of explosion, we find that if mass transfer is 100 per cent efficient the observations can be reproduced by a system consisting of a 15 solar mass primary and a 14 solar mass secondary in an orbit with an initial period of 2100 days. With a mass transfer efficiency of 50 per cent, a more massive system consisting of a 17 solar mass primary and a 16 solar mass secondary in an initial orbit of 2360 days is needed. We also investigate some of the uncertainties in the evolution, including the effects of tidal interaction, convective overshooting and thermohaline mixing.","topic_id":"24396","bibcode":"2011ascl.soft07008E","views":"48","site_list":["http:\/\/www.ast.cam.ac.uk\/~stars\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1972MNRAS.156..361E","http:\/\/adsabs.harvard.edu\/abs\/2004MNRAS.348..201E","http:\/\/adsabs.harvard.edu\/abs\/2009MNRAS.396.1699S"]},
		{"ascl_id":"1107.009","title":"REAS3: Modeling Radio Emission from Cosmic Ray Air Showers","credit":"Ludwig, Marianne; Huege, Tim","abstract":"In recent years, the freely available Monte Carlo code REAS for modelling radio emission from cosmic ray air showers has evolved to include the full complexity of air shower physics. However, it turned out that in REAS2 and all other time-domain models which calculate the radio emission by superposing the radiation of the single air shower electrons and positrons, the calculation of the emission contributions was not fully consistent. In this article, we present a revised implementation in REAS3, which incorporates the missing radio emission due to the variation of the number of charged particles during the air shower evolution using an \"end-point formalism\". With the inclusion of these emission contributions, the structure of the simulated radio pulses changes from unipolar to bipolar, and the azimuthal emission pattern becomes nearly symmetric. Remaining asymmetries can be explained by radio emission due to the variation of the net charge excess in air showers, which is automatically taken into account in the new implementation. REAS3 constitutes the first self-consistent time-domain implementation based on single particle emission taking the full complexity of air shower physics into account, and is freely available for all interested users.","topic_id":"24397","bibcode":"2011ascl.soft07009L","views":"38","site_list":["http:\/\/www.timhuege.de\/reas"],"ref_list":["http:\/\/arxiv.org\/abs\/1010.5343","http:\/\/arxiv.org\/abs\/1009.1994"]},
		{"ascl_id":"1107.010","title":"XDSPRES: CL-based package for Reducing OSIRIS Cross-dispersed Spectra","credit":"Ruschel-Dutra, Daniel; Riffel, Rog\u00e9rio; Ducati, Jorge Ricardo; Pastoriza, Miriani","abstract":"We present a description of the CL-based package XDSPRES, which aims at being a complete reducing facility for cross-dispersed spectra taken with the Ohio State Infrared Imager\/Spectrometer, as installed at the SOAR telescope. This instrument provides spectra in the range between 1.2um and 2.35um in a single exposure, with resolving power of R ~ 1200. XDSPRES consists of two tasks, namely xdflat and doosiris. The former is a completely automated code for preparing normalized flat field images from raw flat field exposures. Doosiris was designed to be a complete reduction pipeline, requiring a minimum of user interaction. General steps towards a fully reduced spectrum are explained, as well as the approach adopted by our code.","topic_id":"24402","bibcode":"2011ascl.soft07010R","views":"48","site_list":["http:\/\/www.if.ufrgs.br\/~ruschel\/software"],"ref_list":["http:\/\/arxiv.org\/abs\/1107.1713"]},
		{"ascl_id":"1107.011","title":"ARCHANGEL: Galaxy Photometry System","credit":"Schombert, James","abstract":"ARCHANGEL is a Unix-based package for the surface photometry of galaxies. While oriented for large angular size systems (i.e. many pixels), its tools can be applied to any imaging data of any size. The package core contains routines to perform the following critical galaxy photometry functions:\n\n<ul><li>sky determination<\/li><li>frame cleaning<\/li><li>ellipse fitting<\/li><li>profile fitting<\/li><li>total and isophotal magnitudes<\/li><\/ul>\n\nThe goal of the package is to provide an automated, assembly-line type of reduction system for galaxy photometry of space-based or ground-based imaging data. The procedures outlined in the documentation are flux independent, thus, these routines can be used for non-optical data as well as typical imaging datasets.\n\nARCHANGEL has been tested on several current OS's (RedHat Linux, Ubuntu Linux, Solaris, Mac OS X). A tarball for installation is available at the download page. The main routines are Python and FORTRAN based, therefore, a current installation of Python and a FORTRAN compiler are required. The ARCHANGEL package also contains Python hooks to the PGPLOT package, an XML processor and network tools which automatically link to data archives (i.e. NED, HST, 2MASS, etc) to download images in a non-interactive manner.","topic_id":"24405","bibcode":"2011ascl.soft07011S","views":"82","site_list":["http:\/\/abyss.uoregon.edu\/~js\/archangel\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0703646","http:\/\/arxiv.org\/abs\/1107.1728"]},
		{"ascl_id":"1107.012","title":"LIME: Flexible, Non-LTE Line Excitation and Radiation Transfer Method for Millimeter and Far-infrared Wavelengths","credit":"Brinch, C.; Hogerheijde, M. R.","abstract":"LIME solves the molecular and atomic excitation and radiation transfer problem in a molecular gas and predicting emergent spectra. The code works in arbitrary three dimensional geometry using unstructured Delaunay latices for the transport of photons. Various physical models can be used as input, ranging from analytical descriptions over tabulated models to SPH simulations. To generate the Delaunay grid we sample the input model randomly, but weigh the sample probability with the molecular density and other parameters, and thereby we obtain an average grid point separation that scales with the local opacity. Slow convergence of opaque models becomes traceable; when convergence between the level populations, the radiation field, and the point separation has been obtained, the grid is ray-traced to produced images that can readily be compared to observations. LIME is particularly well suited for modeling of ALMA data because of the high dynamic range in scales that can be resolved using this type of grid, and can furthermore deal with overlapping lines of multiple molecular and atomic species.","topic_id":"24421","bibcode":"2011ascl.soft07012B","views":"78","site_list":["http:\/\/www.nbi.dk\/~brinch\/lime.php"],"ref_list":["http:\/\/arxiv.org\/abs\/1008.1492"]},
		{"ascl_id":"1107.013","title":"CASA: Common Astronomy Software Applications","credit":"International Consortium Of Scientists","abstract":"CASA, the Common Astronomy Software Applications package, is being developed with the primary goal of supporting the data post-processing needs of the next generation of radio astronomical telescopes such as ALMA and EVLA. The package can process both interferometric and single dish data. The CASA infrastructure consists of a set of C++ tools bundled together under an iPython interface as a set of data reduction tasks. This structure provides flexibility to process the data via task interface or as a python script. In addition to the data reduction tasks, many post-processing tools are available for even more flexibility and special purpose reduction needs.","topic_id":"24434","bibcode":"2011ascl.soft07013I","views":"83","site_list":["http:\/\/casa.nrao.edu\/index.shtml"],"ref_list":["http:\/\/arxiv.org\/abs\/0810.2825"]},
		{"ascl_id":"1107.014","title":"Clumpfind: Determining Structure in Molecular Clouds","credit":"Williams, Jonathan P.; de Geus, Eugene J.; Blitz, Leo","abstract":"We describe an automatic, objective routine for analyzing the clumpy structure in a spectral line position-position-velocity data cube. The algorithm works by first contouring the data at a multiple of the rms noise of the observations, then searches for peaks of emission which locate the clumps, and then follows them down to lower intensities. No a proiri clump profile is assumed. By creating simulated data, we test the performance of the algorithm and show that a contour map most accurately depicts internal structure at a contouring interval equal to twice the rms noise of the map. Blending of clump emission leads to small errors in mass and size determinations and in severe cases can result in a number of clumps being misidentified as a single unit, flattening the measured clump mass spectrum. The algorithm is applied to two real data sets as an example of its use. The Rosette molecular cloud is a 'typical' star-forming cloud, but in the Maddalena molecular cloud high-mass star formation is completely absent. Comparison of the two clump lists generated by the algorithm show that on a one-to-one basis the clumps in the star-forming cloud have higher peak temperatures, higher average densities, and are more gravitationally bound than in the non-star-forming cloud. Collective properties of the clumps, such as temperature-size-line-width-mass relations appear very similar, however. Contrary to the initial results reported in a previous paper (Williams & Blitz 1993), we find that the current, more thoroughly tested analysis finds no significant difference in the clump mass spectrum of the two clouds.","topic_id":"24436","bibcode":"2011ascl.soft07014W","views":"89","site_list":["http:\/\/www.ifa.hawaii.edu\/users\/jpw\/clumpfind.shtml"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1994ApJ...428..693W"]},
		{"ascl_id":"1107.015","title":"McLuster: A Tool to Make a Star Cluster","credit":"Kuepper, A. H. W.; Maschberger, Th.; Kroupa, P.; Baumgardt, H.","abstract":"The tool McLuster is an open source code that can be used to either set up initial conditions for N-body computations or, alternatively, to generate artificial star clusters for direct investigation. There are two different versions of the code, one basic version for generating all kinds of unevolved clusters (in the following called mcluster) and one for setting up evolved stellar populations at a given age. The former is completely contained in the C file main.c. The latter (dubbed mcluster_sse) is more complex and requires additional FORTRAN routines, namely the Single-Star Evolution (SSE) routines by Hurley, Pols & Tout (<a href=\"http:\/\/www.ascl.net\/1303.015\">ascl:1303.015<\/a>) that are provided with the McLuster code.","topic_id":"24444","bibcode":"2011ascl.soft07015K","views":"54","site_list":["http:\/\/www.astro.uni-bonn.de\/~akuepper\/mcluster\/mcluster.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1107.2395"]},
		{"ascl_id":"1107.016","title":"SIGPROC: Pulsar Signal Processing Programs","credit":"Lorimer, D. R.","abstract":"SIGPROC is a package designed to standardize the initial analysis of the many types of fast-sampled pulsar data. Currently recognized machines are the Wide Band Arecibo Pulsar Processor (WAPP), the Penn State Pulsar Machine (PSPM), the Arecibo Observatory Fourier Transform Machine (AOFTM), the Berkeley Pulsar Processors (BPP), the Parkes\/Jodrell 1-bit filterbanks (SCAMP) and the filterbank at the Ooty radio telescope (OOTY). The SIGPROC tools should help users look at their data quickly, without the need to write (yet) another routine to read data or worry about big\/little endian compatibility (byte swapping is handled automatically).","topic_id":"24447","bibcode":"2011ascl.soft07016L","views":"45","site_list":["http:\/\/sigproc.sourceforge.net\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003AAS...203.5307M"]},
		{"ascl_id":"1107.017","title":"PRESTO: PulsaR Exploration and Search TOolkit","credit":"Ransom, Scott","abstract":"PRESTO is a large suite of pulsar search and analysis software. It was primarily designed to efficiently search for binary millisecond pulsars from long observations of globular clusters (although it has since been used in several surveys with short integrations and to process a lot of X-ray data as well). To date, PRESTO has discovered well over a hundred and fifty pulsars, including approximately 100 recycled pulsars, about 80 of which are in binaries. It is written primarily in ANSI C, with many of the recent routines in Python. \r\n\r\nWritten with portability, ease-of-use, and memory efficiency in mind, it can currently handle raw data from the following pulsar machines or formats:\r\n\r\n<ul><li>PSRFITS search-format data (as from GUPPI at the GBT and the Mock Spectrometers at Arecibo)<\/li><li>SPIGOT at the GBT<\/li><li>Most Wideband Arecibo Pulsar Processor (WAPP) at Arecibo<\/li><li>The Parkes and Jodrell Bank 1-bit filterbank formats<\/li><li>Berkeley-Caltech Pulsar Machine (BCPM) at the GBT (may it RIP...)<\/li><li>8-bit filterbank format from SIGPROC (other formats will be added if required)<\/li><li>A time series composed of single precision (i.e. 4-byte) floating point data<\/li><li>Photon arrival times (or events) in ASCII or double-precision binary formats<\/li><\/ul>","topic_id":"24450","bibcode":"2011ascl.soft07017R","views":"43","site_list":["http:\/\/www.cv.nrao.edu\/~sransom\/presto\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002AJ....124.1788R","http:\/\/arxiv.org\/abs\/1102.0648"]},
		{"ascl_id":"1107.018","title":"HEALPix: Hierarchical Equal Area isoLatitude Pixelization of a sphere","credit":"G\u00f3rski, K. M.; Hivon, Eric","abstract":"HEALPix is an acronym for Hierarchical Equal Area isoLatitude Pixelization of a sphere. As suggested in the name, this pixelization produces a subdivision of a spherical surface in which each pixel covers the same surface area as every other pixel. Another property of the HEALPix grid is that the pixel centers occur on a discrete number of rings of constant latitude, the number of constant-latitude rings is dependent on the resolution of the HEALPix grid.","topic_id":"24451","bibcode":"2011ascl.soft07018G","views":"52","site_list":["http:\/\/healpix.jpl.nasa.gov\/index.shtml"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005ApJ...622..759G","http:\/\/arxiv.org\/abs\/1107.2384"]},
		{"ascl_id":"1107.019","title":"PSRPOP: Pulsar Population Modelling Programs","credit":"Lorimer, Duncan","abstract":"PSRPOP is a package developed to model the Galactic population and evolution of radio pulsars. It is a collection of modules unashamadly written in Fortran77 for an analysis of a large sample of pulsars detected by the Parkes Multibeam Pulsar Survey and is now freely available to others wishing to investigate the results of that work and for further analysis. The main programs are:\r\n\r\n<ul><li>populate - creates a model Galaxy of pulsars distributed according according to various assumptions<\/li><li>survey - searches the model galaxies generated using populate using realistic models of pulsar surveys<\/li><li>visualize - a Tk\/PGPLOT script to plot various aspects of model detected pulsars from survey<\/li><\/ul>A sample screenshot from visualize can be found <a href=\"http:\/\/psrpop.sourceforge.net\/psrpop.gif\">here<\/a>.","topic_id":"24466","bibcode":"2011ascl.soft07019L","views":"41","site_list":["http:\/\/psrpop.sourceforge.net\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0607640v1"]},
		{"ascl_id":"1108.001","title":"IMCAT: Image and Catalogue Manipulation Software","credit":"Kaiser, Nick","abstract":"The IMCAT software was developed initially to do faint galaxy photometry for weak lensing studies, and provides a fairly complete set of tools for this kind of work. Unlike most packages for doing data analysis, the tools are standalone unix commands which you can invoke from the shell, via shell scripts or from perl scripts. The tools are arranges in a tree of directories. One main branch is the \u2019imtools\u2019. These deal only with fits files. The most important imtool is the \u2019image calculator\u2019 \u2019ic\u2019 which allows one to do rather general operations on fits images. A second branch is the \u2019catools\u2019 which operate only on catalogues. The key cattool is \u2019lc\u2019; this effectively defines the format of IMCAT catalogues, and allows one to do very general operations on and filtering of such catalogues. A third branch is the \u2019imcattools\u2019. These tend to be much more specialised than the cattools and imcattools and are focussed on faint galaxy photometry.","topic_id":"24667","bibcode":"2011ascl.soft08001K","views":"38","site_list":["http:\/\/www.ifa.hawaii.edu\/faculty\/kaiser\/imcat\/content.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1107.5863"]},
		{"ascl_id":"1108.002","title":"SHERA: SHEar Reconvolution Analysis","credit":"Mandelbaum, Rachel; Hirata, Christopher M.; Leauthaud, Alexie; Massey, Richard J.; Rhodes, Jason","abstract":"Current and upcoming wide-field, ground-based, broad-band imaging surveys promise to address a wide range of outstanding problems in galaxy formation and cosmology. Several such uses of ground-based data, especially weak gravitational lensing, require highly precise measurements of galaxy image statistics with careful correction for the effects of the point-spread function (PSF). The SHERA (SHEar Reconvolution Analysis) software  simulates ground-based imaging data with realistic galaxy morphologies and observing conditions, starting from space-based data (from COSMOS, the Cosmological Evolution Survey) and accounting for the effects of the space-based PSF. This code simulates ground-based data, optionally with a weak lensing shear applied, in a model-independent way using a general Fourier space formalism. The utility of this pipeline is that it allows for a precise, realistic assessment of systematic errors due to the method of data processing, for example in extracting weak lensing galaxy shape measurements or galaxy radial profiles, given user-supplied observational conditions and real galaxy morphologies. Moreover, the simulations allow for the empirical test of error estimates and determination of parameter degeneracies, via generation of many noise maps. The public release of this software, along with a large sample of cleaned COSMOS galaxy images (corrected for charge transfer inefficiency), should enable upcoming ground-based imaging surveys to achieve their potential in the areas of precision weak lensing analysis, galaxy profile measurement, and other applications involving detailed image analysis.","topic_id":"24724","bibcode":"2011ascl.soft08002M","views":"36","site_list":["http:\/\/www.astro.princeton.edu\/~rmandelb\/shera\/shera.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1107.4629"]},
		{"ascl_id":"1108.003","title":"WCSLIB and PGSBOX","credit":"Calabretta, M. R.","abstract":"WCSLIB is a C library, supplied with a full set of Fortran wrappers, that implements the \"World Coordinate System\" (WCS) standard in FITS (Flexible Image Transport System). It also includes a PGPLOT-based routine, PGSBOX, for drawing general curvilinear coordinate graticules and a number of utility programs.","topic_id":"24746","bibcode":"2011ascl.soft08003C","views":"81","site_list":["http:\/\/www.atnf.csiro.au\/people\/mcalabre\/WCS\/"],"ref_list":["http:\/\/www.adass.org\/adass\/proceedings\/adass03\/reprints\/P6-3.pdf"]},
		{"ascl_id":"1108.004","title":"Galacticus: A Semi-Analytic Model of Galaxy Formation","credit":"Benson, Andrew","abstract":"Galacticus is designed to solve the physics involved in the formation of galaxies within the current standard cosmological framework. It is of a type of model known as \u201csemi-analytic\u201d in which the numerous complex non-linear physics involved are solved using a combination of analytic approximations and empirical calibrations from more detailed, numerical solutions. Models of this type aim to begin with the initial state of the Universe (specified shortly after the Big Bang) and apply physical principles to determine the properties of galaxies in the Universe at later times, including the present day. Typical properties computed include the mass of stars and gas in each galaxy, broad structural properties (e.g. radii, rotation speeds, geometrical shape etc.), dark matter and black hole contents, and observable quantities such as luminosities, chemical composition etc.","topic_id":"24754","bibcode":"2011ascl.soft08004B","views":"40","site_list":["https:\/\/sites.google.com\/site\/galacticusmodel\/","https:\/\/launchpad.net\/galacticus"],"ref_list":["http:\/\/arxiv.org\/abs\/1008.1786","http:\/\/arxiv.org\/abs\/1107.4098"]},
		{"ascl_id":"1108.005","title":"Gaepsi: Gadget Visualization Tookit","credit":"Feng, Yu; Croft, Rupert A. C.; Di Matteo, Tiziana; Khandai, Nishikanta; Sargent, Randy; Nourbakhsh, Illah; Dille, Paul; Bartley, Chris; Springel, Volker; Jana, Anirban; Gardner, Jeffrey","abstract":"Gaepsi is a PYTHON extension for visualizing cosmology simulations produced by Gadget. Visualization is the most important facet of Gaepsi, but it also allows data analysis on GADGET simulations with its growing number of physics related subroutines and constants. Unlike mesh based scheme, SPH simulations are directly visible in the sense that a splatting process is required to produce raster images from the simulations. Gaepsi produces images of 2-dimensional line-of-sight projections of the simulation. Scalar fields and vector fields are both supported.\r\n\r\nBesides the traditional way of slicing a simulation, Gaepsi also has built-in support of 'Survey-like' domain transformation proposed by Carlson & White. An improved implementation is used in Gaepsi. Gaepsi both implements an interactive shell for plotting and exposes its API for batch processing. When complied with OpenMP, Gaepsi automatically takes the advantage of the multi-core computers. In interactive mode, Gaepsi is capable of producing images of size up to 32000 x 32000 pixels. The user can zoom, pan and rotate the field with a command in on the finger tip. The interactive mode takes full advantages of matplotlib's rich annotating, labeling and image composition facilities. There are also built-in commands to add objects that are commonly used in cosmology simulations to the figures.","topic_id":"24756","bibcode":"2011ascl.soft08005F","views":"48","site_list":["https:\/\/github.com\/rainwoodman\/gaepsi\/wiki"],"ref_list":["http:\/\/arxiv.org\/abs\/1107.1255"]},
		{"ascl_id":"1108.006","title":"STARLIGHT: Spectral Synthesis Code","credit":"Cid Fernandes, R.; Mateus, A.; Sodr\u00e9, L.; Stasinska, G.; Gomes, J. M.","abstract":"The study of stellar populations in galaxies is entering a new era with the availability of large and high quality databases of both observed galactic spectra and state-of-the-art evolutionary synthesis models. The power of spectral synthesis can be investigated as a mean to estimate physical properties of galaxies. Spectral synthesis is nothing more than the decomposition of an observed spectrum in terms of a superposition of a base of simple stellar populations of various ages and metallicities, producing astrophysically interesting output such as the star-formation and chemical enrichment histories of a galaxy, its extinction and velocity dispersion. This is what the STARLIGHT spectral synthesis code does.","topic_id":"24757","bibcode":"2011ascl.soft08006C","views":"55","site_list":["http:\/\/www.starlight.ufsc.br\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0412481"]},
		{"ascl_id":"1108.007","title":"P\u00c9GASE: Metallicity-consistent Spectral Evolution Model of Galaxies","credit":"Fioc, Michel; Le Borgne, Damien; Rocca-Volmerange, Brigitte","abstract":"P\u00c9GASE (Projet d'\u00c9tude des GAlaxies par Synth\u00e8se \u00c9volutive) is a code to compute the spectral evolution of galaxies. The evolution of the stars, gas and metals is followed for a law of star formation and a stellar initial mass function. The stellar evolutionary tracks extend from the main sequence to the white dwarf stage. The emission of the gas in HII regions is also taken into account. The main improvement in version 2 is the use of evolutionary tracks of different metallicities (from 10-4 to 5\u00d7solar). The effect of extinction by dust is also modelled using a radiative transfer code. P\u00c9GASE.2 uses the BaSeL library of stellar spectra and can therefore synthesize low-resolution (R~200) ultraviolet to near-infrared spectra of Hubble sequence galaxies as well as of starbursts.","topic_id":"24760","bibcode":"2011ascl.soft08007F","views":"42","site_list":["http:\/\/www2.iap.fr\/pegase\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9912179"]},
		{"ascl_id":"1108.008","title":"P\u00c9GASE-HR: Stellar Population Synthesis at High Resolution Spectra","credit":"Le Borgne, Damien; Fioc, Michel; Lan\u00e7on, Ariane; Rocca-Volmerange, Brigitte; Prugniel, Philippe; Soubiran, Caroline","abstract":"P\u00c9GASE-HR is a code aimed at computing synthetic evolutive optical spectra of galaxies with a very high resolution (R=10 000, or dlambda=0.55) in the range Lambda=[4000, 6800] Angstroms. P\u00c9GASE-HR is the result of combining  the code <a href=\"http:\/\/ascl.net\/1108.007\">P\u00c9GASE.2<\/a> with the high-resolution stellar library \u00c9LODIE. This code can also be used at low resolution (R=200) over the range covered by the BaSeL library (from far UV to the near IR), and then produces the same results as P\u00c9GASE.2. In PEGASE-HR, the BaSeL library is replaced by a grid of spectra interpolated from the high-resolution \u00c9LODIE library of stellar spectra. The \u00c9LODIE library is a stellar database of 1959 spectra for 1503 stars, observed with the echelle spectrograph \u00c9LODIE on the 193 cm telescope at the Observatoire de Haute Provence.","topic_id":"24761","bibcode":"2011ascl.soft08008L","views":"59","site_list":["http:\/\/www2.iap.fr\/pegase\/pegasehr\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0408419"]},
		{"ascl_id":"1108.009","title":"LePHARE: Photometric Analysis for Redshift Estimate","credit":"Arnouts, S.; Ilbert, O.","abstract":"LePHARE is a set of Fortran commands to compute photometric redshifts and to perform SED fitting. The latest version includes new features with FIR fitting and a more complete treatment of physical parameters and uncertainties based on <a href=\"http:\/\/ascl.net\/1108.007\">P\u00c9GASE<\/a> and Bruzual & Charlot population synthesis models. The program is based on a  simple chi2 fitting method between the theoretical  and observed photometric catalogue. A simulation program is also available in order to generate realistic multi-colour catalogues taking into account observational effects.","topic_id":"24762","bibcode":"2011ascl.soft08009A","views":"47","site_list":["http:\/\/www.cfht.hawaii.edu\/~arnouts\/LEPHARE\/lephare.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006A&A...457..841I"]},
		{"ascl_id":"1108.010","title":"Hyperz: Photometric Redshift Code","credit":"Bolzonella, Micol; Miralles, Joan-Marc; Pell\u00f3, Roser","abstract":"From a photometric catalogue, hyperz finds the redshift of each object by means of a standard SED fitting procedure, i.e. comparing the observed magnitudes with the expected ones, computed from template Spectral Energy Distributions. The set of templates used in the minimization procedure (age, metallicity, reddening, absorption in the Lyman forest, ...) is studied in detail, through both real and simulated data. The expected accuracy of photometric redshifts, as well as the fraction of catastrophic identifications and wrong detections, is given as a function of the redshift range, the set of filters considered, and the photometric accuracy. Special attention is paid to the results expected from real data.","topic_id":"24764","bibcode":"2011ascl.soft08010B","views":"36","site_list":["http:\/\/webast.ast.obs-mip.fr\/hyperz\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0003380"]},
		{"ascl_id":"1108.011","title":"BPZ: Bayesian Photometric Redshift Code","credit":"Ben\u00edtez, Narciso","abstract":"Photometric redshift estimation is becoming an increasingly important technique, although the currently existing methods present several shortcomings which hinder their application.  Most of those drawbacks are efficiently eliminated when Bayesian probability is consistently applied to this problem. The use of prior probabilities and Bayesian marginalization allows the inclusion of valuable information, e.g. the redshift distributions or the galaxy type mix, which is often ignored by other methods. In those cases when the a priori information is insufficient, it is shown how to `calibrate' the prior distributions, using even the data under consideration. There is an excellent agreement between the 108 HDF spectroscopic redshifts and the predictions of the method, with a rms error Delta z\/(1+z_spec) = 0.08 up to z&lt;6 and no systematic biases nor outliers. The results obtained are more reliable than those of standard techniques even when the latter include near-IR colors. The Bayesian formalism developed here can be generalized to deal with a wide range of problems which make use of photometric redshifts, e.g. the estimation of individual galaxy characteristics as the metallicity, dust content, etc., or the study of galaxy evolution and the cosmological parameters from large multicolor surveys. Finally, using Bayesian probability it is possible to develop an integrated statistical method for cluster mass reconstruction which simultaneously considers the information provided by gravitational lensing and photometric redshifts.","topic_id":"24765","bibcode":"2011ascl.soft08011B","views":"74","site_list":["http:\/\/acs.pha.jhu.edu\/~txitxo\/bayesian.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9811189"]},
		{"ascl_id":"1108.012","title":"TITAN: General-purpose Radiation Hydrodynamics Code","credit":"Laboratory For Computational Astrophysics","abstract":"TITAN is a general-purpose radiation hydrodynamics code developed at the Laboratory for Computational Astrophysics (NCSA, University of Illinois at Urbana-Champaign). TITAN solves the coupled sets of radiation transfer and fluid dynamics equations on an adaptive mesh in one spatial dimension.","topic_id":"24777","bibcode":"2011ascl.soft08012L","views":"64","site_list":["http:\/\/web.archive.org\/web\/20100627125922\/","http:\/\/lca.ucsd.edu\/portal\/software\/titan\/","http:\/\/lca.ucsd.edu\/portal\/software\/titan"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1994PhyD...77..320G","http:\/\/arxiv.org\/abs\/astro-ph\/0103317"]},
		{"ascl_id":"1108.013","title":"STELLA: Multi-group Radiation Hydrodynamics Code","credit":"Blinnikov, Sergei I.; Bartunov, Oleg S.","abstract":"STELLA is a one-dimensional multi-group radiation hydrodynamics code. STELLA incorporates implicit hydrodynamics coupled to a multi-group non-equilibrium radiative transfer for modeling SN II-L light curves. The non-equilibrium description of radiation is crucial for this problem since the presupernova envelope may be of low mass and very dilute. STELLA implicitly treats time dependent equations of the angular moments of intensity averaged over a frequency bin. Local thermodynamic equilibrium is assumed to determine the ionization levels of materials.","topic_id":"24778","bibcode":"2011ascl.soft08013B","views":"50","site_list":["http:\/\/dau.itep.ru\/sn\/code\/stella"],"ref_list":["http:\/\/arxiv.org\/abs\/1009.5799","http:\/\/adsabs.harvard.edu\/abs\/1993A%26A...273..106B"]},
		{"ascl_id":"1108.014","title":"RADICAL: Multi-purpose 2-D Radiative Transfer Code","credit":"Dullemond, C. P.; Mokiem, R.; Turolla, R.","abstract":"RADICAL is a multi-purpose 2-D radiative transfer code for axi-symmetric circumstellar (or circum-black-hole) envelopes \/disks \/ tori etc. It has been extensively tested and found reliable and accurate. The code has recently been supplemented with a Variable Eddington Tensor module which enables it to solve dust continuum radiative transfer problems from very low up to extremely high optical depths with only a few (about 7) iterations at most.","topic_id":"24779","bibcode":"2011ascl.soft08014D","views":"63","site_list":["http:\/\/www.mpia.de\/homes\/dullemon\/radtrans\/radical\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0209323"]},
		{"ascl_id":"1108.015","title":"DISKSTRUCT: A Simple 1+1-D Disk Structure Code","credit":"Dullemond, C. P.","abstract":"DISKSTRUCT is a simple 1+1-D code for modeling protoplanetary disks. It is not based on multidimensional radiative transfer! Instead, a flaring-angle recipe is used to compute the irradiation of the disk, while the disk vertical structure at each cylindrical radius is computed in a 1-D fashion; the models computed with this code are therefore approximate. Moreover, this model cannot deal with the dust inner rim.\r\n\r\nIn spite of these simplifications and drawbacks, the code can still be very useful for disk studies, for the following reasons:\r\n\r\n<ul><li>It allows the disk structure to be studied in a 1-D vertical fashion (one radial cylinder at a time). For understanding the structure of disks, and also for using it as a basis of other models, this can be a great advantage.<\/li><li>For very optically thick disks this code is likely to be much faster than the RADMC full disk model.<\/li><li>Viscous internal heating of the disk is implemented and converges quickly, whereas the RADMC code is still having difficulty to deal with high optical depth combined with viscously generated internal heat.<\/li><\/ul>","topic_id":"24780","bibcode":"2011ascl.soft08015D","views":"40","site_list":["http:\/\/www.ita.uni-heidelberg.de\/~dullemond\/software\/diskstruct\/index.shtml"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002A%26A...389..464D"]},
		{"ascl_id":"1108.016","title":"RADMC: A 2-D Continuum Radiative Transfer Tool","credit":"Dullemond, C. P.","abstract":"RADMC is a 2-D Monte-Carlo code for dust continuum radiative transfer circumstellar disks and envelopes. It is based on the method of Bjorkman & Wood (ApJ 2001, 554, 615), but with several modifications to produce smoother results with fewer photon packages.","topic_id":"24781","bibcode":"2011ascl.soft08016D","views":"44","site_list":["http:\/\/www.ita.uni-heidelberg.de\/~dullemond\/software\/radmc\/index.shtml"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0402357"]},
		{"ascl_id":"1108.017","title":"SHELLSPEC: Simple Radiative Transfer along Line of Sight in Moving Media","credit":"Budaj, Jan; Richards, Mercedes","abstract":"SHELLSPEC is designed to calculate lightcurves, spectra and images of interacting binaries and extrasolar planets immersed in a moving circumstellar environment which is optically thin. It solves simple radiative transfer along the line of sight in moving media. The assumptions include LTE and optional known state quantities and velocity fields in 3D. Optional (non)transparent objects such as a spot, disc, stream, jet, shell or stars as well as an empty space may be defined (embedded) in 3D and their composite synthetic spectrum calculated. Roche model can be used as a boundary condition for the radiative tranfer. The program does not solve the inverse problem of finding the stellar and orbital parameters.","topic_id":"24978","bibcode":"2011ascl.soft08017B","views":"44","site_list":["http:\/\/www.ta3.sk\/~budaj\/shellspec.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004CoSka..34..167B","http:\/\/arxiv.org\/abs\/1108.3646"]},
		{"ascl_id":"1108.018","title":"STECKMAP: STEllar Content and Kinematics via Maximum A Posteriori likelihood","credit":"Ocvirk, P.","abstract":"STECKMAP stands for STEllar Content and Kinematics via Maximum A Posteriori likelihood. It is a tool for interpreting galaxy spectra in terms of their stellar populations through the derivation of their star formation history, age-metallicity relation, kinematics and extinction. The observed spectrum is projected onto a temporal sequence of models of single stellar populations, so as to determine a linear combination of these models that best fits the observed spectrum. The weights of the various components of this linear combination indicate the stellar content of the population. This procedure is regularized using various penalizing functions. The principles of the method are detailed in <a href=\"http:\/\/cdsads.u-strasbg.fr\/abs\/2006MNRAS.365...74O\">Ocvirk et al. 2006<\/a>.","topic_id":"24990","bibcode":"2011ascl.soft08018O","views":"33","site_list":["http:\/\/astro.u-strasbg.fr\/~ocvirk\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1002.3524"]},
		{"ascl_id":"1108.019","title":"BOREAS: Mass Loss Rate of a Cool, Late-type Star","credit":"Cranmer, Steven R.; Saar, Steven H.","abstract":"The basic mechanisms responsible for producing winds from cool, late-type stars are still largely unknown. We take inspiration from recent progress in understanding solar wind acceleration to develop a physically motivated model of the time-steady mass loss rates of cool main-sequence stars and evolved giants. This model follows the energy flux of magnetohydrodynamic turbulence from a subsurface convection zone to its eventual dissipation and escape through open magnetic flux tubes. We show how Alfven waves and turbulence can produce winds in either a hot corona or a cool extended chromosphere, and we specify the conditions that determine whether or not coronal heating occurs. These models do not utilize arbitrary normalization factors, but instead predict the mass loss rate directly from a star's fundamental properties. We take account of stellar magnetic activity by extending standard age-activity-rotation indicators to include the evolution of the filling factor of strong photospheric magnetic fields. We compared the predicted mass loss rates with observed values for 47 stars and found significantly better agreement than was obtained from the popular scaling laws of Reimers, Schroeder, and Cuntz. The algorithm used to compute cool-star mass loss rates is provided as a self-contained and efficient IDL computer code. We anticipate that the results from this kind of model can be incorporated straightforwardly into stellar evolution calculations and population synthesis techniques.","topic_id":"25100","bibcode":"2011ascl.soft08019C","views":"64","site_list":["https:\/\/www.cfa.harvard.edu\/~scranmer\/cranmer_data.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1108.4369"]},
		{"ascl_id":"1109.001","title":"PySpecKit: Python Spectroscopic Toolkit","credit":"Ginsburg, Adam; Mirocha, Jordan","abstract":"PySpecKit is a Python spectroscopic analysis and reduction toolkit meant to be generally applicable to optical, infrared, and radio spectra. It is capable of reading FITS-standard and many non-standard file types including CLASS spectra. It contains procedures for line fitting including gaussian and voigt profile fitters, and baseline-subtraction routines. It is capable of more advanced line fitting using arbitrary model grids.  Fitting can be done both in batch mode and interactively. PySpecKit also produces publication-quality plots with TeX axis labels and annotations. It is designed to be extensible, allowing user-written reader, writer, and fitting routines to be \"plugged in.\" It is actively under development and currently in the 'alpha' phase, with plans for a beta release.","topic_id":"25138","bibcode":"2011ascl.soft09001G","views":"46","site_list":["http:\/\/pyspeckit.bitbucket.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1106.1430v3"]},
		{"ascl_id":"1109.002","title":"ADIPLS: Aarhus Adiabatic Oscillation Package (ADIPACK)","credit":"Christensen-Dalsgaard, J.","abstract":"The goal of the development of the Aarhus Adiabatic Oscillation Package was to have a simple and efficient tool for the computation of adiabatic oscillation frequencies and eigenfunctions for general stellar models, emphasizing also the accuracy of the results. The Fortran code offers considerable flexibility in the choice of integration method as well as ability to determine all frequencies of a given model, in a given range of degree and frequency. Development of the Aarhus adiabatic pulsation code started around 1978. Although the main features have been stable for more than a decade, development of the code is continuing, concerning numerical properties and output. The code has been provided as a generally available package and has seen substantial use at a number of installations. Further development of the package, including bringing the documentation closer to being up to date, is planned as part of the HELAS Coordination Action.","topic_id":"25167","bibcode":"2011ascl.soft09002C","views":"68","site_list":["http:\/\/users-phys.au.dk\/jcd\/adipack.n\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0710.3106"]},
		{"ascl_id":"1109.003","title":"SKIRT: Stellar Kinematics Including Radiative Transfer","credit":"Baes, Maarten; Dejonghe, Herwig; Davies, Jonathan","abstract":"SKIRT is a radiative transfer code based on the Monte Carlo technique. The name SKIRT, acronym for Stellar Kinematics Including Radiative Transfer, reflects the original motivation for its creation: it has been developed to study the effects of dust absorption and scattering on the observed kinematics of dusty galaxies. In a second stage, the SKIRT code was extended with a module to self-consistently calculate the dust emission spectrum under the assumption of local thermal equilibrium. This LTE version of SKIRT has been used to model the dust extinction and emission of various types of galaxies, as well as circumstellar discs and clumpy tori around active galactic nuclei. A new, extended version of SKIRT code can perform efficient 3D radiative transfer calculations including a self-consistent calculation of the dust temperature distribution and the associated FIR\/submm emission with a full incorporation of the emission of transiently heated grains and PAH molecules.","topic_id":"25201","bibcode":"2011ascl.soft09003B","views":"50","site_list":["https:\/\/sites.google.com\/site\/skirtorus\/skirt"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0503483","http:\/\/arxiv.org\/abs\/1109.1286"]},
		{"ascl_id":"1109.004","title":"HAZEL: HAnle and ZEeman Light","credit":"Asensio Ramos, Andr\u00e9s; Trujillo Bueno, Javier; Landi Degl'Innocenti, E.","abstract":"A big challenge in solar and stellar physics in the coming years will be to decipher the magnetism of the solar outer atmosphere (chromosphere and corona) along with its dynamic coupling with the magnetic fields of the underlying photosphere. To this end, it is important to develop rigorous diagnostic tools for the physical interpretation of spectropolarimetric observations in suitably chosen spectral lines. HAZEL is a computer program for the synthesis and inversion of Stokes profiles caused by the joint action of atomic level polarization and the Hanle and Zeeman effects in some spectral lines of diagnostic interest, such as those of the He I 1083.0 nm and 587.6 nm (or D3) multiplets. It is based on the quantum theory of spectral line polarization, which takes into account in a rigorous way all the relevant physical mechanisms and ingredients (optical pumping, atomic level polarization, level crossings and repulsions, Zeeman, Paschen-Back and Hanle effects). The influence of radiative transfer on the emergent spectral line radiation is taken into account through a suitable slab model. The user can either calculate the emergent intensity and polarization for any given magnetic field vector or infer the dynamical and magnetic properties from the observed Stokes profiles via an efficient inversion algorithm based on global optimization methods.","topic_id":"25207","bibcode":"2011ascl.soft09004A","views":"37","site_list":["http:\/\/www.iac.es\/project\/magnetism\/pages\/codes\/hazel.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ApJ...683..542A"]},
		{"ascl_id":"1109.005","title":"PolSpice: Spatially Inhomogeneous Correlation Estimator for Temperature and Polarisation","credit":"Challinor, Anthony; Chon, Gayoung; Colombi, St\u00e9phane; Hivon, Eric; Prunet, Simon; Szapudi, Istv\u00e1n.","abstract":"PolSpice (aka Spice) is a tool to statistically analyze Cosmic Microwave Background (CMB) data, as well as any other diffuse data pixelized on the sphere.\n\nThis Fortran90 program measures the 2 point auto (or cross-) correlation functions w(\u03b8) and the angular auto- (or cross-) power spectra C(l) from one or (two) sky map(s) of Stokes parameters (intensity I and linear polarisation Q and U). It is based on the fast Spherical Harmonic Transforms allowed by isolatitude pixelisations such as Healpix [for Npix pixels over the whole sky, and a C(l) computed up to l=lmax, PolSpice complexity scales like Npix1\/2 lmax2 instead of Npix lmax2]. It corrects for the effects of the masks and can deal with inhomogeneous weights given to the pixels of the map. In the case of polarised data, the mixing of the E and B modes due to the cut sky and pixel weights can be corrected for to provide an unbiased estimate of the \"magnetic\" (B) component of the polarisation power spectrum. Most of the code is parallelized for shared memory (SMP) architecture using OpenMP.","topic_id":"25223","bibcode":"2011ascl.soft09005C","views":"44","site_list":["http:\/\/www2.iap.fr\/users\/hivon\/software\/PolSpice\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001ApJ...548L.115S"]},
		{"ascl_id":"1109.006","title":"MultiNest: Efficient and Robust Bayesian Inference","credit":"Feroz, F.; Hobson, M. P.; Bridges, M.","abstract":"We present further development and the first public release of our multimodal nested sampling algorithm, called MultiNest. This Bayesian inference tool calculates the evidence, with an associated error estimate, and produces posterior samples from distributions that may contain multiple modes and pronounced (curving) degeneracies in high dimensions. The developments presented here lead to further substantial improvements in sampling efficiency and robustness, as compared to the original algorithm presented in Feroz & Hobson (2008), which itself significantly outperformed existing MCMC techniques in a wide range of astrophysical inference problems. The accuracy and economy of the MultiNest algorithm is demonstrated by application to two toy problems and to a cosmological inference problem focusing on the extension of the vanilla $Lambda$CDM model to include spatial curvature and a varying equation of state for dark energy. The MultiNest software is fully parallelized using MPI and includes an interface to <a href=\"http:\/\/ascl.net\/1106.025\">CosmoMC<\/a>. It will also be released as part of the SuperBayeS package, for the analysis of supersymmetric theories of particle physics, at <a href=\"http:\/\/www.ft.uam.es\/personal\/rruiz\/superbayes\/index.php?page=main.html\">this http URL<\/a>.","topic_id":"25225","bibcode":"2011ascl.soft09006F","views":"62","site_list":["http:\/\/ccpforge.cse.rl.ac.uk\/gf\/project\/multinest\/"],"ref_list":["http:\/\/xxx.lanl.gov\/abs\/0809.3437"]},
		{"ascl_id":"1109.007","title":"SuperBayeS: Supersymmetry Parameters Extraction Routines for Bayesian Statistics","credit":"Ruiz de Austri, Roberto; Trotta, Roberto; Feroz, Farhan","abstract":"SuperBayeS is a package for fast and efficient sampling of supersymmetric theories. It uses Bayesian techniques to explore multidimensional SUSY parameter spaces and to compare SUSY predictions with observable quantities, including sparticle masses, collider observables, dark matter abundance, direct detection cross sections, indirect detection quantities etc. Scanning can be performed using Markov Chain Monte Carlo (MCMC) technology or even more efficiently by employing a new scanning technique called, MultiNest. which implements the nested sampling algorithm. Using MultiNest, a full 8-dimensional scan of the CMSSM takes about 12 hours on 10 2.4GHz CPUs. There is also an option for old-style fixed-grid scanning. A <a href=\"http:\/\/groups.google.com\/group\/superbayes-users\">discussion forum for SuperBayeS<\/a> is available.\r\n\r\nThe package combines SoftSusy, DarkSusy, FeynHiggs, Bdecay, MultiNest and MicrOMEGAs. Some of the routines and the plotting tools are based on <a href=\"http:\/\/ascl.net\/1106.025\">CosmoMC<\/a>.\r\n\r\nSuperBayeS comes with SuperEGO, a MATLAB graphical user interface tool for interactive plotting of the results. SuperEGO has been developed by Rachid Lemrani and is based on CosmoloGUI by Sarah Bridle.","topic_id":"25226","bibcode":"2011ascl.soft09007R","views":"41","site_list":["http:\/\/www.ft.uam.es\/personal\/rruiz\/superbayes\/index.php?page=main.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0809.3792"]},
		{"ascl_id":"1109.008","title":"Multipole Vectors: Decomposing Functions on a Sphere","credit":"Copi, C. J.; Huterer, D.; Starkman, G. D.","abstract":"We propose a novel representation of cosmic microwave anisotropy maps, where each multipole order l is represented by l unit vectors pointing in directions on the sky and an overall magnitude. These \"multipole vectors and scalars\" transform as vectors under rotations. Like the usual spherical harmonics, multipole vectors form an irreducible representation of the proper rotation group SO(3). However, they are related to the familiar spherical harmonic coefficients, alm, in a nonlinear way, and are therefore sensitive to different aspects of the CMB anisotropy. Nevertheless, it is straightforward to determine the multipole vectors for a given CMB map and we present an algorithm to compute them. Using the WMAP full-sky maps, we perform several tests of the hypothesis that the CMB anisotropy is statistically isotropic and Gaussian random. We find that the result from comparing the oriented area of planes defined by these vectors between multipole pairs 2&lt;=l1!=l2&lt;=8 is inconsistent with the isotropic Gaussian hypothesis at the 99.4% level for the ILC map and at 98.9% level for the cleaned map of Tegmark et al. A particular correlation is suggested between the l=3 and l=8 multipoles, as well as several other pairs. This effect is entirely different from the now familiar planarity and alignment of the quadrupole and octupole: while the aforementioned is fairly unlikely, the multipole vectors indicate correlations not expected in Gaussian random skies that make them unusually likely. The result persists after accounting for pixel noise and after assuming a residual 10% dust contamination in the cleaned WMAP map. While the definitive analysis of these results will require more work, we hope that multipole vectors will become a valuable tool for various cosmological tests, in particular those of cosmic isotropy.","topic_id":"25233","bibcode":"2011ascl.soft09008C","views":"30","site_list":["http:\/\/www.phys.cwru.edu\/projects\/mpvectors\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0310511"]},
		{"ascl_id":"1109.009","title":"CMBquick: Spectrum and Bispectrum of Cosmic Microwave Background (CMB)","credit":"Pitrou, Cyril","abstract":"CMBquick is a package for Mathematica in which tools are provided to compute the spectrum and bispectrum of Cosmic Microwave Background (CMB). It is unavoidably slow, but the main goal is not to design a tool which can be used for systematic exploration of parameters in cosmology, but rather a toy CMB code which is transparent and easily modified. Considering this, the name chosen is nothing but a joke which refers to the widely spread and used softwares <a href=\"http:\/\/ascl.net\/9909.004\">CMBFAST<\/a>, <a href=\"http:\/\/ascl.net\/1102.026\">CAMB<\/a> or CMBeasy, which should be used for serious and heavy first order CMB computations, and which are indeed very fast.\r\n\r\nThe package CMBquick is unavoidably slow when it comes to compute the multipoles Cls, and most of it is due to the access time for variables which in Mathematica is approximately ten times slower than in C or Fortran. CMBquick is thus approximately 10 times slower than CAMB and cannot be used for the same reasons. It uses the same method as CAMB for computing the CMB spectrum, which is based on the line of sight approach. However the integration is performed in a different gauge with different time steps and k-spacing. It benefits from the power of Mathematica on numerical resolution of stiff differential systems, and the transfer functions can be obtained with exquisite accuracy.\r\n\r\nThe purpose of CMBquick is thus twofold. First, CMBquick is a slow but precise and pedagogical, tool which can be used to explore and modify the physical content of the linear and non-linear dynamics. Second, it is a tool which can help developing templates for nonlinear computations, which could then be hard coded once their correctness is checked. The number of equations for non-linear dynamics is quite sizable and CMBquick makes it easy (but slow) to manipulate the non-linear equations, to solve them precisely, and to plot them.","topic_id":"25237","bibcode":"2011ascl.soft09009P","views":"81","site_list":["http:\/\/www2.iap.fr\/users\/pitrou\/cmbquick.htm"],"ref_list":["http:\/\/arxiv.org\/abs\/1109.1822"]},
		{"ascl_id":"1109.010","title":"PyModelFit: Model-fitting Framework and GUI Tool","credit":"Tollerud, Erik","abstract":"PyModelFit provides a pythonic, object-oriented framework that simplifies the task of designing numerical models to fit data. This is a very broad task, and hence the current functionality of PyModelFit focuses on the simpler tasks of 1D curve-fitting, including a GUI interface to simplify interactive work (using Enthought Traits). For more complicated modeling, PyModelFit also provides a wide range of classes and a framework to support more general model\/data types (2D to Scalar, 3D to Scalar, 3D to 3D, and so on).","topic_id":"25303","bibcode":"2011ascl.soft09010T","views":"50","site_list":["http:\/\/packages.python.org\/PyModelFit\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012ApJ...752...45T"]},
		{"ascl_id":"1109.011","title":"GalactICS: Galaxy Model Building Package","credit":"Kuijken, Konrad; Dubinski, John","abstract":"GalactICS generates N-body realizations of axisymmetric galaxy models consisting of disk, bulge and halo. Some of the code is in Fortran 77, using lines longer than 72 characters in some cases. The -e flag in the makefile allow for this for a Solaris f77 compiler. Other programs are written in C. Again, the linking between these routines works on Solaris systems, but may need to be adjusted for other architectures. We have found that linking using f77 instead of ld will often automatically load the appropriate libraries.\r\n\r\nThe graphics output by some of the programs (dbh, plotforce, diskdf, plothalo) uses the <a href=\"http:\/\/ascl.net\/1103.002\">PGPLOT library<\/a>. Alternatively, remove all calls to routines with names starting with \"PG\", as well as the -lpgplot flag in the Makefile, and the programs should still run fine.","topic_id":"25304","bibcode":"2011ascl.soft09011K","views":"49","site_list":["http:\/\/www.sourcefiles.org\/Scientific\/Astronomy\/Simulation\/GalactICS.tar.gz.shtml"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9502051","http:\/\/arxiv.org\/abs\/1107.4289"]},
		{"ascl_id":"1402.023","title":"HydraLens: Gravitational lens model generator","credit":"Lefor, Alan","abstract":"HydraLens generates gravitational lens model files for <a href=\"http:\/\/ascl.net\/1102.004\">Lenstool<\/a>, <a href=\"http:\/\/ascl.net\/1102.007\">PixeLens<\/a>, <a href=\"http:\/\/ascl.net\/1010.012\">glafic<\/a> and Lensmodel and can also translate lens model files among these four lens model codes. Through a GUI, the user enters a new model by specifying the type of model and is then led through screens to collect the data. Written in MS Visual Basic, the code can also translate an existing model from any of the four supported codes to any of the other three.","topic_id":"32985","bibcode":"2014ascl.soft02023L","views":"52","site_list":["http:\/\/asterisk.apod.com\/download\/file.php?id=12440"],"ref_list":false},
		{"ascl_id":"1109.012","title":"EnBiD: Fast Multi-dimensional Density Estimation","credit":"Sharma, Sanjib; Steinmetz, Matthias","abstract":"We present a method to numerically estimate the densities of a discretely sampled data based on a binary space partitioning tree. We start with a root node containing all the particles and then recursively divide each node into two nodes each containing roughly equal number of particles, until each of the nodes contains only one particle. The volume of such a leaf node provides an estimate of the local density and its shape provides an estimate of the variance. We implement an entropy-based node splitting criterion that results in a significant improvement in the estimation of densities compared to earlier work. The method is completely metric free and can be applied to arbitrary number of dimensions. We use this method to determine the appropriate metric at each point in space and then use kernel-based methods for calculating the density. The kernel-smoothed estimates were found to be more accurate and have lower dispersion. We apply this method to determine the phase-space densities of dark matter haloes obtained from cosmological N-body simulations. We find that contrary to earlier studies, the volume distribution function v(f) of phase-space density f does not have a constant slope but rather a small hump at high phase-space densities. We demonstrate that a model in which a halo is made up by a superposition of Hernquist spheres is not capable in explaining the shape of v(f) versus f relation, whereas a model which takes into account the contribution of the main halo separately roughly reproduces the behaviour as seen in simulations. The use of the presented method is not limited to calculation of phase-space densities, but can be used as a general purpose data-mining tool and due to its speed and accuracy it is ideally suited for analysis of large multidimensional data sets.","topic_id":"25307","bibcode":"2011ascl.soft09012S","views":"42","site_list":["http:\/\/sourceforge.net\/projects\/enbid\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006MNRAS.373.1293S","http:\/\/arxiv.org\/abs\/0812.3659"]},
		{"ascl_id":"1109.013","title":"CULSP: Fast Calculation of the Lomb-Scargle Periodogram Using Graphics Processing Units","credit":"Townsend, R. H. D.","abstract":"I introduce a new code for fast calculation of the Lomb-Scargle periodogram, that leverages the computing power of graphics processing units (GPUs). After establishing a background to the newly emergent field of GPU computing, I discuss the code design and narrate key parts of its source. Benchmarking calculations indicate no significant differences in accuracy compared to an equivalent CPU-based code. However, the differences in performance are pronounced; running on a low-end GPU, the code can match 8 CPU cores, and on a high-end GPU it is faster by a factor approaching thirty. Applications of the code include analysis of long photometric time series obtained by ongoing satellite missions and upcoming ground-based monitoring facilities; and Monte-Carlo simulation of periodogram statistical properties.","topic_id":"25329","bibcode":"2011ascl.soft09013T","views":"45","site_list":["http:\/\/www.astro.wisc.edu\/~townsend\/resource\/download\/code\/culsp.tar.gz"],"ref_list":["http:\/\/arxiv.org\/abs\/1007.1658"]},
		{"ascl_id":"1109.014","title":"Supernova Flux-averaging Likelihood Code","credit":"Wang, Yun","abstract":"Flux-averaging justifies the use of the distance-redshift relation for a smooth universe in the analysis of type Ia supernova (SN Ia) data. Flux-averaging of SN Ia data is required to yield cosmological parameter constraints that are free of the bias induced by weak gravitational lensing. SN Ia data are converted into flux. For a given cosmological model, the distance dependence of the data is removed, then the data are binned in redshift, and placed at the average redshift in each redshift bin. The likelihood of the given cosmological model is then computed using \"flux statistics''. These Fortran codes compute the likelihood of an arbitrary cosmological model [with given H(z)\/H_0] using flux-averaged Type Ia supernova data.","topic_id":"25366","bibcode":"2011ascl.soft09014W","views":"39","site_list":["http:\/\/www.nhn.ou.edu\/~wang\/SNcode\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/9907405v2","http:\/\/arxiv.org\/abs\/1109.3172"]},
		{"ascl_id":"1109.015","title":"WCSTools: Image Astrometry Toolkit","credit":"Mink, Douglas J.","abstract":"WCSTools is a package of programs and a library of utility subroutines for setting and using the world coordinate systems (WCS) in the headers of the most common astronomical image formats, FITS and IRAF .imh, to relate image pixels to sky coordinates. In addition to dealing with image WCS information, WCSTools has extensive catalog search, image header manipulation, and coordinate and time conversion tasks. This software is all written in very portable C, so it should compile and run on any computer with a C compiler.","topic_id":"25370","bibcode":"2011ascl.soft09015M","views":"46","site_list":["http:\/\/tdc-www.harvard.edu\/software\/wcstools\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1999ASPC..172..498M"]},
		{"ascl_id":"1109.016","title":"aXe: Spectral Extraction and Visualization Software","credit":"Space Telescope-European Coordinating Facility (Esa)","abstract":"aXe is a spectroscopic data extraction software package that was designed to handle large format spectroscopic slitless images such as those from the Wide Field Camera 3 (WFC3) and the Advanced Camera for Surveys (ACS) on HST. aXe is a <a href=\"http:\/\/ascl.net\/1207.011\">PyRAF<\/a>\/<a href=\"http:\/\/ascl.net\/9911.002\">IRAF<\/a> package that consists of several tasks and is distributed as part of the Space Telescope Data Analysis System (STSDAS). The various aXe tasks perform specific parts of the extraction and calibration process and are successively used to produce extracted spectra.","topic_id":"25371","bibcode":"2011ascl.soft09016S","views":"76","site_list":["http:\/\/axe.stsci.edu\/axe\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009PASP..121...59K"]},
		{"ascl_id":"1109.017","title":"IRDR: InfraRed Data Reduction","credit":"Sabbey, Chris N.; McMahon, Richard G.; Lewis, James R.; Irwin, Mike J.; Babusiaux, Carine","abstract":"We describe the InfraRed Data Reduction (IRDR) software package, a small ANSI C library of fast image processing routines for automated pipeline reduction of infrared (dithered) observations. We developed the software to satisfy certain design requirements not met in existing packages (e.g., full weight map handling) and to optimize the software for large data sets (non-interactive tasks that are CPU and disk efficient). The software includes stand-alone C programs for tasks such as running sky frame subtraction with object masking, image registration and coaddition with weight maps, dither offset measurement using cross-correlation, and object mask dilation. Although we currently use the software to process data taken with CIRSI (a near-IR mosaic imager), the software is modular and concise and should be easy to adapt\/reuse for other work.","topic_id":"25381","bibcode":"2011ascl.soft09017S","views":"35","site_list":["http:\/\/www.ast.cam.ac.uk\/~optics\/cirsi\/software\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0101181"]},
		{"ascl_id":"1109.018","title":"GIPSY: Groningen Image Processing System","credit":"Allen, R. J.; Ekers, R. D.; Terlouw, J. P.; Vogelaar, M. G. R.","abstract":"GIPSY is an acronym of Groningen Image Processing SYstem. It is a highly interactive software system for the reduction and display of astronomical data. It supports multi-tasking using a versatile user interface, it has an advanced data structure, a powerful script language and good display facilities based on the X Window system.\r\n\r\nGIPSY consists of a number of components which can be divided into a number of classes:\r\n<ul><li>The user interfaces. Currently two user interfaces are available; one for interactive work and one for batch processing.<\/li><li>The data structure.<\/li><li>The display utilities.<\/li><li>The application programs. These are the majority of programs.<\/li><\/ul> GIPSY was designed originally for the reduction of interferometric data from the Westerbork Synthesis Radio Telescope, but in its history of more than 20 years it has grown to a system capable of handling data from many different instruments (e.g. TAURUS, IRAS etc.).","topic_id":"25382","bibcode":"2011ascl.soft09018A","views":"32","site_list":["http:\/\/www.astro.rug.nl\/~gipsy\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0801.2971","http:\/\/adass.org\/adass\/proceedings\/adass00\/P3-04\/"]},
		{"ascl_id":"1109.019","title":"SkyCat: Visualization and Catalog and Data Access Tool","credit":"ESO's Data Management; Very Large Telescope (VLT) Project Divisions; Canadian Astronomical Data Center (CADC)","abstract":"SkyCat is a tool that combines visualization of images and access to catalogs and archive data for astronomy. The tool, developed in Tcl\/Tk, was originally conceived as a demo of the capabilities of the class library that was developed for the VLT. The Skycat sources currently consist of five packages:\r\n<ul><li>Tclutil - Generic Tcl and C++ utilities<\/li><li>Astrotcl - Astronomical Tcl and C++ utilities<\/li><li>RTD - Real-time Display classes and widgets<\/li><li>Catlib - Catalog library and widgets<\/li><li>Skycat - Skycat application and library package <\/li><\/ul>All of the required packages are always included in the tarfile.","topic_id":"25383","bibcode":"2011ascl.soft09019E","views":"86","site_list":["http:\/\/archive.eso.org\/cms\/tools-documentation\/skycat.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1997ASPC..125..333A","http:\/\/adsabs.harvard.edu\/abs\/2004yCat..34150521S"]},
		{"ascl_id":"1109.020","title":"CMFGEN: Probing the Universe through Spectroscopy","credit":"Hillier, John","abstract":"A radiative transfer code designed to solve the radiative transfer and statistical equilibrium equations in spherical geometry.  It has been designed for application to W-R stars, O stars, and Luminous Blue-Variables. CMFGEN allows fundamental parameters such as effective temperatures, stellar radii and stellar luminosities to be determined. It can provide constraints on mass-loss rates, and allow abundance determinations for a wide range of atomic species. Further it can provide accurate energy distributions, and hence ionizing fluxes, which can be used as input for codes which model the spectra of HII regions and ring nebular.","topic_id":"25390","bibcode":"2011ascl.soft09020H","views":"53","site_list":["http:\/\/kookaburra.phyast.pitt.edu\/hillier\/web\/CMFGEN.htm"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1998ApJ...496..407H","http:\/\/iopscience.iop.org\/0067-0049\/146\/2\/417\/56938.text.html"]},
		{"ascl_id":"1109.021","title":"TLUSTY: Stellar Atmospheres, Accretion Disks, and Spectroscopic Diagnostics","credit":"Hubeny, Ivan; Lanz, Thierry","abstract":"TLUSTY is a user-oriented package written in FORTRAN77 for modeling stellar atmospheres and accretion disks and wide range of spectroscopic diagnostics. In the program's maximum configuration, the user may start from scratch and calculate a model atmosphere of a chosen degree of complexity, and end with a synthetic spectrum in a wavelength region of interest for an arbitrary stellar rotation and an arbitrary instrumental profile. The user may also model the vertical structure of annuli of an accretion disk.","topic_id":"25392","bibcode":"2011ascl.soft09021H","views":"54","site_list":["http:\/\/nova.astro.umd.edu\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1995ApJ...439..875H","http:\/\/xxx.lanl.gov\/abs\/astro-ph\/0301454"]},
		{"ascl_id":"1109.022","title":"Synspec: General Spectrum Synthesis Program","credit":"Hubeny, Ivan; Lanz, Thierry","abstract":"Synspec is a user-oriented package written in FORTRAN for modeling stellar atmospheres and for stellar spectroscopic diagnostics. It assumes an existing model atmosphere, calculated previously with Tlusty or taken from the literature (for instance, from the Kurucz grid of models). The opacity sources (continua, atomic and molecular lines) are fully specified by the user. An arbitrary stellar rotation and instrumental profile can be applied to the synthetic spectrum.","topic_id":"25393","bibcode":"2011ascl.soft09022H","views":"62","site_list":["http:\/\/nova.astro.umd.edu\/Synspec43\/synspec.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1003.4682","http:\/\/arxiv.org\/abs\/astro-ph\/9711074"]},
		{"ascl_id":"1109.023","title":"MOKA: A New Tool for Strong Lensing Studies","credit":"Giocoli, Carlo; Meneghetti, Massimo; Bartelmann, Matthias; Moscardini, Lauro; Boldrin, Michele","abstract":"We present a new algorithm for simulating the gravitational lensing signal from cluster-sized haloes: MOKA. This algorithm implements the most recent results from numerical simulations to create realistic lenses with properties independent of numerical resolution. We perform systematic studies of the strong lensing cross section in dependence of halo structure. We find that the cross sections depend most strongly on the concentration and on the inner slope of the density profile of a halo. However, fixing these properties, further important contributions are due to halo triaxiality and the presence of a bright central galaxy.","topic_id":"25410","bibcode":"2011ascl.soft09023G","views":"35","site_list":["http:\/\/cgiocoli.wordpress.com\/research-interests\/moka\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1109.0285"]},
		{"ascl_id":"1109.024","title":"Jupiter: Multidimensional Astrophysical Hydrocode","credit":"Masset, Frederic","abstract":"Jupiter is a multidimensional astrophysical hydrocode. It is based on a Godunov method, and it is parallelized with MPI. The mesh geometry can either be cartesian, cylindrical or spherical. It allows mesh refinement and includes special features adapted to the description of planets embedded in disks and nearly steady states.","topic_id":"23805","bibcode":"2011ascl.soft09024M","views":"42","site_list":["http:\/\/jupiter.in2p3.fr\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1102.0671"]},
		{"ascl_id":"1110.001","title":"analytic_infall: A Molecular Line Infall Fitting Program","credit":"de Vries, Christopher H.; Myers, Philip C.","abstract":"This code contains several simple radiative transfer models used for fitting the blue-asymmetric spectral line signature often found in infalling molecular cloud cores. It attempts to provide a direct measure of several physical parameters of the infalling core, including infall velocity, excitation temperature, and line of site optical depth. The code includes 6 radiative transfer models, however the conclusion of the associated paper is that the 5 parameter \"hill\" model (hill5) is most likely the best match to the physical excitation conditions of real infalling Bonnor-Ebert type clouds.","topic_id":"25442","bibcode":"2011ascl.soft10001D","views":"68","site_list":["https:\/\/bitbucket.org\/devries\/analytic_infall\/wiki\/Home"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005ApJ...620..800D"]},
		{"ascl_id":"1110.002","title":"DarkSUSY: Supersymmetric Dark Matter Calculations","credit":"Gondolo, Paolo; Edsj\u00f6, Joakim; Bergstr\u00f6m, Lars; Ullio, Piero; Schelke, Mia; Baltz, Ted; Bringmann, Torsten; Duda, Gintaras","abstract":"DarkSUSY, written in Fortran, is a publicly-available advanced numerical package for neutralino dark matter calculations. In DarkSUSY one can compute the neutralino density in the Universe today using precision methods which include resonances, pair production thresholds and coannihilations. Masses and mixings of supersymmetric particles can be computed within DarkSUSY or with the help of external programs such as FeynHiggs, ISASUGRA and SUSPECT. Accelerator bounds can be checked to identify viable dark matter candidates. DarkSUSY also computes a large variety of astrophysical signals from neutralino dark matter, such as direct detection in low-background counting experiments and indirect detection through antiprotons, antideuterons, gamma-rays and positrons from the Galactic halo or high-energy neutrinos from the center of the Earth or of the Sun.","topic_id":"25455","bibcode":"2011ascl.soft10002G","views":"39","site_list":["http:\/\/www.physto.se\/~edsjo\/darksusy\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0406204"]},
		{"ascl_id":"1110.003","title":"iGalFit: An Interactive Tool for GalFit","credit":"Ryan, R. E., Jr.","abstract":"We present a suite of IDL routines to interactively run <a href=\"http:\/\/ascl.net\/1104.010\">GALFIT<\/a> whereby the various surface brightness profiles (and their associated parameters) are represented by regions, which the User is expected to place. The regions may be saved and\/or loaded from the ASCII format used by ds9 or in the Hierarchical Data Format (version 5). The software has been tested to run stably on Mac OS X and Linux with IDL 7.0.4. In addition to its primary purpose of modeling galaxy images with GALFIT, this package has several ancillary uses, including a flexible image display routines, several basic photometry functions, and qualitatively assessing <a href=\"http:\/\/ascl.net\/1010.064\">Source Extractor<\/a>. We distribute the package freely and without any implicit or explicit warranties, guarantees, or assurance of any kind. We kindly ask users to report any bugs, errors, or suggestions to us directly (as opposed to fixing them themselves) to ensure version control and uniformity.","topic_id":"25501","bibcode":"2011ascl.soft10003R","views":"40","site_list":["http:\/\/dls.physics.ucdavis.edu\/~rer\/iGalFit\/igalfit_v1.0\/www\/home.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1110.1090"]},
		{"ascl_id":"1110.004","title":"SHTOOLS: Tools for Working with Spherical Harmonics","credit":"Wieczorek, Mark","abstract":"SHTOOLS is an archive of fortran 95 based software that can be used to perform (among others) spherical harmonic transforms and reconstructions, rotations of spherical harmonic coefficients, and multitaper spectral analyses on the sphere. While several collections of code currently exist for working with data expressed in spherical harmonics, this one is unique for several reasons:\n<ul><li>It can accommodate any standard normalization of the spherical harmonic functions (\"geodesy\" 4\u03c0 normalized, Schmidt semi-normalized, orthonormalized, and unnormalized).<\/li><li>Either real or complex spherical harmonics can be employed.<\/li><li>Spherical harmonic transforms are calculated by exact quadrature rules using either (1) the sampling theorem of Driscoll and Healy (1994) where data are equally sampled (or spaced) in latitude and longitude, or (2) Gauss-Legendre quadrature. A least squares inversion routine for irregularly sampled data is included as well.<\/li><li>One can choose to use or exclude the Condon-Shortley phase factor of (-1)m with the associated Legendre functions.<\/li><li>The spherical harmonic transforms are proven to be accurate to approximately degree 2800, corresponding to a spatial resolution of better than 4 arc minutes.<\/li><li>Routines are included for performing localized multitaper spectral analyses.<\/li><li>Routines are included for performing standard gravity calculations, such as computation of the geoid and the determination of the potential associated with finite-amplitude topography.<\/li><li>The routines are fast. Spherical harmonic transforms and reconstructions take on the order of 1 second for bandwidths less than 600 and about 3 minutes for bandwidths close to 2800.<\/li><\/ul>","topic_id":"25531","bibcode":"2011ascl.soft10004W","views":"42","site_list":["http:\/\/www.ipgp.fr\/~wieczor\/SHTOOLS\/SHTOOLS.html"],"ref_list":["http:\/\/geology.cwru.edu\/~hauck\/papers\/ritzer_icarus_2009.pdf"]},
		{"ascl_id":"1110.005","title":"ZEBRA: Zurich Extragalactic Bayesian Redshift Analyzer","credit":"Feldmann, R.; Carollo, C. M.; Porciani, C.; Lilly, S. J.; Oesch, P.","abstract":"The current version of the Zurich Extragalactic Bayesian Redshift Analyzer (ZEBRA) combines and extends several of the classical approaches to produce accurate photometric redshifts down to faint magnitudes. In particular, ZEBRA uses the template-fitting approach to produce Maximum Likelihood and Bayesian redshift estimates based on: (1.) An automatic iterative technique to correct the original set of galaxy templates to best represent the SEDs of real galaxies at different redshifts; (2.) A training set of spectroscopic redshifts for a small fraction of the photometric sample; and (3.) An iterative technique for Bayesian redshift estimates, which extracts the full two-dimensional redshift and template probability function for each galaxy.","topic_id":"25546","bibcode":"2011ascl.soft10005F","views":"50","site_list":["http:\/\/www.astro.ethz.ch\/research\/Projects\/ZEBRA"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0609044","http:\/\/arxiv.org\/abs\/0801.3275"]},
		{"ascl_id":"1110.006","title":"STIFF: Converting Scientific FITS Images to TIFF","credit":"Bertin, Emmanuel","abstract":"STIFF is a program that converts scientific FITS1 images to the more popular TIFF2 format for illustration purposes. Most FITS readers and converters do not do a proper job at converting FITS image data to 8 bits. 8-bit images stored in JPEG, PNG or TIFF files have the intensities implicitely stored in a non-linear way. Most current FITS image viewers and converters provide the user an incorrect translation of the FITS image content by simply rescaling linearly input pixel values. A first consequence is that the people working on astronomical images usually have to apply narrow intensity cuts or square-root or logarithmic intensity transformations to actually see something on their deep-sky images. A less obvious consequence is that colors obtained by combining images processed this way are not consistent across such a large range of surface brightnesses. Though with other software the user is generally afforded a choice of nonlinear transformations to apply in order to make the faint stuff stand out more clearly in the images, with the limited selection of choices provides, colors will not be accurately rendered, and some manual tweaking will be necessary. The purpose of STIFF is to produce beautiful pictures in an automatic and consistent way.","topic_id":"25550","bibcode":"2011ascl.soft10006B","views":"73","site_list":["http:\/\/www.astromatic.net\/software\/stiff"],"ref_list":["http:\/\/www.eso.org\/sci\/php\/meetings\/adass2011\/html\/display.php?topic=Oral_Bertin_1313966778.html"]},
		{"ascl_id":"1110.007","title":"GammaLib: Toolbox for High-level Analysis of Astronomical Gamma-ray Data","credit":"Kn\u00f6dlseder, J.","abstract":"The GammaLib is a versatile toolbox for the high-level analysis of astronomical gamma-ray data. It is implemented as a C++ library that is fully scriptable in the Python scripting language. The library provides core functionalities such as data input and output, interfaces for parameter specifications, and a reporting and logging interface. It implements instruments specific functionalities such as instrument response functions and data formats. Instrument specific functionalities share a common interface to allow for extension of the GammaLib to include new gamma-ray instruments. The GammaLib provides an abstract data analysis framework that enables simultaneous multi-mission analysis.","topic_id":"25569","bibcode":"2011ascl.soft10007K","views":"34","site_list":["http:\/\/sourceforge.net\/projects\/gammalib\/"],"ref_list":["http:\/\/www.eso.org\/sci\/php\/meetings\/adass2011\/html\/display.php?topic=Poster_Knoedlseder_1313098999.html"]},
		{"ascl_id":"1110.008","title":"Glnemo2: Interactive Visualization 3D Program","credit":"Lambert, Jean-Charles","abstract":"Glnemo2 is an interactive 3D visualization program developed in C++ using the OpenGL library and Nokia QT 4.X API. It displays in 3D the particles positions of the different components of an nbody snapshot. It quickly gives a lot of information about the data (shape, density area, formation of structures such as spirals, bars, or peanuts). It allows for in\/out zooms, rotations, changes of scale, translations, selection of different groups of particles and plots in different blending colors. It can color particles according to their density or temperature, play with the density threshold, trace orbits, display different time steps, take automatic screenshots to make movies, select particles using the mouse, and fly over a simulation using a given camera path. All these features are accessible from a very intuitive graphic user interface. \r\n\r\nGlnemo2 supports a wide range of input file formats (Nemo, Gadget 1 and 2, phiGrape, Ramses, list of files, realtime gyrfalcON simulation) which are automatically detected at loading time without user intervention. Glnemo2 uses a plugin mechanism to load the data, so that it is easy to add a new file reader. It's powered by a 3D engine which uses the latest OpenGL technology, such as shaders (glsl), vertex buffer object, frame buffer object, and takes in account the power of the graphic card used in order to accelerate the rendering. With a fast GPU, millions of particles can be rendered in real time. Glnemo2 runs on Linux, Windows (using minGW compiler), and MaxOSX, thanks to the QT4API.","topic_id":"25563","bibcode":"2011ascl.soft10008L","views":"45","site_list":["http:\/\/projects.oamp.fr\/projects\/glnemo2"],"ref_list":["http:\/\/www.eso.org\/sci\/php\/meetings\/adass2011\/html\/display.php?topic=Focus_Lambert_1315915297.html"]},
		{"ascl_id":"1110.009","title":"AAOGlimpse: Three-dimensional Data Viewer","credit":"Shortridge, Keith","abstract":"AAOGlimpse is an experimental display program that uses OpenGL to display FITS data (and even JPEG images) as 3D surfaces that can be rotated and viewed from different angles, all in real-time. It is WCS-compliant and designed to handle three-dimensional data. Each plane in a data cube is surfaced in the same way, and the program allows the user to travel through a cube by 'peeling off' successive planes, or to look into a cube by suppressing the display of data below a given cutoff value. It can blink images and can superimpose images and contour maps from different sources using their world coordinate data. A limited socket interface allows communication with other programs.","topic_id":"25585","bibcode":"2011ascl.soft10009S","views":"97","site_list":["http:\/\/www.aao.gov.au\/local\/www\/ks\/AAOGlimpse.html"],"ref_list":["http:\/\/www.eso.org\/sci\/php\/meetings\/adass2011\/html\/display.php?topic=Oral_Shortridge_1312438034.html"]},
		{"ascl_id":"1110.010","title":"MOCASSIN: MOnte CArlo SimulationS of Ionized Nebulae","credit":"Ercolano, Barbara","abstract":"MOCASSIN is a fully 3D or 2D photoionisation and dust radiative transfer code which employs a Monte Carlo approach to the transfer of radiation through media of arbitrary geometry and density distribution. Written in Fortran, it was originally developed for the modelling of photoionised regions like HII regions and planetary nebulae and has since expanded and been applied to a variety of astrophysical problems, including modelling clumpy dusty supernova envelopes, star forming galaxies, protoplanetary disks and inner shell fluorence emission in the photospheres of stars and disk atmospheres. The code can deal with arbitrary Cartesian grids of variable resolution, it has successfully been used to model complex density fields from SPH calculations and can deal with ionising radiation extending from Lyman edge to the X-ray. The dust and gas microphysics is fully coupled both in the radiation transfer and in the thermal balance.","topic_id":"25616","bibcode":"2011ascl.soft10010E","views":"48","site_list":["http:\/\/mocassin.world-traveller.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1110.2709","http:\/\/cdsads.u-strasbg.fr\/abs\/2005MNRAS.362.1038E"]},
		{"ascl_id":"1110.011","title":"Pacerman: Polarisation Angle CorrEcting Rotation Measure ANalysis","credit":"Dolag, K.; Vogt, C.; Ensslin, T. A.","abstract":"Pacerman, written in IDL, is a new method to calculate Faraday rotation measure maps from multi-frequency polarisation angle data. In order to solve the so called n-pi-ambiguity problem which arises from the observationally ambiguity of the polarisation angle which is only determined up to additions of n times pi, where n is an integer, we suggest using a global scheme. Instead of solving the n-pi-ambiguity for each data point independently, our algorithm, which we chose to call Pacerman solves the n-pi-ambiguity for a high signal-to-noise region \"democratically'' and uses this information to assist computations in adjacent low signal-to-noise areas.","topic_id":"25625","bibcode":"2011ascl.soft10011D","views":"34","site_list":["http:\/\/www.mpa-garching.mpg.de\/~kdolag\/Pacerman\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0401214"]},
		{"ascl_id":"1110.012","title":"Starlink: Multi-purpose Astronomy Software","credit":"Various","abstract":"Starlink has many applications within it to meet a variety of needs; it includes: \r\n<ul><li>a general astronomical image viewer;<\/li><li>data reduction tools, including programs for reducing CCD-like data;<\/li><li>general-purpose data-analysis and visualisation tools;<\/li><li>image processing, data visualisation, and manipulating NDF components;<\/li><li>a flexible and powerful library for handling World Coordinate Systems (partly based on the SLALIB library);<\/li><li>a library of routines intended to make accurate and reliable positional-astronomy applications easier to write; and <\/li><li>and a Hierarchical Data System that is portable and flexible for storing and retrieving data.<\/li><\/ul>","topic_id":"25636","bibcode":"2011ascl.soft10012V","views":"305","site_list":["http:\/\/starlink.jach.hawaii.edu\/starlink\/WelcomePage"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0208448","http:\/\/adsabs.harvard.edu\/abs\/1982QJRAS..23..485D"]},
		{"ascl_id":"1110.013","title":"S2HAT: Scalable Spherical Harmonic Transform Library","credit":"Stompor, Radek","abstract":"Many problems in astronomy and astrophysics require a computation of the spherical harmonic transforms. This is in particular the case whenever data to be analyzed are distributed over the sphere or a set of corresponding mock data sets has to be generated. In many of those contexts, rapidly improving resolutions of both the data and simulations puts increasingly bigger emphasis on our ability to calculate the transforms quickly and reliably. \n\nThe scalable spherical harmonic transform library S2HAT consists of a set of flexible, massively parallel, and scalable routines for calculating diverse (scalar, spin-weighted, etc) spherical harmonic transforms for a class of isolatitude sky grids or pixelizations. The library routines implement the standard algorithm with the complexity of O(n^3\/2), where n is a number of pixels\/grid points on the sphere, however, owing to their efficient parallelization and advanced numerical implementation, they achieve very competitive performance and near perfect scalability. S2HAT is written in Fortran 90 with a C interface. This software is a derivative of the spherical harmonic transforms included in the <a href=\"http:\/\/ascl.net\/1107.018\">HEALPix package<\/a> and is based on both serial and MPI routines of its version 2.01, however, since version 2.5 this software is fully autonomous of HEALPix and can be compiled and run without the HEALPix library.","topic_id":"25565","bibcode":"2011ascl.soft10013S","views":"47","site_list":["http:\/\/www.apc.univ-paris7.fr\/APC_CS\/Recherche\/Adamis\/MIDAS09\/software\/s2hat\/s2hat.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26A...556A.109F"]},
		{"ascl_id":"1110.014","title":"pureS2HAT: S 2HAT-based Pure E\/B Harmonic Transforms","credit":"Grain, J.; Stompor, R.; Tristram, M.","abstract":"The pS2HAT routines allow efficient, parallel calculation of the so-called 'pure' polarized multipoles. The computed multipole coefficients are equal to the standard pseudo-multipoles calculated for the apodized sky maps of the Stokes parameters Q and U subsequently corrected by so-called counterterms. If the applied apodizations fullfill certain boundary conditions, these multipoles correspond to the pure multipoles. Pure multipoles of one type, i.e., either E or B, are ensured not to contain contributions from the other one, at least to within numerical artifacts. They can be therefore further used in the estimation of the sky power spectra via the pseudo power spectrum technique, which has to however correctly account for the applied apodization on the one hand, and the presence of the counterterms, on the other. \n\nIn addition, the package contains the routines permitting calculation of the spin-weighted apodizations, given an input scalar, i.e., spin-0 window. The former are needed to compute the counterterms. It also provides routines for maps and window manipulations. The routines are written in C and based on the <a href=\"http:\/\/ascl.net\/1110.013\">S2HAT library<\/a>, which is used to perform all required spherical harmonic transforms as well as all inter-processor communication. They are therefore parallelized using MPI and follow the distributed-memory computational model. The data distribution patterns, pixelization choices, conventions etc are all as those assumed\/allowed by the S2HAT library.","topic_id":"25566","bibcode":"2011ascl.soft10014G","views":"32","site_list":["http:\/\/www.apc.univ-paris7.fr\/APC_CS\/Recherche\/Adamis\/MIDAS09\/software\/pures2hat\/pureS2HAT.html"],"ref_list":["http:\/\/arxiv.org\/abs\/0903.2350"]},
		{"ascl_id":"1110.015","title":"atlant: Advanced Three Level Approximation for Numerical Treatment of Cosmological Recombination","credit":"Kholupenko, E. E.; Ivanchik, A. V.; Balashev, S. A.; Varshalovich, D. A.","abstract":"atlant is a public numerical code for fast calculations of cosmological recombination of primordial hydrogen-helium plasma is presented. This code is based on the three-level approximation (TLA) model of recombination and allows us to take into account some \"fine'' physical effects of cosmological recombination simultaneously with using fudge factors.","topic_id":"25655","bibcode":"2011ascl.soft10015K","views":"68","site_list":["http:\/\/www.ioffe.ru\/astro\/QC\/CMBR\/atlant\/atlant.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1104.3050"]},
		{"ascl_id":"1110.016","title":"REBOUND: Multi-purpose N-body code for collisional dynamics","credit":"Rein, Hanno; Liu, Shang-Fei","abstract":"REBOUND is a multi-purpose N-body code which is freely available under an open-source license. It was designed for collisional dynamics such as planetary rings but can also solve the classical N-body problem. It is highly modular and can be customized easily to work on a wide variety of different problems in astrophysics and beyond.\r\n\r\nREBOUND comes with three symplectic integrators: leap-frog, the symplectic epicycle integrator (SEI) and a Wisdom-Holman mapping (WH). It supports open, periodic and shearing-sheet boundary conditions. REBOUND can use a Barnes-Hut tree to calculate both self-gravity and collisions. These modules are fully parallelized with MPI as well as OpenMP. The former makes use of a static domain decomposition and a distributed essential tree. Two new collision detection modules based on a plane-sweep algorithm are also implemented. The performance of the plane-sweep algorithm is superior to a tree code for simulations in which one dimension is much longer than the other two and in simulations which are quasi-two dimensional with less than one million particles.","topic_id":"25664","bibcode":"2011ascl.soft10016R","views":"39","site_list":["https:\/\/github.com\/hannorein\/rebound"],"ref_list":["http:\/\/arxiv.org\/abs\/1110.4876"]},
		{"ascl_id":"1110.017","title":"POWMES: Measuring the Power Spectrum in an N-body Simulation","credit":"Colombi, Stephane; Novikov, Dmitri","abstract":"POWMES is a F90 program to measure very accurately the power spectrum in a N-body simulation, using Taylor expansion of some order on the cosine and sine transforms. It can read GADGET format and requires FFTW2 to be installed.","topic_id":"25667","bibcode":"2011ascl.soft10017C","views":"53","site_list":["http:\/\/www.projet-horizon.fr\/article345.html"],"ref_list":["http:\/\/fr.arxiv.org\/abs\/0811.0313"]},
		{"ascl_id":"1110.018","title":"MADmap: Fast Parallel Maximum Likelihood CMB Map Making Code","credit":"Cantalupo, C. M.; Borrill, J. D.; Jaffe, A. H.; Kisner, T. S.; Stompor, R.","abstract":"MADmap is a software application used to produce maximum-likelihood images of the sky from time-ordered data which include correlated noise, such as those gathered by Cosmic Microwave Background (CMB) experiments. It works efficiently on platforms ranging from small workstations to the most massively parallel supercomputers. Map-making is a critical step in the analysis of all CMB data sets, and the maximum-likelihood approach is the most accurate and widely applicable algorithm; however, it is a computationally challenging task. This challenge will only increase with the next generation of ground-based, balloon-borne and satellite CMB polarization experiments. The faintness of the B-mode signal that these experiments seek to measure requires them to gather enormous data sets. MADmap has the ability to address problems typically encountered in the analysis of realistic CMB data sets. The massively parallel and distributed implementation is detailed and scaling complexities are given for the resources required. MADmap is capable of analysing the largest data sets now being collected on computing resources currently available.","topic_id":"25689","bibcode":"2011ascl.soft10018C","views":"39","site_list":["http:\/\/crd.lbl.gov\/~cmc\/MADmap\/doc\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0906.1775"]},
		{"ascl_id":"1110.019","title":"CosmoNest: Cosmological Nested Sampling","credit":"Parkinson, David; Mukherjee, Pia; Liddle, Andrew","abstract":"CosmoNest is an algorithm for cosmological model selection. Given a model, defined by a set of parameters to be varied and their prior ranges, and data, the algorithm computes the evidence (the marginalized likelihood of the model in light of the data). The Bayes factor, which is proportional to the relative evidence of two models, can then be used for model comparison, i.e. to decide whether a model is an adequate description of data, or whether the data require a more complex model.\r\n\r\nFor convenience, CosmoNest, programmed in Fortran, is presented here as an optional add-on to <a href=\"http:\/\/ascl.net\/1106.025\">CosmoMC<\/a>, which is widely used by the cosmological community to perform parameter fitting within a model using a Markov-Chain Monte-Carlo (MCMC) engine. For this reason it can be run very easily by anyone who is able to compile and run CosmoMC. CosmoNest implements a different sampling strategy, geared for computing the evidence very accurately and efficiently. It also provides posteriors for parameter fitting as a by-product.","topic_id":"25691","bibcode":"2011ascl.soft10019P","views":"61","site_list":["http:\/\/cosmonest.org\/"],"ref_list":["http:\/\/xxx.lanl.gov\/abs\/astro-ph\/0605003"]},
		{"ascl_id":"1110.020","title":"CROSS_CMBFAST: ISW-correlation Code","credit":"Corasaniti, P. S.","abstract":"This code is an extension of CMBFAST4.5.1 to compute the ISW-correlation power spectrum and the 2-point angular ISW-correlation function for a given galaxy window function. It includes dark energy models specified by a constant equation of state (w) or a linear parameterization in the scale factor (w0,wa) and a constant sound speed (c2de). The ISW computation is limited to flat geometry. Differently from the original CMBFAST4.5 version dark energy perturbations are implemented for a general dark energy fluid specified by w(z) and c2de in synchronous gauge. For time varying dark energy models it is suggested not to cross the w=-1 line, as Dr. Wenkman says: \"never cross the streams\", bad things can happen.","topic_id":"25692","bibcode":"2011ascl.soft10020C","views":"48","site_list":["http:\/\/luth.obspm.fr\/~luthier\/corasaniti\/ISW_Code.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0504115","http:\/\/arxiv.org\/abs\/0705.4102v1"]},
		{"ascl_id":"1110.021","title":"Univiewer: Visualisation Program for HEALPix Maps","credit":"Mingaliev, Shamil M.; Ashdown, Mark; Stolyarov, Vlad","abstract":"Univiewer is a visualisation program for <a href=\"http:\/\/ascl.net\/1107.018\">HEALPix<\/a> maps. It is written in C++ and uses OpenGL and the wxWidgets library for cross-platform portability. Using it you can:\n\n<ul><li>Rotate and zoom maps on the sphere in 3D;<\/li><li>Create high-resolution views of square patches of the map;<\/li><li>Change maximum and minimum values of the colourmap interactively;<\/li><li>Calculate the power spectrum of the full-sky map or a patch;<\/li><li>Display any column of a HEALPix map FITS file on the sphere.<\/li><\/ul>Since Univiewer uses OpenGL for 3D graphics, its performance is dependent your video card. It has been tested successfully on computers with as little as 8Mb video memory, but it is recommended to have at least 32Mb to get good performance.\n\nIn the 3D view, a HEALPix map is projected onto a ECP pixelation to create a texture which is wrapped around the sphere. In calculating the power spectrum, the spherical harmonic transforms are computed using the same ECP pixelation. This inevitably leads to some discrepancies at small scales due to repixelation effects, but they are reasonably small.","topic_id":"25701","bibcode":"2011ascl.soft10021M","views":"51","site_list":["http:\/\/www.ast.cam.ac.uk\/~vlad\/univiewer\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0804.2904"]},
		{"ascl_id":"1110.022","title":"simple_cosfitter: Supernova-centric Cosmological Fitter","credit":"Conley, Alex","abstract":"This is an implementation of a fairly simple-minded luminosity distance fitter, intended for use with supernova data. The calculational technique is based on evaluating the $chi^2$ of the model fit on a grid and marginalization over various nuisance parameters. Of course, the nature of these things is that this code has gotten steadily more complex, so perhaps the simple moniker is no longer justified.","topic_id":"25702","bibcode":"2011ascl.soft10022C","views":"34","site_list":["http:\/\/qold.astro.utoronto.ca\/conley\/simple_cosfitter\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ApJS..192....1C","http:\/\/arxiv.org\/abs\/0704.1654v1"]},
		{"ascl_id":"1110.023","title":"SiFTO: An Empirical Method for Fitting SN Ia Light Curves","credit":"Conley, Alex; Sullivan, Mark","abstract":"SiFTO is an empirical method for modeling Type Ia supernova (SN Ia) light curves by manipulating a spectral template. We make use of high-redshift SN data when training the model, allowing us to extend it bluer than rest-frame U. This increases the utility of our high-redshift SN observations by allowing us to use more of the available data. We find that when the shape of the light curve is described using a stretch prescription, applying the same stretch at all wavelengths is not an adequate description. SiFTO therefore uses a generalization of stretch which applies different stretch factors as a function of both the wavelength of the observed filter and the stretch in the rest-frame B band. SiFTO has been compared to other published light-curve models by applying them to the same set of SN photometry, and it's been demonstrated that SiFTO and SALT2 perform better than the alternatives when judged by the scatter around the best-fit luminosity distance relationship. When SiFTO and SALT2 are trained on the same data set the cosmological results agree.","topic_id":"25704","bibcode":"2011ascl.soft10023C","views":"36","site_list":["http:\/\/casa.colorado.edu\/~aaconley\/Software.html"],"ref_list":["http:\/\/dx.doi.org\/10.1086\/588518"]},
		{"ascl_id":"1110.024","title":"CosmoMC SNLS: CosmoMC Plug-in to Analyze SNLS3 SN Data","credit":"Conley, Alex","abstract":"This module is a plug-in for <a href=\"http:\/\/ascl.net\/1106.025\">CosmoMC<\/a> and requires that software. Though programmed to analyze SNLS3 SN data, it can also be used for other SN data provided the inputs are put in the right form. In fact, this is probably a good idea, since the default treatment that comes with CosmoMC is flawed. Note that this requires fitting two additional SN nuisance parameters (alpha and beta), but this is significantly faster than attempting to marginalize over them internally.","topic_id":"25706","bibcode":"2011ascl.soft10024C","views":"47","site_list":["http:\/\/casa.colorado.edu\/~aaconley\/cosmomc_snls\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ApJS..192....1C","http:\/\/adsabs.harvard.edu\/abs\/2011ApJ...741...20B"]},
		{"ascl_id":"1110.025","title":"MIS: A Miriad Interferometry Singledish Toolkit","credit":"Pound, Marc; Teuben, Peter","abstract":"MIS is a pipeline toolkit using the package MIRIAD to combine Interferometric and Single Dish data. This was prompted by our observations made with the Combined Array For Research in Millimeter-wave Astronomy (CARMA) interferometer of the star-forming region NGC 1333, a large survey highlighting the new 23-element and singledish observing modes. The project consists of 20 CARMA datasets each containing interferometric as well as simultaneously obtained single dish data, for 3 molecular spectral lines and continuum, in 527 different pointings, covering an area of about 8 by 11 arcminutes. A small group of collaborators then shared this toolkit and their parameters via CVS, and scripts were developed to ensure uniform data reduction across the group. The pipeline was run end-to-end each night that new observations were obtained, producing maps that contained all the data to date. This approach could serve as a model for repeated calibration and mapping of large mixed-mode correlation datasets from ALMA.","topic_id":"25731","bibcode":"2011ascl.soft10025P","views":"39","site_list":["http:\/\/carma.astro.umd.edu\/wiki\/index.php\/Scripts"],"ref_list":["http:\/\/www.eso.org\/sci\/php\/meetings\/adass2011\/html\/display.php?topic=Poster_Pound_1316105060.html"]},
		{"ascl_id":"1111.001","title":"HIPE: Herschel Interactive Processing Environment","credit":"Herschel Science Ground Segment Consortium","abstract":"The Herschel Space Observatory is the fourth cornerstone mission in the ESA science programme and performs photometry and spectroscopy in the 55 - 672 micron range. The development of the Herschel Data Processing System started in 2002 to support the data analysis for Instrument Level Tests. The Herschel Data Processing System was used for the pre-flight characterisation of the instruments, and during various ground segment test campaigns. Following the successful launch of Herschel 14th of May 2009 the Herschel Data Processing System demonstrated its maturity when the first PACS preview observation of M51 was processed within 30 minutes of reception of the first science data after launch. Also the first HIFI observations on DR21 were successfully reduced to high quality spectra, followed by SPIRE observations on M66 and M74. A fast turn-around cycle between data retrieval and the production of science-ready products was demonstrated during the Herschel Science Demonstration Phase Initial Results Workshop held 7 months after launch, which is a clear proof that the system has reached a good level of maturity.","topic_id":"25801","bibcode":"2011ascl.soft11001H","views":"69","site_list":["http:\/\/herschel.esac.esa.int\/HIPE_download.shtml"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010ASPC..434..139O"]},
		{"ascl_id":"1111.002","title":"CRBLASTER: A Parallel-Processing Computational Framework for Embarrassingly-Parallel Image-Analysis Algorithms","credit":"Mighell, Kenneth John","abstract":"The development of parallel-processing image-analysis codes is generally a challenging task that requires complicated choreography of interprocessor communications. If, however, the image-analysis algorithm is embarrassingly parallel, then the development of a parallel-processing implementation of that algorithm can be a much easier task to accomplish because, by definition, there is little need for communication between the compute processes. I describe the design, implementation, and performance of a parallel-processing image-analysis application, called CRBLASTER, which does cosmic-ray rejection of CCD (charge-coupled device) images using the embarrassingly-parallel L.A.COSMIC algorithm. CRBLASTER is written in C using the high-performance computing industry standard Message Passing Interface (MPI) library. The code has been designed to be used by research scientists who are familiar with C as a parallel-processing computational framework that enables the easy development of parallel-processing image-analysis programs based on embarrassingly-parallel algorithms. The CRBLASTER source code is freely available at the official application website at the National Optical Astronomy Observatory. Removing cosmic rays from a single 800x800 pixel Hubble Space Telescope WFPC2 image takes 44 seconds with the IRAF script lacos_im.cl running on a single core of an Apple Mac Pro computer with two 2.8-GHz quad-core Intel Xeon processors. CRBLASTER is 7.4 times faster processing the same image on a single core on the same machine. Processing the same image with CRBLASTER simultaneously on all 8 cores of the same machine takes 0.875 seconds -- which is a speedup factor of 50.3 times faster than the IRAF script. A detailed analysis is presented of the performance of CRBLASTER using between 1 and 57 processors on a low-power Tilera 700-MHz 64-core TILE64 processor.","topic_id":"25802","bibcode":"2011ascl.soft11002M","views":"44","site_list":["http:\/\/www.noao.edu\/noao\/staff\/mighell\/crblaster\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1008.2192"]},
		{"ascl_id":"1111.003","title":"Saada: A Generator of Astronomical Database","credit":"Michel, L.","abstract":"Saada transforms a set of heterogeneous FITS files or VOtables of various categories (images, tables, spectra, etc.) in a powerful database deployed on the Web. Databases are located on your host and stay independent of any external server. This job doesn\u2019t require writing code. Saada can mix data of various categories in multiple collections. Data collections can be linked each to others making relevant browsing paths and allowing data-mining oriented queries. Saada supports 4 VO services (Spectra, images, sources and TAP) . Data collections can be published immediately after the deployment of the Web interface.","topic_id":"25808","bibcode":"2011ascl.soft11003M","views":"37","site_list":["http:\/\/amwdb.u-strasbg.fr\/saada\/spip.php?article32"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005sf2a.conf...71N"]},
		{"ascl_id":"1111.004","title":"CIGALE: Code Investigating GALaxy Emission","credit":"Noll, Stefan; Burgarella, Denis; Giovannoli, \u00c9lodie; Serra, Paolo","abstract":"The CIGALE code has been developed to study the evolution of galaxies by comparing modelled galaxy spectral energy distributions (SEDs) to observed ones from the far ultraviolet to the far infrared. It extends the SED fitting algorithm written by Burgarella et al. (2005, MNRAS 360, 1411). While the previous code was designed to fit SEDs in the optical and near infrared, CIGALE is able to fit SEDs up to the far infrared using Dale & Helou (2002, ApJ 576, 159). CIGALE Bayesian and CIGALE Monte Carlo Markov Chain are available.","topic_id":"25810","bibcode":"2011ascl.soft11004N","views":"52","site_list":["http:\/\/cigale.oamp.fr\/"],"ref_list":["http:\/\/cdsads.u-strasbg.fr\/abs\/2009A%26A...507.1793N"]},
		{"ascl_id":"1111.005","title":"SPECTCOL: Spectroscopic and Collisional Data Retrieval","credit":"Dubernet, Marie-Lise; Nenadovic, Ljerka","abstract":"Studies of astrophysical non-LTE media require the combination of atomic and molecular spectroscopic and collisional data often described differently in various databases. SPECTCOL is a tool that implements <a href=\"http:\/\/www.vamdc.org\">VAMDC<\/a> standards, retrieve relevant information from different databases such as CDMS, HITRAN, BASECOL, and can upload local files. All transfer of data between the client and the databases use the <a href=\"http:\/\/www.vamdc.eu\/documents\/standards\/\">VAMDC-XSAMS schema<\/a>. The spectroscopic and collisional information is combined and useful outputs (ascii or xsams) are provided for the study of the interstellar medium.","topic_id":"25809","bibcode":"2011ascl.soft11005D","views":"34","site_list":["http:\/\/www.vamdc.org\/software"],"ref_list":["http:\/\/www.eso.org\/sci\/php\/meetings\/adass2011\/html\/display.php?topic=Poster_Dubernet_1316018361.html"]},
		{"ascl_id":"1111.006","title":"MOPEX: MOsaicker and Point source EXtractor","credit":"NASA\/IPAC Infrared Science Archive; JPL; Caltech; NASA","abstract":"MOPEX (MOsaicker and Point source EXtractor) is a package for reducing and analyzing imaging data, as well as MIPS SED data. MOPEX includes the point source extraction package, APEX.\r\nMOPEX is designed to allow the user to:\r\n\r\n<ul><li>perform sophisticated background matching of individual data frames<\/li><li>mosaic the individual frames downloaded from the Spitzer archive<\/li><li>perform both temporal and spatial outlier rejection during mosaicking<\/li><li>apply offline pointing refinement for MIPS data (refinement is already applied to IRAC data)<\/li><li>perform source detection on the mosaics using APEX<\/li><li>compute aperture photometry or PRF-fitting photometry for point sources<\/li><li>perform interpolation, coaddition, and spectrum extraction of MIPS SED images.<\/li><\/ul>MOPEX comes in two different interfaces (GUI and command-line), both of which come packaged together. We recommend that all new users start with the GUI, which is more user-friendly than the command-line interface","topic_id":"25835","bibcode":"2011ascl.soft11006N","views":"41","site_list":["http:\/\/irsa.ipac.caltech.edu\/data\/SPITZER\/docs\/dataanalysistools\/tools\/mopex\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005PASP..117.1113M"]},
		{"ascl_id":"1111.007","title":"CUBISM: CUbe Builder for IRS Spectra Maps","credit":"Sings Irs Team; Smith, J. D.; Armus, Lee; Bot, Caroline; Buckalew, Brent; Dale, Danny; Helou, George; Jarrett, Tom; Roussel, Helene; Sheth, Kartik","abstract":"CUBISM, written in IDL, is a tool for constructing spectral cubes, maps, and arbitrary aperture 1D spectral extractions from sets of mapping mode spectra taken with Spitzer's IRS spectrograph. CUBISM is optimized for non-sparse maps of extended objects, e.g. the nearby galaxy sample of SINGS, but can be used with data from any spectral mapping AOR (primarily validated for maps which are designed as suggested by the mapping HOWTO).","topic_id":"25836","bibcode":"2011ascl.soft11007S","views":"43","site_list":["http:\/\/irsa.ipac.caltech.edu\/data\/SPITZER\/docs\/dataanalysistools\/tools\/cubism\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007PASP..119.1133S"]},
		{"ascl_id":"1111.008","title":"SITools2: A Framework for Archival Systems","credit":"Malapert, Jean-Christophe; Marseille, Matthieu","abstract":"SITools2 is a new CNES generic tool performed by a joint effort between CNES and scientific laboratories. SITools provides a self-manageable data access layer deployed on already existing scientific laboratory databases. This new version of SITools is a JAVA-based framework, under open source license, that provides a portable archive system, highly configurable, easy to use by laboratories, with a plugin mechanism so developers can add their own applications.","topic_id":"25843","bibcode":"2011ascl.soft11008M","views":"37","site_list":["http:\/\/sourceforge.net\/projects\/sitools2\/"],"ref_list":["http:\/\/www.eso.org\/sci\/php\/meetings\/adass2011\/html\/display.php?topic=Oral_Malapert_1312286267.html"]},
		{"ascl_id":"1111.009","title":"MESS: Multi-purpose Exoplanet Simulation System","credit":"Bonavita, M.; Chauvin, G.; Desidera, S.; Gratton, R.; Janson, M.; Beuzit, J. L.; Kasper, M.; Mordasini, C.","abstract":"MESS is a Monte Carlo simulation IDL code which uses either the results of the statistical analysis of the properties of discovered planets, or the results of the planet formation theories, to build synthetic planet populations fully described in terms of frequency, orbital elements and physical properties. They can then be used to either test the consistency of their properties with the observed population of planets given different detection techniques or to actually predict the expected number of planets for future surveys. It can be used to probe the physical and orbital properties of a putative companion within the circumstellar disk of a given star and to test constrain the orbital distribution properties of a potential planet population around the members of the TW Hydrae association. Finally, using in its predictive mode, the synergy of future space and ground-based telescopes instrumentation has been investigated to identify the mass-period parameter space that will be probed in future surveys for giant and rocky planets.","topic_id":"25937","bibcode":"2011ascl.soft11009B","views":"37","site_list":["http:\/\/messthecode.com\/welcome-to-the-mess-2\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1110.4917"]},
		{"ascl_id":"1111.010","title":"Starbase Data Tables: An ASCII Relational Database for Unix","credit":"Roll, John","abstract":"Database management is an increasingly important part of astronomical data analysis. Astronomers need easy and convenient ways of storing, editing, filtering, and retrieving data about data. Commercial databases do not provide good solutions for many of the everyday and informal types of database access astronomers need. The Starbase database system with simple data file formatting rules and command line data operators has been created to answer this need. The system includes a complete set of relational and set operators, fast search\/index and sorting operators, and many formatting and I\/O operators. Special features are included to enhance the usefulness of the database when manipulating astronomical data. The software runs under UNIX, MSDOS and IRAF.","topic_id":"25971","bibcode":"2011ascl.soft11010R","views":"36","site_list":["https:\/\/www.cfa.harvard.edu\/~john\/starbase\/starbase.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1996ASPC..101..536R"]},
		{"ascl_id":"1111.011","title":"3DEX: Fast Fourier-Bessel Decomposition of Spherical 3D Surveys","credit":"Leistedt, B.; Rassat, A.; Refregier, A.; Starck, J.-L.","abstract":"High precision cosmology requires analysis of large scale surveys in 3D spherical coordinates, i.e. Fourier-Bessel decomposition. Current methods are insufficient for future data-sets from wide-field cosmology surveys. 3DEX (3D EXpansions) is a public code for fast Fourier-Bessel decomposition of 3D all-sky surveys which takes advantage of HEALPix for the calculation of tangential modes. For surveys with millions of galaxies, computation time is reduced by a factor 4-12 depending on the desired scales and accuracy. The formulation is also suitable for pre-calculations and external storage of the spherical harmonics, which allows for further speed improvements. The 3DEX code can accommodate data with masked regions of missing data.  It can be applied not only to cosmological data, but also to 3D data in spherical coordinates in other scientific fields.","topic_id":"25975","bibcode":"2011ascl.soft11011L","views":"100","site_list":["https:\/\/github.com\/ixkael\/3DEX"],"ref_list":["http:\/\/arxiv.org\/abs\/1111.3591"]},
		{"ascl_id":"1111.012","title":"VAPOR: Visualization and Analysis Platform for Ocean, Atmosphere, and Solar Researchers","credit":"Computational Information Systems Laboratory At The National Center For Atmospheric Research","abstract":"VAPOR is the Visualization and Analysis Platform for Ocean, Atmosphere, and Solar Researchers. VAPOR provides an interactive 3D visualization environment that runs on most UNIX and Windows systems equipped with modern 3D graphics cards. VAPOR provides:\r\n\r\n<ul><li>A visual data discovery environment tailored towards the specialized needs of the astro and geosciences CFD community<\/li><li>A desktop solution capable of handling terascale size data sets<\/li><li>Advanced interactive 3D visualization tightly coupled with quantitative data analysis<\/li><li>Support for multi-variate, time-varying data<\/li><li>Close coupling with RSI's powerful interpretive data language, IDL<\/li><li>Support for 3D visualization of WRF-ARW datasets<\/li><\/ul>","topic_id":"25986","bibcode":"2011ascl.soft11012C","views":"49","site_list":["http:\/\/www.vapor.ucar.edu\/"],"ref_list":["http:\/\/iopscience.iop.org\/1367-2630\/9\/8\/301"]},
		{"ascl_id":"1111.013","title":"FIBRE-pac: FMOS Image-based Reduction Package","credit":"Iwamuro, F.; Moritani, Y.; Yabe, K.; Sumiyoshi, M.; Kawate, K.; Tamura, N.; Akiyama, M.; Kimura, M.; Takato, N.; Tait, P.; Ohta, K.; Totani, T.; Suzuki, Y.; Tonegawa, M.","abstract":"The FIBRE-pac (FMOS image-based reduction package) is an IRAF-based reduction tool for the fiber multiple-object spectrograph (FMOS) of the Subaru telescope. To reduce FMOS images, a number of special techniques are necessary because each image contains about 200 separate spectra with airglow emission lines variable in spatial and time domains, and with complicated throughput patterns for the airglow masks. In spite of these features, almost all of the reduction processes except for a few steps are carried out automatically by scripts in text format making it easy to check the commands step by step. Wavelength- and flux-calibrated images together with their noise maps are obtained using this reduction package.","topic_id":"26033","bibcode":"2011ascl.soft11013I","views":"37","site_list":["http:\/\/www.naoj.org\/Observing\/Instruments\/FMOS\/information.html#dr"],"ref_list":["http:\/\/arxiv.org\/abs\/1111.6746"]},
		{"ascl_id":"1111.014","title":"FITSH: Software Package for Image Processing","credit":"P\u00e1l, Andr\u00e1s","abstract":"FITSH provides a standalone environment for analysis of data acquired by imaging astronomical detectors. The package provides utilities both for the full pipeline of subsequent related data processing steps (including image calibration, astrometry, source identification, photometry, differential analysis, low-level arithmetic operations, multiple image combinations, spatial transformations and interpolations, etc.) and for aiding the interpretation of the (mainly photometric and\/or astrometric) results. The package also features a consistent implementation of photometry based on image subtraction, point spread function fitting and aperture photometry and provides easy-to-use interfaces for comparisons and for picking the most suitable method for a particular problem. The utilities in the package are built on the top of the commonly used UNIX\/POSIX shells (hence the name of the package), therefore both frequently used and well-documented tools for such environments can be exploited and managing massive amount of data is rather convenient.","topic_id":"26029","bibcode":"2011ascl.soft11014P","views":"59","site_list":["http:\/\/fitsh.szofi.net\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1111.1998"]},
		{"ascl_id":"1111.015","title":"TIPSY: Code for Display and Analysis of N-body Simulations","credit":"N-Body Shop","abstract":"The development of TIPSY was motivated by the need to quickly display and analyze the results of N-body simulations. Most data visualization packages are designed for the display of gridded data, and hence are unsuitable for use with particle data. Therefore, a special package was built that could easily perform the following functions:\n<ul><li>Display particle positions (as points), and velocities (as line segments) from an arbitrary viewpoint.<\/li><li>Zoom in to a chosen position. Due to their extremely clustered nature, structure of interest in an N-body simulation is often so small that it can not be seen when looking at the simulation as a whole.<\/li><li>Color particles to display scalar fields. Examples of such fields are potential energy, or for SPH particles, density and temperature.<\/li><li>Selection of a subset of the particles for display and analysis. Regions of interest are generally small subsets of the simulation.<\/li><li>Following selected particles from one timestep to another.<\/li><li>Finding cumulative properties of a collection of particles. This usually involves just a sum over the particles. <\/li><\/ul>The basic data structure is an array of particle structures. Since TIPSY was built for use with cosmological N-body simulations, there are actually three separate arrays for each of the types of particle used in such simulations: collisionless particles, SPH particles, and star particles. A single timestep is read into these arrays from a disk file. Display is done by finding the x and y coordinates of the particles in the rotated coordinate system, and storing them in arrays. Screen coordinates are calculated from these arrays according to the current zoom factor. Also, a software Z-buffer is maintained to save time if many particles project to the same screen pixel. There are several types of display. An \"all plot\" displays all particles colored according to their type. A \"radial plot\" will color particles according to the projection of the velocity along the line-of-sight. A \"gas plot\" will color gas according to SPH quantities such as density, temperature, neutral hydrogen fraction, etc. Subsets of particles are maintained using boxes.\" A box structure contains a bounding box, and an array of pointers to particles within the box. All display and analysis functions are performed on the \"active box.\" By default all particles are loaded into box 0, which becomes the active box. If a new timestep is read from disk, all boxes are destroyed. A selection of particles can be followed between timesteps via a \"mark\" array. Marked particles are displayed in a different color, and the analysis functions can be told to only operate on the marked particles.","topic_id":"26030","bibcode":"2011ascl.soft11015N","views":"51","site_list":["http:\/\/www-hpcc.astro.washington.edu\/tools\/tipsy\/tipsy.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001ApJ...562..605F"]},
		{"ascl_id":"1112.001","title":"Eclipse: ESO C Library for an Image Processing Software Environment","credit":"Devillard, Nicolas","abstract":"Written in ANSI C, eclipse is a library offering numerous services related to astronomical image processing: FITS data access, various image and cube loading methods, binary image handling and filtering (including convolution and morphological filters), 2-D cross-correlation, connected components, cube and image arithmetic, dead pixel detection and correction, object detection, data extraction, flat-fielding with robust fit, image generation, statistics, photometry, image-space resampling, image combination, and cube stacking. It also contains support for mathematical tools like random number generation, FFT, curve fitting, matrices, fast median computation, and point-pattern matching. The main feature of this library is its ability to handle large amounts of input data (up to 2GB in the current version) regardless of the amount of memory and swap available on the local machine. Another feature is the very high speed allowed by optimized C, making it an ideal base tool for programming efficient number-crunching applications, e.g., on parallel (Beowulf) systems.","topic_id":"26064","bibcode":"2011ascl.soft12001D","views":"39","site_list":["http:\/\/www.eso.org\/sci\/software\/eclipse\/"],"ref_list":["http:\/\/www.adass.org\/adass\/proceedings\/adass00\/P3-07\/"]},
		{"ascl_id":"1112.002","title":"Funtools: FITS Users Need Tools","credit":"Mandel, Eric; Murray, Stephen S.; Roll, John","abstract":"Funtools is a \"minimal buy-in\" FITS library and utility package developed at the the High Energy Astrophysics Division of SAO. The Funtools library provides simplified access to a wide array of file types: standard astronomical FITS images and binary tables, raw arrays and binary event lists, and even tables of ASCII column data. A sophisticated region filtering library (compatible with ds9) filters images and tables using boolean operations between geometric shapes, support world coordinates, etc. Funtools also supports advanced capabilities such as optimized data searching using index files.\r\n\r\nBecause Funtools consists of a library and a set of user programs, it is most appropriately built from source. Funtools has been ported to Solaris, Linux, LinuxPPC, SGI, Alpha OSF1, Mac OSX (darwin) and Windows 98\/NT\/2000\/XP. Once the source code tar file is retrieved, Funtools can be built and installed easily using standard commands.","topic_id":"26065","bibcode":"2011ascl.soft12002M","views":"71","site_list":["https:\/\/www.cfa.harvard.edu\/~john\/funtools\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001ASPC..238..225M"]},
		{"ascl_id":"1112.003","title":"THERMINATOR 2: THERMal heavy IoN generATOR 2","credit":"Chojnacki, Mikolaj; Kisiel, Adam; Florkowski, Wojciech; Broniowski, Wojciech","abstract":"THERMINATOR is a Monte Carlo event generator dedicated to studies of the statistical production of particles in relativistic heavy-ion collisions. The increased functionality of the code contains the following features: The input of any shape of the freeze-out hypersurface and the expansion velocity field, including the 3+1 dimensional profiles, in particular those generated externally with various hydrodynamic codes. The hypersufraces may have variable thermal parameters, which allows for studies departing significantly from the mid-rapidity region, where the baryon chemical potential becomes large. We include a library of standard sets of hypersurfaces and velocity profiles describing the RHIC Au+Au data at sqrt(s_(NN)) = 200 GeV for various centralities, as well as those anticipated for the LHC Pb+Pb collisions at sqrt(s_(NN)) = 5.5 TeV. A separate code, FEMTO-THERMINATOR, is provided to carry out the analysis of femtoscopic correlations which are an important source of information concerning the size and expansion of the system. We also include several useful scripts that carry out auxiliary tasks, such as obtaining an estimate of the number of elastic collisions after the freeze-out, counting of particles flowing back into the fireball and violating causality (typically very few), or visualizing various results: the particle p_T-spectra, the elliptic flow coefficients, and the HBT correlation radii. We also investigate the problem of the back-flow of particles into the hydrodynamic region, as well as estimate the elastic rescattering in terms of trajectory crossings. The package is written in C++ and uses the CERN ROOT environment.","topic_id":"26066","bibcode":"2011ascl.soft12003C","views":"34","site_list":["http:\/\/therminator2.ifj.edu.pl\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1102.0273"]},
		{"ascl_id":"1112.004","title":"PHOX: X-ray Photon Simulator","credit":"Biffi, Veronica; Dolag, Klaus; Boehringer, Hans; Lemson, Gerard","abstract":"PHOX is a novel, virtual X-ray observatory designed to obtain synthetic observations from hydro-numerical simulations. The code is a photon simulator and can be apply to simulate galaxy clusters. In fact, X-ray observations of clusters of galaxies continue to provide us with an increasingly detailed picture of their structure and of the underlying physical phenomena governing the gaseous component, which dominates their baryonic content. Therefore, it is fundamental to find the most direct and faithful way to compare such observational data with hydrodynamical simulations of cluster-like objects, which can currently include various complex physical processes. Here, we present and analyse synthetic Suzaku observations of two cluster-size haloes obtained by processing with PHOX the hydrodynamical simulation of the large-scale, filament-like region in which they reside. Taking advantage of the simulated data, we test the results inferred from the X-ray analysis of the mock observations against the underlying, known solution. Remarkably, we are able to recover the theoretical temperature distribution of the two haloes by means of the multi-temperature fitting of the synthetic spectra. Moreover, the shapes of the reconstructed distributions allow us to trace the different thermal structure that distinguishes the dynamical state of the two haloes.","topic_id":"26098","bibcode":"2011ascl.soft12004B","views":"58","site_list":["http:\/\/www.mpa-garching.mpg.de\/~kdolag\/Phox\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1112.0314"]},
		{"ascl_id":"1112.005","title":"GIDGET: Gravitational Instability-Dominated Galaxy Evolution Tool","credit":"Forbes, John; Krumholz, Mark R.; Burkert, Andreas","abstract":"Observations of disk galaxies at z~2 have demonstrated that turbulence driven by gravitational instability can dominate the energetics of the disk. GIDGET is a 1D simulation code, which we have made publicly available, that economically evolves these galaxies from z~2 to z~0 on a single CPU in a matter of minutes, tracking column density, metallicity, and velocity dispersions of gaseous and multiple stellar components. We include an H$_2$ regulated star formation law and the effects of stellar heating by transient spiral structure. We use this code to demonstrate a possible explanation for the existence of a thin and thick disk stellar population and the age-velocity dispersion correlation of stars in the solar neighborhood: the high velocity dispersion of gas in disks at z~2 decreases along with the cosmological accretion rate, while at lower redshift, the dynamically colder gas forms the low velocity dispersion stars of the thin disk.","topic_id":"26119","bibcode":"2011ascl.soft12005F","views":"36","site_list":["http:\/\/www.ucolick.org\/~jforbes\/gidget.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1112.1410"]},
		{"ascl_id":"1112.006","title":"PhAst: Display and Analysis of FITS Images","credit":"Rehnberg, Morgan; Crawford, R.; Trueblood, M.; Mighell, K.","abstract":"PhAst (Photometry-Astrometry) is an IDL astronomical image viewer based on the existing application ATV which displays and analyzes FITS images. It can calibrate raw images, provide astrometric solutions, and do circular aperture photometry. PhAst allows the user to load, process, and blink any number of images. Analysis packages include image calibration, photometry, and astrometry (provided through an interface with <a href=\"http:\/\/ascl.net\/1010.064\">SExtractor<\/a>, SCAMP, and missFITS). PhAst has been designed to generate reports for Minor Planet Center reporting.","topic_id":"26144","bibcode":"2011ascl.soft12006R","views":"35","site_list":["http:\/\/www.noao.edu\/staff\/mighell\/phast\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012AAS...21914502R"]},
		{"ascl_id":"1112.007","title":"FLAGCAL: FLAGging and CALlibration Pipeline for GMRT Data","credit":"Prasad, Jayanti; Chengalur, Jayaram","abstract":"FLAGging and CALlibration (FLAGCAL) is a software pipeline developed for automatic flagging and calibration of the GMRT data. This pipeline can be used for preprocessing (before importing the data in AIPS) any other interferromteric data also (given that the data file is in FITS format and contains multiple channels & scans).There are also a few GUI based tools which can be used for quick visualization of the data.","topic_id":"26148","bibcode":"2011ascl.soft12007P","views":"40","site_list":["http:\/\/www.iucaa.ernet.in\/~jayanti\/flagcal.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1111.6415"]},
		{"ascl_id":"1112.008","title":"GGobi: A data visualization system","credit":"Swayne, Deborah F.; Buja, Andreas; Temple Lang, Duncan; Cook, Di","abstract":"GGobi is an open source visualization program for exploring high-dimensional data. It provides highly dynamic and interactive graphics such as tours, as well as familiar graphics such as the scatterplot, barchart and parallel coordinates plots. Plots are interactive and linked with brushing and identification.","topic_id":"26151","bibcode":"2011ascl.soft12008S","views":"36","site_list":["http:\/\/www.ggobi.org\/"],"ref_list":["http:\/\/www.ci.tuwien.ac.at\/Conferences\/DSC-2003\/Proceedings\/SwayneEtAl.pdf","http:\/\/arxiv.org\/abs\/1108.6221v1"]},
		{"ascl_id":"1112.009","title":"LISACode: A scientific simulator of LISA","credit":"Petiteau, Antoine","abstract":"LISACode is a simulator of the LISA mission. Its ambition is to achieve a new degree of sophistication allowing to map, as closely as possible, the impact of the different subsystems on the measurements.  Its also a useful tool for generating realistic data including several kind of sources (Massive Black Hole binaries, EMRIs, cosmic string cusp, stochastic background, etc) and for preparing their analysis. It\u2019s fully integrated to the Mock LISA Data Challenge.  LISACode is not a detailed simulator at the engineering level but rather a tool whose purpose is to bridge the gap between the basic principles of LISA and a future, sophisticated end-to-end simulator.","topic_id":"26152","bibcode":"2011ascl.soft12009P","views":"43","site_list":["http:\/\/www.apc.univ-paris7.fr\/~petiteau\/LISACode\/Home.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008PhRvD..77b3002P"]},
		{"ascl_id":"1112.010","title":"MRS3D: 3D Spherical Wavelet Transform on the Sphere","credit":"Lanusse, F.; Rassat, A.; Starck, J.-L.","abstract":"Future cosmological surveys will provide 3D large scale structure maps with large sky coverage, for which a 3D Spherical Fourier-Bessel (SFB) analysis is natural. Wavelets are particularly well-suited to the analysis and denoising of cosmological data, but a spherical 3D isotropic wavelet transform does not currently exist to analyse spherical 3D data. We present a new fast Discrete Spherical Fourier-Bessel Transform (DSFBT) based on both a discrete Bessel Transform and the HEALPIX angular pixelisation scheme. We tested the 3D wavelet transform and as a toy-application, applied a denoising algorithm in wavelet space to the Virgo large box cosmological simulations and found we can successfully remove noise without much loss to the large scale structure. The new spherical 3D isotropic wavelet transform, called MRS3D, is ideally suited to analysing and denoising future 3D spherical cosmological surveys; it uses a novel discrete spherical Fourier-Bessel Transform. MRS3D is based on two packages, IDL and Healpix and can be used only if these two packages have been installed.","topic_id":"26192","bibcode":"2011ascl.soft12010L","views":"43","site_list":["http:\/\/jstarck.free.fr\/mrs3d.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1112.0561"]},
		{"ascl_id":"1112.011","title":"CMBview: A Mac OS X program for viewing HEALPix-format sky map data on a sphere","credit":"Portsmouth, Jamie","abstract":"CMBview is a viewer for FITS files containing HEALPix sky maps. Sky maps are projected onto a 3d sphere which can be rotated and zoomed interactively with the mouse. Features include: \r\n\r\n    <ul><li>rendering of the field of Stokes vectors\r\n    <\/li><li>ray-tracing mode in which each screen pixel is projected onto the sphere for high quality rendering\r\n    <\/li><li>control over sphere lighting\r\n    <\/li><li>export an arbitrarily large rendered texture\r\n    <\/li><li>variety of preset colormaps <\/li><\/ul>","topic_id":"26209","bibcode":"2011ascl.soft12011P","views":"48","site_list":["http:\/\/code.google.com\/p\/cmbview\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0711.3793v3","http:\/\/arxiv.org\/abs\/0711.1540"]},
		{"ascl_id":"1112.012","title":"CORA: Emission Line Fitting with Maximum Likelihood","credit":"Ness, Jan-Uwe; Wichmann, Rainer","abstract":"The advent of pipeline-processed data both from space- and ground-based observatories often disposes of the need of full-fledged data reduction software with its associated steep learning curve. In many cases, a simple tool doing just one task, and doing it right, is all one wishes. In this spirit we introduce CORA, a line fitting tool based on the maximum likelihood technique, which has been developed for the analysis of emission line spectra with low count numbers and has successfully been used in several publications. CORA uses a rigorous application of Poisson statistics. From the assumption of Poissonian noise we derive the probability for a model of the emission line spectrum to represent the measured spectrum. The likelihood function is used as a criterion for optimizing the parameters of the theoretical spectrum and a fixed point equation is derived allowing an efficient way to obtain line fluxes. As an example we demonstrate the functionality of the program with an X-ray spectrum of Capella obtained with the Low Energy Transmission Grating Spectrometer (LETGS) on board the Chandra observatory and choose the analysis of the Ne IX triplet around 13.5 \u00c5.","topic_id":"26206","bibcode":"2011ascl.soft12012N","views":"42","site_list":["http:\/\/www.hs.uni-hamburg.de\/DE\/Ins\/Per\/Ness\/Cora\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002AN....323..129N"]},
		{"ascl_id":"1112.013","title":"XEphem: Interactive Astronomical Ephemeris","credit":"Downey, Elwood Charles","abstract":"XEphem is a scientific-grade interactive astronomical ephemeris package for UNIX-like systems. Written in C, X11 and Motif, it is easily ported to systems. Among other things, XEphem:\r\n\r\n<ul><li> computes heliocentric, geocentric and topocentric information for all objects;<\/li><li> has built-in support for all planets; the moons of Mars, Jupiter, Saturn, Uranus and Earth; central meridian longitude of Mars and Jupiter; Saturn's rings; and Jupiter's Great Red Spot;<\/li><li> allows user-defined objects including stars, deepsky objects, asteroids, comets and Earth satellites;<\/li><li> provides special efficient handling of large catalogs including Tycho, Hipparcos, GSC;<\/li><li> displays data in configurable tabular formats in conjunction with several interactive graphical views;<\/li><li> displays a night-at-a-glance 24 hour graphic showing when any selected objects are up;<\/li><li> displays 3-D stereo Solar System views that are particularly well suited for visualizing comet trajectories;<\/li><li> quickly finds all close pairs of objects in the sky; and<\/li><li> sorts and prints all catalogs with very flexible criteria for creating custom observing lists.<\/li><\/ul>\r\nIts capabilities are listed more fully in the <a href=\"http:\/\/www.clearskyinstitute.com\/xephem\/help\/xephem.html#mozTocId374556\">user manual introduction<\/a>.","topic_id":"26324","bibcode":"2011ascl.soft12013D","views":"61","site_list":["http:\/\/www.clearskyinstitute.com\/xephem\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0211093v3"]},
		{"ascl_id":"1112.014","title":"PyEphem: Astronomical Ephemeris for Python","credit":"Rhodes, Brandon Craig","abstract":"PyEphem provides scientific-grade astronomical computations for the Python programming language. Given a date and location on the Earth\u2019s surface, it can compute the positions of the Sun and Moon, of the planets and their moons, and of any asteroids, comets, or earth satellites whose orbital elements the user can provide. Additional functions are provided to compute the angular separation between two objects in the sky, to determine the constellation in which an object lies, and to find the times at which an object rises, transits, and sets on a particular day.\n\nThe numerical routines that lie behind PyEphem are those from the wonderful <a href=\"http:\/\/ascl.net\/1112.013\">XEphem astronomy application<\/a>, whose author, Elwood Downey, generously gave permission for us to use them as the basis for PyEphem.","topic_id":"26325","bibcode":"2011ascl.soft12014R","views":"53","site_list":["http:\/\/rhodesmill.org\/pyephem\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1110.5370v1"]},
		{"ascl_id":"1112.015","title":"Dexter: Data Extractor for scanned graphs","credit":"Demleitner, Markus","abstract":"The NASA Astrophysics Data System (ADS) now holds 1.3 million scanned pages, containing numerous plots and figures for which the original data sets are lost or inaccessible. The availability of scans of the figures can significantly ease the regeneration of the data sets. For this purpose, the ADS has developed Dexter, a Java applet that supports the user in this process. Dexter's basic functionality is to let the user manually digitize a plot by marking points and defining the coordinate transformation from the logical to the physical coordinate system. Advanced features include automatic identification of axes, tracing lines and finding points matching a template.","topic_id":"26207","bibcode":"2011ascl.soft12015D","views":"49","site_list":["http:\/\/dexter.sourceforge.net\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001ASPC..238..321D"]},
		{"ascl_id":"1112.016","title":"PREDICT: Satellite tracking and orbital prediction","credit":"Magliacane, John A.","abstract":"PREDICT is an open-source, multi-user satellite tracking and orbital prediction program written under the Linux operating system. PREDICT provides real-time satellite tracking and orbital prediction information to users and client applications through:\r\n\r\n<ul><li> the system console<\/li><li> the command line<\/li><li> a network socket<\/li><li> the generation of audio speech<\/li><\/ul>Data such as a spacecraft's sub-satellite point, azimuth and elevation headings, Doppler shift, path loss, slant range, orbital altitude, orbital velocity, footprint diameter, orbital phase (mean anomaly), squint angle, eclipse depth, the time and date of the next AOS (or LOS of the current pass), orbit number, and sunlight and visibility information are provided on a real-time basis. PREDICT can also track (or predict the position of) the Sun and Moon. PREDICT has the ability to control AZ\/EL antenna rotators to maintain accurate orientation in the direction of communication satellites. As an aid in locating and tracking satellites through optical means, PREDICT can articulate tracking coordinates and visibility information as plain speech.","topic_id":"26208","bibcode":"2011ascl.soft12016M","views":"45","site_list":["http:\/\/www.qsl.net\/kd2bd\/predict.html"],"ref_list":["http:\/\/www.css.tayloru.edu\/~physics\/picosat\/papers\/paper-2002-utah-conf2.pdf"]},
		{"ascl_id":"1112.017","title":"ASpec: Astronomical Spectrum Analysis Package","credit":"Eisenhamer, Jonathan D.; Hulbert, Stephen J.; Levay, Zoltan G.; Shaw, Richard A.","abstract":"ASpec is a spectrum and line analysis package developed at STScI. ASpec is designed as an add-on package for IRAF and incorporates a variety of analysis techniques for astronomical spectra. ASpec operates on spectra from a wide variety of ground-based and space-based instruments and allows simultaneous handling of spectra from different wavelength regimes. The package accommodates non-linear dispersion relations and provides a variety of functions, individually or in combination, with which to fit spectral features and the continuum. It also permits the masking of known bad data. ASpec provides a powerful, intuitive graphical user interface implemented using the IRAF Object Manager and customized to handle: data input\/output (I\/O); on-line help; selection of relevant features for analysis; plotting and graphical interaction; and data base management.","topic_id":"26063","bibcode":"2011ascl.soft12017E","views":"75","site_list":["ftp:\/\/ftp.stsci.edu\/pub\/software\/ASpec\/"],"ref_list":["http:\/\/adass.org\/adass\/proceedings\/adass94\/hulberts.html"]},
		{"ascl_id":"1112.018","title":"SwiftVis: Data Analysis & Visualization For Planetary Science","credit":"Lewis, Mark","abstract":"SwiftVis is a tool originally developed as part of a rewrite of <a href=\"http:\/\/ascl.net\/1303.001\">Swift<\/a> to be used for analysis and plotting of simulations performed with Swift and Swifter. The extensibility built into the design has allowed us to make SwiftVis a general purpose analysis and plotting package customized to be usable by the planetary science community at large. SwiftVis is written in Java and has been tested on Windows, Linux, and Mac platforms. Its graphical interface allows users to do complex analysis and plotting without having to write custom code.","topic_id":"26359","bibcode":"2011ascl.soft12018L","views":"56","site_list":["http:\/\/www.cs.trinity.edu\/~mlewis\/SwiftVis\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007DDA....38.1311L"]},
		{"ascl_id":"1112.019","title":"Aladin: Interactive Sky Atlas","credit":"Centre de Donn\u00e9es Astronomiques de Strasbourg (Cds)","abstract":"Aladin is an interactive software sky atlas allowing the user to visualize digitized astronomical images, superimpose entries from astronomical catalogues or databases, and interactively access related data and information from the Simbad database, the VizieR service and other archives for all known sources in the field.\r\n\r\nCreated in 1999, Aladin has become a widely-used VO tool capable of addressing challenges such as locating data of interest, accessing and exploring distributed datasets, visualizing multi-wavelength data. Compliance with existing or emerging VO standards, interconnection with other visualisation or analysis tools, ability to easily compare heterogeneous data are key topics allowing Aladin to be a powerful data exploration and integration tool as well as a science enabler.","topic_id":"26360","bibcode":"2011ascl.soft12019C","views":"108","site_list":["http:\/\/aladin.u-strasbg.fr\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0711.1889","http:\/\/cdsbib.u-strasbg.fr\/cgi-bin\/cdsbib?2000A%26AS..143...33B"]},
		{"ascl_id":"1201.001","title":"McScatter: Three-Body Scattering with Stellar Evolution","credit":"Heggie, Douglas C.; Portegies Zwart, Simon; Hurley, Jarrod","abstract":"McScatter illustrates a method of combining stellar dynamics with stellar evolution. The method is intended for elaborate applications, especially the dynamical evolution of rich star clusters. The dynamics is based on binary scattering in a multi-mass field of stars with uniform density and velocity dispersion, using the scattering cross section of Giersz (<a href=\"http:\/\/adsabs.harvard.edu\/abs\/2001MNRAS.324..218G\">MNRAS, 2001, 324, 218-30<\/a>).","topic_id":"26372","bibcode":"2012ascl.soft01001H","views":"271","site_list":["http:\/\/manybody.org\/manybody\/McScatter.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0604294"]},
		{"ascl_id":"1201.002","title":"Roche: Visualization and analysis tool for Roche-lobe grometry of evolving binaries","credit":"Portegies Zwart, Simon F.","abstract":"Roche is a visualization and analysis tool for drawing the Roche-lobe grometry of evolving binaries. Roche can be used as a standalone program reading data from the command line or from a file generated by SeBa. Eventually Roche will be able to read data from any other binary evolution program. Roche requires <a href=\"http:\/\/ascl.net\/1010.076\">Starlab<\/a> (version 4.1.1 or later) and the <a href=\"http:\/\/ascl.net\/1103.002\">pgplot<\/a> libraries. Roche creates a series of images, based on the <a href=\"http:\/\/ascl.net\/1201.003\">SeBa<\/a> output file SeBa.data, displaying the evolutionary state of a binary.","topic_id":"26374","bibcode":"2012ascl.soft01002P","views":"43","site_list":["http:\/\/www.manybody.org\/manybody\/roche.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0604294"]},
		{"ascl_id":"1201.003","title":"SeBa: Stellar and binary evolution","credit":"Portegies Zwart, S. F.; Verbunt, F.","abstract":"The stellar and binary evolution package SeBa is fully integrated into the kira integrator, although it can also be used as a stand-alone module for non-dynamical applications. Due to the interaction between stellar evolution and stellar dynamics, it is difficult to solve for the evolution of both systems in a completely self-consistent way. The trajectories of stars are computed using a block timestep scheme, as described earlier. Stellar and binary evolution is updated at fixed intervals (every 1\/64 of a crossing time, typically a few thousand years). Any feedback between the two systems may thus experience a delay of at most one timestep. Internal evolution time steps may differ for each star and binary, and depend on binary period, perturbations due to neighbors, and the evolutionary state of the star. Time steps in this treatment vary from several milliseconds up to (at most) a million years.","topic_id":"26375","bibcode":"2012ascl.soft01003P","views":"47","site_list":["http:\/\/www.sns.ias.edu\/~starlab\/seba\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1111.6125"]},
		{"ascl_id":"1201.004","title":"emGain: Determination of EM gain of CCD","credit":"Daigle, Olivier; Carignan, Claude; Blais-Ouellette, Sebastien","abstract":"The determination of the EM gain of the CCD is best done by fitting the histogram of many low-light frames. Typically, the dark+CIC noise of a 30ms frame itself is a sufficient amount of signal to determine accurately the EM gain with about 200 512x512 frames. The IDL code emGain takes as an input a cube of frames and fit the histogram of all the pixels with the EM stage output probability function. The function returns the EM gain of the frames as well as the read-out noise and the mean signal level of the frames.","topic_id":"26377","bibcode":"2012ascl.soft01004D","views":"35","site_list":["http:\/\/www.astro.umontreal.ca\/~odaigle\/emccd\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0606203"]},
		{"ascl_id":"1201.005","title":"2LPTIC: 2nd-order Lagrangian Perturbation Theory Initial Conditions","credit":"Crocce, M.; Pueblas, S.; Scoccimarro, R.","abstract":"Setting initial conditions in numerical simulations using the standard procedure based on the Zel'dovich approximation (ZA) generates incorrect second and higher-order growth and therefore excites long-lived transients in the evolution of the statistical properties of density and velocity fields. Using more accurate initial conditions based on second-order Lagrangian perturbation theory (2LPT) reduces transients significantly; initial conditions based on 2LPT are thus much more appropriate for numerical simulations devoted to precision cosmology. The 2LPTIC code provides initial conditions for running cosmological simulations based on second-order Lagrangian Perturbation Theory (2LPT), rather than first-order (Zel'dovich approximation).","topic_id":"26379","bibcode":"2012ascl.soft01005C","views":"95","site_list":["http:\/\/cosmo.nyu.edu\/roman\/2LPT\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0606505v2"]},
		{"ascl_id":"1201.006","title":"VIM: Visual Integration and Mining","credit":"U. S. National Virtual Observatory (VAO)","abstract":"VIM (Virtual Observatory Integration and Mining) is a data retrieval and exploration application that assumes an astronomer has a list of 'sources' (positions in the sky), and wants to explore archival catalogs, images, and spectra of the sources, in order to identify, select, and mine the list. VIM does this either through web forms, building a custom 'data matrix,' or locally through downloadable Python code. Any VO-registered catalog service can be used by VIM, as well as co-registered image cutouts from VO-image services, and spectra from VO-spectrum services. The user could, for example, show together: proper motions from GSC2, name and spectral type from NED, magnitudes and colors from 2MASS, and cutouts and spectra from SDSS. VIM can compute columns across surveys and sort on these (eg. 2MASS J magnitude minus SDSS g). For larger sets of sources, VIM utilizes the asynchronous Nesssi services from NVO, that can run thousands of cone and image services overnight.","topic_id":"26364","bibcode":"2012ascl.soft01006U","views":"48","site_list":["http:\/\/www.us-vo.org\/vim\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ASPC..394..173W"]},
		{"ascl_id":"1201.007","title":"Fisher4Cast: Fisher Matrix Toolbox","credit":"Bassett, Bruce A.; Fantaye, Yabebal; Hlozek, Renee; Kotze, Jacques","abstract":"The Fisher4Cast suite, which requires MatLab, provides a standard, tested tool set for general Fisher Information matrix prediction and forecasting for use in both research and education. The toolbox design is robust and modular, allowing for easy additions and adaptation while keeping the user interface intuitive and easy to use. Fisher4Cast is completely general but the default is coded for cosmology. It provides parameter error forecasts for cosmological surveys providing distance, Hubble expansion and growth measurements in a general, curved FLRW background.","topic_id":"26424","bibcode":"2012ascl.soft01007B","views":"36","site_list":["http:\/\/www.mathworks.com\/matlabcentral\/fileexchange\/20008%20?"],"ref_list":["http:\/\/arxiv.org\/abs\/0906.0993"]},
		{"ascl_id":"1201.008","title":"Mercury: A software package for orbital dynamics","credit":"Chambers, John E.","abstract":"Mercury is a new general-purpose software package for carrying out orbital integrations for problems in solar-system dynamics. Suitable applications include studying the long-term stability of the planetary system, investigating the orbital evolution of comets, asteroids or meteoroids, and simulating planetary accretion. Mercury is designed to be versatile and easy to use, accepting initial conditions in either Cartesian coordinates or Keplerian elements in \"cometary\" or \"asteroidal\" format, with different epochs of osculation for different objects. Output from an integration consists of osculating elements, written in a machine-independent compressed format, which allows the results of a calculation performed on one platform to be transferred (e.g. via FTP) and decoded on another. \r\n\r\nDuring an integration, Mercury monitors and records details of close encounters, sungrazing events, ejections and collisions between objects. The effects of non-gravitational forces on comets can also be modeled. The package supports integrations using a mixed-variable symplectic routine, the Bulirsch-Stoer method, and a hybrid code for planetary accretion calculations.","topic_id":"26446","bibcode":"2012ascl.soft01008C","views":"90","site_list":["http:\/\/www.arm.ac.uk\/~jec\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000AJ....119..425C"]},
		{"ascl_id":"1201.009","title":"ExoFit: Orbital parameters of extra-solar planets from radial velocity","credit":"Balan, Sreekumar Thaithara; Lahav, Ofer","abstract":"ExoFit is a freely available software package for estimating orbital parameters of extra-solar planets. ExoFit can search for either one or two planets and employs a Bayesian Markov Chain Monte Carlo (MCMC) method to fit a Keplerian radial velocity curve onto the radial velocity data.","topic_id":"26505","bibcode":"2012ascl.soft01009B","views":"71","site_list":["http:\/\/www.star.ucl.ac.uk\/~lahav\/exofit.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009MNRAS.394.1936B"]},
		{"ascl_id":"1201.010","title":"HNBody: Hierarchical N-Body Symplectic Integration Package","credit":"Rauch, Kevin P.; Hamilton, Douglas P.","abstract":"HNBody is a new set of software utilities geared to the integration of hierarchical (nearly-Keplerian) N-body systems. Our focus is on symplectic methods, and we have included explicit support for three classes of particles (heavy, light, and massless), second and fourth order methods, post-Newtonian corrections, and the use of a symplectic corrector (among other things). For testing purposes, we also provide support for more general integration schemes (Bulirsch-Stoer & Runge-Kutta). Configuration files employing an intuitive syntax allow for easy problem setup, and many simple simulations can be done without the user compiling any code. Low-level interfaces are also available, enabling extensive customization.","topic_id":"26762","bibcode":"2012ascl.soft01010R","views":"46","site_list":["http:\/\/janus.astro.umd.edu\/HNBody\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002DDA....33.0802R"]},
		{"ascl_id":"1201.011","title":"Duchamp: A 3D source finder for spectral-line data","credit":"Whiting, Matthew","abstract":"Duchamp is software designed to find and describe sources in 3-dimensional, spectral-line data cubes. Duchamp has been developed with HI (neutral hydrogen) observations in mind, but is widely applicable to many types of astronomical images. It features efficient source detection and handling methods, noise suppression via smoothing or multi-resolution wavelet reconstruction, and a range of graphical and text-based outputs to allow the user to understand the detections.","topic_id":"26780","bibcode":"2012ascl.soft01011W","views":"37","site_list":["http:\/\/www.atnf.csiro.au\/people\/Matthew.Whiting\/Duchamp\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1201.2710"]},
		{"ascl_id":"1201.012","title":"CLUMPY: A code for gamma-ray signals from dark matter structures","credit":"Charbonnier, A.; Combet, C.; Maurin, D.","abstract":"CLUMPY is a public code for semi-analytical calculation of the gamma-ray flux astrophysical J-factor from dark matter annihilation\/decay in the Galaxy, including dark matter substructures. The core of the code is the calculation of the line of sight integral of the dark matter density squared (for annihilations) or density (for decaying dark matter). The code can be used in three modes: i) to draw skymaps from the Galactic smooth component and\/or the substructure contributions, ii) to calculate the flux from a specific halo (that is not the Galactic halo, e.g. dwarf spheroidal galaxies) or iii) to perform simple statistical operations from a list of allowed DM profiles for a given object. Extragalactic contributions and other tracers of DM annihilation (e.g. positrons, antiprotons) will be included in a second release.","topic_id":"26816","bibcode":"2012ascl.soft01012C","views":"53","site_list":["http:\/\/lpsc.in2p3.fr\/clumpy\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012CoPhC.183..656C"]},
		{"ascl_id":"1201.013","title":"SPS: SPIRE Photometer Simulator","credit":"Sibthorpe, Bruce","abstract":"The SPS software simulates the operation of the Spectral and Photometric Imaging Receiver on-board the ESA\u2019s Herschel Space Observatory. It is coded using the Interactive Data Language (IDL), and produces simulated data at the level-0 stage (non-calibrated data in digitised units). The primary uses for the simulator are to:\n\n<ul><li>optimize and characterize the photometer observing functions<\/li><li>aid in the development, validation, and characterization of the SPIRE data pipeline<\/li><li>provide a realistic example of SPIRE data, and thus to facilitate the development of specific analysis tools for specific science cases.<\/li><\/ul>It should be noted that the SPS is not an officially supported product of the SPIRE ICC, and was originally developed for ICC use only. Consequently the SPS can be supported only on a \"best efforts\" basis.","topic_id":"26923","bibcode":"2012ascl.soft01013S","views":"47","site_list":["https:\/\/web.archive.org\/web\/20101126231122\/","http:\/\/www.roe.ac.uk\/~sib\/sps\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0906.3307v1"]},
		{"ascl_id":"1201.014","title":"Hammurabi: Simulating polarized Galactic synchrotron emission","credit":"Jaffe, Tess; Waelkens, Andre","abstract":"The Hammurabi code is a publicly available C++ code for generating mock polarized observations of Galactic synchrotron emission with telescopes such as LOFAR, SKA, Planck, and WMAP, based on model inputs for the Galactic magnetic field (GMF), the cosmic-ray density distribution, and the thermal electron density. The Hammurabi code allows one to perform simulations of several different data sets simultaneously, providing a more reliable constraint of the magnetized ISM.","topic_id":"26924","bibcode":"2012ascl.soft01014J","views":"50","site_list":["http:\/\/www.mpa-garching.mpg.de\/hammurabi\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0807.2262"]},
		{"ascl_id":"1201.015","title":"FFTW: Fastest Fourier Transform in the West","credit":"Frigo, Matteo; Johnson, Steven G.","abstract":"FFTW is a C subroutine library for computing the discrete Fourier transform (DFT) in one or more dimensions, of arbitrary input size, and of both real and complex data (as well as of even\/odd data, i.e. the discrete cosine\/sine transforms or DCT\/DST). \r\n\r\nBenchmarks performed on a variety of platforms show that FFTW's performance is typically superior to that of other publicly available FFT software, and is even competitive with vendor-tuned codes. In contrast to vendor-tuned codes, however, FFTW's performance is portable: the same program will perform well on most architectures without modification.\r\n\r\nThe FFTW library is required by other codes such as <a href=\"http:\/\/ascl.net\/1010.074\">StarCrash<\/a> and <a href=\"http:\/\/ascl.net\/1201.014\">Hammurabi<\/a>.","topic_id":"26947","bibcode":"2012ascl.soft01015F","views":"38","site_list":["http:\/\/www.fftw.org\/"],"ref_list":["http:\/\/www.fftw.org\/fftw-paper-ieee.pdf"]},
		{"ascl_id":"1201.016","title":"LumFunc: Luminosity Function Modeling","credit":"Cooray, Asantha; Milosavljevi\u0107, Milo\u0161","abstract":"LumFunc is a numerical code to model the Luminosity Function based on central galaxy luminosity-halo mass and total galaxy luminosity-halo mass relations. The code can handle rest b_J-band (2dFGRS), r'-band (SDSS), and K-band luminosities, and any redshift with redshift dependences specified by the user. It separates the luminosity function (LF) to conditional luminosity functions, LF as a function of halo mass, and also to galaxy types. By specifying a narrow mass range, the code will return the conditional luminosity functions. The code returns luminosity functions for galaxy types as well (broadly divided to early-type and late-type). The code also models the cluster luminosity function, either mass averaged or for individual clusters.","topic_id":"26978","bibcode":"2012ascl.soft01016C","views":"39","site_list":["http:\/\/www.cooray.org\/lumfunc.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005ApJ...627L..89C"]},
		{"ascl_id":"1201.017","title":"Inflation: Monte-Carlo Code for Slow-Roll Inflation","credit":"Friedman, Brett C.; Cooray, Asantha; Melchiorri, Alessandro","abstract":"Inflation is a numerical code to generate power spectra and other observables through numerical solutions to flow equations. The code generates tensor and scalar power spectra as a function of wavenumber and various other parameters at specific wavenumbers of interest (such as for CMB, scalar perturbations at smaller scales, gravitational wave detection at direct detection frequencies). The output can be easily ported to publicly available Markov Chain codes to constrain cosmological parameters with data.","topic_id":"26979","bibcode":"2012ascl.soft01017F","views":"40","site_list":["http:\/\/www.cooray.org\/inflation.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0610220"]},
		{"ascl_id":"1202.001","title":"CISM_DX: Visualization and analysis tool","credit":"Weigel, Bob; Wilson, Erik; Wiltberger, Mike","abstract":"CISM_DX is a <a href=\"http:\/\/www.bu.edu\/cism\/cismdx\/contributing\/contributors.htm\">community-developed<\/a> suite of integrated data, models, and data and model explorers, for research and education. The data and model explorers are based on code written for OpenDX and Octave; OpenDX provides the visualization infrastructures as well as the process for creating user interfaces to the model and data, and Octave allows for extensive data manipulation and reduction operations. The CISM-DX package extends the capabilities of the core software programs to meet the needs of space physics researchers.","topic_id":"27078","bibcode":"2012ascl.soft02001W","views":"36","site_list":["http:\/\/www.bu.edu\/cism\/cismdx\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005JGRA..11009224W"]},
		{"ascl_id":"1202.002","title":"ZODIPIC: Zodiacal Cloud Image Synthesis","credit":"Kuchner, Marc","abstract":"ZODIPIC synthesizes images of exozodiacal clouds. As a default, ZODIPIC creates an image of the solar zodiacal cloud as seen from 10 pc, but it contains many parameters that are tweakable from the command line, making it a handy general-purpose model for optically-thin debris disks that yields both accurate images and photometric information simultaneously. Written in IDL, ZODIPIC includes dust with real optical constants, user-specified dust maps and can compute images as seen through a linear polarizer.","topic_id":"27079","bibcode":"2012ascl.soft02002K","views":"50","site_list":["http:\/\/asd.gsfc.nasa.gov\/Marc.Kuchner\/home.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010DPS....42.2717F"]},
		{"ascl_id":"1202.003","title":"NOVAS: Naval Observatory Vector Astrometry Software","credit":"Kaplan, George; Bartlett, Jennifer Lynn; Monet, Alice; Bangert, John; Puatua, Wendy; Harris, William; Fredericks, Amy; Barron, Eric G.; Barrett, Paul","abstract":"NOVAS is an integrated package of subroutines and functions for computing various commonly needed quantities in positional astronomy. The package can provide, in one or two subroutine or function calls, the instantaneous coordinates of any star or planet in a variety of coordinate systems. At a lower level, NOVAS also supplies astrometric utility transformations, such as those for precession, nutation, aberration, parallax, and the gravitational deflection of light. The computations are accurate to better than one milliarcsecond. The NOVAS package is an easy-to-use facility that can be incorporated into data reduction programs, telescope control systems, and simulations. The U.S. parts of The Astronomical Almanac are prepared using NOVAS. Three editions of NOVAS are available: Fortran, C, and Python.","topic_id":"27202","bibcode":"2012ascl.soft02003K","views":"52","site_list":["http:\/\/aa.usno.navy.mil\/software\/novas\/novas_info.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010AAS...21547504K","http:\/\/adsabs.harvard.edu\/abs\/2011AAS...21734414B"]},
		{"ascl_id":"1202.004","title":"TALYS: Nuclear Reaction Simulator","credit":"Koning, Arjan; Hilaire, Stephane; Duijvestijn, Marieke","abstract":"TALYS is software that simulates nuclear reactions which involve neutrons, gamma-rays, protons, deuterons, tritons, helions and alpha-particles, in the 1 keV-200MeV energy range. A suite of nuclear reaction models has been implemented into a single code system, enabling one to evaluate basically all nuclear reactions beyond the resonance range. In particular, TALYS estimates the Maxwellian-averaged reaction rates that are of astrophysical relevance. This enables reaction rates to be calculated with increased accuracy and reliability and the approximations of previous codes to be investigated. The TALYS predictions for the thermonuclear rates of relevance to astrophysics are detailed and compared with those derived by widely-used codes for the same nuclear ingredients. TALYS predictions may differ significantly from those of previous codes, in particular for nuclei for which no or little nuclear data is available. The pre-equilibrium process is shown to influence the astrophysics rates of exotic neutron-rich nuclei significantly. The TALYS code provides a tool to estimate all nuclear reaction rates of relevance to astrophysics with improved accuracy and reliability.","topic_id":"27203","bibcode":"2012ascl.soft02004K","views":"45","site_list":["http:\/\/www.talys.eu\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0806.2239"]},
		{"ascl_id":"1202.005","title":"Mangle: Angular Mask Software","credit":"Swanson, Molly; Tegmark, Max; Hamilton, Andrew; Hill, Colin","abstract":"Mangle is a suite of software designed to deal accurately and efficiently with complex angular masks, such as occur typically in galaxy surveys. Mangle performs the following tasks: <ul>\r\n<li>converts masks between many handy formats (including HEALPix),<\/li><li>rapidly finds the polygons containing a given point on the sphere,<\/li><li>rapidly decomposes a set of polygons into disjoint parts,<\/li><li>expands masks in spherical harmonics,<\/li><li>generates random points with weights given by the mask, and <\/li><li>implements computations for correlation function analysis.<\/li><\/ul>To mangle, a mask is an arbitrary union of arbitrarily weighted angular regions bounded by arbitrary numbers of edges. The restrictions on the mask are only (1) that each edge must be part of some circle on the sphere (but not necessarily a great circle), and (2) that the weight within each subregion of the mask must be constant. Mangle is complementary to and integrated with the HEALPix package; mangle works with vector graphics whereas HEALPix works with pixels.","topic_id":"27204","bibcode":"2012ascl.soft02005S","views":"47","site_list":["http:\/\/space.mit.edu\/~molly\/mangle\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0711.4352"]},
		{"ascl_id":"1202.006","title":"CORSIKA: An Air Shower Simulation Program","credit":"Heck, Dieter; Peirog, Tanguy; Knapp, Johannes","abstract":"CORSIKA (COsmic Ray Simulations for KAscade) is a program for detailed simulation of extensive air showers initiated by high energy cosmic ray particles. Protons, light nuclei up to iron, photons, and many other particles may be treated as primaries. The particles are tracked through the atmosphere until they undergo reactions with the air nuclei or, in the case of unstable secondaries, decay. The hadronic interactions at high energies may be described by several reaction models. Hadronic interactions at lower energies are described, and in particle decays all decay branches down to the 1% level are taken into account. Options for the generation of Cherenkov radiation and neutrinos exist. CORSIKA may be used up to and beyond the highest energies of 100 EeV.","topic_id":"27363","bibcode":"2012ascl.soft02006H","views":"61","site_list":["http:\/\/www-ik.fzk.de\/corsika\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000APh....13..277N"]},
		{"ascl_id":"1202.007","title":"CRUNCH3D: Three-dimensional compressible MHD code","credit":"Dahlburg, Russ; Picone, Mike; Dahlburg, Jill; Karpen, Judy; Norton, Dave; Huang, Edith; Clune, Tom","abstract":"CRUNCH3D is a massively parallel, viscoresistive, three-dimensional compressible MHD code. The code employs a Fourier collocation spatial discretization, and uses a second-order Runge-Kutta temporal discretization. CRUNCH3D can be applied to MHD turbulence and magnetic fluxtube reconnection research.","topic_id":"27366","bibcode":"2012ascl.soft02007D","views":"56","site_list":["http:\/\/www.lcp.nrl.navy.mil\/hpcc-ess\/crunch3d.4.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003AdSpR..32.1131D"]},
		{"ascl_id":"1202.008","title":"Chombo: Adaptive Solutions of Partial Differential Equations","credit":"Applied Numerical Algorithms Group; LBNL Computational Research Division","abstract":"Chombo provides a set of tools for implementing finite difference methods for the solution of partial differential equations on block-structured adaptively refined rectangular grids. Both elliptic and time-dependent modules are included. Chombo supports calculations in complex geometries with both embedded boundaries and mapped grids, and also supports particle methods. Most parallel platforms are supported, and cross-platform self-describing file formats are included.\r\n\r\nThe Chombo package is a product of the community of Collaborators working with the Applied Numerical Algorithms Group (ANAG), part of the Computational Research Division at LBNL.","topic_id":"27367","bibcode":"2012ascl.soft02008A","views":"52","site_list":["http:\/\/chombo.lbl.gov"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ASPC..359...25K"]},
		{"ascl_id":"1202.009","title":"MOOG: LTE line analysis and spectrum synthesis","credit":"Sneden, Chris; Bean, Jacob; Ivans, Inese; Lucatello, Sara; Sobeck, Jennifer","abstract":"MOOG performs a variety of LTE line analysis and spectrum synthesis tasks. The typical use of MOOG is to assist in the determination of the chemical composition of a star. The basic equations of LTE stellar line analysis are followed. The coding is in various subroutines that are called from a few driver routines; these routines are written in standard FORTRAN. The standard MOOG version has been developed on unix, linux and macintosh computers. \r\n\r\nOne of the chief assets of MOOG is its ability to do on-line graphics. The plotting commands are given within the FORTRAN code. MOOG uses the graphics package SM, chosen for its ease of implementation in FORTRAN codes. Plotting calls are concentrated in just a few routines, and it should be possible for users of other graphics packages to substitute other appropriate FORTRAN commands.","topic_id":"27386","bibcode":"2012ascl.soft02009S","views":"57","site_list":["http:\/\/www.as.utexas.edu\/~chris\/moog.html"],"ref_list":["http:\/\/xxx.lanl.gov\/abs\/1105.2208"]},
		{"ascl_id":"1202.010","title":"SPECTRE: Manipulation of single-order spectra","credit":"Sneden, Chris; Uomoto, Alan; Cottrell, Peter; Fitzpatrick, Mike","abstract":"SPECTRE's chief purpose is the manipulation of single-order spectra, and it performs many of the tasks contained in such IRAF routines as \"splot\" and \"rv\". It is not meant to replace the much more general capabilities of IRAF, but does some functions in a manner that some might find useful. A brief list of SPECTRE tasks are:\r\n\r\n<ul><li>spectrum smoothing<\/li><li>equivalent width calculation<\/li><li>continuum rectification, noise spike excision, and<\/li><li>spectrum comparison.<\/li><\/ul>SPECTRE was written to manipulate coude spectra, and thus is probably most useful for working on high dispersion spectra. Echelle spectra can be gathered from various observatories, reduced to singly-dimensioned spectra using IRAF, then written out as FITS files, thus becoming accessible to SPECTRE. Three different spectra may be manipulated and displayed simultaneously. SPECTRE, written in standard FORTRAN77, can be used only with the SM graphics package.","topic_id":"27387","bibcode":"2012ascl.soft02010S","views":"37","site_list":["http:\/\/www.as.utexas.edu\/~chris\/spectre.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008PASP..120.1332S"]},
		{"ascl_id":"1202.011","title":"Lattimer-Swesty Equation of State Code","credit":"Lattimer, James M.; Swesty, F. Douglas","abstract":"The Lattimer-Swesty Equation of State code is rapid enough to use directly in hydrodynamical simulations such as stellar collapse calculations. It contains an adjustable nuclear force that accurately models both potential and mean-field interactions and allows for the input of various nuclear parameters, including the bulk incompressibility parameter, the bulk and surface symmetry energies, the symmetric matter surface tension, and the nucleon effective masses. This permits parametric studies of the equation of state in astrophysical situations. The equation of state is modeled after the Lattimer, Lamb, Pethick, and Ravenhall (LLPR) compressible liquid drop model for nuclei, and includes the effects of interactions and degeneracy of the nucleon outside nuclei.","topic_id":"27399","bibcode":"2012ascl.soft02011L","views":"40","site_list":["http:\/\/www.astro.sunysb.edu\/dswesty\/lseos.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1991NuPhA.535..331L"]},
		{"ascl_id":"1202.012","title":"CoCoNuT: General relativistic hydrodynamics code with dynamical space-time evolution","credit":"Dimmelmeier, Harald; Novak, J\u00e9r\u00f4me; Cerd\u00e1-Dur\u00e1n, Pablo","abstract":"CoCoNuT is a general relativistic hydrodynamics code with dynamical space-time evolution. The main aim of this numerical code is the study of several astrophysical scenarios in which general relativity can play an important role, namely the collapse of rapidly rotating stellar cores and the evolution of isolated neutron stars. The code has two flavors: CoCoA, the axisymmetric (2D) magnetized version, and CoCoNuT, the 3D non-magnetized version.","topic_id":"27364","bibcode":"2012ascl.soft02012D","views":"49","site_list":["http:\/\/www.mpa-garching.mpg.de\/hydro\/COCONUT\/intro.php"],"ref_list":["http:\/\/arxiv.org\/abs\/1202.0815"]},
		{"ascl_id":"1202.013","title":"SME: Spectroscopy Made Easy","credit":"Valenti, J. A.; Piskunov, N.","abstract":"Spectroscopy Made Easy (SME) is IDL software and a compiled external library that fits an observed high-resolution stellar spectrum with a synthetic spectrum to determine stellar parameters. The SME external library is available for Mac, Linux, and Windows systems. Atomic and molecular line data formatted for SME may be obtained from VALD. SME can solve for empirical log(gf) and damping parameters, using an observed spectrum of a star (usually the Sun) as a constraint.","topic_id":"27471","bibcode":"2012ascl.soft02013V","views":"53","site_list":["http:\/\/www.stsci.edu\/~valenti\/sme.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1996A%26AS..118..595V"]},
		{"ascl_id":"1202.014","title":"FISA: Fast Integrated Spectra Analyzer","credit":"Ben\u00edtez-Llambay, Alejandro","abstract":"FISA (Fast Integrated Spectra Analyzer) permits fast and reasonably accurate age and reddening determinations for small angular diameter open clusters by using their integrated spectra in the (3600-7400) AA  range and currently available template spectrum libraries. This algorithm and its implementation help to achieve astrophysical results in shorter times than from other methods. FISA has successfully been applied to integrated spectroscopy of open clusters, both in the Galaxy and in the Magellanic Clouds, to determine ages and reddenings.","topic_id":"27480","bibcode":"2012ascl.soft02014B","views":"42","site_list":["http:\/\/sites.google.com\/site\/intspectroscopy\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1202.1957"]},
		{"ascl_id":"1202.015","title":"RADMC-3D: A multi-purpose radiative transfer tool","credit":"Dullemond, C. P.","abstract":"RADMC-3D is a software package for astrophysical radiative transfer calculations in arbitrary 1-D, 2-D or 3-D geometries. It is mainly written for continuum radiative transfer in dusty media, but also includes modules for gas line transfer and gas continuum transfer. RADMC-3D is a new incarnation of the older software package <a href=\"http:\/\/ascl.net\/1108.016\">RADMC<\/a>.","topic_id":"27484","bibcode":"2012ascl.soft02015D","views":"62","site_list":["http:\/\/www.ita.uni-heidelberg.de\/~dullemond\/software\/radmc-3d\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1109.3478"]},
		{"ascl_id":"1203.001","title":"AE: ACIS Extract","credit":"Broos, Patrick; Townsley, Leisa; Getman, Konstantin; Bauer, Franz","abstract":"ACIS Extract (AE), written in the IDL language, provides innovative and automated solutions to the varied challenges found in the analysis of X-ray data taken by the ACIS instrument on NASA's Chandra observatory. AE addresses complications found in many Chandra projects: large numbers of point sources (hundreds to several thousand), faint point sources, misaligned multiple observations of an astronomical field, point source crowding, and scientifically relevant diffuse emission. AE can perform virtually all the data processing and analysis tasks that lie between Level 2 ACIS data and publishable LaTeX tables of point-like and diffuse source properties and spectral models.","topic_id":"27673","bibcode":"2012ascl.soft03001B","views":"79","site_list":["http:\/\/www2.astro.psu.edu\/xray\/docs\/TARA\/AE.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010ApJ...714.1582B"]},
		{"ascl_id":"1203.002","title":"GALAPAGOS: Galaxy Analysis over Large Areas: Parameter Assessment by GALFITting Objects from SExtractor","credit":"Barden, Marco; H\u00e4u\u00dfler, Boris; Peng, Chien Y.; McIntosh, Daniel H.; Guo, Yicheng","abstract":"GALAPAGOS, Galaxy Analysis over Large Areas: Parameter Assessment by GALFITting Objects from <a href=\"http:\/\/ascl.net\/1010.064\">SExtractor<\/a> (ascl:1010.064), automates source detection, two-dimensional light-profile Sersic modelling and catalogue compilation in large survey applications. Based on a single setup, GALAPAGOS can process a complete set of survey images. It detects sources in the data, estimates a local sky background, cuts postage stamp images for all sources, prepares object masks, performs Sersic fitting including neighbours and compiles all objects in a final output catalogue. For the initial source detection GALAPAGOS applies SExtractor, while <a href=\"http:\/\/ascl.net\/1104.010\">GALFIT<\/a> (ascl:1104.010) is incorporated for modelling Sersic profiles. It measures the background sky involved in the Sersic fitting by means of a flux growth curve. GALAPAGOS determines postage stamp sizes based on SExtractor shape parameters. In order to obtain precise model parameters GALAPAGOS incorporates a complex sorting mechanism and makes use of multiplexing capabilities. It combines SExtractor and GALFIT data in a single output table. When incorporating information from overlapping tiles, GALAPAGOS automatically removes multiple entries from identical sources. GALAPAGOS is programmed in the Interactive Data Language, IDL. A C implementation of the software, GALAPAGOS-C (ascl:1408.011), is available.","topic_id":"27698","bibcode":"2012ascl.soft03002B","views":"309","site_list":["http:\/\/astro-staff.uibk.ac.at\/~m.barden\/galapagos\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1203.1831"]},
		{"ascl_id":"1203.003","title":"spec2d: DEEP2 DEIMOS Spectral Pipeline","credit":"Cooper, Michael C.; Newman, Jeffrey A.; Davis, Marc; Finkbeiner, Douglas P.; Gerke, Brian F.","abstract":"The DEEP2 DEIMOS Data Reduction Pipeline (\"spec2d\") is an IDL-based, automated software package designed to reduce Keck\/DEIMOS multi-slit spectroscopic observations, collected as part of the DEEP2 Galaxy Redshift Survey. The pipeline is best suited for handling data taken with the 1200 line\/mm grating tilted towards the red (lambda_c ~ 7800\u00c5). The spec2d reduction package takes the raw DEIMOS data as its input and produces a variety of outputs including 2-d slit spectra and 1-d object spectra.","topic_id":"27711","bibcode":"2012ascl.soft03003C","views":"59","site_list":["http:\/\/deep.berkeley.edu\/spec2d\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0905.2233v1"]},
		{"ascl_id":"1203.004","title":"FERENGI: Full and Efficient Redshifting of Ensembles of Nearby Galaxy Images","credit":"Barden, Marco; Jahnke, Knud; H\u00e4u\u00dfler, Boris","abstract":"Bandpass shifting and the (1+z)5 surface brightness dimming (for a fixed width filter) make standard tools for the extraction of structural parameters of galaxies wavelength dependent. If only few (or one) observed high-res bands exist, this dependence has to be corrected to make unbiased statements on the evolution of structural parameters or on galaxy subsamples defined by morphology. FERENGI artificially redshifts low-redshift galaxy images to different redshifts by applying the correct cosmological corrections for size, surface brightness and bandpass shifting. A set of artificially redshifted galaxies in the range 0.1&lt;z&lt;1.1 using a set of ~100 SDSS low-redshift (v&lt;7000 km s-1) images as input has been created to use as a training set of realistic images of galaxies of diverse morphologies and a large range of redshifts for the GEMS and COSMOS galaxy evolution projects. This training set allows other studies to investigate and quantify the effects of cosmological redshift on the determination of galaxy morphologies, distortions, and other galaxy properties that are potentially sensitive to resolution, surface brightness, and bandpass issues. The data sets are also available for download from the FERENGI website.","topic_id":"27808","bibcode":"2012ascl.soft03004B","views":"44","site_list":["http:\/\/www.mpia-hd.mpg.de\/FERENGI\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ApJS..175..105B"]},
		{"ascl_id":"1203.005","title":"Gyoto: General relativitY Orbit Tracer of Observatoire de Paris","credit":"Vincent, Frederic H.; Paumard, Thibaut; Gourgoulhon, Eric; Perrin, Guy","abstract":"GYOTO, a general relativistic ray-tracing code, aims at computing images of astronomical bodies in the vicinity of compact objects, as well as trajectories of massive bodies in relativistic environments. This code is capable of integrating the null and timelike geodesic equations not only in the Kerr metric, but also in any metric computed numerically within the 3+1 formalism of general relativity. Simulated images and spectra have been computed for a variety of astronomical targets, such as a moving star or a toroidal accretion structure. The underlying code is open source and freely available. It is user-friendly, quickly handled and very modular so that extensions are easy to integrate. Custom analytical metrics and astronomical targets can be implemented in C++ plug-in extensions independent from the main code.","topic_id":"27809","bibcode":"2012ascl.soft03005V","views":"29","site_list":["http:\/\/gyoto.obspm.fr\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1109.4769"]},
		{"ascl_id":"1203.006","title":"EMACSS: Evolve Me A Cluster of StarS","credit":"Alexander, Poul E. R.; Gieles, Mark","abstract":"The star cluster evolution code Evolve Me A Cluster of StarS (EMACSS) is a simple yet physically motivated computational model that describes the evolution of some fundamental properties of star clusters in static tidal fields. The prescription is based upon the flow of energy within the cluster, which is a constant fraction of the total energy per half-mass relaxation time. According to Henon's predictions, this flow is independent of the precise mechanisms for energy production within the core, and therefore does not require a complete description of the many-body interactions therein. Dynamical theory and analytic descriptions of escape mechanisms is used to construct a series of coupled differential equations expressing the time evolution of cluster mass and radius for a cluster of equal-mass stars. These equations are numerically solved using a fourth-order Runge-Kutta integration kernel; the results were benchmarked against a data base of direct N-body simulations. EMACSS is publicly available and reproduces the N-body results to within ~10 per cent accuracy for the entire post-collapse evolution of star clusters.","topic_id":"28139","bibcode":"2012ascl.soft03006A","views":"42","site_list":["http:\/\/arxiv.org\/src\/1203.4744v1\/anc"],"ref_list":["http:\/\/arxiv.org\/abs\/1203.4744"]},
		{"ascl_id":"1203.007","title":"EBTEL: Enthalpy-Based Thermal Evolution of Loops","credit":"Klimchuk, J. A.; Patsourakos, S.; Cargill, P. J.","abstract":"Observational and theoretical evidence suggests that coronal heating is impulsive and occurs on very small cross-field spatial scales. A single coronal loop could contain a hundred or more individual strands that are heated quasi-independently by nanoflares. It is therefore an enormous undertaking to model an entire active region or the global corona. Three-dimensional MHD codes have inadequate spatial resolution, and 1D hydro codes are too slow to simulate the many thousands of elemental strands that must be treated in a reasonable representation. Fortunately, thermal conduction and flows tend to smooth out plasma gradients along the magnetic field, so \"0D models\" are an acceptable alternative. We have developed a highly efficient model called Enthalpy-Based Thermal Evolution of Loops (EBTEL) that accurately describes the evolution of the average temperature, pressure, and density along a coronal strand. It improves significantly upon earlier models of this type--in accuracy, flexibility, and capability. It treats both slowly varying and highly impulsive coronal heating; it provides the differential emission measure distribution, DEM(T), at the transition region footpoints; and there are options for heat flux saturation and nonthermal electron beam heating. EBTEL gives excellent agreement with far more sophisticated 1D hydro simulations despite using four orders of magnitude less computing time. It promises to be a powerful new tool for solar and stellar studies.","topic_id":"28140","bibcode":"2012ascl.soft03007K","views":"41","site_list":["http:\/\/asterisk.apod.com\/download\/file.php?id=6646"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ApJ...682.1351K","http:\/\/arxiv.org\/abs\/1202.4819"]},
		{"ascl_id":"1203.008","title":"MegaLUT: Correcting ellipticity measurements of galaxies","credit":"Tewes, Malte; Cantale, Nicolas; Courbin, Fr\u00e9d\u00e9ric; Kitching, Thomas; Meylan, Georges","abstract":"MegaLUT is a simple and fast method to correct ellipticity measurements of galaxies from the distortion by the instrumental and atmospheric point spread function (PSF), in view of weak lensing shear measurements. The method performs a classification of galaxies and associated PSFs according to measured shape parameters, and builds a lookup table of ellipticity corrections by supervised learning. This new method has been applied to the GREAT10 image analysis challenge, and demonstrates a refined solution that obtains the highly competitive quality factor of Q = 142, without any power spectrum denoising or training. Of particular interest is the efficiency of the method, with a processing time below 3 ms per galaxy on an ordinary CPU.","topic_id":"28148","bibcode":"2012ascl.soft03008T","views":"43","site_list":["http:\/\/lastro.epfl.ch\/megalut"],"ref_list":["http:\/\/arxiv.org\/abs\/1203.4429"]},
		{"ascl_id":"1203.009","title":"MYRIAD: N-body code for simulations of star clusters","credit":"Konstantinidis, Simos; Kokkotas, Kostas D.","abstract":"MYRIAD is a C++ code for collisional N-body simulations of star clusters. The code uses the Hermite fourth-order scheme with block time steps, for advancing the particles in time, while the forces and neighboring particles are computed using the GRAPE-6 board. Special treatment is used for close encounters, binary and multiple sub-systems that either form dynamically or exist in the initial configuration. The structure of the code is modular and allows the appropriate treatment of more physical phenomena, such as stellar and binary evolution, stellar collisions and evolution of close black-hole binaries. Moreover, it can be easily modified so that the part of the code that uses GRAPE-6 could be replaced by another module that uses other accelerating-hardware like the Graphics Processing Units (GPUs). Appropriate choice of the free parameters give a good accuracy and speed for simulations of star clusters up to and beyond core collapse. The code accuracy becomes comparable and even better than the accuracy of existing codes when a number of close binary systems is dynamically created in a simulation; this is due to the high accuracy of the method that is used for close binary and multiple sub-systems. The code can be used for evolving star clusters containing equal-mass stars or star clusters with an initial mass function (IMF) containing an intermediate mass black hole (IMBH) at the center and\/or a fraction of primordial binaries, which are systems of particular astrophysical interest.","topic_id":"28149","bibcode":"2012ascl.soft03009K","views":"37","site_list":["http:\/\/www.tat.physik.uni-tuebingen.de\/~tat\/MYRIAD.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1006.3326"]},
		{"ascl_id":"1203.010","title":"Youpi: YOUr processing PIpeline","credit":"Monnerville, Mathias; S\u00e9mah, Gregory","abstract":"Youpi is a portable, easy to use web application providing high level functionalities to perform data reduction on scientific FITS images. Built on top of various open source reduction tools released to the community by TERAPIX (<!-- m --><a href=\"http:\/\/terapix.iap.fr\">http:\/\/terapix.iap.fr<\/a><!-- m -->), Youpi can help organize data, manage processing jobs on a computer cluster in real time (using Condor) and facilitate teamwork by allowing fine-grain sharing of results and data. Youpi is modular and comes with plugins which perform, from within a browser, various processing tasks such as evaluating the quality of incoming images (using the QualityFITS software package), computing astrometric and photometric solutions (using <a href=\"http:\/\/ascl.net\/1010.063\">SCAMP<\/a>), resampling and co-adding FITS images (using <a href=\"http:\/\/ascl.net\/1010.068\">SWarp<\/a>) and extracting sources and building source catalogues from astronomical images (using <a href=\"http:\/\/ascl.net\/1010.064\">SExtractor<\/a>). Youpi is useful for small to medium-sized data reduction projects; it is free and is published under the GNU General Public License.","topic_id":"28154","bibcode":"2012ascl.soft03010M","views":"63","site_list":["https:\/\/github.com\/matm\/Youpi"],"ref_list":["http:\/\/arxiv.org\/abs\/1006.1074"]},
		{"ascl_id":"1402.030","title":"P2SAD: Particle Phase Space Average Density","credit":"Zavala, Jesus; Afshordi, Niayesh","abstract":"P2SAD computes the Particle Phase Space Average Density (P2SAD) in galactic haloes. The model for the calculation is based on the stable clustering hypothesis in phase space, the spherical collapse model, and tidal disruption of substructures. The multiscale prediction for P2SAD computed by this IDL code can be used to estimate signals sensitive to the small scale structure of dark matter distributions (e.g. dark matter annihilation). The code computes P2SAD averaged over the whole virialized region of a Milky-Way-size halo at redshift zero.","topic_id":"32991","bibcode":"2014ascl.soft02030Z","views":"45","site_list":["http:\/\/spaces.perimeterinstitute.ca\/p2sad\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1311.3296Z"]},
		{"ascl_id":"1203.011","title":"SALT2: Spectral Adaptive Lightcurve Template","credit":"Guy, Julien","abstract":"SALT (Spectral Adaptive Lightcurve Template) is a package for Type Ia Supernovae light curve fitting. Its main purpose is to provide a distance estimator but it can also be used for photometric redshifts, and spectroscopic + photometric identification.","topic_id":"28155","bibcode":"2012ascl.soft03011G","views":"37","site_list":["http:\/\/supernovae.in2p3.fr\/~guy\/salt\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007A%26A...466...11G"]},
		{"ascl_id":"1203.012","title":"Astrometrica: Astrometric data reduction of CCD images","credit":"Raab, Herbert","abstract":"Astrometrica is an interactive software tool for scientific grade astrometric data reduction of CCD images. The current version of the software is for the Windows 32bit operating system family. Astrometrica reads FITS (8, 16 and 32 bit integer files) and SBIG image files. The size of the images is limited only by available memory. It also offers automatic image calibration (Dark Frame and Flat Field correction), automatic reference star identification, automatic moving object detection and identification, and access to new-generation star catalogs (PPMXL, UCAC 3 and CMC-14), in addition to online help and other features. Astrometrica is shareware, available for use for a limited period of time (100 days) for free; special arrangements can be made for educational projects.","topic_id":"28162","bibcode":"2012ascl.soft03012R","views":"78","site_list":["http:\/\/www.astrometrica.at\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012AAS...21914707W"]},
		{"ascl_id":"1203.013","title":"Figaro: Data Reduction Software","credit":"Shortridge, Keith","abstract":"Figaro is a data reduction system that originated at Caltech and whose development continued at the Anglo-Australian Observatory. Although it is intended to be able to deal with any sort of data, almost all its applications to date are geared towards processing optical and infrared data. Figaro uses hierarchical data structures to provide flexibility in its data file formats. Figaro was originally written to run under DEC's VMS operating system, but is now available both for VMS and for various flavours of UNIX.","topic_id":"28168","bibcode":"2012ascl.soft03013S","views":"164","site_list":["http:\/\/www.aao.gov.au\/figaro\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1993ASPC...52..219S"]},
		{"ascl_id":"1204.001","title":"WM-basic: Modeling atmospheres of hot stars","credit":"Pauldrach, A. W. A.","abstract":"WM-basic is an easy-to-use interface to a program package which models the atmospheres of Hot Stars (and also SN and GN). The release comprises all programs required to calculate model atmospheres which especially yield ionizing fluxes and synthetic spectra. WM-basic is a native 32-bit application, conforming to the Multiple Documents Interface (MDI) standards for Windows XP\/2000\/NT\/9x. All components of the program package have been compiled with Digital Visual Fortran V6.6(Pro) and Microsoft Visual C++.","topic_id":"28170","bibcode":"2012ascl.soft04001P","views":"45","site_list":["http:\/\/www.usm.uni-muenchen.de\/people\/adi\/Programs\/Programs.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003ApJ...599.1333S"]},
		{"ascl_id":"1204.002","title":"pyBLoCXS: Bayesian Low-Count X-ray Spectral analysis","credit":"Siemiginowska, Aneta; Kashyap, Vinay; Refsdal, Brian; van Dyk, David; Connors, Alanna; Park, Taeyoung","abstract":"pyBLoCXS is a sophisticated Markov chain Monte Carlo (MCMC) based algorithm designed to carry out Bayesian Low-Count X-ray Spectral (BLoCXS) analysis in the <a href=\"http:\/\/ascl.net\/1107.005\">Sherpa<\/a> environment. The code is a Python extension to Sherpa that explores parameter space at a suspected minimum using a predefined Sherpa model to high-energy X-ray spectral data. pyBLoCXS includes a flexible definition of priors and allows for variations in the calibration information. It can be used to compute posterior predictive p-values for the likelihood ratio test. The pyBLoCXS code has been tested with a number of simple single-component spectral models; it should be used with great care in more complex settings.","topic_id":"28171","bibcode":"2012ascl.soft04002S","views":"39","site_list":["http:\/\/hea-www.harvard.edu\/AstroStat\/pyBLoCXS\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ASPC..442..439S"]},
		{"ascl_id":"1204.003","title":"BUDDA: BUlge\/Disk Decomposition Analysis","credit":"de Souza, Ronaldo Eust\u00e1quio; Gadotti, Dimitri Alexei; dos Anjos, Sandra","abstract":"Budda is a Fortran code developed to perform a detailed structural analysis on galaxy images. It is simple to use and gives reliable estimates of the galaxy structural parameters, which can be used, for instance, in Fundamental Plane studies. Moreover, it has a powerful ability to reveal hidden sub-structures, like inner disks, secondary bars and nuclear rings.","topic_id":"28182","bibcode":"2012ascl.soft04003D","views":"75","site_list":["http:\/\/www.sc.eso.org\/~dgadotti\/budda.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004ApJS..153..411D","http:\/\/adsabs.harvard.edu\/abs\/2008MNRAS.384..420G"]},
		{"ascl_id":"1204.004","title":"Fosite: 2D advection problem solver","credit":"Illenseer, Tobias","abstract":"Fosite implements a method for the solution of hyperbolic conservation laws in curvilinear orthogonal coordinates. It is written in Fortran 90\/95 integrating object-oriented (OO) design patterns, incorporating the flexibility of OO-programming into Fortran 90\/95 while preserving the efficiency of the numerical computation. Although mainly intended for CFD simulations, Fosite's modular design allows its application to other advection problems as well. Unlike other two-dimensional implementations of finite volume methods, it accounts for local conservation of specific angular momentum. This feature turns the program into a perfect tool for astrophysical simulations where angular momentum transport is crucial. Angular momentum transport is not only implemented for standard coordinate systems with rotational symmetry (i.e. cylindrical, spherical) but also for a general set of orthogonal coordinate systems allowing the use of exotic curvilinear meshes (e.g. oblate-spheroidal). As in the case of the advection problem, this part of the software is also kept modular, therefore new geometries may be incorporated into the framework in a straightforward manner.","topic_id":"28186","bibcode":"2012ascl.soft04004I","views":"40","site_list":["http:\/\/sourceforge.net\/projects\/fosite\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009CoPhC.180.2283I"]},
		{"ascl_id":"1204.005","title":"MC3D: Monte-Carlo 3D Radiative Transfer Code","credit":"Wolf, S.; Henning, T.; Stecklum, B.","abstract":"MC3D is a 3D continuum radiative transfer code; it is based on the Monte-Carlo method and solves the radiative transfer problem self-consistently. It is designed for the simulation of dust temperatures in arbitrary geometric configurations and the resulting observables: spectral energy distributions, wavelength-dependent images, and polarization maps. The main objective is the investigation of \"dust-dominated\" astrophysical systems such as young stellar objects surrounded by an optically thick circumstellar disk and an optically thin(ner) envelope, debris disks around more evolved stars, asymptotic giant branch stars, the dust component of the interstellar medium, and active galactic nuclei.","topic_id":"28188","bibcode":"2012ascl.soft04005W","views":"51","site_list":["http:\/\/www.astrophysik.uni-kiel.de\/~star\/index.php?seite=mc3d"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1999A%26A...349..839W"]},
		{"ascl_id":"1204.006","title":"GRASIL: Spectral evolution of stellar systems with dust","credit":"Silva, Laura; Granato, Gian Luigi","abstract":"GRASIL (which stands for GRAphite and SILicate) computes the spectral evolution of stellar systems taking into account the effects of dust, which absorbs and scatters optical and UV photons and emits in the IR-submm region. It may be used as well to do \u201cstandard\u201d no-dust stellar spectral synthesis. The code is very well calibrated and applied to interpret galaxies at different redshifts. GRASIL can be downloaded or run online using the <a href=\"http:\/\/galsynth.oapd.inaf.it\/galsynth\/\">GALSYNTH WEB<\/a> interface.","topic_id":"28189","bibcode":"2012ascl.soft04006S","views":"42","site_list":["http:\/\/adlibitum.oats.inaf.it\/silva\/grasil\/grasil.html"],"ref_list":["http:\/\/esoads.eso.org\/abs\/1998ApJ...509..103S","http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.423..746S"]},
		{"ascl_id":"1204.007","title":"VH-1: Multidimensional ideal compressible hydrodynamics code","credit":"Hawley, John; Blondin, John; Lindahl, Greg; Lufkin, Eric","abstract":"VH-1 is a multidimensional ideal compressible hydrodynamics code written in FORTRAN for use on any computing platform, from desktop workstations to supercomputers. It uses a Lagrangian remap version of the Piecewise Parabolic Method developed by Paul Woodward and Phil Colella in their 1984 paper. VH-1 comes in a variety of versions, from a simple one-dimensional serial variant to a multi-dimensional version scalable to thousands of processors.","topic_id":"28197","bibcode":"2012ascl.soft04007H","views":"51","site_list":["http:\/\/wonka.physics.ncsu.edu\/pub\/VH-1\/index.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1991ApJ...371..684B"]},
		{"ascl_id":"1204.008","title":"StarFISH: For Inferring Star-formation Histories","credit":"Harris, Jason; Zaritsky, Dennis","abstract":"StarFISH is a suite of programs designed to determine the star formation history (SFH) of a stellar population, given multicolor stellar photometry and a library of theoretical isochrones. It constructs a library of synthetic color-magnitude diagrams from the isochrones, which includes the effects of extinction, photometric errors and completeness, and binarity. A minimization routine is then used to determine the linear combination of synthetic CMDs that best matches the observed photometry. The set of amplitudes modulating each synthetic CMD describes the star formation history of the observed stellar population.","topic_id":"28205","bibcode":"2012ascl.soft04008H","views":"49","site_list":["http:\/\/www.noao.edu\/staff\/jharris\/SFH\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001ApJS..136...25H"]},
		{"ascl_id":"1204.009","title":"STOKES: Modeling Radiative Transfer and Polarization","credit":"Goosmann, Ren\u00e9 W.","abstract":"STOKES was designed to perform three-dimensional radiative transfer simulations for astronomical applications. The code also considers the polarization properties of the radiation. The program is based on the Monte-Carlo method and treats optical and ultraviolet polarization induced by scattering off free electrons or dust grains. Emission and scattering regions can be arranged in various geometries within the model space, the computed continuum and line spectra can be evaluated at different inclinations and azimuthal viewing angles.","topic_id":"28208","bibcode":"2012ascl.soft04009G","views":"39","site_list":["http:\/\/www.stokes-program.info\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007A%26A...465..129G","http:\/\/adsabs.harvard.edu\/abs\/2011sf2a.conf..597M"]},
		{"ascl_id":"1204.010","title":"Shape: A 3D Modeling Tool for Astrophysics","credit":"Koning, Nico; Steffen, Wolfgang","abstract":"Shape is a flexible interactive 3D morpho-kinematical modeling application for astrophysics. It reduces the restrictions on the physical assumptions, data type and amount required for a reconstruction of an object's morphology. It applies interactive graphics and allows astrophysicists to provide a-priori knowledge about the object by interactively defining 3D structural elements. By direct comparison of model prediction with observational data, model parameters can then be automatically optimized to fit the observation.","topic_id":"28218","bibcode":"2012ascl.soft04010K","views":"42","site_list":["http:\/\/bufadora.astrosen.unam.mx\/shape\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010arXiv1003.2012S"]},
		{"ascl_id":"1204.011","title":"EXCOP: EXtraction of COsmological Parameters","credit":"Abroe, Matthew","abstract":"The EXtraction of COsmological Parameters software (EXCOP) is a set of C and IDL programs together with a very large database of cosmological models generated by <a href=\"http:\/\/ascl.net\/9909.004\">CMBFAST<\/a> that will compute likelihood functions for cosmological parameters given some CMB data. This is the software and database used in the <a href=\"http:\/\/xxx.lanl.gov\/abs\/astro-ph\/0105062\">Stompor et al. (2001)<\/a> analysis of a high resoultion Maxima1 CMB anisotropy map.","topic_id":"28220","bibcode":"2012ascl.soft04011A","views":"32","site_list":["http:\/\/groups.physics.umn.edu\/cosmology\/combat\/excop\/"],"ref_list":["http:\/\/xxx.lanl.gov\/abs\/astro-ph\/0105062"]},
		{"ascl_id":"1204.012","title":"VirGO: A Visual Browser for the ESO Science Archive Facility","credit":"Ch\u00e9reau, Fabien","abstract":"VirGO is the next generation Visual Browser for the ESO Science Archive Facility developed by the Virtual Observatory (VO) Systems Department. It is a plug-in for the popular open source software Stellarium adding capabilities for browsing professional astronomical data. VirGO gives astronomers the possibility to easily discover and select data from millions of observations in a new visual and intuitive way. Its main feature is to perform real-time access and graphical display of a large number of observations by showing instrumental footprints and image previews, and to allow their selection and filtering for subsequent download from the ESO SAF web interface. It also allows the loading of external FITS files or VOTables, the superimposition of Digitized Sky Survey (DSS) background images, and the visualization of the sky in a `real life' mode as seen from the main ESO sites. All data interfaces are based on Virtual Observatory standards which allow access to images and spectra from external data centers, and interaction with the ESO SAF web interface or any other VO applications supporting the PLASTIC messaging system.","topic_id":"28230","bibcode":"2012ascl.soft04012C","views":"51","site_list":["http:\/\/archive.eso.org\/cms\/tools-documentation\/visual-archive-browser.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ASPC..394..221C"]},
		{"ascl_id":"1204.013","title":"ORSA: Orbit Reconstruction, Simulation and Analysis","credit":"Tricarico, Pasquale","abstract":"ORSA is an interactive tool for scientific grade Celestial Mechanics computations. Asteroids, comets, artificial satellites, solar and extra-solar planetary systems can be accurately reproduced, simulated, and analyzed. The software uses JPL ephemeris files for accurate planets positions and has a Qt-based graphical user interface. It offers an  advanced 2D plotting tool and 3D OpenGL viewer and the standalone numerical library liborsa and can import asteroids and comets from all the known databases (MPC, JPL, Lowell, AstDyS, and NEODyS). In addition, it has an integrated download tool to update databases.","topic_id":"28280","bibcode":"2012ascl.soft04013T","views":"40","site_list":["http:\/\/orsa.sourceforge.net\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010cosp...38..687J"]},
		{"ascl_id":"1204.014","title":"WOMBAT: sWift Objects for Mhd BAsed on Tvd","credit":"Mendygral, Peter; Porter, David; Edmon, Paul; Delgado, Jennifer","abstract":"WOMBAT (sWift Objects for Mhd BAsed on Tvd) is an astrophysical fluid code that is an implementation of a non-relativistic MHD TVD scheme; an extension for relativistic MHD has been added. The code operates on 1, 2, and 3D Eulerian meshes (cartesian and cylindrical coordinates) with magnetic field divergence restriction controlled by a constrained transport (CT) scheme. The user can tune code performance to a given processor based on chip cache sizes. Proper settings yield significant speed-ups due to efficient cache reuse.","topic_id":"28392","bibcode":"2012ascl.soft04014M","views":"52","site_list":["http:\/\/www.astro.umn.edu\/groups\/compastro\/?q=node\/112"],"ref_list":["http:\/\/arxiv.org\/abs\/1203.2312"]},
		{"ascl_id":"1204.015","title":"PROFIT: Emission-line PROfile FITting routine","credit":"Riffel, Rogemar A.","abstract":"The PROFIT is an IDL routine to do automated fitting of emission-line profiles by Gaussian curves or Gauss-Hermite series otimized for use in Integral Field and Fabry-Perot data cubes. As output PROFIT gives two-dimensional FITS files for the emission-line flux distribution, centroid velocity, velocity dispersion and higher order Gauss-Hermite moments (h3 and h4).","topic_id":"28389","bibcode":"2012ascl.soft04015R","views":"45","site_list":["http:\/\/w3.ufsm.br\/rogemar\/software.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010Ap%26SS.327..239R","http:\/\/adsabs.harvard.edu\/abs\/2011A%26A...533A.104E"]},
		{"ascl_id":"1204.016","title":"ASCfit: Automatic Stellar Coordinate Fitting Package","credit":"Pickles, Andrew","abstract":"A modular software package for automatically fitting astrometric world coordinates (WCS) onto raw optical or infrared FITS images. Image stars are identified with stars in a reference catalog (USNO-A2 or 2MASS), and coordinates derived as a simple linear transformation from (X,Y) pixels to (RA,DEC) to the accuracy level of the reference catalog used. The package works with both optical and infrared images, at sidereal and non-sidereal tracking rates.","topic_id":"28388","bibcode":"2012ascl.soft04016P","views":"75","site_list":["http:\/\/secure.lcogt.net\/user\/apickles\/dev\/README.ascfit3.5.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002ASPC..281..207J"]},
		{"ascl_id":"1204.017","title":"epsnoise: Pixel noise in ellipticity and shear measurements","credit":"Melchior, Peter; Viola, Massimo","abstract":"epsnoise simulates pixel noise in weak-lensing ellipticity and shear measurements. This open-source python code can efficiently create an intrinsic ellipticity distribution, shear it, and add noise, thereby mimicking a \"perfect\" measurement that is not affected by shape-measurement biases. For theoretical studies, we provide the Marsaglia distribution, which describes the ratio of normal variables in the general case of non-zero mean and correlation. We also added a convenience method that evaluates the Marsaglia distribution for the ratio of moments of a Gaussian-shaped brightness distribution, which gives a very good approximation of the measured ellipticity distribution also for galaxies with different radial profiles. We provide four shear estimators, two based on the \u03b5 ellipticity measure, two on \u03c7. While three of them are essentially plain averages, we introduce a new estimator which requires a functional minimization.","topic_id":"28358","bibcode":"2012ascl.soft04017M","views":"36","site_list":["https:\/\/github.com\/pmelchior\/epsnoise"],"ref_list":["http:\/\/arxiv.org\/abs\/1204.5147"]},
		{"ascl_id":"1205.001","title":"Mechanic: Numerical MPI framework for dynamical astronomy","credit":"Slonina, Mariusz; Gozdziewski, Krzysztof; Migaszewski, Cezary","abstract":"The Mechanic package is a numerical framework for dynamical astronomy, designed to help in massive numerical simulations by efficient task management and unified data storage. The code is built on top of the Message Passing Interface (MPI) and Hierarchical Data Format (HDF5) standards and uses the Task Farm approach to manage numerical tasks. It relies on the core-module approach. The numerical problem implemented in the user-supplied module is separated from the host code (core). The core is designed to handle basic setup, data storage and communication between nodes in a computing pool. It has been tested on large CPU-clusters, as well as desktop computers. The Mechanic may be used in computing dynamical maps, data optimization or numerical integration.","topic_id":"28482","bibcode":"2012ascl.soft05001S","views":"31","site_list":["https:\/\/github.com\/mslonina\/Mechanic"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013MNRAS.430..533G","http:\/\/adsabs.harvard.edu\/abs\/2012ocpd.conf..125S"]},
		{"ascl_id":"1205.002","title":"p3d: General data-reduction tool for fiber-fed integral-field spectrographs","credit":"Sandin, C.; Becker, T.; Roth, M. M.; Gerssen, J.; Monreal-Ibero, A.; B\u00f6hm, P.; Weilbacher, P.","abstract":"p3d is semi-automatic data-reduction tool designed to be used with fiber-fed integral-field spectrographs. p3d is a highly general and freely available tool based on IDL but can be used with full functionality without an IDL license. It is easily extended to include improved algorithms, new visualization tools, and support for additional instruments. It uses a novel algorithm for automatic finding and tracing of spectra on the detector, and includes two methods of optimal spectrum extraction in addition to standard aperture extraction. p3d also provides tools to combine several images, perform wavelength calibration and flat field data.","topic_id":"28511","bibcode":"2012ascl.soft05002S","views":"35","site_list":["http:\/\/p3d.sourceforge.net\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010A%26A...515A..35S"]},
		{"ascl_id":"1205.003","title":"MIA+EWS: MIDI data reduction tool","credit":"K\u00f6hler, Rainer; Jaffe, Walter","abstract":"MIA+EWS is a package of two data reduction tools for MIDI data which uses power-spectrum analysis or the information contained in the spectrally-dispersed fringe measurements in order to estimate the correlated flux and the visibility as function of wavelength in the N-band. MIA, which stands for MIDI Interactive Analysis, uses a Fast Fourier Transformation to calculate the Fourier amplitudes of the fringe packets to calculate the correlated flux and visibility. EWS stands for Expert Work-Station, which is a collection of IDL tools to apply coherent visibility analysis to reduce MIDI data. The EWS package allows the user to control and examine almost every aspect of MIDI data and its reduction. The usual data products are the correlated fluxes, total fluxes and differential phase.","topic_id":"28529","bibcode":"2012ascl.soft05003K","views":"34","site_list":["http:\/\/home.strw.leidenuniv.nl\/~nevec\/MIDI\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008poii.conf..569K"]},
		{"ascl_id":"1205.004","title":"Turbospectrum: Code for spectral synthesis","credit":"Plez, B.","abstract":"Turbospectrum is a 1D LTE spectrum synthesis code which covers 600 molecules, is fast with many lines, and uses the treatment of line broadening described by Barklem & O\u2019Mara (1998).","topic_id":"28539","bibcode":"2012ascl.soft05004P","views":"62","site_list":["http:\/\/www.pages-perso-bertrand-plez.univ-montp2.fr\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1998A%26A...330.1109A","http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1205.2270D"]},
		{"ascl_id":"1205.005","title":"Fv: Interactive FITS file editor","credit":"Pence, William; Chai, Pan","abstract":"Fv is an easy-to-use graphical program for viewing and editing any FITS format image or table. The Fv software is small, completely self-contained and runs on Windows PCs, most Unix platforms and Mac OS-X. Fv also provides a portal into the <a href=\"http:\/\/heasarc.gsfc.nasa.gov\/hera\/\">Hera<\/a> data analysis service from the <a href=\"http:\/\/heasarc.gsfc.nasa.gov\/\">HEASARC<\/a>.","topic_id":"28390","bibcode":"2012ascl.soft05005P","views":"40","site_list":["http:\/\/heasarc.gsfc.nasa.gov\/docs\/software\/ftools\/fv\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1998ASPC..145...97P"]},
		{"ascl_id":"1205.006","title":"Flexion: IDL code for calculating gravitational flexion","credit":"Goldberg, David M.","abstract":"Gravitational flexion is a technique for measuring 2nd order gravitational lensing signals in background galaxies and radio lobes. Unlike shear, flexion directly probes variations of the potential field. Moreover, the information contained in flexion is orthogonal to what is found in the shear. Thus, we get the information \"for free.\"","topic_id":"28540","bibcode":"2012ascl.soft05006G","views":"39","site_list":["http:\/\/www.physics.drexel.edu\/~goldberg\/flexion\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007ApJ...666...51L"]},
		{"ascl_id":"1205.007","title":"Iris: The VAO SED Application","credit":"US Virtual Astronomical Observatory","abstract":"Iris is a downloadable Graphical User Interface (GUI) application which allows the astronomer to build and analyze wide-band Spectral Energy Distributions (SEDs). The components of Iris have been contributed by members of the VAO. <a href=\"http:\/\/ascl.net\/1210.016\">Specview<\/a>, contributed by STScI, provides a GUI for reading, editing, and displaying SEDs, as well as defining models and parameter values. <a href=\"http:\/\/ascl.net\/1107.005\">Sherpa<\/a>, contributed by the Chandra project at SAO, provides a library of models, fit statistics, and optimization methods; the underlying I\/O library, SEDLib, is a VAO product written by SAO to current IVOA (International Virtual Observatory Alliance) data model standards. NED is a service provided by IPAC for easy location of data for a given extragalactic source, including SEDs. SedImporter converts non-standard SED data files into a format supported by Iris.","topic_id":"28554","bibcode":"2012ascl.soft05007U","views":"38","site_list":["http:\/\/cxc.cfa.harvard.edu\/iris\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1205.2419"]},
		{"ascl_id":"1205.008","title":"Mayavi2: 3D Scientific Data Visualization and Plotting","credit":"Ramachandran, Prabhu; Varoquaux, Ga\u00ebl","abstract":"Mayavi is an open-source, general-purpose, 3D scientific visualization package. It seeks to provide easy and interactive tools for data visualization that fit with the scientific user's workflow. Mayavi provides several entry points: a full-blown interactive application; a Python library with both a MATLAB-like interface focused on easy scripting and a feature-rich object hierarchy; widgets associated with these objects for assembling in a domain-specific application, and plugins that work with a general purpose application-building framework.","topic_id":"28652","bibcode":"2012ascl.soft05008R","views":"44","site_list":["http:\/\/code.enthought.com\/projects\/mayavi\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007ApJ...660L.129W","http:\/\/arxiv.org\/abs\/1010.4891"]},
		{"ascl_id":"1205.009","title":"ARES: Automatic Routine for line Equivalent widths in stellar Spectra","credit":"Sousa, S\u00e9rgio G.","abstract":"ARES was developed for the measurement of Equivalent Width of absortion lines in stellar spectra; it can also be used to determine fundamental spectroscopic stellar parameters.The code reads a 1D FITS spectra and fits the requested lines in order to calculate the Equivalent width. The code is written in C++ based on the standard method of determining EWs. It automates the manual procedure that one normally carries out when using interactive routines such as the splot routine implemented in IRAF.","topic_id":"28723","bibcode":"2012ascl.soft05009S","views":"82","site_list":["http:\/\/www.astro.up.pt\/~sousasag\/ares\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007A%26A...469..783S"]},
		{"ascl_id":"1205.010","title":"Meudon PDR: Atomic & molecular structure of interstellar clouds","credit":"Le Petit, Franck; Roueff, Evelyne; Le Bourlot, Jacques; Nehm\u00e9, Cyrine","abstract":"The Meudon PDR code computes the atomic and molecular structure of interstellar clouds. It can be used to study the physics and chemistry of diffuse clouds, photodissociation regions (PDRs), dark clouds, or circumstellar regions. The model computes the thermal balance of a stationary plane-parallel slab of gas and dust illuminated by a radiation field and takes into account heating processes such as the photoelectric effect on dust, chemistry, cosmic rays, etc. and cooling resulting from infrared and millimeter emission of the abundant species. Chemistry is solved for any number of species and reactions. Once abundances of atoms and molecules and level excitation of the most important species have been computed at each point, line intensities and column densities can be deduced.","topic_id":"28744","bibcode":"2012ascl.soft05010L","views":"42","site_list":["http:\/\/pdr.obspm.fr\/PDRcode.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1205.5689","http:\/\/adsabs.harvard.edu\/abs\/2006ApJS..164..506L"]},
		{"ascl_id":"1205.011","title":"VOSpec: VO Spectral Analysis Tool","credit":"ESAVO Team","abstract":"VOSpec is a multi-wavelength spectral analysis tool with access to spectra, theoretical models and atomic and molecular line databases registered in the VO. The standard tools of VOSpec include line and continuum fitting, redshift and reddening correction, spectral arithmetic and convolution between spectra, equivalent width and flux calculations, and a best fitting algorithm for fitting selected SEDs to a TSAP service. VOSpec offers several display modes (tree vs table) and organising functionalities according to the available metadata for each service, including distance from the observation position.","topic_id":"28721","bibcode":"2012ascl.soft05011E","views":"51","site_list":["http:\/\/www.sciops.esa.int\/index.php?project=ESAVO&page=vospec"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ASPC..394..227A"]},
		{"ascl_id":"1206.001","title":"RegiStax: Alignment, stacking and processing of images","credit":"Berrevoets, Cor; DeClerq, Bart; George, Tony; Makolkin, Dmitry; Maxson, Paul; Pilz, Bob; Presnyakov, Pavel; Roel, Eric; Weiller, Sylvain","abstract":"RegiStax is software for alignment\/stacking\/processing of images; it was released over 10 years ago and continues to be developed and improved. The current version is RegiStax 6, which supports the following formats: AVI, SER, RFL (RegiStax Framelist), BMP, JPG, TIF, and FIT. This version has a shorter and simpler processing sequence than its predecessor, and optimizing isn't necessary anymore as a new image alignment method optimizes directly. The interface of RegiStax 6 has been simplified to look more uniform in appearance and functionality, and RegiStax 6 now uses Multi-core processing, allowing the user to have up to have multiple cores(recommended to use maximally 4) working simultaneous during alignment\/stacking.","topic_id":"28990","bibcode":"2012ascl.soft06001B","views":"40","site_list":["http:\/\/www.astronomie.be\/registax\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006JASS...23..453P"]},
		{"ascl_id":"1206.002","title":"FITS Liberator: Image processing software","credit":"Lindberg Christensen, Lars; Nielsen, Lars Holm; Nielsen, Kaspar K.; Johansen, Teis; Hurt, Robert; de Martin, David","abstract":"The ESA\/ESO\/NASA FITS Liberator makes it possible to process and edit astronomical science data in the FITS format to produce stunning images of the universe. Formerly a plugin for Adobe Photoshop, the current version of FITS Liberator is a stand-alone application and no longer requires Photoshop. This image processing software makes it possible to create color images using raw observations from a range of telescopes; the FITS Liberator continues to support the FITS and PDS formats, preferred by astronomers and planetary scientists respectively, which enables data to be processed from a wide range of telescopes and planetary probes, including ESO\u2019s Very Large Telescope, the NASA\/ESA Hubble Space Telescope, NASA\u2019s Spitzer Space Telescope, ESA\u2019s XMM\u2013Newton Telescope and Cassini\u2013Huygens or Mars Reconnaissance Orbiter.","topic_id":"28783","bibcode":"2012ascl.soft06002L","views":"43","site_list":["http:\/\/www.spacetelescope.org\/projects\/fits_liberator\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ASPC..442..169L"]},
		{"ascl_id":"1206.003","title":"STSDAS: IRAF Tools for Hubble Space Telescope data reduction","credit":"Science Software Branch of the Operations and Engineering Division at STScI","abstract":"The Space Telescope Science Data Analysis System (STSDAS) is a software package for reducing and analyzing astronomical data. It is layered on top of IRAF and provides general-purpose tools for astronomical data analysis as well as routines specifically designed for HST data. In particular, STSDAS contains all the programs used for the calibration and reduction of HST data in the STScI post-observation processing pipelines.","topic_id":"28785","bibcode":"2012ascl.soft06003S","views":"35","site_list":["http:\/\/www.stsci.edu\/institute\/software_hardware\/stsdas"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1994ASPC...61..339B"]},
		{"ascl_id":"1206.004","title":"MOLSCAT: MOLecular SCATtering","credit":"Hutson, Jeremy M.; Green, Sheldon","abstract":"MOLSCAT is a FORTRAN code for quantum mechanical (coupled channel) solution of the nonreactive molecular scattering problem and was developed to obtain collision rates for molecules in the interstellar gas which are needed to understand microwave and infrared astronomical observations. The code is implemented for various types of collision partners. In addition to the essentially exact close coupling method several approximate methods, including the Coupled States and Infinite Order Sudden approximations, are provided.","topic_id":"28848","bibcode":"2012ascl.soft06004H","views":"29","site_list":["http:\/\/www.giss.nasa.gov\/tools\/molscat\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1997ApJ...477..241W"]},
		{"ascl_id":"1206.005","title":"bhint: High-precision integrator for stellar systems","credit":"L\u00f6ckmann, Ulf","abstract":"bhint is a post-Newtonian, high-precision integrator for stellar systems surrounding a super-massive black hole. The algorithm makes use of the fact that the Keplerian orbits in such a potential can be calculated directly and are only weakly perturbed. For a given average number of steps per orbit, bhint is almost a factor of 100 more accurate than the standard Hermite method.","topic_id":"28952","bibcode":"2012ascl.soft06005L","views":"69","site_list":["http:\/\/www.astro.uni-bonn.de\/en\/download\/software\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008MNRAS.384..323L"]},
		{"ascl_id":"1206.006","title":"statpl: Goodness-of-fit for power-law distributed data","credit":"Maschberger, Thomas","abstract":"statpl estimates the parameter of power-law distributed data and calculates goodness-of-fit tests for them. Many objects studied in astronomy follow a power-law distribution function (DF), for example the masses of stars or star clusters. Such data is often analyzed by generating a histogram and fitting a straight line to it. The parameters obtained in this way can be severely biased, and the properties of the underlying DF, such as its shape or a possible upper limit, are difficult to extract. statpl is an (effectively) bias-free estimator for the exponent and the upper limit.","topic_id":"28953","bibcode":"2012ascl.soft06006M","views":"62","site_list":["http:\/\/www.astro.uni-bonn.de\/en\/download\/software\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009MNRAS.395..931M"]},
		{"ascl_id":"1206.007","title":"Plumix: Generating mass segregated star clusters","credit":"\u0160ubr, Ladislav","abstract":"Plumix is a small package for generating mass segregated star clusters. Its output can be directly used as input initial conditions for NBODY4 or NBODY6 code. Mass segregation stands as one of the most robust features of the dynamical evolution of self-gravitating star clusters. We formulate parametrized models of mass segregated star clusters in virial equilibrium. To this purpose we introduce mean inter-particle potentials for statistically described unsegregated systems and suggest a single-parameter generalization of its form which gives a mass-segregated state. Plumix is a numerical C-code generating the cluster according the algorithm given for construction of appropriate star cluster models. Their stability over several crossing-times is verified by following the evolution by means of direct N-body integration.","topic_id":"28954","bibcode":"2012ascl.soft06007S","views":"36","site_list":["http:\/\/www.astro.uni-bonn.de\/en\/download\/software\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008MNRAS.385.1673S"]},
		{"ascl_id":"1206.008","title":"Catena: Ensemble of stars orbit integration","credit":"Pflamm-Altenburg, Jan","abstract":"Catena integrates the orbits of an ensemble of stars using the chain-regularization method (Mikkola & Aarseth) with an embedded Runge-Kutta integration method of 9(8)th order (Prince & Dormand).","topic_id":"28955","bibcode":"2012ascl.soft06008P","views":"48","site_list":["http:\/\/www.astro.uni-bonn.de\/en\/download\/software\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006MNRAS.373..295P"]},
		{"ascl_id":"1206.009","title":"Libimf","credit":"Pflamm-Altenburg, Jan","abstract":"Libimf provides a collection of programming functions based on the general IMF-algorithm by Pflamm-Altenburg & Kroupa (2006).","topic_id":"28956","bibcode":"2012ascl.soft06009P","views":"33","site_list":["http:\/\/www.astro.uni-bonn.de\/en\/download\/software\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006MNRAS.373..295P"]},
		{"ascl_id":"1206.010","title":"mkj_libs: Helper routines for plane-fitting & analysis tools","credit":"Metz, Manuel","abstract":"mkj_libs provides a set of helper routines (vector operations, astrometry, statistical analysis of spherical data) for the main plane-fitting and analysis tools.","topic_id":"28957","bibcode":"2012ascl.soft06010M","views":"40","site_list":["http:\/\/www.astro.uni-bonn.de\/en\/download\/software\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007MNRAS.374.1125M"]},
		{"ascl_id":"1206.011","title":"Double Eclipsing Binary Fitting","credit":"Cagas, P.; Pejcha, O.","abstract":"The parameters of the mutual orbit of eclipsing binaries that are physically connected can be obtained by precision timing of minima over time through light travel time effect, apsidal motion or orbital precession. This, however, requires joint analysis of data from different sources obtained through various techniques and with insufficiently quantified uncertainties. In particular, photometric uncertainties are often underestimated, which yields too small uncertainties in minima timings if determined through analysis of a \u03c72 surface. The task is even more difficult for double eclipsing binaries, especially those with periods close to a resonance such as CzeV344, where minima get often blended with each other.\n\nThis code solves the double binary parameters simultaneously and then uses these parameters to determine minima timings (or more specifically O-C values) for individual datasets. In both cases, the uncertainties (or more precisely confidence intervals) are determined through bootstrap resampling of the original data. This procedure to a large extent alleviates the common problem with underestimated photometric uncertainties and provides a check on possible degeneracies in the parameters and the stability of the results. While there are shortcomings to this method as well when compared to Markov Chain Monte Carlo methods, the ease of the implementation of bootstrapping is a significant advantage.","topic_id":"28959","bibcode":"2012ascl.soft06011C","views":"43","site_list":["http:\/\/www.astronomy.ohio-state.edu\/~pejcha\/czev343\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1206.4058"]},
		{"ascl_id":"1206.012","title":"Time Utilities","credit":"Eastman, Jason","abstract":"Time Utilities are software tools that, in principal, allow one to calculate BJD to a precision of 1 \u03bcs for any target from anywhere on Earth or from any spacecraft. As the quality and quantity of astrophysical data continue to improve, the precision with which certain astrophysical events can be timed becomes limited not by the data themselves, but by the manner, standard, and uniformity with which time itself is referenced. While some areas of astronomy (most notably pulsar studies) have required absolute time stamps with precisions of considerably better than 1 minute for many decades, recently new areas have crossed into this regime. In particular, in the exoplanet community, we have found that the (typically unspecified) time standards adopted by various groups can differ by as much as a minute. Left uncorrected, this ambiguity may be mistaken for transit timing variations and bias eccentricity measurements. We recommend using BJD_TDB, the Barycentric Julian Date in the Barycentric Dynamical Time standard for any astrophysical event. The BJD_TDB is the most practical absolute time stamp for extraterrestrial phenomena, and is ultimately limited by the properties of the target system. We compile a general summary of factors that must be considered in order to achieve timing precisions ranging from 15 minutes to 1 \u03bcs, and provide software for download and online webapps for use.","topic_id":"28960","bibcode":"2012ascl.soft06012E","views":"48","site_list":["http:\/\/astroutils.astronomy.ohio-state.edu\/time\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010PASP..122..935E"]},
		{"ascl_id":"1206.013","title":"ImageJ: Image processing and analysis in Java","credit":"Rasband, W. S.","abstract":"ImageJ is a public domain Java image processing program inspired by NIH Image.  It can display, edit, analyze, process, save and print 8-bit, 16-bit and 32-bit images. It can read many image formats including TIFF, GIF, JPEG, BMP, DICOM, FITS and \"raw\". It supports \"stacks\", a series of images that share a single window. It is multithreaded, so time-consuming operations such as image file reading can be performed in parallel with other operations.","topic_id":"28784","bibcode":"2012ascl.soft06013R","views":"165","site_list":["http:\/\/rsb.info.nih.gov\/ij\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0611686"]},
		{"ascl_id":"1206.014","title":"ImageHealth: Quality Assurance for Large FITS Images","credit":"Kuehn, Kyler; Hupe, Ryan","abstract":"ImageHealth (IH) is a c program that makes use of standard CFITSIO routines to examine, in an automated fashion, .FITS images with any number of extensions, find objects within those images, and determine basic parameters of those images (stellar flux, background counts, FWHM, and ellipticity, along with sky background counts) in order to provide a snapshot of the quality of those images. A variety of python wrappers have also been written to test large numbers of such images and compare the results of ImageHealth to other image analysis programs, such as SourceExtractor. Additional IH-related tools will be made available in the future.\r\n\r\nEfforts are now focused on an implementation of IH specifically for the <a href=\"http:\/\/www.darkenergysurvey.org\">Dark Energy Camera<\/a>; we do not envision providing support for the instrument-independent version of the code offered here though comments, questions, and feedback are welcome.","topic_id":"28890","bibcode":"2012ascl.soft06014K","views":"38","site_list":["http:\/\/gate.hep.anl.gov\/kkuehn\/imagehealth.c"],"ref_list":["http:\/\/lanl.arxiv.org\/abs\/1204.0066"]},
		{"ascl_id":"1207.001","title":"EXOFAST: Fast transit and\/or RV fitter for single exoplanet","credit":"Eastman, Jason; Gaudi, B. Scott; Agol, Eric","abstract":"We present EXOFAST, a fast, robust suite of routines written in IDL which is designed to fit exoplanetary transits and radial velocity variations simultaneously or separately, and characterize the parameter uncertainties and covariances with a Differential Evolution Markov Chain Monte Carlo method. Our code self-consistently incorporates both data sets to simultaneously derive stellar parameters along with the transit and RV parameters, resulting in consistent, but tighter constraints on an example fit of the discovery data of HAT-P-3b that is well-mixed in under two minutes on a standard desktop computer. EXOFAST has an easy-to-use online interface for several basic features of our transit and radial velocity fitting.","topic_id":"29034","bibcode":"2012ascl.soft07001E","views":"44","site_list":["http:\/\/astroutils.astronomy.ohio-state.edu\/exofast\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012AJ....143..107W"]},
		{"ascl_id":"1207.002","title":"HiGPUs: Hermite&#39;s N-body integrator running on Graphic Processing Units","credit":"Spera, M.; Capuzzo Dolcetta, R.; Punzo, D.","abstract":"HiGPUs is an implementation of the numerical integration of the classical, gravitational, N-body problem, based on a 6th order Hermite\u2019s integration scheme with block time steps, with a direct evaluation of the particle-particle forces. The main innovation of this code is its full parallelization, exploiting both OpenMP and MPI in the use of the multicore Central Processing Units as well as either Compute Unified Device Architecture (CUDA) or OpenCL for the hosted Graphic Processing Units. We tested both performance and accuracy of the code using up to 256 GPUs in the supercomputer IBM iDataPlex DX360M3 Linux Infiniband Cluster provided by the italian supercomputing consortium CINECA, for values of N \u2264 8 millions. We were able to follow the evolution of a system of 8 million bodies for few crossing times, task previously unreached by direct summation codes. \n\nHiGPUs is also available as part of the <a href=\"http:\/\/ascl.net\/1107.007\">AMUSE<\/a> project.","topic_id":"29079","bibcode":"2012ascl.soft07002S","views":"48","site_list":["http:\/\/astrowww.phys.uniroma1.it\/dolcetta\/HPCcodes\/HiGPUs.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1207.2367"]},
		{"ascl_id":"1207.003","title":"VAC: Versatile Advection Code","credit":"T\u00f3th, G\u00e1bor; Keppens, Rony","abstract":"The Versatile Advection Code (VAC) is a freely available general hydrodynamic and magnetohydrodynamic simulation software that works in 1, 2 or 3 dimensions on Cartesian and logically Cartesian grids. VAC runs on any Unix\/Linux system with a Fortran 90 (or 77) compiler and Perl interpreter. VAC can run on parallel machines using either the Message Passing Interface (MPI) library or a High Performance Fortran (HPF) compiler.","topic_id":"29080","bibcode":"2012ascl.soft07003T","views":"44","site_list":["http:\/\/grid.engin.umich.edu\/~gtoth\/VAC\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007A%26A...467.1299E"]},
		{"ascl_id":"1207.004","title":"Hyperion: Parallelized 3D Dust Continuum Radiative Transfer Code","credit":"Robitaille, Thomas","abstract":"Hyperion is a three-dimensional dust continuum Monte-Carlo radiative transfer code that is designed to be as generic as possible, allowing radiative transfer to be computed through a variety of three-dimensional grids. The main part of the code is problem-independent, and only requires an arbitrary three-dimensional density structure, dust properties, the position and properties of the illuminating sources, and parameters controlling the running and output of the code. Hyperion is parallelized, and is shown to scale well to thousands of processes. Two common benchmark models for protoplanetary disks were computed, and the results are found to be in excellent agreement with those from other codes. Finally, to demonstrate the capabilities of the code, dust temperatures, SEDs, and synthetic multi-wavelength images were computed for a dynamical simulation of a low-mass star formation region.","topic_id":"29173","bibcode":"2012ascl.soft07004R","views":"38","site_list":["http:\/\/www.hyperion-rt.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1112.1071"]},
		{"ascl_id":"1207.005","title":"L.A.Cosmic: Laplacian Cosmic Ray Identification","credit":"van Dokkum, Pieter G.; Bloom, J.; Tewes, Malte","abstract":"Conventional algorithms for rejecting cosmic rays in single CCD exposures rely on the contrast between cosmic rays and their surroundings and may produce erroneous results if the point-spread function is smaller than the largest cosmic rays. This code uses a robust algorithm for cosmic-ray rejection, based on a variation of Laplacian edge detection. The algorithm identifies cosmic rays of arbitrary shapes and sizes by the sharpness of their edges and reliably discriminates between poorly sampled point sources and cosmic rays. Examples of its performance are given for spectroscopic and imaging data, including Hubble Space Telescope Wide Field Planetary Camera 2 images, in the code paper.","topic_id":"29180","bibcode":"2012ascl.soft07005V","views":"39","site_list":["http:\/\/www.astro.yale.edu\/dokkum\/lacosmic\/","http:\/\/obswww.unige.ch\/~tewes\/cosmics_dot_py\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001PASP..113.1420V"]},
		{"ascl_id":"1207.006","title":"dcr: Cosmic Ray Removal","credit":"Pych, W.","abstract":"This code provides a method for detecting cosmic rays in single images. The algorithm is based on a simple analysis of the histogram of the image data and does not use any modeling of the picture of the object. It does not require a good signal-to-noise ratio in the image data. Identification of multiple-pixel cosmic-ray hits is realized by running the procedure for detection and replacement iteratively. The method is very effective when applied to the images with spectroscopic data, and is also very fast in comparison with other single-image algorithms found in astronomical data-processing packages. Practical implementation and examples of application are presented in the code paper.","topic_id":"29181","bibcode":"2012ascl.soft07006P","views":"51","site_list":["http:\/\/users.camk.edu.pl\/pych\/DCR\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004PASP..116..148P"]},
		{"ascl_id":"1207.007","title":"Astropysics: Astrophysics utilities for python","credit":"Tollerud, Erik","abstract":"Astropysics is a library containing a variety of utilities and algorithms for reducing, analyzing, and visualizing astronomical data. Best of all, it encourages the user to leverage the existing capabilities of Python to make this quick, easy, and as painless as cutting-edge science can even actually be. There do exist other Python packages with some of the capabilities of this project, but the goal of this project is to integrate all these tools together and make them interact in the most straightforward ways possible.","topic_id":"29182","bibcode":"2012ascl.soft07007T","views":"85","site_list":["http:\/\/packages.python.org\/Astropysics\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1112.1067"]},
		{"ascl_id":"1207.008","title":"xSonify: Sonification software","credit":"Candey, Robert M.; Schertenleib, Anton; Qian, Frances; Boller, Ryan; Diaz, Wanda; Harris, Bernard","abstract":"xSonify maps scientific data to acoustic sequences. Listening to data can help discover patterns in huge amounts of data. Written in Java, xSonify allows visually impaired people to examine numerical data for patterns. The data can be imported from local files or from remote databases via the Internet. Single results of measurements from spacecraft instruments can be selected by their corresponding variables in a specific time frame. The results are transformed into MIDI sequences which can be played with a selection of different instruments from a soundbank. Another software module enables xSonify to convert the sonified data into other sound formats to make it easier to archive and exchange the Sonification results with other scientists.","topic_id":"29095","bibcode":"2012ascl.soft07008C","views":"50","site_list":["http:\/\/spdf.gsfc.nasa.gov\/research\/sonification\/sonification_software.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012IAUS..285..133D"]},
		{"ascl_id":"1207.009","title":"PyFITS: Python FITS Module","credit":"Barrett, Paul; Hsu, J. C.; Hanley, Chris; Taylor, James; Droettboom, Michael; Bray, Erik M.; Hack, Warren; Greenfield, Perry; Wyckoff, Eric; Jedrzejewski, Robert; De La Pena, Michele; Hodge, Phil","abstract":"PyFITS provides an interface to FITS formatted files in the Python scripting language and <a href=\"http:\/\/ascl.net\/1207.011\">PyRAF<\/a>, the Python-based interface to IRAF. It is useful both for interactive data analysis and for writing analysis scripts in Python using FITS files as either input or output. PyFITS is a development project of the Science Software Branch at the Space Telescope Science Institute.","topic_id":"29184","bibcode":"2012ascl.soft07009B","views":"85","site_list":["http:\/\/www.stsci.edu\/institute\/software_hardware\/pyfits"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000ASPC..216...67B"]},
		{"ascl_id":"1207.010","title":"PySALT: SALT science pipeline","credit":"Crawford, S. M.; Still, M.; Schellart, P.; Balona, L.; Buckley, D. A. H.; Gulbis, A. A. S.; Kniazev, A.; Kotze, M.; Loaring, N.; Nordsieck, K. H.; Pickering, T. E.; Potter, S.; Romero Colmenero, E.; Vaisanen, P.; Wiliams, T.; Zietsman, E.","abstract":"The PySALT user package contains the primary reduction and analysis software tools for the SALT telescope. Currently, these tools include basic data reductions for RSS and SALTICAM in both imaging, spectroscopic, and slot modes. Basic analysis software for slot mode data is also provided. These tools are primarily written in python\/<a href=\"http:\/\/ascl.net\/1207.011\">PyRAF<\/a> with some additional IRAF code.","topic_id":"29186","bibcode":"2012ascl.soft07010C","views":"36","site_list":["http:\/\/pysalt.salt.ac.za\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010SPIE.7737E..54C"]},
		{"ascl_id":"1207.011","title":"PyRAF: Python alternative for IRAF","credit":"Science Software Branch at STScI","abstract":"PyRAF is a command language for running IRAF tasks that is based on the Python scripting language. It gives users the ability to run IRAF tasks in an environment that has all the power and flexibility of Python. PyRAF can be installed along with an existing IRAF installation; users can then choose to run either PyRAF or the IRAF CL.","topic_id":"29185","bibcode":"2012ascl.soft07011S","views":"76","site_list":["http:\/\/www.stsci.edu\/institute\/software_hardware\/pyraf\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012SASS...31..159G"]},
		{"ascl_id":"1207.012","title":"PCA: Principal Component Analysis for spectra modeling","credit":"Hurley, Peter D.; Oliver, Seb; Farrah, Duncan; Wang, Lingyu; Efstathiou, Andreas","abstract":"The mid-infrared spectra of ultraluminous infrared galaxies (ULIRGs) contain a variety of spectral features that can be used as diagnostics to characterize the spectra. However, such diagnostics are biased by our prior prejudices on the origin of the features. Moreover, by using only part of the spectrum they do not utilize the full information content of the spectra. Blind statistical techniques such as principal component analysis (PCA) consider the whole spectrum, find correlated features and separate them out into distinct components.\r\n\r\nThis code, written in IDL, classifies principal components of IRS spectra to define a new classification scheme using 5D Gaussian mixtures modelling. The five PCs and average spectra for the four classifications to classify objects are made available with the code.","topic_id":"29189","bibcode":"2012ascl.soft07012H","views":"39","site_list":["http:\/\/www.phys.susx.ac.uk\/~pdh21\/PCA\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1205.6312"]},
		{"ascl_id":"1207.013","title":"JKTEBOP: Analyzing light curves of detached eclipsing binaries","credit":"Southworth, John","abstract":"The JKTEBOP code is used to fit a model to the light curves of detached eclipsing binary stars in order to derive the radii of the stars as well as various other quantities. It is very stable and includes extensive Monte Carlo or bootstrapping error analysis algorithms. It is also excellent for transiting extrasolar planetary systems. All input and output is done by text files; JKTEBOP is written in almost-standard FORTRAN 77 using first the g77 compiler and now the ifort compiler.","topic_id":"29190","bibcode":"2012ascl.soft07013S","views":"44","site_list":["http:\/\/www.astro.keele.ac.uk\/jkt\/codes\/jktebop.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1207.5797"]},
		{"ascl_id":"1207.014","title":"wvrgcal: Correction of atmospheric phase fluctuations in ALMA observations","credit":"Nikolic, Bojan; Graves, Sarah F.; Bolton, Rosie C.; Richer, John S.","abstract":"wvrgcal is a command line front end to LibAIR, the atmospheric inference library for phase correction of ALMA data using water vapour radiometers, and is the user-facing application for calculating atmospheric phase correction from WVR data. wvrgcal outputs a CASA gain calibration table which can then be applied to the observed data in the usual way.","topic_id":"29191","bibcode":"2012ascl.soft07014N","views":"61","site_list":["http:\/\/www.mrao.cam.ac.uk\/~bn204\/alma\/wvrsoft.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1207.6069"]},
		{"ascl_id":"1208.001","title":"Astrometry.net: Astrometric calibration of images","credit":"Lang, Dustin; Hogg, David W.; Mierle, Keir; Blanton, Michael; Roweis, Sam","abstract":"Astrometry.net is a reliable and robust system that takes as input an astronomical image and returns as output the pointing, scale, and orientation of that image (the astrometric calibration or World Coordinate System information). The system requires no first guess, and works with the information in the image pixels alone; that is, the problem is a generalization of the \"lost in space\" problem in which nothing\u2014not even the image scale\u2014is known. After robust source detection is performed in the input image, asterisms (sets of four or five stars) are geometrically hashed and compared to pre-indexed hashes to generate hypotheses about the astrometric calibration. A hypothesis is only accepted as true if it passes a Bayesian decision theory test against a null hypothesis. With indices built from the USNO-B catalog and designed for uniformity of coverage and redundancy, the success rate is &gt;99.9% for contemporary near-ultraviolet and visual imaging survey data, with no false positives. The failure rate is consistent with the incompleteness of the USNO-B catalog; augmentation with indices built from the Two Micron All Sky Survey catalog brings the completeness to 100% with no false positives. We are using this system to generate consistent and standards-compliant meta-data for digital and digitized imaging from plate repositories, automated observatories, individual scientific investigators, and hobbyists.","topic_id":"29303","bibcode":"2012ascl.soft08001L","views":"67","site_list":["http:\/\/astrometry.net\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010AJ....139.1782L"]},
		{"ascl_id":"1208.002","title":"BINSYN: Simulating Spectra and Light Curves of Binary Systems with or without Accretion Disks","credit":"Linnell, Albert P.; DeStefano, Paul; Hubeny, Ivan","abstract":"The BINSYN program suite is a collection of programs for analysis of binary star systems with or without an optically thick accretion disk. BINSYN produces synthetic spectra of individual binary star components plus a synthetic spectrum of the system. If the system includes an accretion disk, BINSYN also produces a separate synthetic spectrum of the disk face and rim. A system routine convolves the synthetic spectra with filter profiles of several photometric standards to produce absolute synthetic photometry output. The package generates synthetic light curves and determines an optimized solution for system parameters.","topic_id":"29309","bibcode":"2012ascl.soft08002L","views":"67","site_list":["https:\/\/github.com\/AlLinnell\/Binsyn\/wiki"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010ApJ...719..271L"]},
		{"ascl_id":"1208.003","title":"APT: Aperture Photometry Tool","credit":"Laher, Russ","abstract":"Aperture Photometry Tool (APT) is software for astronomers and students interested in manually exploring the photometric qualities of astronomical images. It has a graphical user interface (GUI) which allows the image data associated with aperture photometry calculations for point and extended sources to be visualized and, therefore, more effectively analyzed. Mouse-clicking on a source in the displayed image draws a circular or elliptical aperture and sky annulus around the source and computes the source intensity and its uncertainty, along with several commonly used measures of the local sky background and its variability. The results are displayed and can be optionally saved to an aperture-photometry-table file and plotted on graphs in various ways using functions available in the software. APT is geared toward processing sources in a small number of images and is not suitable for bulk processing a large number of images, unlike other aperture photometry packages (e.g., <a href=\"http:\/\/ascl.net\/1010.064\">SExtractor<\/a>). However, APT does have a convenient source-list tool that enables calculations for a large number of detections in a given image. The source-list tool can be run either in automatic mode to generate an aperture photometry table quickly or in manual mode to permit inspection and adjustment of the calculation for each individual detection. APT displays a variety of useful graphs,  including image histogram, and aperture slices, source scatter plot, sky scatter plot, sky histogram, radial profile, curve of growth, and aperture-photometry-table scatter plots and histograms. APT has functions for customizing calculations, including outlier rejection, pixel \u201cpicking\u201d and \u201czapping,\u201d and a selection of source and sky models. The radial-profile-interpolation source model, accessed via the radial-profile-plot panel, allows recovery of source intensity from pixels with missing data and can be especially beneficial in crowded fields.","topic_id":"29315","bibcode":"2012ascl.soft08003L","views":"65","site_list":["http:\/\/www.aperturephotometry.org\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011AJ....142...25R"]},
		{"ascl_id":"1208.004","title":"PyKE: Reduction and analysis of Kepler Simple Aperture Photometry data","credit":"Still, Martin; Barclay, Tom","abstract":"PyKE is a python-based <a href=\"http:\/\/ascl.net\/1207.011\">PyRAF<\/a> package that can also be run as a stand-alone program within a unix-based shell without compiling against PyRAF. It is a group of tasks developed for the reduction and analysis of Kepler Simple Aperture Photometry (SAP) data of individual targets with individual characteristics. The main purposes of these tasks are to i) re-extract light curves from manually-chosen pixel apertures and ii) cotrend and\/or detrend the data in order to reduce or remove systematic noise structure using methods tunable to user and target-specific requirements. PyKE is an open source project and contributions of new tasks or enhanced functionality of existing tasks by the community are welcome.","topic_id":"29327","bibcode":"2012ascl.soft08004S","views":"66","site_list":["http:\/\/keplergo.arc.nasa.gov\/PyKE.shtml"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012PASP..124..963K"]},
		{"ascl_id":"1208.005","title":"PSM: Planck Sky Model","credit":"Ashdown, Mark; Aumont, Jonathan; Baccigalupi, Carlo; Banday, Anthony; Basak, Soumen; Bernard, Jean-Philippe; Betoule, Marc; Bouchet, Fran\u00e7ois; Castex, Guillaume; Clements, Dave; Da Silva, Antonio; De Zotti, Gianfranco; Delabrouille, Jacques; Dickinson, Clive; Dodu, Fabrice; Dolag, Klaus; Elsner, Franz; Fauvet, Lauranne; Fa\u00ff, Gilles; Giardino, Giovanna; Gonzalez-Nuevo, Joaquin; le Jeune, Maude; Leach, Samuel; Lesgourgues, Julien; Liguori, Michele; Macias, Juan; Massardi, Marcella; Matarrese, Sabino; Mazzotta, Pasquale; Melin, Jean-Baptiste; Miville-Desch\u00eanes, Marc-Antoine; Montier, Ludovic; Mottet, Sylvain; Paladini, Roberta; Partridge, Bruce; Piffaretti, Rocco; Pr\u00e9zeau, Gary; Prunet, Simon; Ricciardi, Sara; Roman, Matthieu; Schaefer, Bjorn; Toffolatti, Luigi","abstract":"The Planck Sky Model (PSM) is a global representation of the multi-component sky at frequencies ranging from a few GHz to a few THz. It summarizes in a synthetic way as much of our present knowledge as possible of the GHz sky. PSM is a complete and versatile set of programs and data that can be used for the simulation or the prediction of sky emission in the frequency range of typical CMB experiments, and in particular of the Planck sky mission. It was originally  developed as part of the activities of Planck component separation Working Group (or \"Working Group 2\" - WG2), and of the ADAMIS team at APC.\r\n\r\nPSM gives users the opportunity to investigate the model in some depth: look at its parameters, visualize its predictions for all individual components in various formats, simulate sky emission compatible with a given parameter set, and observe the modeled sky with a synthetic instrument. In particular, it makes possible the simulation of sky emission maps as could be plausibly observed by Planck or other CMB experiments that can be used as inputs for the development and testing of data processing and analysis techniques.","topic_id":"29328","bibcode":"2012ascl.soft08005A","views":"44","site_list":["http:\/\/www.apc.univ-paris7.fr\/~delabrou\/PSM\/psm.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1207.3675"]},
		{"ascl_id":"1208.006","title":"ccogs: Cosmological Calculations on the GPU","credit":"Bard, Deborah; Bellis, Matthew; Allen, Mark T.; Yepremyan, Hasmik; Kratochvil, Jan M.","abstract":"This suite contains two packages for computing cosmological quantities on the GPU: aperture_mass, which calculates the aperture mass map for a given dataset using the filter proposed by Schirmer et al (2007) (an NFW profile with exponential cut-offs at zero and large radii), and angular_correlation, which calculates the 2-pt angular correlation function using data and a flat distribution of randomly generated galaxies. A particular estimator is chosen, but the user has the flexibility to explore other estimators.","topic_id":"29346","bibcode":"2012ascl.soft08006B","views":"49","site_list":["https:\/\/github.com\/djbard\/ccogs"],"ref_list":["http:\/\/arxiv.org\/abs\/1208.3658"]},
		{"ascl_id":"1208.007","title":"Big MACS: Accurate photometric calibration","credit":"Kelly, P. L.; von der Linden, A.; Applegate, D.; Allen, M.; Allen, S. W.; Burchat, P. R.; Burke, D. L.; Ebeling, H.; Capak, P.; Czoske, O.; Donovan, D.; Mantz, A.; Morris, R. G.","abstract":"Big MACS is a Python program that estimates an accurate photometric calibration from only an input catalog of stellar magnitudes and filter transmission functions. The user does not have to measure color terms which can be difficult to characterize. Supplied with filter transmission functions, Big MACS synthesizes an expected stellar locus for your data and then simultaneously solves for all unknown zeropoints when fitting to the instrumental locus. The code uses a spectroscopic model for the SDSS stellar locus in color-color space and filter functions to compute expected locus. The stellar locus model is corrected for Milky Way reddening. If SDSS or 2MASS photometry is available for stars in field, Big MACS can yield a highly accurate absolute calibration.","topic_id":"29348","bibcode":"2012ascl.soft08007K","views":"76","site_list":["https:\/\/code.google.com\/p\/big-macs-calibrate\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1208.0602"]},
		{"ascl_id":"1208.008","title":"TiRiFiC: Tilted Ring Fitting Code","credit":"J\u00f3zsa, Gyula I. G.; Kenn, Franz; Oosterloo, Thomas A.; Klein, Ulrich","abstract":"Tilted Ring Fitting Code (TiRiFiC) is a prototype computer program to construct simulated (high-resolution) astronomical spectroscopic 3d-observations (data cubes) of simple kinematical and morphological models of rotating (galactic) disks. It is possible to automatically optimize the parameterizations of constructed model disks to fit spectroscopic (3d-) observations via a \u03c72 minimization. TiRiFiC is currently implemented as an add-on to the Groningen Image Processing System (GIPSY) software package and  attempts to provide a method to automatically fit an extended tilted-ring model directly to a data cube.","topic_id":"29374","bibcode":"2012ascl.soft08008J","views":"50","site_list":["http:\/\/www.astron.nl\/~jozsa\/tirific\/index.html"],"ref_list":["http:\/\/esoads.eso.org\/abs\/2007A%26A...468..731J"]},
		{"ascl_id":"1208.009","title":"BLOBCAT: Software to Catalog Blobs","credit":"Hales, C. A.; Murphy, T.; Curran, J. R.; Middelberg, E.; Gaensler, B. M.; Norris, R. P.","abstract":"BLOBCAT is a source extraction software that utilizes the flood fill algorithm to detect and catalog blobs, or islands of pixels representing sources, in 2D astronomical images. The software is designed to process radio-wavelength images of both Stokes I intensity and linear polarization, the latter formed through the quadrature sum of Stokes Q and U intensities or as a by-product of rotation measure synthesis. BLOBCAT corrects for two systematic biases to enable the flood fill algorithm to accurately measure flux densities for Gaussian sources. BLOBCAT exhibits accurate measurement performance in total intensity and, in particular, linear polarization, and is particularly suited to the analysis of large survey data.","topic_id":"29385","bibcode":"2012ascl.soft08009H","views":"80","site_list":["http:\/\/blobcat.sourceforge.net\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1205.5313H"]},
		{"ascl_id":"1208.010","title":"BASE: Bayesian Astrometric and Spectroscopic Exoplanet Detection and Characterization Tool","credit":"Schulze-Hartung, Tim","abstract":"BASE is a novel program for the combined or separate Bayesian analysis of astrometric and radial-velocity measurements of potential exoplanet hosts and binary stars. The tool fulfills two major tasks of exoplanet science, namely the detection of exoplanets and the characterization of their orbits. BASE was developed to provide the possibility of an integrated Bayesian analysis of stellar astrometric and Doppler-spectroscopic measurements with respect to their binary or planetary companions\u2019 signals, correctly treating the astrometric measurement uncertainties and allowing to explore the whole parameter space without the need for informative prior constraints. The tool automatically diagnoses convergence of its Markov chain Monte Carlo (MCMC[2]) sampler to the posterior and regularly outputs status information. For orbit characterization, BASE delivers important results such as the probability densities and correlations of model parameters and derived quantities. BASE is a highly configurable command-line tool developed in Fortran 2008 and compiled with GFortran. Options can be used to control the program\u2019s behaviour and supply information such as the stellar mass or prior information. Any option can be supplied in a configuration file and\/or on the command line.","topic_id":"29389","bibcode":"2012ascl.soft08010S","views":"78","site_list":["http:\/\/www.mpia.de\/homes\/schulze\/base.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1207.6276"]},
		{"ascl_id":"1208.011","title":"Fewbody: Numerical toolkit for simulating small-N gravitational dynamics","credit":"Fregeau, John","abstract":"Fewbody is a numerical toolkit for simulating small-N gravitational dynamics. It is a general N-body dynamics code, although it was written for the purpose of performing scattering experiments, and therefore has several features that make it well-suited for this purpose. Fewbody uses the 8th-order Runge-Kutta Prince-Dormand integration method with 9th-order error estimate and adaptive timestep to advance the N-body system forward in time. It integrates the usual formulation of the N-body equations in configuration space, but allows for the option of global pairwise Kustaanheimo-Stiefel (K-S) regularization (Heggie 1974; Mikkola 1985). The code uses a binary tree algorithm to classify the N-body system into a set of independently bound hierarchies, and performs collisions between stars in the \u201csticky star\u201d approximation. Fewbody contains a collection of command line utilities that can be used to perform individual scattering and N-body interactions, but is more generally a library of functions that can be used from within other codes.","topic_id":"29390","bibcode":"2012ascl.soft08011F","views":"40","site_list":["http:\/\/sourceforge.net\/projects\/fewbody\/files\/"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0401004"]},
		{"ascl_id":"1208.012","title":"Swarm-NG: Parallel n-body Integrations","credit":"Dindar, Saleh; Ford, Eric B.; Juric, Mario; Young, In Yeo; Gao, Jianwei; Boley, Aaron C.; Nelson, Benjamin; Peters, Jorg","abstract":"Swarm-NG is a C++ library for the efficient direct integration of many n-body systems using highly-parallel Graphics Processing Units (GPU). Swarm-NG focuses on many few-body systems, e.g., thousands of systems with 3...15 bodies each, as is typical for the study of planetary systems; the code parallelizes the simulation, including both the numerical integration of the equations of motion and the evaluation of forces using NVIDIA's \"Compute Unified Device Architecture\" (CUDA) on the GPU. Swarm-NG includes optimized implementations of 4th order time-symmetrized Hermite integration and mixed variable symplectic integration as well as several sample codes for other algorithms to illustrate how non-CUDA-savvy users may themselves introduce customized integrators into the Swarm-NG framework. Applications of Swarm-NG include studying the late stages of planet formation, testing the stability of planetary systems and evaluating the goodness-of-fit between many planetary system models and observations of extrasolar planet host stars (e.g., radial velocity, astrometry, transit timing). While Swarm-NG focuses on the parallel integration of many planetary systems,the underlying integrators could be applied to a wide variety of problems that require repeatedly integrating a set of ordinary differential equations many times using different initial conditions and\/or parameter values.","topic_id":"29392","bibcode":"2012ascl.soft08012D","views":"43","site_list":["http:\/\/www.astro.ufl.edu\/~eford\/code\/swarm\/doxygen\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1208.1157"]},
		{"ascl_id":"1208.013","title":"SolarSoft: Programming and data analysis environment for solar physics","credit":"Freeland, S. L.; Handy, B. N.","abstract":"SolarSoft is a set of integrated software libraries, data bases, and system utilities which provide a common programming and data analysis environment for Solar Physics. The SolarSoftWare (SSW) system is built from Yohkoh, SOHO, SDAC and Astronomy libraries and draws upon contributions from many members of those projects. It is primarily an IDL based system, although some instrument teams integrate executables written in other languages. The SSW environment provides a consistent look and feel at widely distributed co-investigator institutions to facilitate data exchange and to stimulate coordinated analysis. Commonalities and overlap in solar data and analysis goals are exploited to permit application of fundamental utilities to the data from many different solar instruments. The use of common libraries, utilities, techniques and interfaces minimizes the learning curve for investigators who are analyzing new solar data sets, correlating results from multiple experiments or performing research away from their home institution.","topic_id":"29393","bibcode":"2012ascl.soft08013F","views":"85","site_list":["http:\/\/www.lmsal.com\/solarsoft\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1998SoPh..182..497F"]},
		{"ascl_id":"1208.014","title":"MPI-AMRVAC: MPI-Adaptive Mesh Refinement-Versatile Advection Code","credit":"van der Holst, Bar; Keppens, Rony; Meliani, Zakaria; Porth, Oliver; van Marle, Allard Jan; Delmont, Peter; Xia, Chun","abstract":"MPI-AMRVAC is an MPI-parallelized Adaptive Mesh Refinement code, with some heritage (in the solver part) to the Versatile Advection Code or VAC, initiated by G\u00e1bor T\u00f3th at the Astronomical Institute at Utrecht in November 1994, with help from Rony Keppens since 1996. Previous incarnations of the Adaptive Mesh Refinement version of VAC were of restricted use only, and have been used for basic research in AMR strategies, or for well-targeted applications. This MPI version uses a full octree block-based approach, and allows for general orthogonal coordinate systems. MPI-AMRVAC aims to advance any system of (primarily hyperbolic) partial differential equations by a number of different numerical schemes. The emphasis is on (near) conservation laws, with shock-dominated problems as a main research target. The actual equations are stored in separate modules, can be added if needed, and they can be selected by a simple configuration of the VACPP preprocessor. The dimensionality of the problem is also set through VACPP. The numerical schemes are able to handle discontinuities and smooth flows as well.","topic_id":"28995","bibcode":"2012ascl.soft08014V","views":"39","site_list":["http:\/\/homes.esat.kuleuven.be\/~keppens\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012JCoPh.231..718K"]},
		{"ascl_id":"1208.015","title":"Lare3d: Lagrangian-Eulerian remap scheme for MHD","credit":"Arber, T. D.; Longbottom, A. W.; Gerrard, C. L.; Milne, A. M.","abstract":"Lare3d is a Lagrangian-remap code for solving the non-linear MHD equations in three spatial dimensions.","topic_id":"29429","bibcode":"2012ascl.soft08015A","views":"43","site_list":["http:\/\/ccpforge.cse.rl.ac.uk\/gf\/project\/lare3d\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001JCoPh.171..151A","http:\/\/arxiv.org\/abs\/1208.5885"]},
		{"ascl_id":"1208.016","title":"VARTOOLS: Light Curve Analysis Program","credit":"Hartman, Joel","abstract":"The VARTOOLS program is a command line utility that provides tools for analyzing time series astronomical data. It implements a number of routines for calculating variability\/periodicity statistics of light curves, as well as tools for modifying and filtering light curves.","topic_id":"29440","bibcode":"2012ascl.soft08016H","views":"61","site_list":["http:\/\/www.astro.princeton.edu\/~jhartman\/vartools.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ApJ...675.1254H"]},
		{"ascl_id":"1208.017","title":"APLpy: Astronomical Plotting Library in Python","credit":"Robitaille, Thomas; Bressert, Eli","abstract":"APLpy (the Astronomical Plotting Library in Python) is a Python module for producing publication-quality plots of astronomical imaging data in FITS format. The module uses Matplotlib, a powerful and interactive plotting package. It is capable of creating output files in several graphical formats, including EPS, PDF, PS, PNG, and SVG. Plots can be made interactively or by using scripts, and can generate co-aligned FITS cubes to make three-color RGB images. It also offers different overlay capabilities, including contour sets, markers with customizable symbols, and coordinate grids, and a range of other useful features.","topic_id":"29302","bibcode":"2012ascl.soft08017R","views":"101","site_list":["http:\/\/aplpy.github.com\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012ApJ...748..123S"]},
		{"ascl_id":"1208.018","title":"CUBEP3M: High performance P3M N-body code","credit":"Harnois-Deraps, Joachim; Pen, Ue-Li; Iliev, Ilian T.; Merz, Hugh; Emberson, J. D.; Desjacques, Vincent","abstract":"CUBEP<sup>3<\/sup>M is a high performance cosmological N-body code which has many utilities and extensions, including a runtime halo finder, a non-Gaussian initial conditions generator, a tuneable accuracy, and a system of unique particle identification. CUBEP<sup>3<\/sup>M is fast, has a memory imprint up to three times lower than other widely used N-body codes, and has been run on up to 20,000 cores, achieving close to ideal weak scaling even at this problem size. It is well suited and has already been used for a broad number of science applications that require either large samples of non-linear realizations or very large dark matter N-body simulations, including cosmological reionization, baryonic acoustic oscillations, weak lensing or non-Gaussian statistics.","topic_id":"29417","bibcode":"2012ascl.soft08018H","views":"54","site_list":["https:\/\/github.com\/jharno\/cubep3m"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.424..762D","http:\/\/arxiv.org\/abs\/1208.5098"]},
		{"ascl_id":"1208.019","title":"MPFIT: Robust non-linear least squares curve fitting","credit":"Markwardt, Craig","abstract":"These IDL routines provide a robust and relatively fast way to perform least-squares curve and surface fitting. The algorithms are translated from MINPACK-1, which is a rugged minimization routine found on Netlib, and distributed with permission. This algorithm is more desirable than CURVEFIT because it is generally more stable and less likely to crash than the brute-force approach taken by CURVEFIT, which is based upon Numerical Recipes.","topic_id":"29445","bibcode":"2012ascl.soft08019M","views":"228","site_list":["http:\/\/purl.com\/net\/mpfit"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009ASPC..411..251M"]},
		{"ascl_id":"1208.020","title":"ParselTongue: AIPS Python Interface","credit":"Kettenis, Mark; Sipior, Mike","abstract":"ParselTongue is a Python interface to classic AIPS, Obit and possibly other task-based data reduction packages. It serves as the software infrastructure for some of the ALBUS implementation. It allows you to run AIPS tasks, and access AIPS headers and extension tables from Python. There is also support for running Obit tasks and accessing data in FITS files. Full access to the visibilities in AIPS UV data is also available.","topic_id":"29446","bibcode":"2012ascl.soft08020K","views":"210","site_list":["http:\/\/www.jive.nl\/dokuwiki\/doku.php?id=parseltongue:parseltongue"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ASPC..351..497K"]},
		{"ascl_id":"1208.021","title":"EzGal: A Flexible Interface for Stellar Population Synthesis Models","credit":"Mancone, Conor; Gonzalez, Anthony","abstract":"EzGal is a flexible Python program which generates observable parameters (magnitudes, colors, and mass-to-light ratios) for arbitrary input stellar population synthesis (SPS) models; it enables simple, direct comparison of different model sets so that the uncertainty introduced by choice of model set can be quantified. EzGal is also capable of generating composite stellar population models (CSPs) for arbitrary input star-formation histories and reddening laws, and can be used to interpolate between metallicities for a given model set.","topic_id":"29448","bibcode":"2012ascl.soft08021M","views":"41","site_list":["http:\/\/www.baryons.org\/ezgal\/index.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012PASP..124..606M"]},
		{"ascl_id":"1209.001","title":"Bayesian Blocks: Detecting and characterizing local variability in time series","credit":"Scargle, Jeffrey D.; Norris, Jay P.; Jackson, Brad; Chiang, James","abstract":"Bayesian Blocks is a time-domain algorithm for detecting localized structures (bursts), revealing pulse shapes within bursts, and generally characterizing intensity variations. The input is raw time series data, in almost any form. Three data modes are elaborated: (1) time-tagged events, (2) binned counts, and (3) measurements at arbitrary times with normal errors. The output is the most probable segmentation of the observation interval into sub-intervals during which the signal is perceptibly constant, i.e. has no statistically significant variations. The idea is not that the source is deemed to actually have this discontinuous, piecewise constant form, rather that such an approximate and generic model is often useful. Treatment of data gaps, variable exposure, extension to piecewise linear and piecewise exponential representations, multi-variate time series data, analysis of variance, data on the circle, other data modes, and dispersed data are included.\r\n\r\nThis implementation is exact and replaces the greedy, approximate, and outdated algorithm implemented in <a href=\"http:\/\/ascl.net\/9909.005\">BLOCK<\/a>.","topic_id":"29458","bibcode":"2012ascl.soft09001S","views":"88","site_list":["http:\/\/arxiv.org\/src\/1207.5578v3\/anc"],"ref_list":["http:\/\/arxiv.org\/abs\/1207.5578"]},
		{"ascl_id":"1209.002","title":"JAGS: Just Another Gibbs Sampler","credit":"Plummer, Martyn","abstract":"JAGS analyzes Bayesian hierarchical models using Markov Chain Monte Carlo (MCMC) simulation not wholly unlike <a href=\"http:\/\/www.openbugs.info\/w\/\">BUGS<\/a>. JAGS has three aims:\r\n\r\n<ul><li>to have a cross-platform engine for the BUGS language;<\/li><li>to be extensible, allowing users to write their own functions, distributions and samplers; and<\/li><li>to be a platform for experimentation with ideas in Bayesian modeling.<\/li><\/ul>","topic_id":"29500","bibcode":"2012ascl.soft09002P","views":"39","site_list":["http:\/\/mcmc-jags.sourceforge.net\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1209.0565"]},
		{"ascl_id":"1209.003","title":"LSD: Large Survey Database framework","credit":"Juric, Mario","abstract":"The Large Survey Database (LSD) is a Python framework and DBMS for distributed storage, cross-matching and querying of large survey catalogs (>10^9 rows, &gt;1 TB). The primary driver behind its development is the analysis of Pan-STARRS PS1 data. It is specifically optimized for fast queries and parallel sweeps of positionally and temporally indexed datasets. It transparently scales to more than &gt;10^2 nodes, and can be made to function in \"shared nothing\" architectures.","topic_id":"29508","bibcode":"2012ascl.soft09003J","views":"39","site_list":["http:\/\/mwscience.net\/trac\/wiki\/LargeSurveyDatabase"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011AAS...21743319J"]},
		{"ascl_id":"1209.004","title":"CHORIZOS: CHi-square cOde for parameterRized modeling and characterIZation of phOtometry and Spectrophotmetry","credit":"Ma\u00edz Apell\u00e1niz, Jes\u00fas","abstract":"CHORIZOS is a multi-purpose Bayesian code developed in IDL to compare photometric data with model spectral energy distributions (SEDs). The user can select the SED family (e.g. Kurucz) and choose the behavior of each parameter (e.g. Teff) to be fixed, constrained to a given range, or unconstrained. The code calculates the likelihood for the full specified parameter ranges, thus allowing for the identification of multiple solutions and the evaluation of the full correlation matrix for the derived parameters of a single solution.","topic_id":"29536","bibcode":"2012ascl.soft09004M","views":"144","site_list":["http:\/\/jmaiz.iaa.es\/software\/chorizos\/chorizos.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004PASP..116..859M"]},
		{"ascl_id":"1209.005","title":"HARM: A Numerical Scheme for General Relativistic Magnetohydrodynamics","credit":"Gammie, Charles, F.; McKinney, Jonathan C.; T\u00f3th, G\u00e1bor","abstract":"HARM uses a conservative, shock-capturing scheme for evolving the equations of general relativistic magnetohydrodynamics. The fluxes are calculated using the Harten, Lax, & van Leer scheme. A variant of constrained transport, proposed earlier by T\u00f3th, is used to maintain a divergence-free magnetic field. Only the covariant form of the metric in a coordinate basis is required to specify the geometry. On smooth flows HARM converges at second order.","topic_id":"29541","bibcode":"2012ascl.soft09005G","views":"47","site_list":["http:\/\/rainman.astro.illinois.edu\/codelib\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003ApJ...589..444G"]},
		{"ascl_id":"1209.006","title":"macula: Rotational modulations in the photometry of spotted stars","credit":"Kipping, David M.","abstract":"Photometric rotational modulations due to starspots remain the most common and accessible way to study stellar activity. Modelling rotational modulations allows one to invert the observations into several basic parameters, such as the rotation period, spot coverage, stellar inclination and differential rotation rate. The most widely used analytic model for this inversion comes from Budding (1977) and Dorren (1987), who considered circular, grey starspots for a linearly limb darkened star. That model is extended to be more suitable in the analysis of high precision photometry such as that by Kepler. Macula, a Fortran 90 code, provides several improvements, such as non-linear limb darkening of the star and spot, a single-domain analytic function, partial derivatives for all input parameters, temporal partial derivatives, diluted light compensation, instrumental offset normalisations, differential rotation, starspot evolution and predictions of transit depth variations due to unocculted spots. The inclusion of non-linear limb darkening means macula has a maximum photometric error an order-of-magnitude less than that of Dorren (1987) for Sun-like stars observed in the Kepler-bandpass. The code executes three orders-of-magnitude faster than comparable numerical codes making it well-suited for inference problems.","topic_id":"29548","bibcode":"2012ascl.soft09006K","views":"35","site_list":["https:\/\/www.cfa.harvard.edu\/~dkipping\/macula.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1209.2985"]},
		{"ascl_id":"1209.007","title":"TMCalc: Fast estimation of stellar metallicity [Fe\/H]","credit":"Sousa, S\u00e9rgio G.; Santos, Nuno C.; Israelian, Garik","abstract":"TMCalc is a C code developed as an extension to ARES. Using the line list given, the code can be used as a precise and fast indicator of the spectroscopic temperature and metallicity for dwarf FKG stars with effective temperatures ranging from 4500 K to 6500 K and with [Fe\/H] ranging from -0.8 dex to 0.4 dex.","topic_id":"29554","bibcode":"2012ascl.soft09007S","views":"55","site_list":["http:\/\/www.astro.up.pt\/~sousasag\/ares\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012A%26A...544A.122S"]},
		{"ascl_id":"1209.008","title":"Phantom-GRAPE: SIMD accelerated numerical library for N-body simulations","credit":"Tanikawa, Ataru; Yoshikawa, Kohji; Nitadori, Keigo; Okamoto, Takashi","abstract":"Phantom-GRAPE is a numerical software library to accelerate collisionless $N$-body simulation with SIMD instruction set on x86 architecture. The Newton's forces and also central forces with an arbitrary shape f(r), which have a finite cutoff radius r_cut (i.e. f(r)=0 at r>r_cut), can be quickly computed.","topic_id":"29597","bibcode":"2012ascl.soft09008T","views":"41","site_list":["http:\/\/code.google.com\/p\/phantom-grape\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1203.4037"]},
		{"ascl_id":"1209.009","title":"ANNz: Artificial Neural Networks for estimating photometric redshifts","credit":"Lahav, Ofer; Collister, Adrian A.","abstract":"ANNz is a freely available software package for photometric redshift estimation using Artificial Neural Networks. ANNz learns the relation between photometry and redshift from an appropriate training set of galaxies for which the redshift is already known. Where a large and representative training set is available, ANNz is a highly competitive tool when compared with traditional template-fitting methods.","topic_id":"29598","bibcode":"2012ascl.soft09009L","views":"78","site_list":["http:\/\/www.homepages.ucl.ac.uk\/~ucapola\/annz.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0311058"]},
		{"ascl_id":"1209.010","title":"MeqTrees: Software package for implementing Measurement Equations","credit":"Noordam, Jan E.; Smirnov, Oleg M.","abstract":"MeqTrees is a software package for implementing Measurement Equations. This makes it uniquely suited for simulation and calibration of radioastronomical data, especially that involving new radiotelescopes and observational regimes. MeqTrees is implemented as a Python-based front-end called the meqbrowser, and an efficient (C++-based) computational back-end called the meqserver. Numerical models are defined on the front-end via a Python-based Tree Definition Language (TDL), then rapidly executed on the back-end. The use of TDL facilitates an extremely short turn-around time for experimentation with new ideas. This is also helped by unprecedented visualization capabilities for all final and intermediate results. A flexible data model and a number of important optimizations in the back-end ensures that the numerical performance is comparable to that of hand-written code. \r\n\r\nMeqTrees includes a highly capable FITS viewer and sky model manager called Tigger, which can also work as a standalone tool.","topic_id":"29599","bibcode":"2012ascl.soft09010N","views":"39","site_list":["http:\/\/www.astron.nl\/meqwiki"],"ref_list":["http:\/\/arxiv.org\/abs\/1101.1745"]},
		{"ascl_id":"1209.011","title":"DiskFit: Modeling Asymmetries in Disk Galaxies","credit":"Kuzio de Naray, Rache; Arsenault, Cameron A.; Spekkens, Kristine; Sellwood, J. A.; McDonald, Michael; Simon, Joshua D.; Teuben, Peter","abstract":"DiskFit implements procedures for fitting non-axisymmetries in either kinematic or photometric data. DiskFit can analyze H-alpha and CO velocity field data as well as HI kinematics to search for non-circular motions in the disk galaxies. DiskFit can also be used to constrain photometric models of the disc, bar and bulge. It deprecates an earlier version, by a subset of these authors, called <a href=\"http:\/\/ascl.net\/1010.021\">velfit<\/a>.","topic_id":"29610","bibcode":"2012ascl.soft09011K","views":"44","site_list":["http:\/\/www.physics.rutgers.edu\/~spekkens\/diskfit\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1209.4653"]},
		{"ascl_id":"1209.012","title":"Scanamorphos: Maps from scan observations made with bolometer arrays","credit":"Roussel, H\u00e9l\u00e8ne","abstract":"Scanamorphos is an IDL program to build maps from scan observations made with bolometer arrays. Scanamorphos can post-process scan observations performed with the Herschel photometer arrays. This post-processing mainly consists in subtracting the total low-frequency noise (both its thermal and non-thermal components), masking cosmic ray hit residuals, and projecting the data onto a map. Although it was developed for Herschel, it is also applicable with minimal adjustment to scan observations made with other bolometer arrays provided they entail sufficient redundancy; it was successfully applied to P-Artemis, an instrument operating on the APEX telescope. Scanamorphos does not assume any particular noise model and does not apply any Fourier-space filtering to the data. It is an empirical tool using only the redundancy built in the observations, taking advantage of the fact that each portion of the sky is sampled at multiple times by multiple bolometers. The user is allowed to optionally visualize and control results at each intermediate step, but the processing is fully automated.","topic_id":"29645","bibcode":"2012ascl.soft09012R","views":"45","site_list":["http:\/\/www2.iap.fr\/users\/roussel\/herschel\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1205.2576"]},
		{"ascl_id":"1209.013","title":"IRACproc: IRAC Post-BCD Processing","credit":"Schuster, Mike; Marengo, Massimo; Patten, Brian","abstract":"IRACproc is a software suite that facilitates the co-addition of dithered or mapped Spitzer\/IRAC data to make them ready for further analysis with application to a wide variety of IRAC observing programs. The software runs within PDL, a numeric extension for Perl available from pdl.perl.org, and as stand alone perl scripts. In acting as a wrapper for the Spitzer Science Center's <a href=\"http:\/\/ascl.net\/1111.006\">MOPEX<\/a> software, IRACproc improves the rejection of cosmic rays and other transients in the co-added data. In addition, IRACproc performs (optional) Point Spread Function (PSF) fitting, subtraction, and masking of saturated stars.","topic_id":"29647","bibcode":"2012ascl.soft09013S","views":"45","site_list":["https:\/\/www.cfa.harvard.edu\/twiki\/bin\/view\/Main\/IracProc"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006SPIE.6270E..65S"]},
		{"ascl_id":"1209.014","title":"FAMIAS: Frequency Analysis and Mode Identification for AsteroSeismology","credit":"Zima, Wolfgang","abstract":"FAMIAS (Frequency Analysis and Mode Identification for Asteroseismology) is a package of software tools programmed in C++ for the analysis of photometric and spectroscopic time-series data. FAMIAS provides analysis tools that are required for the steps between the data reduction and the seismic modeling. Two main sets of tools are incorporated in FAMIAS. The first set permits to search for periodicities in the data using Fourier and non-linear least-squares fitting techniques. The other set permits to carry out a mode identification for the detected pulsation frequencies to determine their harmonic degree l, and azimuthal order m. FAMIAS is applicable to main-sequence pulsators hotter than the Sun. This includes Gamma Dor, Delta Sct stars, slowly pulsating B (SPB)-stars and Beta Cep stars - basically all stars for which empirical mode identification is required to successfully carry out asteroseismology.","topic_id":"29648","bibcode":"2012ascl.soft09014Z","views":"51","site_list":["http:\/\/www.ster.kuleuven.be\/~zima\/famias\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1101.1590"]},
		{"ascl_id":"1209.015","title":"Aspects: Probabilistic\/positional association of catalogs of sources","credit":"Fioc, Michel","abstract":"Given two catalogs <span style=\"font-style: italic\">K<\/span> and <span style=\"font-style: italic\">K'<\/span> of <span style=\"font-style: italic\">n<\/span> and <span style=\"font-style: italic\">n'<\/span> astrophysical sources, respectively, Aspects (Association positionnelle\/probabiliste de catalogues de sources) computes, for any objects <span style=\"font-style: italic\">M<sub>i<\/sub><\/span> \u2208 <span style=\"font-style: italic\">K<\/span> and <span style=\"font-style: italic\">M'<sub>j<\/sub><\/span> \u2208 <span style=\"font-style: italic\">K'<\/span>, the probability that <span style=\"font-style: italic\">M'<sub>j<\/sub><\/span> is a counterpart of <span style=\"font-style: italic\">M<sub>i<\/sub><\/span>, <span style=\"font-style: italic\">i.e.<\/span> that they are the same source. To determine this probability of association, the code takes into account the coordinates and the positional uncertainties of all the objects. Aspects also computes the probability <span style=\"font-style: italic\">P(A<sub>i, 0<\/sub> | C \u2229 C')<\/span> that <span style=\"font-style: italic\">M<sub>i<\/sub><\/span> has no counterpart.\n\nAspects is written in Fortran 95 and requires a number of Numerical Recipes routines in Fortran 90.","topic_id":"29658","bibcode":"2012ascl.soft09015F","views":"74","site_list":["http:\/\/www2.iap.fr\/users\/fioc\/Aspects\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1209.5361"]},
		{"ascl_id":"1210.001","title":"GP2PCF: Brute-force computation of 2-point correlation functions","credit":"C\u00e1rdenas-Montes, Miguel; Ponce, Rafael","abstract":"The two-point correlation function is a simple statistic that quantifies the clustering of a given distribution of objects. In studies of the large scale structure of the Universe, it is an important tool containing information about the matter clustering and the evolution of the Universe at different cosmological epochs. A classical application of this statistic is the galaxy-galaxy correlation function to find constraints on the parameter Omega_m or the location of the baryonic acoustic oscillation peak. This calculation, however, is very expensive in terms of computer power and Graphics Processing Units provide one solution for efficient analysis of the increasingly larger galaxy surveys that are currently taking place.\r\n\r\nGP2PCF is a public code in CUDA for performing this computation; with a single GPU board it is possible to achieve 120-fold speedups with respect to a standard implementation in C running on a single CPU. With respect to other solutions such as k-trees the improvement is of a factor of a few retaining full precision. The speedup is comparable to running in parallel in a cluster of O(100) cores.","topic_id":"29703","bibcode":"2012ascl.soft10001C","views":"45","site_list":["http:\/\/wwwae.ciemat.es\/cosmo\/gp2pcf\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1204.6630"]},
		{"ascl_id":"1210.002","title":"pPXF: Penalized Pixel-Fitting stellar kinematics extraction","credit":"Cappellari, Michele","abstract":"pPXF is an IDL (and free GDL or FL) program which extracts the stellar kinematics or stellar population from absorption-line spectra of galaxies using the Penalized Pixel-Fitting method (pPXF) developed by Cappellari & Emsellem (2004, PASP, 116, 138). Additional features implemented in the pPXF routine include:\r\n\r\n<ul><li>Optimal template: Fitted together with the kinematics to minimize template-mismatch errors. Also useful to extract gas kinematics or derive emission-corrected line-strengths indexes. One can use synthetic templates to study the stellar population of galaxies via \"Full Spectral Fitting\" instead of using traditional line-strengths.<\/li><li>Regularization of templates weights: To reduce the noise in the recovery of the stellar population parameters and attach a physical meaning to the output weights assigned to the templates in term of the star formation history (SFH) or metallicity distribution of an individual galaxy.<\/li><li>Iterative sigma clipping: To clean the spectra from residual bad pixels or cosmic rays.<\/li><li>Additive\/multiplicative polynomials: To correct low frequency continuum variations. Also useful for calibration purposes.<\/li><\/ul>","topic_id":"29715","bibcode":"2012ascl.soft10002C","views":"70","site_list":["http:\/\/www-astro.physics.ox.ac.uk\/~mxc\/idl\/#ppxf"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004PASP..116..138C","http:\/\/adsabs.harvard.edu\/abs\/2009ApJ...704L..34C"]},
		{"ascl_id":"1210.003","title":"GOSSIP: SED fitting code","credit":"Franzetti, Paolo; Scodeggio, Marco","abstract":"GOSSIP fits the electro-magnetic emission of an object (the SED, Spectral Energy Distribution) against synthetic models to find the simulated one that best reproduces the observed data. It builds-up the observed SED of an object (or a large sample of objects) combining magnitudes in different bands and eventually a spectrum; then it performs a chi-square minimization fitting procedure versus a set of synthetic models. The fitting results are used to estimate a number of physical parameters like the Star Formation History, absolute magnitudes, stellar mass and their Probability Distribution Functions.","topic_id":"29718","bibcode":"2012ascl.soft10003F","views":"42","site_list":["http:\/\/cosmos.iasf-milano.inaf.it\/pandora\/gossip.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ASPC..394..642F"]},
		{"ascl_id":"1210.004","title":"EZ: A Tool For Automatic Redshift Measurement","credit":"Fumana, Marco; Garilli, Bianca","abstract":"EZ (Easy-Z) estimates redshifts for extragalactic objects. It compares the observed spectrum with a set of (user given) spectral templates to find out the best value for the redshift. To accomplish this task, it uses a highly configurable set of algorithms. EZ is easily extendible with new algorithms. It is implemented as a set of C programs and a number of python classes. It can be used as a standalone program, or the python classes can be directly imported by other applications.","topic_id":"29719","bibcode":"2012ascl.soft10004F","views":"36","site_list":["http:\/\/cosmos.iasf-milano.inaf.it\/pandora\/EZ.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010PASP..122..827G"]},
		{"ascl_id":"1210.005","title":"SGNAPS: Software for Graphical Navigation, Analysis and Plotting of Spectra","credit":"Paioro, Luigi; Franzetti, Paolo","abstract":"SGNAPS allows the user to plot a one-dimensional spectrum, together with the corresponding two-dimensional and a reference spectrum (for example the sky spectrum). This makes it possible to check on the reality of spectral features that are present in the one-dimensional spectrum, which could be due to bad sky subtraction or fringing residuals. It is also possible to zoom in and out all three spectra, edit the one-dimensional spectrum, smooth it with a simple square window function, measure the signal to noise over a selected wavelength interval, and fit the position of a selected spectral line. SGNAPS also allows the astronomer to obtain quick redshift estimates by providing a tool to fit or mark the position of a spectral line, and a function that will compute a list of possible redshifts based on a list of known lines in galaxy spectra. SGNAPS is derived from the plotting tools of <a href=\"http:\/\/cosmos.iasf-milano.inaf.it\/pandora\/vipgi.html\">VIPGI<\/a> and contains almost all of their capabilities.","topic_id":"29720","bibcode":"2012ascl.soft10005P","views":"40","site_list":["http:\/\/cosmos.iasf-milano.inaf.it\/pandora\/sgnaps.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005PASP..117.1284S"]},
		{"ascl_id":"1210.006","title":"TA-DA: A Tool for Astrophysical Data Analysis","credit":"Da Rio, Nicola; Robberto, Massimo","abstract":"TA-DA is a pre-compiled IDL widget-based application which greatly simplifies and improves the analysis of stellar photometric data in comparison with theoretical models and allows the derivation of stellar parameters from multi-band photometry. It is flexible and can address a number of problems, from the interpolation of stellar models or sets of stellar physical parameters in general to the computation of synthetic photometry in arbitrary filters or units. It also analyzes observed color-magnitude diagrams and allows a Bayesian derivation of stellar parameters (and extinction) based on multi-band data.","topic_id":"29727","bibcode":"2012ascl.soft10006D","views":"45","site_list":["http:\/\/www.astro.ufl.edu\/~ndario\/TADA\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1210.1850"]},
		{"ascl_id":"1210.007","title":"FLUKA: Fully integrated particle physics Monte Carlo simulation package","credit":"Fass\u00f2, Alberto; Ferrari, Alfredo; Ranft, Johannes; Sala, Paola; Mairani, Andrea; Empl, Anton; Sommerer, Florian; Cerutti, Francesco; Battistoni, Giuseppe; Roesler, Stefan; Vlachoudis, Vasilis; Patera, Vincenzo; Aarnio, P.; M\u00f6hring, J.-H.; Stevenson, G. R.; Zazula, J. M.","abstract":"FLUKA (FLUktuierende KAskade) is a general-purpose tool for calculations of particle transport and interactions with matter. FLUKA can simulate with high accuracy the interaction and propagation in matter of about 60 different particles, including photons and electrons from 1 keV to thousands of TeV, neutrinos, muons of any energy, hadrons of energies up to 20 TeV (up to 10 PeV by linking FLUKA with the DPMJET code) and all the corresponding antiparticles, neutrons down to thermal energies and heavy ions. The program, written in Fortran, can also transport polarised photons (e.g., synchrotron radiation) and optical photons. Time evolution and tracking of emitted radiation from unstable residual nuclei can be performed online.","topic_id":"29735","bibcode":"2012ascl.soft10007F","views":"40","site_list":["http:\/\/www.fluka.org\/fluka.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007AIPC..896...31B"]},
		{"ascl_id":"1210.008","title":"Rockstar: Phase-space halo finder","credit":"Behroozi, Peter; Wechsler, Risa; Wu, Hao-Yi","abstract":"Rockstar (Robust Overdensity Calculation using K-Space Topologically Adaptive Refinement) identifies dark matter halos, substructure, and tidal features. The approach is based on adaptive hierarchical refinement of friends-of-friends groups in six phase-space dimensions and one time dimension, which allows for robust (grid-independent, shape-independent, and noise-resilient) tracking of substructure. Our method is massively parallel (up to 10^5 CPUs) and runs on the largest current simulations (>10^10 particles) with high efficiency (10 CPU hours and 60 gigabytes of memory required per billion particles analyzed). Rockstar offers significant improvement in substructure recovery as compared to several other halo finders.","topic_id":"29748","bibcode":"2012ascl.soft10008B","views":"40","site_list":["http:\/\/code.google.com\/p\/rockstar\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1110.4372","http:\/\/arxiv.org\/abs\/1210.2578"]},
		{"ascl_id":"1210.009","title":"PAHFIT: Properties of PAH Emission","credit":"Smith, J. D.; Draine, Bruce","abstract":"PAHFIT is an IDL tool for decomposing Spitzer IRS spectra of PAH emission sources, with a special emphasis on the careful recovery of ambiguous silicate absorption, and weak, blended dust emission features. PAHFIT is primarily designed for use with full 5-35 micron Spitzer low-resolution IRS spectra. PAHFIT is a flexible tool for fitting spectra, and you can add or disable features, compute combined flux bands, change fitting limits, etc., without changing the code.\r\n\r\nPAHFIT uses a simple, physically-motivated model, consisting of starlight, thermal dust continuum in a small number of fixed temperature bins, resolved dust features and feature blends, prominent emission lines (which themselves can be blended with dust features), as well as simple fully-mixed or screen dust extinction, dominated by the silicate absorption bands at 9.7 and 18 microns. Most model components are held fixed or are tightly constrained. PAHFIT uses Drude profiles to recover the full strength of dust emission features and blends, including the significant power in the wings of the broad emission profiles. This means the resulting feature strengths are larger (by factors of 2-4) than are recovered by methods which estimate the underlying continuum using line segments or spline curves fit through fiducial wavelength anchors.","topic_id":"29749","bibcode":"2012ascl.soft10009S","views":"37","site_list":["http:\/\/tir.astro.utoledo.edu\/jdsmith\/research\/pahfit.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007ApJ...656..770S"]},
		{"ascl_id":"1210.010","title":"CALCLENS: Curved-sky grAvitational Lensing for Cosmological Light conE simulatioNS","credit":"Becker, Matthew R.","abstract":"CALCLENS, written in C and employing widely available software libraries, efficiently computes weak gravitational lensing shear signals from large N-body light cone simulations over a curved sky. The algorithm properly accounts for the sky curvature and boundary conditions, is able to produce redshift-dependent shear signals including corrections to the Born approximation by using multiple-plane ray tracing, and properly computes the lensed images of source galaxies in the light cone. The key feature of this algorithm is a new, computationally efficient Poisson solver for the sphere that combines spherical harmonic transform and multgrid methods. As a result, large areas of sky (~10,000 square degrees) can be ray traced efficiently at high-resolution using only a few hundred cores on widely available machines. Coupled with realistic galaxy populations placed in large N-body light cone simulations, CALCLENS is ideally suited for the construction of synthetic weak lensing shear catalogs to be used to test for systematic effects in data analysis procedures for upcoming large-area sky surveys.","topic_id":"29747","bibcode":"2012ascl.soft10010B","views":"57","site_list":["http:\/\/code.google.com\/p\/calclens\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1210.3069"]},
		{"ascl_id":"1210.011","title":"Consistent Trees: Gravitationally Consistent Halo Catalogs and Merger Trees for Precision Cosmology","credit":"Behroozi, Peter S.; Wechsler, Risa H.; Wu, Hao-Yi; Busha, Michael T.; Klypin, Anatoly A.; Primack, Joel R.","abstract":"Consistent Trees generates merger trees and halo catalogs which explicitly ensure consistency of halo properties (mass, position, velocity, radius) across timesteps. It has demonstrated the ability to improve both the completeness (through detecting and inserting otherwise missing halos) and purity (through detecting and removing spurious objects) of both merger trees and halo catalogs. Consistent Trees is able to robustly measure the self-consistency of halo finders and to directly measure the uncertainties in halo positions, halo velocities, and the halo mass function for a given halo finder based on consistency between snapshots in cosmological simulations.","topic_id":"29756","bibcode":"2012ascl.soft10011B","views":"55","site_list":["http:\/\/code.google.com\/p\/consistent-trees"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011arXiv1110.4370B"]},
		{"ascl_id":"1210.012","title":"SearchCal: The JMMC Evolutive Search Calibrator Tool","credit":"Bonneau, D.; Delfosse, X.; Clausse, J.-M.; Mourard, D.","abstract":"SearchCal builds an evolutive catalog of stars suitable as calibrators within any given user-defined angular distance and magnitude around a scientific target. SearchCal can select suitable bright calibration stars (V \u2264 10; K \u2264 5.0) for obtaining the ultimate precision of current interferometric instruments like the VLTI and faint calibration stars up to K ~ 15  around the scientific target. Star catalogs available at the CDS are searched via web requests and provide the useful astrometric and photometric informations for selecting calibrators. The missing photometries are computed with an accuracy of about 0.1 mag. The stellar angular diameter is estimated with a precision of about 10% through newly determined surface-brightness versus color-index relations based on the I, J, H and K magnitudes. For each star the squared visibility is computed taking into account the central wavelength and the maximum baseline of the predicted observations.","topic_id":"29754","bibcode":"2012ascl.soft10012B","views":"47","site_list":["http:\/\/www.jmmc.fr\/searchcal"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006A%26A...456..789B","http:\/\/adsabs.harvard.edu\/abs\/2011A%26A...535A..53B"]},
		{"ascl_id":"1210.013","title":"ConvPhot: A profile-matching algorithm for precision photometry","credit":"De Santis, C.; Grazian, A.; Fontana, A.; Santini, P.","abstract":"ConvPhot measures colors between two images having different resolutions. ConvPhot is designed to work especially for faint galaxies, accurately measuring colors in relatively crowded fields. It makes full use of the spatial and morphological information contained in the highest quality images to analyze multiwavelength data with inhomogeneous image quality.","topic_id":"29755","bibcode":"2012ascl.soft10013D","views":"46","site_list":["http:\/\/lbc.mporzio.astro.it\/photoTools.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007NewA...12..271D"]},
		{"ascl_id":"1210.014","title":"TRIP: General computer algebra system for celestial mechanics","credit":"Laskar, J.; Gastineau, M.","abstract":"TRIP is an interactive computer algebra system that is devoted to perturbation series computations, and specially adapted to celestial mechanics. Its development started in 1988, as an upgrade of the special purpose FORTRAN routines elaborated by J. Laskar for the demonstration of the chaotic behavior of the Solar System. TRIP is a mature and efficient tool for handling multivariate generalized power series, and embeds two kernels, a symbolic and a numerical kernel. This numerical kernel communicates with <a href=\"http:\/\/www.gnuplot.info\/\">Gnuplot<\/a> or <a href=\"http:\/\/plasma-gate.weizmann.ac.il\/Grace\/.\">Grace<\/a> to plot the graphics and allows one to plot the numerical evaluation of symbolic objects.","topic_id":"29768","bibcode":"2012ascl.soft10014L","views":"46","site_list":["http:\/\/www.imcce.fr\/Equipes\/ASD\/trip\/trip.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012A%26A...546A..71D"]},
		{"ascl_id":"1210.015","title":"Tempo2: Pulsar Timing Package","credit":"Hobbs, George; Edwards, Russell","abstract":"Tempo2 is a pulsar timing package developed to be used both for general pulsar timing applications and also for pulsar timing array research in which data-sets from multiple pulsars need to be processed simultaneously. It was initially developed by George Hobbs and Russell Edwards as part of the Parkes Pulsar Timing Array project. Tempo2 is based on the original tempo code and can be used (from the command-line) in a similar fashion. It is very versatile and can be extended by plugins.","topic_id":"29769","bibcode":"2012ascl.soft10015H","views":"34","site_list":["http:\/\/www.atnf.csiro.au\/research\/pulsar\/tempo2\/index.php?n=Main.Download"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008A%26A...492..923S"]},
		{"ascl_id":"1210.016","title":"Specview: 1-D spectral visualization and analysis of astronomical spectrograms","credit":"Space Telescope Science Institute","abstract":"Specview is a tool for 1-D spectral visualization and analysis of astronomical spectrograms. Written in Java, it is capable of reading all the Hubble Space Telescope spectral data formats as well as data from several other instruments (such as IUE, FUSE, ISO, FORS and SDSS), preview spectra from MAST, and data from generic FITS and ASCII tables. It can read data from Virtual Observatory servers, and read and write spectrogram data in Virtual Observatory SED format. It can also read files in the SPC Galactic format used in the chemistry field. Once ingested, data can be plotted and examined with a large selection of custom settings. Specview supports instrument-specific data quality handling, flexible spectral units conversions, custom plotting attributes, plot annotations, tiled plots, hardcopy to JPEG files and PostScript file or printer, etc. Specview can be used to build wide-band SEDs, overplotting or combining data from the same astronomical source taken with different instruments and\/or spectral bands. Data can be further processed with averaging, splicing, detrending, and Fourier filtering tools. Specview has a spectral model fitting capability that enables the user to work with multi-component models (including user-defined models) and fit models to data.","topic_id":"29783","bibcode":"2012ascl.soft10016S","views":"52","site_list":["http:\/\/www.stsci.edu\/institute\/software_hardware\/specview\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002SPIE.4847..410B"]},
		{"ascl_id":"1210.017","title":"McPHAC: McGill Planar Hydrogen Atmosphere Code","credit":"Haakonsen, Christian Bernt; Turner, Monica L.; Tacik, Nick A.; Rutledge, Robert E.","abstract":"The McGill Planar Hydrogen Atmosphere Code (McPHAC) v1.1 calculates the hydrostatic equilibrium structure and emergent spectrum of an unmagnetized hydrogen atmosphere in the plane-parallel approximation at surface gravities appropriate for neutron stars. McPHAC incorporates several improvements over previous codes for which tabulated model spectra are available: (1) Thomson scattering is treated anisotropically, which is shown to result in a 0.2%-3% correction in the emergent spectral flux across the 0.1-5 keV passband; (2) the McPHAC source code is made available to the community, allowing it to be scrutinized and modified by other researchers wishing to study or extend its capabilities; and (3) the numerical uncertainty resulting from the discrete and iterative solution is studied as a function of photon energy, indicating that McPHAC is capable of producing spectra with numerical uncertainties &lt;0.01%. The accuracy of the spectra may at present be limited to ~1%, but McPHAC enables researchers to study the impact of uncertain inputs and additional physical effects, thereby supporting future efforts to reduce those inaccuracies. Comparison of McPHAC results with spectra from one of the previous model atmosphere codes (NSA) shows agreement to lsim1% near the peaks of the emergent spectra. However, in the Wien tail a significant deficit of flux in the spectra of the previous model is revealed, determined to be due to the previous work not considering large enough optical depths at the highest photon frequencies. The deficit is most significant for spectra with T eff &lt; 105.6 K, though even there it may not be of much practical importance for most observations.","topic_id":"29791","bibcode":"2012ascl.soft10017H","views":"43","site_list":["https:\/\/github.com\/McPHAC\/McPHAC"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012ApJ...749...52H"]},
		{"ascl_id":"1210.018","title":"Systemic Console: Advanced analysis of exoplanetary data","credit":"Meschiari, Stefano; Wolf, Aaron S.; Rivera, Eugenio; Laughlin, Gregory; Vogt, Steve; Butler, Paul","abstract":"Systemic Console is a tool for advanced analysis of exoplanetary data. It comprises a graphical tool for fitting radial velocity and transits datasets and a library of routines for non-interactive calculations. Among its features are interactive plotting of RV curves and transits, combined fitting of RV and transit timing (primary and secondary), interactive periodograms and FAP estimation, and bootstrap and MCMC error estimation. The console package includes public radial velocity and transit data.","topic_id":"29812","bibcode":"2012ascl.soft10018M","views":"56","site_list":["http:\/\/www.stefanom.org\/?page_id=74"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009PASP..121.1016M"]},
		{"ascl_id":"1210.019","title":"QFitsView: FITS file viewer","credit":"Ott, Thomas","abstract":"QFitsView is a FITS file viewer that can display one, two, and three-dimensional FITS files. It has three modes of operation, depending of what kind of data is being displayed. One-dimensional data are shown in an x-y plot. Two-dimensional images are shown in the main window. Three-dimensional data cubes can be displayed in a variety of ways, with the third dimension shown as a x-y plot at the bottom of the image display. QFitsView was written in C++ and uses the Qt widget library, which makes it available for all major platforms: Windows, MAC OS X, and many Unix variants.","topic_id":"29818","bibcode":"2012ascl.soft10019O","views":"44","site_list":["http:\/\/www.mpe.mpg.de\/~ott\/QFitsView\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1005.4748"]},
		{"ascl_id":"1210.020","title":"GASGANO: Data File Organizer","credit":"ESO","abstract":"GASGANO is a GUI software tool for managing and viewing data files produced by VLT\r\nControl System (VCS) and the Data Flow System (DFS). It is developed and maintained by ESO to help its user community manage and organize astronomical data observed and produced by all VLT compliant telescopes in a systematic way. The software understands FITS, PAF, and ASCII files, and Reduction Blocks, and can group, sort, classify, filter, and search data in addition to allowing the user to browse, view, and manage them.","topic_id":"29819","bibcode":"2012ascl.soft10020E","views":"36","site_list":["http:\/\/www.eso.org\/sci\/software\/gasgano\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0701297"]},
		{"ascl_id":"1210.021","title":"SMART: Spectroscopic Modeling Analysis and Reduction Tool","credit":"IRS Team at Cornell University","abstract":"SMART is an IDL-based software tool, developed by the IRS Instrument Team at Cornell University, that allows users to reduce and analyze Spitzer data from all four modules of the Infrared Spectrograph, including the peak-up arrays. The software is designed to make full use of the ancillary files generated in the Spitzer Science Center pipeline so that it can either remove or flag artifacts and corrupted data and maximize the signal-to-noise ratio in the extraction routines. It can be run in both interactive and batch modes. SMART includes visualization tools for assessing data quality, basic arithmetic operations for either two-dimensional images or one-dimensional spectra, extraction of both point and extended sources, and a suite of spectral analysis tools.","topic_id":"29820","bibcode":"2012ascl.soft10021I","views":"70","site_list":["http:\/\/isc.astro.cornell.edu\/IRS\/SmartRelease"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004PASP..116..975H"]},
		{"ascl_id":"1210.022","title":"HAM2D: 2D Shearing Box Model","credit":"Gammie, Charles F.; Guan, Xiaoyue","abstract":"HAM solves non-relativistic hyperbolic partial differential equations in conservative form using high-resolution shock-capturing techniques. This version of HAM has been configured to solve the magnetohydrodynamic equations of motion in axisymmetry to evolve a shearing box model.","topic_id":"29827","bibcode":"2012ascl.soft10022G","views":"36","site_list":["http:\/\/rainman.astro.illinois.edu\/codelib\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ApJS..174..145G"]},
		{"ascl_id":"1210.023","title":"inf_solv: Kerr inflow solver","credit":"Gammie, Charles F.","abstract":"The efficiency of thin disk accretion onto black holes depends on the inner boundary condition, specifically the torque applied to the disk at the last stable orbit. This is usually assumed to vanish. This code estimates the torque on a magnetized disk using a steady magnetohydrodynamic inflow model originally developed by Takahashi et al. The efficiency e can depart significantly from the classical thin disk value. In some cases e &gt; 1, i.e., energy is extracted from the black hole.","topic_id":"29828","bibcode":"2012ascl.soft10023G","views":"39","site_list":["http:\/\/rainman.astro.illinois.edu\/codelib\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1999ApJ...522L..57G"]},
		{"ascl_id":"1210.024","title":"ORBADV: ORBital ADVection by interpolation","credit":"Johnson, Bryan; Guan, Xiaoyue; Gammie, Charles F.","abstract":"ORBADV adopts a ZEUS-like scheme to solve magnetohydrodynamic equations of motion in a shearing sheet. The magnetic field is discretized on a staggered mesh, and magnetic field variables represent fluxes through zone faces. The code uses obital advection to ensure fast and accurate integration in a large shearing box.","topic_id":"29829","bibcode":"2012ascl.soft10024J","views":"43","site_list":["http:\/\/rainman.astro.illinois.edu\/codelib\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ApJS..177..373J"]},
		{"ascl_id":"1210.025","title":"TwoDSSM: Self-gravitating 2D shearing sheet","credit":"Gammie, Charles F.; McKinney, Jonathan C.; Noble, Scott C.; T\u00f3th, G\u00e1bor; Del Zanna, Luca","abstract":"TwoDSSM solves the equations of self-gravitating hydrodynamics in the shearing sheet, with cooling. TwoDSSM is configured to use a simple, exponential cooling model, although it contains code for a more complicated (and perhaps more realistic) cooling model based on a one-zone vertical model. The complicated cooling model can be switched on using a flag.","topic_id":"29830","bibcode":"2012ascl.soft10025G","views":"52","site_list":["http:\/\/rainman.astro.illinois.edu\/codelib\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001ApJ...553..174G","http:\/\/adsabs.harvard.edu\/abs\/2006ApJ...636...63J"]},
		{"ascl_id":"1210.026","title":"PVS-GRMHD: Conservative GRMHD Primitive Variable Solvers","credit":"Noble, Scott C.; Gammie, Charles F.; McKinney, Jonathan C.; Del Zanna, Luca","abstract":"Conservative numerical schemes for general relativistic magnetohydrodynamics (GRMHD) require a method for transforming between \"conserved'' variables such as momentum and energy density and \"primitive\" variables such as rest-mass density, internal energy, and components of the four-velocity. The forward transformation (primitive to conserved) has a closed-form solution, but the inverse transformation (conserved to primitive) requires the solution of a set of five nonlinear equations. This code performs the inversion.","topic_id":"29832","bibcode":"2012ascl.soft10026N","views":"40","site_list":["http:\/\/rainman.astro.illinois.edu\/codelib\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ApJ...641..626N"]},
		{"ascl_id":"1210.027","title":"PyCosmic: Detecting cosmics in CALIFA and other fiber-fed integral-field spectroscopy datasets","credit":"Husemann, B.; Kamann, S.; Sandin, C.; S\u00e1nchez, S. F.; Garc\u00eda-Benito, R.; Mast, D.","abstract":"The detection of cosmic ray hits (cosmics) in fiber-fed integral-field spectroscopy (IFS) data of single exposures is a challenging task because of the complex signal recorded by IFS instruments. Existing detection algorithms are commonly found to be unreliable in the case of IFS data, and the optimal parameter settings are usually unknown a priori for a given dataset. The Calar Alto legacy integral field area (CALIFA) survey generates hundreds of IFS datasets for which a reliable and robust detection algorithm for cosmics is required as an important part of the fully automatic CALIFA data reduction pipeline. PyCosmic combines the edge-detection algorithm of L.A.Cosmic with a point-spread function convolution scheme. PyCosmic is the only algorithm that achieves an acceptable detection performance for CALIFA data. Only for strongly undersampled IFS data does L.A.Cosmic exceed the performance of PyCosmic by a few percent. Thus, PyCosmic appears to be the most versatile cosmics detection algorithm for IFS data.","topic_id":"29852","bibcode":"2012ascl.soft10027H","views":"33","site_list":["http:\/\/pycosmic.sf.net\/"],"ref_list":["http:\/\/esoads.eso.org\/abs\/2012A%26A...545A.137H"]},
		{"ascl_id":"1210.028","title":"QYMSYM: A GPU-accelerated hybrid symplectic integrator","credit":"Moore, Alexander; Quillen, Alice C.","abstract":"QYMSYM is a GPU accelerated 2nd order hybrid symplectic integrator that identifies close approaches between particles and switches from symplectic to Hermite algorithms for particles that require higher resolution integrations. This is a parallel code running with CUDA on a video card that puts the many processors on board to work while taking advantage of fast shared memory.","topic_id":"29874","bibcode":"2012ascl.soft10028M","views":"43","site_list":["http:\/\/astro.pas.rochester.edu\/~aquillen\/qymsym\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011NewA...16..445M"]},
		{"ascl_id":"1210.029","title":"Sapporo: N-body simulation library for GPUs","credit":"Gaburov, Evghenii; Harfst, Stefan; Portegies Zwart, Simon","abstract":"Sapporo mimics the behavior of GRAPE hardware and uses the GPU to perform high-precision gravitational N-body simulations. It makes use of CUDA and therefore only works on NVIDIA GPUs. N-body codes currently running on GRAPE-6 can switch to Sapporo by a simple relinking of the library. Sapporo's precision is comparable to that of GRAPE-6, even though internally the GPU hardware is limited to single precision arithmetics. This limitation is effectively overcome by emulating double precision for calculating the distance between particles.","topic_id":"29875","bibcode":"2012ascl.soft10029G","views":"47","site_list":["http:\/\/castle.strw.leidenuniv.nl\/software\/sapporo.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009NewA...14..630G"]},
		{"ascl_id":"1210.030","title":"BOOTTRAN: Error Bars for Keplerian Orbital Parameters","credit":"Wang, Sharon Xuesong; Wright, Jason T.","abstract":"BOOTTRAN calculates error bars for Keplerian orbital parameters for both single- and multiple-planet systems. It takes the best-fit parameters and radial velocity data (BJD, velocity, errors) and calculates the error bars from sampling distribution estimated via bootstrapping. It is recommended to be used together with the <a href=\"http:\/\/ascl.net\/1210.031\">RVLIN<\/a> package, which find best-fit Keplerian orbital parameters. Both RVLIN and BOOTTRAN are compatible with multiple-telescope data. BOOTTRAN also calculates the transit time and secondary eclipse time and their associated error bars. The algorithm is described in the appendix of the code paper (<!-- m --><a href=\"http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1210.6985X\">http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1210.6985X<\/a><!-- m -->).","topic_id":"29897","bibcode":"2012ascl.soft10030W","views":"71","site_list":["http:\/\/exoplanets.org\/old\/code\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1210.6985X"]},
		{"ascl_id":"1210.031","title":"RVLIN: Fitting Keplerian curves to radial velocity data","credit":"Wright, Jason; Howard, Andrew","abstract":"The RVLIN package for IDL is a set of routines that quickly fits an arbitrary number of Keplerian curves to radial velocity data. It can handle data from multiple telescopes (i.e. it solves for the offset), constraints on P, e, and time of peri passage, and can incorporate transit timing data. The code handles fixed periods and circular orbits in combination and transit time constraints, including for multiple transiting planets.","topic_id":"29908","bibcode":"2012ascl.soft10031W","views":"91","site_list":["http:\/\/exoplanets.org\/old\/code\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009ApJS..182..205W"]},
		{"ascl_id":"1211.001","title":"S2LET: Fast wavelet analysis on the sphere","credit":"Leistedt, Boris; McEwen, Jason","abstract":"S2LET provides high performance routines for fast wavelet analysis of signals on the sphere. It uses the SSHT code built on the MW sampling theorem to perform exact spherical harmonic transforms on the sphere. The resulting wavelet transform implemented in S2LET is theoretically exact, <span style=\"font-style: italic\">i.e.<\/span> a band-limited signal can be recovered from its wavelet coefficients exactly and the wavelet coefficients capture all the information. S2LET also supports the HEALPix sampling scheme, in which case the transforms are not theoretically exact but achieve good numerical accuracy. The core routines of S2LET are written in C and have interfaces in Matlab, IDL and Java. Real signals can be written to and read from FITS files and plotted as Mollweide projections.","topic_id":"29986","bibcode":"2012ascl.soft11001L","views":"38","site_list":["http:\/\/www.s2let.org\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1211.1680"]},
		{"ascl_id":"1211.002","title":"FreeEOS: Equation of State for stellar interiors calculations","credit":"Irwin, Alan W.","abstract":"FreeEOS is a Fortran library for rapidly calculating the equation of state using an efficient free-energy minimization technique that is suitable for physical conditions in stellar interiors. Converged FreeEOS solutions can be reliably determined for the first time for physical conditions occurring in stellar models with masses between 0.1 M<sub>\u2609<\/sub> and the hydrogen-burning limit near 0.07 M<sub>\u2609<\/sub> and hot brown-dwarf models just below that limit. However, an initial survey of results for those conditions showed EOS discontinuities (plasma phase transitions) and other problems which will need to be addressed in future work by adjusting the interaction radii characterizing the pressure ionization used for the FreeEOS calculations.","topic_id":"29994","bibcode":"2012ascl.soft11002I","views":"46","site_list":["http:\/\/freeeos.sourceforge.net\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1211.0706"]},
		{"ascl_id":"1211.003","title":"WVT Binning: Spatially adaptive 2-D binning","credit":"Diehl, Steven; Statler, Thomas S.","abstract":"WVT Binning is a spatially adaptive 2-dimensional binning algorithm designed to bin sparse X-ray data. It can handle background subtracted, exposure corrected data to produce intensity images, hardness ratio maps, or temperature maps. The algorithm is an extension of Cappellari & Copin's (2003) <a href=\"http:\/\/ascl.net\/1211.006\">Voronoi binning code<\/a> and uses Weighted Voronoi Tesselations (WVT) to produce a very compact binning structure with a constant S\/N per bin. The bin size adjusts to the required resolution in single-pixel steps, which minimizes the scatter around the target S\/N. The code is very versatile and can in principle be applied to any type of data. The user manual contains instructions on how to apply the WVT binning code to X-ray data and how to extend the algorithm to other problems.","topic_id":"30262","bibcode":"2012ascl.soft11003D","views":"43","site_list":["http:\/\/www.phy.ohiou.edu\/~diehl\/WVT\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006MNRAS.368..497D"]},
		{"ascl_id":"1211.004","title":"CORRFIT: Cross-Correlation Routines","credit":"Statler, Thomas S.","abstract":"CORRFIT is a set of routines that use the cross-correlation method to extract parameters of the line-of-sight velocity distribution from galactic spectra and stellar templates observed on the same system. It works best when the broadening function is well sampled at the spectral resolution used (e.g. 200 km\/s dispersion at 2 Angstrom resolution). Results become increasingly sensitive to the spectral match between galaxy and template if the broadening function is not well sampled. CORRFIT does not work well for dispersions less than the velocity sampling interval ('delta' in the code) unless the template is perfect.","topic_id":"30263","bibcode":"2012ascl.soft11004S","views":"62","site_list":["http:\/\/www.phy.ohiou.edu\/~tss\/software.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1995AJ....109.1371S"]},
		{"ascl_id":"1211.005","title":"C-m Emu: Concentration-mass relation emulator","credit":"Kwan, Juliana; Bhattacharya, Suman; Heitmann, Katrin; Habib, Salman","abstract":"The concentration-mass relation for dark matter-dominated halos is one of the essential results expected from a theory of structure formation. C-m Emu is a simple numerical code for the c-M relation as a function of cosmological parameters for wCDM models generates the best-fit power-law model for each redshift separately and then interpolate between the redshifts. This produces a more accurate answer at each redshift at the minimal cost of running a fast code for every c -M prediction instead of using one fitting formula. The emulator is constructed from 37 individual models, with three nested N-body gravity-only simulations carried out for each model. The mass range covered by the emulator is 2 x 10^{12} M_sun &lt; M &lt;10^{15} M_sun with a corresponding redshift range of z=0 -1. Over this range of mass and redshift, as well as the variation of cosmological parameters studied, the mean halo concentration varies from c ~ 2 to c ~ 8. The distribution of the concentration at fixed mass is Gaussian with a standard deviation of one-third of the mean value, almost independent of cosmology, mass, and redshift over the ranges probed by the simulations.","topic_id":"30266","bibcode":"2012ascl.soft11005K","views":"61","site_list":["http:\/\/www.hep.anl.gov\/cosmology\/CosmicEmu\/emu.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1210.1576"]},
		{"ascl_id":"1211.006","title":"Voronoi binning method","credit":"Cappellari, Michele; Copin, Yannick","abstract":"The Voronoi binning method is an IDL program to bin two-dimensional data to a constant signal-to-noise ratio per bin. It optimally solves the problem of preserving the maximum spatial resolution of general two-dimensional data, given a constraint on the minimum signal-to-noise ratio.","topic_id":"30267","bibcode":"2012ascl.soft11006C","views":"64","site_list":["http:\/\/www-astro.physics.ox.ac.uk\/~mxc\/idl\/#binning"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003MNRAS.342..345C"]},
		{"ascl_id":"1212.001","title":"Bonsai: N-body GPU tree-code","credit":"B\u00e9dorf, Jeroen; Gaburov, Evghenii; Portegies Zwart, Simon","abstract":"Bonsai is a gravitational N-body tree-code that runs completely on the GPU. This reduces the amount of time spent on communication with the CPU. The code runs on NVIDIA GPUs and on a GTX480 it is able to integrate ~2.8M particles per second. The tree construction and traverse algorithms are portable to many-core devices which have support for CUDA or OpenCL programming languages.","topic_id":"30322","bibcode":"2012ascl.soft12001B","views":"73","site_list":["http:\/\/castle.strw.leidenuniv.nl\/software\/bonsai-gpu-tree-code.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012ASPC..453..325B"]},
		{"ascl_id":"1212.002","title":"XPHOT: Estimation of properties of weak X-ray sources","credit":"Getman, Konstantin; Feigelson, Eric; Broos, Patrick; Townsley, Leisa; Garmire, Gordon","abstract":"XPHOT is an IDL implementation of a non-parametric method for estimating the apparent and intrinsic broad-band fluxes and absorbing X-ray column densities of weak X-ray sources. XPHOT is intended for faint sources with greater than \u223c5-7 counts but fewer than 100-300 counts where parametric spectral fitting methods will be superior. This method is similar to the long-standing use of color-magnitude diagrams in optical and infrared astronomy, with X-ray median energy replacing color index and X-ray source counts replacing magnitude. Though XPHOT was calibrated for thermal spectra characteristic of stars in young stellar clusters, recalibration should be possible for some other classes of faint X-ray sources such as extragalactic active galactic nuclei.","topic_id":"30309","bibcode":"2012ascl.soft12002G","views":"46","site_list":["http:\/\/www2.astro.psu.edu\/users\/gkosta\/XPHOT\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010ApJ...708.1760G"]},
		{"ascl_id":"1212.003","title":"MPWide: Light-weight communication library for distributed computing","credit":"Groen, Derek; Rieder, Steven; Grosso, Paola; de Laat, Cees; Portegies Zwart, Simon","abstract":"MPWide is a light-weight communication library for distributed computing. It is specifically developed to allow message passing over long-distance networks using path-specific optimizations. An early version of MPWide was used in the Gravitational Billion Body Project to allow simulations across multiple supercomputers.","topic_id":"30323","bibcode":"2012ascl.soft12003G","views":"39","site_list":["http:\/\/castle.strw.leidenuniv.nl\/software\/mpwide.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010CS%26D....3a5002G"]},
		{"ascl_id":"1212.004","title":"MOLIERE-5: Forward and inversion model for sub-mm wavelengths","credit":"Urban, J.; Baron, P.; Lautie, N.","abstract":"MOLIERE-5 (Microwave Observation LIne Estimation and REtrieval) is a versatile forward and inversion model for the millimeter and submillimeter wavelengths range and includes an inversion model. The MOLIERE-5 forward model includes modules for the calculation of absorption coefficients, radiative transfer, and instrumental characteristics. The radiative transfer model is supplemented by a sensitivity module for estimating the contribution to the spectrum of each catalog line at its center frequency enabling the model to effectively filter for small spectral lines.  The instrument model consists of several independent modules, including the calculation of the convolution of spectra and weighting functions with the spectrometer response functions. The instrument module also provides several options for modeling of frequency-switched observations. The MOLIERE-5 inversion model calculates linear Optimal Estimation, a least-squares retrieval method which uses statistical apriori knowledge on the retrieved parameters for the regularization of ill-posed inversion problems and  computes diagnostics such as the measurement and smoothing error covariance matrices along with contribution and averaging kernel functions.","topic_id":"30326","bibcode":"2012ascl.soft12004U","views":"38","site_list":["http:\/\/www.rss.chalmers.se\/~jo\/moliere5\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004JQSRT..83..529U"]},
		{"ascl_id":"1212.005","title":"General complex polynomial root solver","credit":"Skowron, J.; Gould, A.","abstract":"This general complex polynomial root solver, implemented in Fortran and further optimized for binary microlenses, uses a new algorithm to solve polynomial equations and is 1.6-3 times faster than the ZROOTS subroutine that is commercially available from Numerical Recipes, depending on application. The largest improvement, when compared to naive solvers, comes from a fail-safe procedure that permits skipping the majority of the calculations in the great majority of cases, without risking catastrophic failure in the few cases that these are actually required.","topic_id":"30379","bibcode":"2012ascl.soft12005S","views":"34","site_list":["http:\/\/www.astrouw.edu.pl\/~jskowron\/cmplx_roots_sg\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1203.1034S","http:\/\/adsabs.harvard.edu\/abs\/2012RAA....12..947M"]},
		{"ascl_id":"1212.006","title":"CosmoPMC: Cosmology sampling with Population Monte Carlo","credit":"Kilbinger, Martin; Benabed, Karim; Capp\u00e9, Olivier; Coupon, Jean; Cardoso, Jean-Fran\u00e7ois; Fort, Gersende; McCracken, Henry Joy; Prunet, Simon; Robert, Christian P.; Wraith, Darren","abstract":"CosmoPMC is a Monte-Carlo sampling method to explore the likelihood of various cosmological probes. The sampling engine is implemented with the package pmclib. It is called Population MonteCarlo (PMC), which is a novel technique to sample from the posterior. PMC is an adaptive importance sampling method which iteratively improves the proposal to approximate the posterior. This code has been introduced, tested and applied to various cosmology data sets.","topic_id":"30375","bibcode":"2012ascl.soft12006K","views":"57","site_list":["http:\/\/www.cosmopmc.info"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010MNRAS.405.2381K"]},
		{"ascl_id":"1212.007","title":"WOLF: FITS file processor","credit":"Shamir, Lior","abstract":"WOLF processes FITS files and generates photometry files, annotated JPGs, opacity maps, background, transient detection and luminance changes detection. This software was used to process data for the Night Sky Live project.","topic_id":"30376","bibcode":"2012ascl.soft12007S","views":"53","site_list":["http:\/\/vfacstaff.ltu.edu\/lshamir\/downloads\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005PASA...22..111S"]},
		{"ascl_id":"1212.008","title":"SIR: Stokes Inversion based on Response functions","credit":"Ruiz Cobo, B.; del Toro Iniesta, J. C.","abstract":"SIR is a general-purpose code capable of dealing with gradients of the physical quantities with height. It admits one and two-component model atmospheres. It allows the recovery of the stratification of the temperature, the magnetic field vector, and the line of sight velocity through the atmosphere, and the micro- and macroturbulence velocities - which are assumed to be constant with depth. It is based on the response functions, which enter a Marquardt nonlinear least-squares algorithm in a natural way. Response functions are calculated at the same time as the full radiative transfer equation for polarized light is integrated, which determines values of many free parameters in a reasonable computation time. SIR demonstrates high stability, accuracy, and uniqueness of results, even when simulated observations present signal-to-noise ratios of the order of the lowest acceptable values in real observations.","topic_id":"30382","bibcode":"2012ascl.soft12008R","views":"45","site_list":["https:\/\/w3.iaa.es\/hinode_europe\/index.php\/gb\/inversion_codes\/sir"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1992ApJ...398..375R"]},
		{"ascl_id":"1212.009","title":"Aegean: Compact source finding in radio images","credit":"Hancock, P. J.; Murphy, T.; Gaensler, B. M.; Hopkins, A.; Curran, J. R.","abstract":"Aegean, written in python, finds compact sources within radio images by seeking out islands of pixels above a given threshold and then using the curvature of the image to determine how many Gaussian components should be used to describe the island. The Gaussian fitting is initiated with parameters determined from the curvature and intensity maps, and makes use of <a href=\"http:\/\/ascl.net\/1208.019\">mpfit<\/a> to perform a constrained fit. Aegean has been optimized for compact radio sources in images that have no diffuse background emission, but by pre-processing the images with a spatial filter, or by convolving an optical image with an appropriately small PSF, Aegean is able to produce excellent results in a range of applications.","topic_id":"30381","bibcode":"2012ascl.soft12009H","views":"101","site_list":["https:\/\/www.sites.google.com\/site\/mrpaulhancock\/data-and-code\/aegean"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.422.1812H"]},
		{"ascl_id":"1212.010","title":"Synth3: Non-magnetic spectrum synthesis code","credit":"Kochukhov, Oleg","abstract":"Synth3 is a non-magnetic spectrum synthesis code. It works with model atmospheres in Kurucz format and VALD Sf line lists and features element stratification, molecular equilibrium and individual microturbulence for each line. Disk integration can be done with s3di which is included in the archive. Synth3 computes spectra emergent from the stellar atmospheres with a depth-dependent chemical composition if depth-dependent abundance is provided in the input model atmosphere file.","topic_id":"30335","bibcode":"2012ascl.soft12010K","views":"44","site_list":["http:\/\/www.astro.uu.se\/~oleg\/download.html?"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007pms..conf..109K","http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1211.2388S"]},
		{"ascl_id":"1212.011","title":"DrizzlePac: HST image software","credit":"STSCI Development Team","abstract":"DrizzlePac allows users to easily and accurately align and combine HST images taken at multiple epochs, and even with different instruments. It is a suite of supporting tasks for AstroDrizzle which includes:\r\n\r\n<ul><li>astrodrizzle to align and combine images<\/li><li>tweakreg and tweakback for aligning images in different visits<\/li><li>pixtopix transforms an X,Y pixel position to its pixel position after distortion corrections<\/li><li>skytopix transforms sky coordinates to X,Y pixel positions. A reverse transformation can be done using the task pixtosky.<\/li><\/ul>","topic_id":"30374","bibcode":"2012ascl.soft12011S","views":"56","site_list":["http:\/\/drizzlepac.stsci.edu\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012AAS...22013513A"]},
		{"ascl_id":"1212.012","title":"ddisk: Debris disk time-evolution","credit":"Hahn, Joseph M.","abstract":"ddisk is an IDL script that calculates the time-evolution of a circumstellar debris disk. It calculates dust abundances over time for a debris-disk that is produced by a planetesimal disk that is grinding away due to collisional erosion.","topic_id":"30418","bibcode":"2012ascl.soft12012H","views":"49","site_list":["http:\/\/gemelli.spacescience.org\/~hahnjm\/software\/ddisk\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1006.4311"]},
		{"ascl_id":"1212.013","title":"EXSdetect: Extended X-ray Source Detection","credit":"Liu, Teng; Tozzi, Paolo; Tundo, Elena; Moretti, A.; Wang, Jun-Xian; Rosati, Piero; Guglielmetti, Fabrizia","abstract":"EXSdetect is a python implementation of an X-ray source detection algorithm which is optimally designed to detected faint extended sources and makes use of Voronoi tessellation and Friend-of-Friend technique. It is a flexible tool capable of detecting extended sources down to the lowest flux levels attainable within instrumental limitations while maintaining robust photometry, high completeness, and low contamination, regardless of source morphology. EXSdetect was developed mainly to exploit the ever-increasing wealth of archival X-ray data, but is also ideally suited to explore the scientific capabilities of future X-ray facilities, with a strong focus on investigations of distant groups and clusters of galaxies.","topic_id":"30436","bibcode":"2012ascl.soft12013L","views":"43","site_list":["http:\/\/adlibitum.oats.inaf.it\/sxcs\/EXSdetect.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1212.4038L"]},
		{"ascl_id":"1212.014","title":"Thrust: Productivity-Oriented Library for CUDA","credit":"Bell, Nathan; Hoberock, Jared","abstract":"Thrust is a parallel algorithms library which resembles the C++ Standard Template Library (STL). Thrust's high-level interface greatly enhances programmer productivity while enabling performance portability between GPUs and multicore CPUs. Interoperability with established technologies (such as CUDA, TBB, and OpenMP) facilitates integration with existing software.","topic_id":"30442","bibcode":"2012ascl.soft12014B","views":"50","site_list":["http:\/\/thrust.github.com\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012ASPC..461...37B"]},
		{"ascl_id":"1212.015","title":"TMAP: T\u00fcbingen NLTE Model-Atmosphere Package","credit":"Werner, Klaus; Dreizler, Stefan; Rauch, Thomas","abstract":"The T\u00fcbingen NLTE Model-Atmosphere Package (TMAP) is a tool to calculate stellar atmospheres in spherical or plane-parallel geometry in hydrostatic and radiative equilibrium allowing departures from local thermodynamic equilibrium (LTE) for the population of atomic levels. It is based on the Accelerated Lambda Iteration (ALI) method and is able to account for line blanketing by metals. All elements from hydrogen to nickel may be included in the calculation with model atoms which are tailored for the aims of the user.","topic_id":"30445","bibcode":"2012ascl.soft12015W","views":"54","site_list":["http:\/\/astro.uni-tuebingen.de\/~TMAP\/TMAP.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003ASPC..288..103R"]},
		{"ascl_id":"1301.001","title":"PSFEx: Point Spread Function Extractor","credit":"Bertin, Emmanuel","abstract":"PSFEx  (\u201cPSF Extractor\u201d) extracts models of the Point Spread Function (PSF) from FITS images processed with <a href=\"http:\/\/ascl.net\/1010.064\">SExtractor<\/a> and measures the quality of images. The generated PSF models can be used for model-fitting photometry or morphological analyses.","topic_id":"30570","bibcode":"2013ascl.soft01001B","views":"61","site_list":["http:\/\/www.astromatic.net\/software\/psfex"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ASPC..442..435B"]},
		{"ascl_id":"1302.001","title":"MARX: Model of AXAF Response to X-rays","credit":"Wise, Michael W.; Davis, John E.; Huenemoerder, David P.; Houck, John C.; Dewey, Dan","abstract":"MARX (Model of AXAF Response to X-rays) is a suite of programs designed to enable the user to simulate the on-orbit performance of the Chandra satellite. MARX provides a detailed ray-trace simulation of how Chandra responds to a variety of astrophysical sources and can generate standard FITS events files and images as output. It contains models for the HRMA mirror system onboard Chandra as well as the HETG and LETG gratings and all focal plane detectors.","topic_id":"30644","bibcode":"2013ascl.soft02001W","views":"38","site_list":["http:\/\/space.mit.edu\/ASC\/MARX\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004ApJ...610.1204L"]},
		{"ascl_id":"1302.002","title":"ISIS: Interactive Spectral Interpretation System for High Resolution X-Ray Spectroscopy","credit":"Houck, John C.; Davis, John E.; Huenemoerder, David; Dewey, Dan; Nowak, Mike; Davis, David S.","abstract":"ISIS, the Interactive Spectral Interpretation System, is designed to facilitate the interpretation and analysis of high resolution X-ray spectra. It is being developed as a programmable, interactive tool for studying the physics of X-ray spectrum formation, supporting measurement and identification of spectral features, and interaction with a database of atomic structure parameters and plasma emission models.","topic_id":"20393","bibcode":"2013ascl.soft02002H","views":"37","site_list":["http:\/\/space.mit.edu\/ASC\/ISIS\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000ASPC..216..591H"]},
		{"ascl_id":"1302.003","title":"ACS: ALMA Common Software","credit":"Chiozzi, Gianluca; \u0160ekoranja, Matej","abstract":"ALMA Common Software (ACS) provides a software infrastructure common to all ALMA partners and consists of a documented collection of common patterns and components which implement those patterns. The heart of ACS is based on a distributed Component-Container model, with ACS Components implemented as CORBA objects in any of the supported programming languages. ACS provides common CORBA-based services such as logging, error and alarm management, configuration database and lifecycle management. Although designed for ALMA, ACS can and is being used in other control systems and distributed software projects, since it implements proven design patterns using state of the art, reliable technology. It also allows, through the use of well-known standard constructs and components, that other team members whom are not authors of ACS easily understand the architecture of software modules, making maintenance affordable even on a very large project.","topic_id":"30694","bibcode":"2013ascl.soft02003C","views":"73","site_list":["http:\/\/www.eso.org\/projects\/alma\/develop\/acs\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002ASPC..281..103R"]},
		{"ascl_id":"1302.004","title":"pNbody: A python parallelized N-body reduction toolbox","credit":"Revaz, Yves","abstract":"pNbody is a parallelized python module toolbox designed to manipulate and interactively display very large N-body systems. It allows the user to perform complicated manipulations with only very few commands and to load an N-body system and explore it interactively using the python interpreter. pNbody may also be used in python scripts. pNbody contains graphical facilities for creating maps of physical values of the system, such as density, temperature, and velocities maps. Stereo capabilities are also implemented. pNbody is not limited by file format; the user may use a parameter file to redefine how to read a preferred format.","topic_id":"30744","bibcode":"2013ascl.soft02004R","views":"43","site_list":["http:\/\/obswww.unige.ch\/~revaz\/pNbody\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009A%26A...501..189R"]},
		{"ascl_id":"1302.005","title":"EPICS: Experimental Physics and Industrial Control System","credit":"EPICS Development Team","abstract":"EPICS is a set of software tools and applications developed collaboratively and used to create distributed soft real-time control systems for scientific instruments such as particle accelerators and telescopes. Such distributed control systems typically comprise tens or even hundreds of computers, networked together to allow communication between them and to provide control and feedback of the various parts of the device from a central control room, or even remotely over the internet. EPICS uses Client\/Server and Publish\/Subscribe techniques to communicate between the various computers. A Channel Access Gateway allows engineers and physicists elsewhere in the building to examine the current state of the IOCs, but prevents them from making unauthorized adjustments to the running system. In many cases the engineers can make a secure internet connection from home to diagnose and fix faults without having to travel to the site.\r\n\r\nEPICS is used by many facilities worldwide, including the Advanced Photon Source at Argonne National Laboratory, Fermilab, Keck Observatory, Laboratori Nazionali di Legnaro, Brazilian Synchrotron Light Source, Los Alamos National Laboratory, Australian Synchrotron, and Stanford Linear Accellerator Center.","topic_id":"30695","bibcode":"2013ascl.soft02005E","views":"38","site_list":["http:\/\/www.aps.anl.gov\/epics\/index.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002SPIE.4848..107B","http:\/\/adsabs.harvard.edu\/abs\/2003ApJ...592L..83C"]},
		{"ascl_id":"1302.006","title":"Minerva: Cylindrical coordinate extension for Athena","credit":"Skinner, M. Aaron; Ostriker, Eve C.","abstract":"Minerva is a cylindrical coordinate extension of the <a href=\"http:\/\/ascl.net\/1010.014\">Athena astrophysical MHD code<\/a> of Stone, Gardiner, Teuben, and Hawley. The extension follows the approach of Athena's original developers and has been designed to alter the existing Cartesian-coordinates code as minimally and transparently as possible. The numerical equations in cylindrical coordinates are formulated to maintain consistency with constrained transport (CT), a central feature of the Athena algorithm, while making use of previously implemented code modules such as the Riemann solvers. Angular momentum transport, which is critical in astrophysical disk systems dominated by rotation, is treated carefully.","topic_id":"30696","bibcode":"2013ascl.soft02006S","views":"56","site_list":["http:\/\/www.astro.umd.edu\/~askinner\/minerva\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010ApJS..188..290S"]},
		{"ascl_id":"1302.007","title":"GRID-core: Gravitational Potential Identification of Cores","credit":"Gong, Hao; Ostriker, Eve C.","abstract":"GRID-core is a core-finding method using the contours of the local gravitational potential to identify core boundaries. The GRID-core method applied to 2D surface density and 3D volume density are in good agreement for bound cores. We have implemented a version of the GRID-core algorithm in IDL, suitable for core-finding in observed maps. The required input is a two-dimensional FITS file containing a map of the column density in a region of a cloud.","topic_id":"30731","bibcode":"2013ascl.soft02007G","views":"37","site_list":["http:\/\/www.astro.umd.edu\/~hgong\/GRID_core.htm"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ApJ...729..120G"]},
		{"ascl_id":"1302.008","title":"FASTPHOT: A simple and quick IDL PSF-fitting routine","credit":"B\u00e9thermin, M.; Dole, H.; Cousin, M.; Bavouzet, N.","abstract":"PSF fitting photometry allows a simultaneously fit of a PSF profile on the sources. Many routines use PSF fitting photometry, including IRAF\/allstar, Strarfinder, and Convphot. These routines are in general complex to use and slow. FASTPHOT is optimized for prior extraction (the position of the sources is known) and is very fast and simple.","topic_id":"30733","bibcode":"2013ascl.soft02008B","views":"56","site_list":["http:\/\/www.ias.u-psud.fr\/irgalaxies\/downloads.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010A%26A...516A..43B"]},
		{"ascl_id":"1302.009","title":"IAS Stacking Library in IDL","credit":"Bavouzet, Nicolas; Beelen, Alexandre; Bethermin, Matthieu; Dole, Herve; Ponthieu, Nicolas","abstract":"This IDL library is designed to be used on astronomical images. Its main aim is to stack data to allow a statistical detection of faint signal, using a prior.  For instance, you can stack 160um data using the positions of galaxies detected at 24um or 3.6um, or use WMAP sources to stack Planck data. It can estimate error bars using bootstrap, and it can perform photometry (aperture photometry, or PSF fitting, or other that you can plug). The IAS Stacking Library works with gnomonic projections (RA---TAN), and also with HEALPIX projection.","topic_id":"30734","bibcode":"2013ascl.soft02009B","views":"50","site_list":["http:\/\/www.ias.u-psud.fr\/irgalaxies\/downloads.php"],"ref_list":["http:\/\/cdsads.u-strasbg.fr\/abs\/2010A%26A...512A..78B"]},
		{"ascl_id":"1302.010","title":"ICORE: Image Co-addition with Optional Resolution Enhancement","credit":"Masci, Frank","abstract":"ICORE is a command-line driven co-addition, mosaicking, and resolution enhancement (HiRes) tool for creating science quality products from image data in FITS format and with World Coordinate System information following the FITS-WCS standard. It includes preparatory steps such as image background matching, photometric gain-matching, and pixel-outlier rejection. Co-addition and\/or HiRes'ing can be performed in either the inertial WCS or in the rest frame of a moving object. Three interpolation methods are supported: overlap-area weighting, drizzle, and weighting by the detector Point Response Function (PRF). The latter enables the creation of matched-filtered products for optimal point-source detection, but most importantly allows for resolution enhancement using a spatially-dependent deconvolution method. This is a variant of the classic Richardson-Lucy algorithm with the added benefit to simultaneously register and co-add multiple images to optimize signal-to-noise and sampling of the instrumental PSF. It can assume real (or otherwise \"flat\") image priors, mitigate \"ringing\" artifacts, and assess the quality of image solutions using statistically-motivated convergence criteria. Uncertainties are also estimated and internally validated for all products. The software supports multithreading that can be configured for different architectures. Numerous example scripts are included (with test data) to co-add and\/or HiRes image data from Spitzer-IRAC\/MIPS, WISE, and Herschel-SPIRE.","topic_id":"30755","bibcode":"2013ascl.soft02010M","views":"38","site_list":["http:\/\/web.ipac.caltech.edu\/staff\/fmasci\/home\/icore.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012AJ....144...68J"]},
		{"ascl_id":"1302.011","title":"GALA: Stellar atmospheric parameters and chemical abundances","credit":"Mucciarelli, A.; Pancino, E.; Lovisi, L.; Ferraro, F. R.; Lapenna, E.","abstract":"GALA is a freely distributed Fortran code to derive the atmospheric parameters (temperature, gravity, microturbulent velocity and overall metallicity) and abundances for individual species of stellar spectra using the classical method based on the equivalent widths of metallic lines. The abundances of individual spectral lines are derived by using the WIDTH9 code developed by R. L. Kurucz. GALA is designed to obtain the best model atmosphere, by optimizing temperature, surface gravity, microturbulent velocity and metallicity, after rejecting the discrepant lines. Finally, it computes accurate internal errors for each atmospheric parameter and abundance. The code obtains chemical abundances and atmospheric parameters for large stellar samples quickly, thus making GALA an useful tool in the epoch of the multi-object spectrographs and large surveys.","topic_id":"30778","bibcode":"2013ascl.soft02011M","views":"41","site_list":["http:\/\/www.cosmic-lab.eu\/gala\/gala.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1302.3618M"]},
		{"ascl_id":"1302.012","title":"ME(SSY)**2: Monte Carlo Code for Star Cluster Simulations","credit":"Freitag, Marc Dewi","abstract":"ME(SSY)**2 stands for \u201cMonte-carlo Experiments with Spherically SYmmetric Stellar SYstems.\" This code simulates the long term evolution of spherical clusters of stars; it was devised specifically to treat dense galactic nuclei. It is based on the pioneering Monte Carlo scheme proposed by H\u00e9non in the 70's and includes all relevant physical ingredients (2-body relaxation, stellar mass spectrum, collisions, tidal disruption, ldots). It is basically a Monte Carlo resolution of the Fokker-Planck equation. It can cope with any stellar mass spectrum or velocity distribution. Being a particle-based method, it also allows one to take stellar collisions into account in a very realistic way. This unique code, featuring most important physical processes, allows million particle simulations, spanning a Hubble time, in a few CPU days on standard personal computers and provides a wealth of data only rivalized by N-body simulations. The current version of the software requires the use of routines from the \"Numerical Recipes in Fortran 77\" (<!-- m --><a href=\"http:\/\/www.nrbook.com\/a\/bookfpdf.php\">http:\/\/www.nrbook.com\/a\/bookfpdf.php<\/a><!-- m -->).","topic_id":"30783","bibcode":"2013ascl.soft02012F","views":"48","site_list":["http:\/\/members.aei.mpg.de\/amaro-seoane\/messy2-monte-carlo-simulations-for-stellar-dynamics\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001A%26A...375..711F"]},
		{"ascl_id":"1302.013","title":"NIFTY: A versatile Python library for signal inference","credit":"Selig, Marco; Bell, Michael R.; Junklewitz, Henrik; Oppermann, Niels; Reinecke, Martin; Greiner, Maksim; Pachajoa, Carlos; En\u00dflin, Torsten A.","abstract":"NIFTY (Numerical Information Field TheorY) is a versatile library enables the development of signal inference algorithms that operate regardless of the underlying spatial grid and its resolution. Its object-oriented framework is written in Python, although it accesses libraries written in Cython, C++, and C for efficiency. NIFTY offers a toolkit that abstracts discretized representations of continuous spaces, fields in these spaces, and operators acting on fields into classes. Thereby, the correct normalization of operations on fields is taken care of automatically. This allows for an abstract formulation and programming of inference algorithms, including those derived within information field theory. Thus, NIFTY permits rapid prototyping of algorithms in 1D and then the application of the developed code in higher-dimensional settings of real world problems. NIFTY operates on point sets, n-dimensional regular grids, spherical spaces, their harmonic counterparts, and product spaces constructed as combinations of those.","topic_id":"30796","bibcode":"2013ascl.soft02013S","views":"51","site_list":["http:\/\/www.mpa-garching.mpg.de\/ift\/nifty\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1301.4499S"]},
		{"ascl_id":"1302.014","title":"SYNMAG Photometry: Catalog-level Matched Colors of Extended Sources","credit":"Bundy, Kevin; Hogg, David W.; Higgs, Tim D.; Nichol, Robert C.; Yasuda, Naoki; Masters, Karen L.; Lang, Dustin; Wake, David A.","abstract":"SYNMAG is a tool for producing synthetic aperture magnitudes to enable fast matched photometry at the catalog level without reprocessing imaging data. Aperture magnitudes are the most widely tabulated flux measurements in survey catalogs; obtaining reliable, matched photometry for galaxies imaged by different observatories represents a key challenge in the era of wide-field surveys spanning more than several hundred square degrees. Methods such as flux fitting, profile fitting, and PSF homogenization followed by matched-aperture photometry are all computationally expensive. An alternative solution called \"synthetic aperture photometry\" exploits galaxy profile fits in one band to efficiently model the observed, point-spread-function-convolved light profile in other bands and predict the flux in arbitrarily sized apertures.","topic_id":"30798","bibcode":"2013ascl.soft02014B","views":"48","site_list":["http:\/\/member.ipmu.jp\/kevin.bundy\/synmag"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012AJ....144..188B"]},
		{"ascl_id":"1302.015","title":"DisPerSE: Discrete Persistent Structures Extractor","credit":"Sousbie, Thierry","abstract":"DisPerSE is open source software for the identification of persistent topological features such as peaks, voids, walls and in particular filamentary structures within noisy sampled distributions in 2D, 3D. Using DisPerSE, structure identification can be achieved through the computation of the discrete Morse-Smale complex. The software can deal directly with noisy datasets via the concept of persistence (a measure of the robustness of topological features). Although developed for the study of the properties of filamentary structures in the cosmic web of galaxy distribution over large scales in the Universe, the present version is quite versatile and should be useful for any application where a robust structure identification is required, such as for segmentation or for studying the topology of sampled functions (for example, computing persistent Betti numbers). Currently, it can be applied can work indifferently on many kinds of cell complex (such as structured and unstructured grids, 2D manifolds embedded within a 3D space, discrete point samples using delaunay tesselation, and Healpix tesselations of the sphere). The only constraint is that the distribution must be defined over a manifold, possibly with boundaries.","topic_id":"30806","bibcode":"2013ascl.soft02015S","views":"48","site_list":["http:\/\/www2.iap.fr\/users\/sousbie\/web\/html\/indexd41d.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011MNRAS.414..350S"]},
		{"ascl_id":"1302.016","title":"XDQSO: Photometic quasar probabilities and redshifts","credit":"Bovy, Jo; Hennawi, Joseph F.; Hogg, David W.; Myers, Adam D.; Kirkpatrick, Jessica A.; Schlegel, David J.; Ross, Nicholas P.; Sheldon, Erin S.; McGreer, Ian D.; Schneider, Donald P.; Weaver, Benjamin A.","abstract":"XDQSO, written in IDL, calculates photometric quasar probabilities to mimick SDSS-III\u2019s BOSS quasar target selection or photometric redshifts for quasars, whether in three redshift ranges (z &lt; 2.2; 2.2 leq z leq 3.5; z &gt; 3.5) or arbitrary redshift ranges.","topic_id":"30809","bibcode":"2013ascl.soft02016B","views":"59","site_list":["http:\/\/www.sdss3.org\/svn\/repo\/xdqso\/tags\/v0_6\/doc\/build\/html\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ApJ...729..141B"]},
		{"ascl_id":"1302.017","title":"ESO-MIDAS: General tools for image processing and data reduction","credit":"European Southern Observatory","abstract":"The ESO-MIDAS system provides general tools for image processing and data reduction with emphasis on astronomical applications including imaging and special reduction packages for ESO instrumentation at La Silla and the VLT at Paranal. In addition it contains applications packages for stellar and surface photometry, image sharpening and decomposition, statistics, data fitting, data presentation in graphical form, and more.","topic_id":"30811","bibcode":"2013ascl.soft02017E","views":"111","site_list":["http:\/\/www.eso.org\/sci\/software\/esomidas\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1997A%26AS..124..163A","http:\/\/adsabs.harvard.edu\/abs\/1992ASPC...25..120B"]},
		{"ascl_id":"1303.001","title":"SWIFT: A solar system integration software package","credit":"Levison, Harold F.; Duncan, Martin J.","abstract":"SWIFT follows the long-term dynamical evolution of a swarm of test particles in the solar system. The code efficiently and accurately handles close approaches between test particles and planets while retaining the powerful features of recently developed mixed variable symplectic integrators. Four integration techniques are included: Wisdom-Holman Mapping; Regularized Mixed Variable Symplectic (RMVS) method; fourth order T+U Symplectic (TU4) method; and Bulirsch-Stoer method. The package is designed so that the calls to each of these look identical so that it is trivial to replace one with another. Complex data manipulations and results can be analyzed with the graphics packace <a href=\"http:\/\/ascl.net\/1112.018\">SwiftVis<\/a>.","topic_id":"30825","bibcode":"2013ascl.soft03001L","views":"65","site_list":["http:\/\/www.boulder.swri.edu\/~hal\/swift.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1994Icar..108...18L"]},
		{"ascl_id":"1303.002","title":"emcee: The MCMC Hammer","credit":"Foreman-Mackey, Daniel; Conley, Alex; Meierjurgen Farr, Will; Hogg, David W.; Long, Dustin; Marshall, Phil; Price-Whelan, Adrian; Sanders, Jeremy; Zuntz, Joe","abstract":"emcee is an extensible, pure-Python implementation of Goodman & Weare's Affine Invariant Markov chain Monte Carlo (MCMC) Ensemble sampler. It's designed for Bayesian parameter estimation. The algorithm behind emcee has several advantages over traditional MCMC sampling methods and has excellent performance as measured by the autocorrelation time (or function calls per independent sample). One advantage of the algorithm is that it requires hand-tuning of only 1 or 2 parameters compared to $sim N^2$ for a traditional algorithm in an N-dimensional parameter space. Exploiting the parallelism of the ensemble method, emcee permits any user to take advantage of multiple CPU cores without extra effort.","topic_id":"30831","bibcode":"2013ascl.soft03002F","views":"59","site_list":["http:\/\/dan.iel.fm\/emcee\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012ApJ...752..147D","http:\/\/arxiv.org\/abs\/1202.3665"]},
		{"ascl_id":"1303.003","title":"CosmoHammer: Cosmological parameter estimation with the MCMC Hammer","credit":"Akeret, Jo\u00ebl; Seehars, Sebastian; Amara, Adam; Refregier, Alexandre; Csillaghy, Andr\u00e9","abstract":"CosmoHammer is a Python framework for the estimation of cosmological parameters. The software embeds the Python package <a href=\"http:\/\/ascl.net\/1303.002\">emcee<\/a> by Foreman-Mackey et al. (2012) and gives the user the possibility to plug in modules for the computation of any desired likelihood. The major goal of the software is to reduce the complexity when one wants to extend or replace the existing computation by modules which fit the user's needs as well as to provide the possibility to easily use large scale computing environments. CosmoHammer can efficiently distribute the MCMC sampling over thousands of cores on modern cloud computing infrastructure.","topic_id":"30833","bibcode":"2013ascl.soft03003A","views":"43","site_list":["http:\/\/www.astro.ethz.ch\/refregier\/research\/Software\/cosmohammer"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1212.1721A"]},
		{"ascl_id":"1303.004","title":"UCL_PDR: Time dependent photon-dissociation regions model","credit":"Viti, Serena","abstract":"UCL_PDR is a time dependent photon-dissociation regions model that calculates self consistently the thermal balance. It can be used with gas phase only species as well as with surface species. It is very modular, has the possibility of accounting for density and pressure gradients and can be coupled with UCL_CHEM as well as with SMMOL. It has been used to model small scale (e.g. knots in proto-planetary nebulae) to large scale regions (high redshift galaxies).","topic_id":"30834","bibcode":"2013ascl.soft03004V","views":"50","site_list":["http:\/\/www.ucl.ac.uk\/star\/research\/stars_galaxies\/codes\/uclpdr"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010MNRAS.404.1910V"]},
		{"ascl_id":"1303.005","title":"SMMOL: Spherical Multi-level MOLecular line radiative transfer","credit":"Yates, Jeremy","abstract":"SMMOL (Spherical Multi-level MOLecular line radiative transfer) is a molecular line radiative transfer code that uses Accelerated Lambda Iteration to solve the coupled level population and line transfer problem in spherical geometry. The code uses a discretized grid and a ray tracing methodology. SMMOL is designed for high optical depth regimes and can cope with maser emission as long as the spatial-velocity sampling is fine enough.","topic_id":"30876","bibcode":"2013ascl.soft03005Y","views":"41","site_list":["http:\/\/www.ucl.ac.uk\/star\/research\/stars_galaxies\/codes\/smmol"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010MNRAS.404.1910V"]},
		{"ascl_id":"1303.006","title":"UCL_CHEM: time and depth dependent gas-grain chemical model","credit":"Viti, Serena","abstract":"UCL_CHEM is a time and depth dependent gas-grain chemical model that can be used to estimate the fractional abundances (with respect to hydrogen) of gas and surface species in every environment where molecules are present. The model includes both gas and surface reactions. The code starts from the most diffuse state where all the gas is in atomic form and evolve sthe gas to its final density. Depending on the temperature, atoms and molecules from the gas freeze on to the grains and they hydrogenate where possible. The advantage of this approach is that the ice composition is not assumed but it is derived by a time-dependent computation of the chemical evolution of the gas-dust interaction process. The code is very modular, has been used to model a variety of regions and can be coupled with the UCL_PDR  and SMMOL codes.","topic_id":"30878","bibcode":"2013ascl.soft03006V","views":"47","site_list":["http:\/\/www.ucl.ac.uk\/star\/research\/stars_galaxies\/codes\/uclchem"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012JPhCS.372a2039A"]},
		{"ascl_id":"1303.007","title":"micrOMEGAs: Calculation of dark matter properties","credit":"B\u00e9langer, Genevi\u00e8ve; Boudjema, Fawzi; Pukhov, Alexander; Semenov, Andrei","abstract":"micrOMEGAs calculates the properties of cold dark matter in a generic model of particle physics. First developed to compute the relic density of dark matter, the code also computes the rates for dark matter direct and indirect detection. The code provides the mass spectrum, cross-sections, relic density and exotic fluxes of gamma rays, positrons and antiprotons. The propagation of charged particles in the Galactic halo is handled with a module that allows to easily modify the propagation parameters. The cross-sections for both spin dependent and spin independent interactions of WIMPS on protons are computed automatically as well as the rates for WIMP scattering on nuclei in a large detector. Annihilation cross-sections of the dark matter candidate at zero velocity, relevant for indirect detection of dark matter, are computed automatically, and the propagation of charged particles in the Galactic halo is also handled.","topic_id":"30879","bibcode":"2013ascl.soft03007B","views":"36","site_list":["http:\/\/lapth.cnrs.fr\/micromegas\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011CoPhC.182..842B"]},
		{"ascl_id":"1303.008","title":"TYCHO: Stellar evolution code","credit":"Arnett, D.","abstract":"TYCHO is a general, one dimensional (spherically symmetric) stellar evolution code written in structured Fortran 77; it is designed for hydrostatic and hydrodynamic stages including mass loss, accretion, pulsations and explosions. Mixing and convection algorithms are based on 3D time-dependent simulations. It offers extensive on-line graphics using Tim Pearson's PGPLOT with X-windows and runs effectively on Linux and Mac OS X laptop and desktop computers.","topic_id":"30911","bibcode":"2013ascl.soft03008A","views":"57","site_list":["http:\/\/chandra.as.arizona.edu\/~dave\/tycho.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006Apj...640..891Y"]},
		{"ascl_id":"1303.009","title":"MAGIX: Modeling and Analysis Generic Interface for eXternal numerical codes","credit":"M\u00f6ller, T.; Bernst, I.; Panoglou, D.; Muders, D.; Ossenkopf, V.; R\u00f6llig, M.; Schilke, P.","abstract":"MAGIX provides an interface between existing codes and an iterating engine that minimizes deviations of the model results from available observational data; it constrains the values of the model parameters and provides corresponding error estimates. Many models (and, in principle, not only astrophysical models) can be plugged into MAGIX to explore their parameter space and find the set of parameter values that best fits observational\/experimental data. MAGIX complies with the data structures and reduction tools of Atacama Large Millimeter Array (ALMA), but can be used with other astronomical and with non-astronomical data.","topic_id":"30928","bibcode":"2013ascl.soft03009M","views":"39","site_list":["http:\/\/www.astro.uni-koeln.de\/projects\/schilke\/MAGIX"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A&A...549A..21M"]},
		{"ascl_id":"1303.010","title":"TAC-maker: Transit Analytical Curve maker","credit":"Kjurkchieva, D.; Dimitrov, D.; Vladev, A.; Yotov, V.","abstract":"TAC-maker allows for rapid and interactive calculation of synthetic planet transits by numerical computations of the integrals, allowing the use of an arbitrary limb-darkening law of the host star. This advantage together with the practically arbitrary precision of the calculations makes the code a valuable tool for the continuously increasing photometric precision of ground-based and space observations.","topic_id":"30949","bibcode":"2013ascl.soft03010K","views":"41","site_list":["http:\/\/astro.shu-bg.net\/software\/TAC-maker\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1303.2573K"]},
		{"ascl_id":"1303.011","title":"MOPSIC: Extended Version of MOPSI","credit":"Zylka, Robert","abstract":"MOPSIC was created to analyze bolometer data but can be used for much more versatile tasks. It is an extension of MOPSI; this software had been merged with the command interpreter of GILDAS. For data reduction, MOPSIC uses a special method to calculate the chopped signal. This gives much better results than the straight difference of the signals obtained at both chopper positions. In addition there are also scripts to reduce pointings, skydips, and to calculate the RCPs (Receiver Channel Parameters) from calibration maps. MOPSIC offers a much broader range of applications including advanced planning functions for mapping and onoff observations, post-reduction data analysis and processing and even reduction of non-bolometer data (optical, IR, spectroscopy).","topic_id":"30950","bibcode":"2013ascl.soft03011Z","views":"38","site_list":["http:\/\/www.iram.es\/IRAMES\/mainWiki\/CookbookMopsic","http:\/\/www.iram.fr\/~gildas\/dist\/archive\/mopsic\/"],"ref_list":false},
		{"ascl_id":"1303.012","title":"TGCat: Chandra Transmission Grating Catalog and Archive","credit":"Huenemoerder, David; Nowak, Mike; Dewey, Dan; Schulz, Norbert; Mitschang, Arik","abstract":"TGCat is an archive of Chandra transmission grating spectra and a suite of software for processing such data. Users can browse and categorize Chandra gratings observations quickly and easily, generate custom plots of resulting response corrected spectra on-line without the need for special software and download analysis ready products from multiple observations in one convenient operation. Data processing for the catalog is done with a suite of ISIS\/S-Lang scripts; the software is available for download. These ISIS scripts wrap and call CIAO tools for reprocessing from \"Level 1\" (acis_process_events or hrc_process_events) through \"Level 2\" (binned spectra, via tg_resolve_events and tgextract), compute responses (grating \"RMFs\" and \"ARFs\", via mkgrmf and mkgarf), and make summary plots.","topic_id":"30954","bibcode":"2013ascl.soft03012H","views":"46","site_list":["http:\/\/space.mit.edu\/cxc\/analysis\/tgcat\/index.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1001.0039"]},
		{"ascl_id":"1303.013","title":"idistort: CMB spectral distortions templates and code","credit":"Khatri, Rishi; Sunyaev, Rashid","abstract":"Spectrum created by energy release in the early Universe, before recombination, creates distortions which are a superposition of \u03bc-type, y-type and intermediate-type distortions. The final spectrum can thus be constructed from the templates, once energy injection rate as a function of redshift is known. This package contains the templates spaced at dy=0.001 for y&lt;1 and dy=0.01 for y&gt;1 covering a range 0.001 &lt; y &lt; 10. Also included is a Mathematica code which can combine these templates for user-defined rate of energy injection as a function of redshift. Silk damping, particle decay and annihilation examples are also included.","topic_id":"30956","bibcode":"2013ascl.soft03013K","views":"41","site_list":["http:\/\/www.mpa-garching.mpg.de\/~khatri\/idistort.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012JCAP...09..016K"]},
		{"ascl_id":"1303.014","title":"BSE: Binary Star Evolution","credit":"Hurley, Jarrod R.; Tout, Christopher A.; Pols, Onno R.","abstract":"BSE is a rapid binary star evolution code. It can model circularization of eccentric orbits and synchronization of stellar rotation with the orbital motion owing to tidal interaction in detail. Angular momentum loss mechanisms, such as gravitational radiation and magnetic braking, are also modelled. Wind accretion, where the secondary may accrete some of the material lost from the primary in a wind, is allowed with the necessary adjustments made to the orbital parameters in the event of any mass variations. Mass transfer occurs if either star fills its Roche lobe and may proceed on a nuclear, thermal or dynamical time-scale. In the latter regime, the radius of the primary increases in response to mass-loss at a faster rate than the Roche-lobe of the star. Prescriptions to determine the type and rate of mass transfer, the response of the secondary to accretion and the outcome of any merger events are in place in BSE.","topic_id":"30958","bibcode":"2013ascl.soft03014H","views":"85","site_list":["http:\/\/astronomy.swin.edu.au\/~jhurley\/bsedload.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002MNRAS.329..897H"]},
		{"ascl_id":"1303.015","title":"SSE: Single Star Evolution","credit":"Hurley, Jarrod R.; Pols, Onno R.; Tout, Christopher A.","abstract":"SSE is a rapid single-star evolution (SSE) code; these analytical formulae cover all phases of evolution from the zero-age main-sequence up to and including remnant phases. It is valid for masses in the range 0.1-100 Msun and metallicity can be varied. The SSE package contains a prescription for mass loss by stellar winds. It also follows the evolution of rotational angular momentum for the star.","topic_id":"30959","bibcode":"2013ascl.soft03015H","views":"71","site_list":["http:\/\/astronomy.swin.edu.au\/~jhurley\/bsedload.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000MNRAS.315..543H"]},
		{"ascl_id":"1303.016","title":"2MASS Kit: 2MASS Catalog Server Kit","credit":"Yamauchi, Chisato","abstract":"2MASS Kit is an open source software for use in easily constructing a high performance search server for important astronomical catalogs. It is tuned for optimal coordinate search performance (Radial Search, Box Search, Rectangular Search) of huge catalogs, thus increasing the speed by more than an order of magnitude when compared to simple indexing on a single table. Optimal conditions enable more than 3,000 searches per second for radial search of 2MASS PSC. The kit is best characterized by its flexible tuning. Each table index is registered in one of six table spaces (each resides in a separate directory), thus allowing only the essential parts to be easily moved onto fast devices. Given the terrific evolution that has taken place with recent SSDs in performance, a very cost-effective way of constructing high-performance servers is moving part of or all table indices to a fast SSD.","topic_id":"30961","bibcode":"2013ascl.soft03016Y","views":"87","site_list":["http:\/\/www.ir.isas.jaxa.jp\/~cyamauch\/2masskit\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011PASP..123.1324Y"]},
		{"ascl_id":"1303.017","title":"CADRE: CArma Data REduction pipeline","credit":"Friedel, Douglas","abstract":"CADRE, the Combined Array for Millimeter-wave Astronomy (CARMA) data reduction pipeline, gives investigators a first look at a fully reduced set of their data. It runs automatically on all data produced by the telescope as they arrive in the data archive. The pipeline is written in python and uses python wrappers for MIRIAD subroutines for direct access to the data. It applies passband, gain and flux calibration to the data sets and produces a set of continuum and spectral line maps in both MIRIAD and FITS format.","topic_id":"30968","bibcode":"2013ascl.soft03017F","views":"54","site_list":["https:\/\/github.com\/astro-friedel\/CADRE"],"ref_list":false},
		{"ascl_id":"1303.018","title":"Galactus: Modeling and fitting of galaxies from neutral hydrogen (HI) cubes","credit":"Peters, S. P. C.","abstract":"Galactus, written in python, is an astronomical software tool for the modeling and fitting of galaxies from neutral hydrogen (HI) cubes. Galactus uses a uniform medium to generate a cube. Galactus can perform the full-radiative transfer for the HI, so can model self-absorption in the galaxy.","topic_id":"30977","bibcode":"2013ascl.soft03018P","views":"44","site_list":["https:\/\/sourceforge.net\/p\/galactus"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1303.2463P"]},
		{"ascl_id":"1303.019","title":"GBTIDL: Reduction and Analysis of GBT Spectral Line Data","credit":"Marganian, P.; Garwood, R. W.; Braatz, J. A.; Radziwill, N. M.; Maddalena, R. J.","abstract":"GBTIDL is an interactive package for reduction and analysis of spectral line data taken with the Robert C. Byrd Green Bank Telescope (GBT). The package, written entirely in IDL, consists of straightforward yet flexible calibration, averaging, and analysis procedures (the \"GUIDE layer\") modeled after the UniPOPS and CLASS data reduction philosophies, a customized plotter with many built-in visualization features, and Data I\/O and toolbox functionality that can be used for more advanced tasks. GBTIDL makes use of data structures which can also be used to store intermediate results. The package consumes and produces data in GBT SDFITS format. GBTIDL can be run online and have access to the most recent data coming off the telescope, or can be run offline on preprocessed SDFITS files.","topic_id":"30980","bibcode":"2013ascl.soft03019M","views":"39","site_list":["http:\/\/gbtidl.nrao.edu\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ASPC..351..512M"]},
		{"ascl_id":"1303.020","title":"Ginga: Flexible FITS viewer","credit":"Jeschke, Eric","abstract":"Ginga is a viewer for astronomical data FITS (Flexible Image Transport System) files; the viewer centers around a FITS display widget which supports zooming and panning, color and intensity mapping, a choice of several automatic cut levels algorithms and canvases for plotting scalable geometric forms. In addition to this widget, the FITS viewer provides a flexible plugin framework for extending the viewer with many different features. A fairly complete set of \"standard\" plugins are provided for expected features of a modern viewer: panning and zooming windows, star catalog access, cuts, star pick\/fwhm, thumbnails, and others.  This viewer was written by software engineers at Subaru Telescope, National Astronomical Observatory of Japan, and is in use at that facility.","topic_id":"30990","bibcode":"2013ascl.soft03020J","views":"39","site_list":["http:\/\/ejeschke.github.com\/ginga\/"],"ref_list":false},
		{"ascl_id":"1303.021","title":"Xmatch: GPU Enhanced Astronomic Catalog Cross-Matching","credit":"Budavari, Tamas; Lee, Matthias A.","abstract":"Xmatch is a cross-platform, multi-GPU tool which allows for extremely fast cross-matching between two Astronomic catalogs. It is capable of asyncronously managing multiple GPUs, ideal for workstation and cluster environments.","topic_id":"30991","bibcode":"2013ascl.soft03021B","views":"50","site_list":["http:\/\/matthiaslee.github.com\/Xmatch\/"],"ref_list":false},
		{"ascl_id":"1303.022","title":"ionFR: Ionospheric Faraday rotation","credit":"Sotomayor-Beltran, C.; Sobey, C.; Hessels, J. W. T.; de Bruyn, G.; Noutsos, A.; Alexov, A.; Anderson, J.; Asgekar, A.; Avruch, I. M.; Beck, R.; Bell, M. E.; Bell, M. R.; Bentum, M. J.; Bernardi, G.; Best, P.; Birzan, L.; Bonafede, A.; Breitling, F.; Broderick, J.; Brouw, W. N.; Brueggen, M.; Ciardi, B.; de Gasperin, F.; Dettmar, R.-J.; van Duin, A.; Duscha, S.; Eisloeffel, J.; Falcke, H.; Fallows, R. A.; Fender, R.; Ferrari, C.; Frieswijk, W.; Garrett, M. A.; Griessmeier, J.; Grit, T.; Gunst, A. W.; Hassall, T. E.; Heald, G.; Hoeft, M.; Horneffer, A.; Iacobelli, M.; Juette, E.; Karastergiou, A.; Keane, E.; Kohler, J.; Kramer, M.; Kondratiev, V. I.; Koopmans, L. V. E.; Kuniyoshi, M.; Kuper, G.; van Leeuwen, J.; Maat, P.; Macario, G.; Markoff, S.; McKean, J. P.; Mulcahy, D. D.; Munk, H.; Orru, E.; Paas, H.; Pandey-Pommier, M.; Pilia, M.; Pizzo, R.; Polatidis, A. G.; Reich, W.; Roettgering, H.; Serylak, M.; Sluman, J.; Stappers, B. W.; Tagger, M.; Tang, Y.; Tasse, C.; ter Veen, S.; Vermeulen, R.; van Weeren, R. J.; Wijers, R. A. M. J.; Wijnholds, S. J.; Wise, M. W.; Wucknitz, O.; Yatawatta, S.; Zarka, P.","abstract":"ionFR calculates the amount of ionospheric Faraday rotation for a specific epoch, geographic location, and line-of-sight. The code uses a number of publicly available, GPS-derived total electron content maps and the most recent release of the International Geomagnetic Reference Field. ionFR can be used for the calibration of radio polarimetric observations; its accuracy had been demonstrated using LOFAR pulsar observations.","topic_id":"31032","bibcode":"2013ascl.soft03022S","views":"57","site_list":["http:\/\/sourceforge.net\/projects\/ionfarrot\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26A...552A..58S"]},
		{"ascl_id":"1303.023","title":"pysynphot: Synthetic photometry software package","credit":"STScI development Team","abstract":"pysynphot is a synthetic photometry software package suitable for either library or interactive use. Intended as a modern-language successor to the IRAF\/STSDAS synphot package, it provides improved algorithms that address known shortcomings in synphot, and its object-oriented design is more easily extensible than synphot's task-oriented approach. It runs under <a href=\"http:\/\/ascl.net\/1207.011\">PyRAF<\/a>, and a backwards compatibility mode is provided that recognizes all spectral and throughput tables, obsmodes, and spectral expressions used by synphot, to facilitate the transition for legacy code.","topic_id":"31037","bibcode":"2013ascl.soft03023S","views":"43","site_list":["http:\/\/www.astropython.org\/resource\/2009\/11\/pysynphot"],"ref_list":false},
		{"ascl_id":"1303.024","title":"ATLAS12: Opacity sampling model atmosphere program","credit":"Kurucz, Robert L.","abstract":"ATLAS12 is an opacity sampling model atmosphere program to allow computation of models with individual abundances using line data. ATLAS12 is able to compute the same models as ATLAS9 which uses pretabulated opacities, plus models with arbitrary abundances. ATLAS12 sampled fluxes are quite accurate for predicting the total flux except in the intermediate or narrow bandpass intervals because the sample size is too small.","topic_id":"31038","bibcode":"2013ascl.soft03024K","views":"81","site_list":["http:\/\/kurucz.harvard.edu\/programs.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1303.6629"]},
		{"ascl_id":"1303.025","title":"DPUSER: Interactive language for image analysis","credit":"Ott, Thomas","abstract":"DPUSER is an interactive language capable of handling numbers (both real and complex), strings, and matrices. Its main aim is to do astronomical image analysis, for which it provides a comprehensive set of functions, but it can also be used for many other applications.","topic_id":"31069","bibcode":"2013ascl.soft03025O","views":"44","site_list":["http:\/\/www.mpe.mpg.de\/~ott\/dpuser\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1303.7071T"]},
		{"ascl_id":"1303.026","title":"ACORNS-ADI: Algorithms for Calibration, Optimized Registration and Nulling the Star in Angular Differential Imaging","credit":"Brandt, Tim","abstract":"ACORNS-ADI, written in python, is a parallelized software package which reduces high-contrast imaging data. Originally written for imaging data from Subaru\/HiCIAO, it requires minimal modification to reduce data from other instruments. It is efficient,  open-source, and includes several optional features which may improve performance.","topic_id":"31070","bibcode":"2013ascl.soft03026B","views":"757","site_list":["https:\/\/github.com\/t-brandt\/acorns-adi"],"ref_list":["http:\/\/arxiv.org\/abs\/1209.3014"]},
		{"ascl_id":"1303.027","title":"GaPP: Gaussian Processes in Python","credit":"Seikel, Marina; Clarkson, Chris; Smith, Mathew","abstract":"The algorithm Gaussian processes can reconstruct a function from a sample of data without assuming a parameterization of the function. The GaPP code can be used on any dataset to reconstruct a function. It handles individual error bars on the data and can be used to determine the derivatives of the reconstructed function. The data sample can consist of observations of the function and of its first derivative.","topic_id":"31071","bibcode":"2013ascl.soft03027S","views":"50","site_list":["http:\/\/www.acgc.uct.ac.za\/~seikel\/GAPP\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012JCAP...06..036S"]},
		{"ascl_id":"1303.028","title":"Stellarics: Inverse Compton scattering from stellar heliospheres","credit":"Orlando, Elena; Strong, Andrew W.","abstract":"Cosmic ray electrons scatter on the photon fields around stars, including the sun, to create gamma rays by the inverse Compton effect. Stellarics computes the spectrum and angular distribution of this emission. The software also includes general-purpose routines for inverse Compton scattering on a given electron spectrum, for example for interstellar or astrophysical source modelling.","topic_id":"31073","bibcode":"2013ascl.soft03028O","views":"43","site_list":["http:\/\/sourceforge.net\/projects\/stellarics\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1303.5491"]},
		{"ascl_id":"1303.029","title":"iSAP: Interactive Sparse Astronomical Data Analysis Packages","credit":"Fourt, O.; Starck, J.-L.; Sureau, F.; Bobin, J.; Moudden, Y.; Abrial, P.; Schmitt, J.","abstract":"iSAP consists of three programs, written in IDL, which together are useful for spherical data analysis. MR\/S (MultiResolution on the Sphere) contains routines for wavelet, ridgelet and curvelet transform on the sphere, and applications such denoising on the sphere using wavelets and\/or curvelets, Gaussianity tests and Independent Component Analysis on the Sphere. MR\/S has been designed for the PLANCK project, but can be used for many other applications. SparsePol (Polarized Spherical Wavelets and Curvelets) has routines for polarized wavelet, polarized ridgelet and polarized curvelet transform on the sphere, and applications such denoising on the sphere using wavelets and\/or curvelets, Gaussianity tests and blind source separation on the Sphere. SparsePol has been designed for the PLANCK project. MS-VSTS (Multi-Scale Variance Stabilizing Transform on the Sphere), designed initially for the FERMI project, is useful for spherical mono-channel and multi-channel data analysis when the data are contaminated by a Poisson noise. It contains routines for wavelet\/curvelet denoising, wavelet deconvolution, multichannel wavelet denoising and deconvolution.","topic_id":"31076","bibcode":"2013ascl.soft03029F","views":"43","site_list":["http:\/\/jstarck.free.fr\/isap.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009A%26A...497..931S"]},
		{"ascl_id":"1303.030","title":"Sunrise: Radiation transfer through interstellar dust","credit":"Jonsson, Patrik","abstract":"Sunrise is a Monte Carlo radiation transfer code for calculating absorption and scattering of light to study the effects of dust in hydrodynamic simulations of interacting galaxies. It uses an adaptive mesh refinement grid to describe arbitrary geometries of emitting and absorbing\/scattering media, with spatial dynamical range exceeding 10<sup>4<\/sup>; it can efficiently generate images of the emerging radiation at arbitrary points in space and spectral energy distributions of simulated galaxies run with the <a href=\"http:\/\/ascl.net\/0003.001\">Gadget<\/a>, Gasoline, Arepo, <a href=\"http:\/\/ascl.net\/1010.072\">Enzo<\/a> or ART codes. In addition to the monochromatic radiative transfer typically used by Monte Carlo codes, Sunrise can propagate a range of wavelengths simultaneously. This \"polychromatic\" algorithm gives significant improvements in efficiency and accuracy when spectral features are calculated.","topic_id":"31077","bibcode":"2013ascl.soft03030J","views":"50","site_list":["http:\/\/code.google.com\/p\/sunrise\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006MNRAS.372....2J"]},
		{"ascl_id":"1304.001","title":"PEC: Period Error Calculator","credit":"Mighell, Kenneth J.","abstract":"The PEC (Period Error Calculator) algorithm estimates the period error for eclipsing binaries observed by the Kepler Mission. The algorithm is based on propagation of error theory and assumes that observation of every light curve peak\/minimum in a long time-series observation can be unambiguously identified. A simple C implementation of the PEC algorithm is available.","topic_id":"31092","bibcode":"2013ascl.soft04001M","views":"33","site_list":["http:\/\/www.noao.edu\/staff\/mighell\/pec\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1304.1422M"]},
		{"ascl_id":"1304.002","title":"Astropy: Community Python library for astronomy","credit":"Greenfield, Perry; Robitaille, Thomas; Tollerud, Erik; Aldcroft, Tom; Barbary, Kyle; Barrett, Paul; Bray, Erik; Crighton, Neil; Conley, Alex; Conseil, Simon; Davis, Matt; Deil, Christoph; Dencheva, Nadia; Droettboom, Michael; Ferguson, Henry; Ginsburg, Adam; Grollier, Fr\u00e9d\u00e9ric; Moritz G\u00fcnther, Hans; Hanley, Chris; Hsu, J. C.; Kerzendorf, Wolfgang; Kramer, Roban; Lian Lim, Pey; Muna, Demitri; Nair, Prasanth; Price-Whelan, Adrian; Shiga, David; Singer, Leo; Taylor, James; Turner, James; Woillez, Julien; Zabalza, Victor","abstract":"Astropy provides a common framework, core package of code, and affiliated packages for astronomy in Python. Development is actively ongoing, with major packages such as <a href=\"http:\/\/ascl.net\/1207.009\">PyFITS<\/a>, PyWCS, vo, and asciitable already merged in. Astropy is intended to contain much of the core functionality and some common tools needed for performing astronomy and astrophysics with Python.","topic_id":"31097","bibcode":"2013ascl.soft04002G","views":"102","site_list":["http:\/\/www.astropy.org\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1307.6212T"]},
		{"ascl_id":"1304.003","title":"GALSVM: Automated Morphology Classification","credit":"Huertas-Company, Marc","abstract":"GALSVM is IDL software for automated morphology classification. It was specially designed for high redshift data but can be used at low redshift as well. It analyzes morphologies of galaxies based on a particular family of learning machines called support vector machines. The method can be seen as a generalization of the classical CAS classification but with an unlimited number of dimensions and non-linear boundaries between decision regions. It is fully automated and consequently well adapted to large cosmological surveys.","topic_id":"31127","bibcode":"2013ascl.soft04003H","views":"33","site_list":["http:\/\/gepicom04.obspm.fr\/galSVM\/Home.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008A%26A...478..971H"]},
		{"ascl_id":"1304.004","title":"Wqed: Lightcurve Analysis Suite","credit":"Thompson, Susan; Mullally, Fergal","abstract":"Wqed (pronounced \"Wicked\") is a set of tools developed by the Delaware Asteroseismic Research Center (DARC) to simplify the process of reducing time-series CCD data on variable stars. It does not provide tools to measure the brightness of stars in individual frames, focusing instead on what comes next:\r\n<ul>- selecting and removing data lost to cloud, \r\n    - removing the effects of light cloud and seeing variations, \r\n    - keeping track of what star a given data set refers to, and when that data was taken, and\r\n    - performing barycentric corrections to data. \r\n<\/ul>","topic_id":"31128","bibcode":"2013ascl.soft04004T","views":"48","site_list":["http:\/\/www.physics.udel.edu\/~darc\/wqed\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009JPhCS.172a2081T"]},
		{"ascl_id":"1304.005","title":"VOBOZ\/ZOBOV: Halo-finding and Void-finding algorithms","credit":"Neyrinck, Mark; Hamilton, Andrew J. S.; Gnedin, Nickolay Y.","abstract":"VOBOZ (VOronoi BOund Zones) is an algorithm to find haloes in an N-body dark matter simulation which has little dependence on free parameters.\r\n\r\nZOBOV (ZOnes Bordering On Voidness) is an algorithm that finds density depressions in a set of points without any free parameters or assumptions about shape. It uses the Voronoi tessellation to estimate densities to find both voids and subvoids. It also measures probabilities that each void or subvoid arises from Poisson fluctuations.","topic_id":"31129","bibcode":"2013ascl.soft04005N","views":"186","site_list":["http:\/\/skysrv.pha.jhu.edu\/~neyrinck\/voboz\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005MNRAS.356.1222N","http:\/\/adsabs.harvard.edu\/abs\/2008MNRAS.386.2101N"]},
		{"ascl_id":"1304.006","title":"CosmicEmuLog: Cosmological Power Spectra Emulator","credit":"Neyrinck, Mark","abstract":"CosmicEmuLog is a simple Python emulator for cosmological power spectra. In addition to the power spectrum of the conventional overdensity field, it emulates the power spectra of the log-density as well as the Gaussianized density. It models fluctuations in the power spectrum at each k as a linear combination of contributions from fluctuations in each cosmological parameter. The data it uses for emulation consist of ASCII files of the mean power spectrum, together with derivatives of the power spectrum with respect to the five cosmological parameters in the space spanned by the Coyote Universe suite. This data can also be used for Fisher matrix analysis. At present, CosmicEmuLog is restricted to redshift 0.","topic_id":"31130","bibcode":"2013ascl.soft04006N","views":"45","site_list":["http:\/\/skysrv.pha.jhu.edu\/~neyrinck\/CosmicEmuLog\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ApJ...742...91N"]},
		{"ascl_id":"1304.007","title":"DESPOTIC: Derive the Energetics and SPectra of Optically Thick Interstellar Clouds","credit":"Krumholz, Mark R.","abstract":"DESPOTIC (Derive the Energetics and SPectra of Optically Thick Interstellar Clouds), written in Python, represents optically thick interstellar clouds using a one-zone model and calculates line luminosities, line cooling rates, and in restricted cases line profiles using an escape probability formalism. DESPOTIC calculates clouds' equilibrium gas and dust temperatures and their time-dependent thermal evolution. The code allows rapid and interactive calculation of clouds' characteristic temperatures, identification of their dominant heating and cooling mechanisms, and prediction of their observable spectra across a wide range of interstellar environments.","topic_id":"31166","bibcode":"2013ascl.soft04007K","views":"52","site_list":["https:\/\/sites.google.com\/a\/ucsc.edu\/krumholz\/codes\/despotic","https:\/\/code.google.com\/p\/despotic\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1304.2404K"]},
		{"ascl_id":"1304.008","title":"Diffusion.f: Diffusion of elements in stars","credit":"Thoul, Anne","abstract":"Diffusion.f is an exportable subroutine to calculate the diffusion of elements in stars. The routine solves exactly the Burgers equations and can include any number of elements as variables. The code has been used successfully by a number of different groups; applications include diffusion in the sun and diffusion in globular cluster stars. There are many other possible applications to main sequence and to evolved stars. The associated README file explains how to use the subroutine.","topic_id":"31170","bibcode":"2013ascl.soft04008T","views":"50","site_list":["http:\/\/www.sns.ias.edu\/~jnb\/SNdata\/diffusion.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1994ApJ...421..828T"]},
		{"ascl_id":"1304.009","title":"S\u00e9rsic: Exact deprojection of S\u00e9rsic surface brightness profiles","credit":"Novak, Greg","abstract":"S\u00e9rsic is an implementation of the exact deprojection of S\u00e9rsic surface brightness profiles described in Baes and Gentile (2011). This code depends on the <a href=\"http:\/\/mpmath.googlecode.com\">mpmath python library<\/a> for an implementation of the Meijer G function required by the Baes and Gentile (hereafter B+G) formulas for rational values of the S\u00e9rsic index. S\u00e9rsic requires rational S\u00e9rsic indices, but any irrational number can be approximated arbitrarily well by some rational number. The code also depends on <a href=\"http:\/\/scipy.org\">scipy<\/a>, but the dependence is mostly for testing. The implementation of the formulas and the formulas themselves have undergone comprehensive testing.","topic_id":"31174","bibcode":"2013ascl.soft04009N","views":"46","site_list":["https:\/\/pypi.python.org\/pypi\/sersic\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.424..635N"]},
		{"ascl_id":"1304.011","title":"TPZ: Trees for Photo-Z","credit":"Carrasco Kind, Matias; Brunner, Robert","abstract":"TPZ, a parallel code written in python, produces robust and accurate photometric redshift PDFs by using prediction tree and random forests. The code also produces ancillary information about the sample used, such as prior unbiased errors estimations (giving an estimation of performance) and a ranking of importance of variables as well as a map of performance indicating where extra training data is needed to improve overall performance. It is designed to be easy to use and a tutorial is available.","topic_id":"31207","bibcode":"2013ascl.soft04011C","views":"69","site_list":["http:\/\/lcdm.astro.illinois.edu\/research\/TPZ.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1303.7269C"]},
		{"ascl_id":"1304.012","title":"ORIGAMI: Structure-finding routine in N-body simulation","credit":"Falck, Bridget","abstract":"ORIGAMI is a dynamical method of determining the morphology of particles in a cosmological simulation by checking for whether, and in how many dimensions, a particle has undergone shell-crossing. The code is written in C and makes use of the Delaunay tessellation calculation routines from the <a href=\"http:\/\/ascl.net\/1304.005\">VOBOZ<\/a> package (which relies on the <a href=\"http:\/\/ascl.net\/1304.016\">Qhull<\/a> package).","topic_id":"31212","bibcode":"2013ascl.soft04012F","views":"41","site_list":["http:\/\/icg.port.ac.uk\/~falckb\/origami.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012ApJ...754..126F"]},
		{"ascl_id":"1304.013","title":"SFH: Star Formation History","credit":"Rasera, Yann","abstract":"SFH is an efficient IDL tool that quickly computes accurate predictions for the baryon budget history in a galactic halo.","topic_id":"31213","bibcode":"2013ascl.soft04013R","views":"39","site_list":["http:\/\/yann.rasera.free.fr\/websitefiles\/mysfh.tar.gz"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006A%26A...445....1R"]},
		{"ascl_id":"1304.014","title":"MPgrafic: A parallel MPI version of Grafic-1","credit":"Prunet, Simon; Pichon, Christophe","abstract":"MPgrafic is a parallel MPI version of <a href=\"http:\/\/ascl.net\/9910.004\">Grafic-1<\/a> which can produce large cosmological initial conditions on a cluster without requiring shared memory. The real Fourier transforms are carried in place using fftw while minimizing the amount of used memory (at the expense of performance) in the spirit of Grafic-1. The writing of the output file is also carried in parallel. In addition to the technical parallelization, it provides three extensions over Grafic-1:\n\n<ul><li>it can produce power spectra with baryon wiggles (DJ Eisenstein and W. Hu, Ap. J. 496);<\/li><li>it has the optional ability to load a lower resolution noise map corresponding to the low frequency component which will fix the larger scale modes of the simulation (extra flag 0\/1 at the end of the input process) in the spirit of <a href=\"http:\/\/ascl.net\/1106.008\">Grafic-2<\/a>;<\/li><li>it can be used in conjunction with <span style=\"font-style: italic\">constrfield<\/span>, which generates initial conditions phases from a list of local constraints on density, tidal field density gradient and velocity.<\/li><\/ul>","topic_id":"31214","bibcode":"2013ascl.soft04014P","views":"37","site_list":["http:\/\/www2.iap.fr\/users\/pichon\/mpgrafic.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010AIPC.1241.1202F"]},
		{"ascl_id":"1304.015","title":"TVD: Total Variation Diminishing code","credit":"Pen, Ue-Li; Arras, Phil; Wong, ShingKwong","abstract":"TVD solves the magnetohydrodynamic (MHD) equations by updating the fluid variables along each direction using the flux-conservative, second-order, total variation diminishing (TVD), upwind scheme of Jin & Xin. The magnetic field is updated separately in two-dimensional advection-constraint steps. The electromotive force (EMF) is computed in the advection step using the TVD scheme, and this same EMF is used immediately in the constraint step in order to preserve \u2207\u02d9B=0 without the need to store intermediate fluxes. The code is extended to three dimensions using operator splitting, and Runge-Kutta is used to get second-order accuracy in time. TVD offers high-resolution per grid cell, second-order accuracy in space and time, and enforcement of the \u2207\u02d9B=0 constraint to machine precision. Written in Fortran, It has no memory overhead and is fast. It is also available in a fully scalable message-passing parallel MPI implementation.","topic_id":"31246","bibcode":"2013ascl.soft04015P","views":"55","site_list":["http:\/\/www.cita.utoronto.ca\/~pen\/MHD\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003ApJS..149..447P"]},
		{"ascl_id":"1304.016","title":"Qhull: Quickhull algorithm for computing the convex hull","credit":"Barber, C. Bradford; Dobkin, David P.; Huhdanpaa, Hannu","abstract":"Qhull computes the convex hull, Delaunay triangulation, Voronoi diagram, halfspace intersection about a point, furthest-site Delaunay triangulation, and furthest-site Voronoi diagram. The source code runs in 2-d, 3-d, 4-d, and higher dimensions. Qhull implements the Quickhull algorithm for computing the convex hull. It handles roundoff errors from floating point arithmetic. It computes volumes, surface areas, and approximations to the convex hull.","topic_id":"31267","bibcode":"2013ascl.soft04016B","views":"66","site_list":["http:\/\/www.qhull.org\/"],"ref_list":["http:\/\/citeseerx.ist.psu.edu\/viewdoc\/summary?doi=10.1.1.117.405","http:\/\/adsabs.harvard.edu\/abs\/2004AAS...20516106X"]},
		{"ascl_id":"1304.017","title":"CosmoRec: Cosmological Recombination code","credit":"Chluba, Jens; Thomas, Rajat Mani","abstract":"CosmoRec solves the recombination problem including recombinations to highly excited states, corrections to the 2s-1s two-photon channel, HI Lyn-feedback, n&gt;2 two-photon profile corrections, and n\u22652 Raman-processes. The code can solve the radiative transfer equation of the Lyman-series photon field to obtain the required modifications to the rate equations of the resolved levels, and handles electron scattering, the effect of HeI intercombination transitions, and absorption of helium photons by hydrogen. It also allows accounting for dark matter annihilation and optionally includes detailed helium radiative transfer effects.","topic_id":"31268","bibcode":"2013ascl.soft04017C","views":"52","site_list":["http:\/\/www.chluba.de\/CosmoRec"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011MNRAS.412..748C"]},
		{"ascl_id":"1304.018","title":"SZpack: Computation of Sunyaev-Zeldovich (SZ) signals","credit":"Chluba, Jens; Switzer, Eric; Nagai, Daisuke; Sazonov, Sergey; Nelson, Kaylea","abstract":"SZpack is a numerical library which allows fast and precise computation of the Sunyaev-Zeldovich (SZ) signal for hot, moving clusters of galaxies. Both explicit numerical integration as well as approximate representation of the SZ signals can be obtained. Variations of the electron temperature and bulk velocity along the line-of-sight can be included. SZpack allows very fast and precise (<~0.001% at frequencies h nu <~ 30kT_g and electron temperature kTe ~ 75 keV) computation and its accuracy practically eliminates uncertainties related to more expensive numerical evaluation of the Boltzmann collision term. It furthermore cleanly separates kinematic corrections from scattering physics, effects that previously have not been clarified.","topic_id":"31269","bibcode":"2013ascl.soft04018C","views":"42","site_list":["http:\/\/www.chluba.de\/SZpack"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.426..510C","http:\/\/adsabs.harvard.edu\/abs\/2013MNRAS.430.3054C"]},
		{"ascl_id":"1304.019","title":"IFrIT: Ionization FRont Interactive Tool","credit":"Gnedin, Nick","abstract":"IFrIT (Ionization FRont Interactive Tool) is a powerful general purpose visualization tool that can be used to visualize 3-dimensional data sets. IFrIT is written in C++ and is based on the <a href=\"http:\/\/www.vtk.org\/\">Visualization ToolKit<\/a> (VTK) and, optionally, uses a GUI toolkit <a href=\"http:\/\/qt.digia.com\/\">Qt<\/a>. IFrIT can visualize scalar, vector field, tensor, and particle data. Several visualization windows can exist at the same time, each one having a full set of visualization objects. Some visualization windows can share the data between them, while other windows can be fully independent. Images from several visualization windows can be combined into one image file on the disk, tiling some  windows together, and inserting reduced versions of some windows into larger other windows. A large array of features is also available, including highly advanced animation capabilities, a complex set of lights, markers to label various points in space, and a capability to \"pick\" a point in the scene and retrieve information about the data at this location.","topic_id":"31270","bibcode":"2013ascl.soft04019G","views":"38","site_list":["https:\/\/sites.google.com\/site\/ifrithome\/Home"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008NJPh...10l5008K"]},
		{"ascl_id":"1304.020","title":"pyCloudy: Tools to manage astronomical Cloudy photoionization code","credit":"Morisset, Christophe","abstract":"PyCloudy is a Python library that handles input and output files of the <a href=\"http:\/\/ascl.net\/9910.001\">Cloudy photoionization code<\/a> (Gary Ferland). It can also generate 3D nebula from various runs of the 1D Cloudy code. pyCloudy allows you to:\n<ul><li>define and write input file(s) for Cloudy code. As you can have it in a code, you may generate automatically sets of input files, changing parameters from one to the other.<\/li><li>read the Cloudy output files and play with the data: you will be able to plot line emissivity ratio vs. the radius of the nebula, the electron temperature, or any Cloudy output.<\/li><li>build pseudo-3D models, a la <a href=\"http:\/\/ascl.net\/1103.015\">Cloudy_3D<\/a>, by running a set of models, changing parameters (e.g. inner radius, density) following angular laws, reading the outputs of the set of models and interpolating the results (Te, ne, line emissivities) in a 3D cube.<\/li><\/ul>","topic_id":"31272","bibcode":"2013ascl.soft04020M","views":"58","site_list":["https:\/\/sites.google.com\/site\/pycloudy\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26A...551A..82S"]},
		{"ascl_id":"1304.021","title":"PyNeb: Analysis of emission lines","credit":"Luridiana, V.; Morisset, C.; Shaw, R. A.","abstract":"PyNeb (previously PyNebular) is an update and expansion of the IRAF package NEBULAR; rewritten in Python, it is designed to be more user-friendly and powerful, increasing the speed, easiness of use, and graphic visualization of emission lines analysis. In PyNeb, the atom is represented as an n-level atom. For given density and temperature, PyNeb solves the equilibrium equations and determines the level populations. PyNeb can compute physical conditions from suitable diagnostic line ratios and level populations, critical densities and line emissivities, and can compute and display emissivity grids as a function of Te and Ne. It can also deredden line intensities, read and manage observational data, and plot and compare atomic data from different publications, and compute ionic abundances from line intensities and physical conditions and elemental abundances from ionic abundances and icfs.","topic_id":"31274","bibcode":"2013ascl.soft04021L","views":"50","site_list":["http:\/\/www.iac.es\/proyecto\/PyNeb\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012A%26A...538A..54G"]},
		{"ascl_id":"1304.022","title":"Copter: Cosmological perturbation theory","credit":"Carlson, Jordan","abstract":"Copter is a software package for doing calculations in cosmological perturbation theory.  Specifically, Copter includes code for computing statistical observables in the large-scale structure of matter using various forms of perturbation theory, including linear theory, standard perturbation theory, renormalized perturbation theory, and many others. Copter is written in C++ and makes use of the Boost C++ library headers.","topic_id":"31290","bibcode":"2013ascl.soft04022C","views":"60","site_list":["https:\/\/github.com\/jwgcarlson\/Copter"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009PhRvD..80d3531C"]},
		{"ascl_id":"1305.001","title":"ESTER: Evolution STEllaire en Rotation","credit":"Rieutord, Michel","abstract":"The ESTER code computes the steady state of an isolated star of mass larger than two solar masses. The only convective region computed as such is the core where isentropy is assumed. ESTER provides solutions of the partial differential equations, for the pressure, density, temperature, angular velocity and meridional velocity for the whole volume. The angular velocity (differential rotation) and meridional circulation are computed consistently with the structure and are driven by the baroclinic torque. The code uses spectral methods, both radially and horizontally, with spherical harmonics and Chebyshev polynomials. The iterations follow Newton's algorithm. The code is object-oriented and is written in C++; a python suite allows an easy visualization of the results. While running, PGPLOT graphs are displayed to show evolution of the iterations.","topic_id":"31310","bibcode":"2013ascl.soft05001R","views":"38","site_list":["http:\/\/code.google.com\/p\/ester-project\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007A%26A...470.1013E"]},
		{"ascl_id":"1305.002","title":"pynbody: N-Body\/SPH analysis for python","credit":"Pontzen, Andrew; Ro\u0161kar, Rok; Stinson, Greg; Woods, Rory","abstract":"Pynbody is a lightweight, portable, format-transparent analysis package for astrophysical N-body and smooth particle hydrodynamic simulations supporting PKDGRAV\/Gasoline, Gadget, N-Chilada, and RAMSES AMR outputs. Written in python, the core tools are accompanied by a library of publication-level analysis routines.","topic_id":"31311","bibcode":"2013ascl.soft05002P","views":"75","site_list":["https:\/\/github.com\/pynbody\/pynbody"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1211.1982R"]},
		{"ascl_id":"1305.003","title":"TPM: Tree-Particle-Mesh code","credit":"Bode, Paul","abstract":"TPM carries out collisionless (dark matter) cosmological N-body simulations, evolving a system of N particles as they move under their mutual gravitational interaction. It combines aspects of both Tree and Particle-Mesh algorithms. After the global PM forces are calculated, spatially distinct regions above a given density contrast are located; the tree code calculates the gravitational interactions inside these denser objects at higher spatial and temporal resolution. The code is parallel and uses MPI for message passing.","topic_id":"31312","bibcode":"2013ascl.soft05003B","views":"50","site_list":["https:\/\/web.archive.org\/web\/20120225093350\/http:\/\/www.astro.princeton.edu\/~bode\/TPM\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000ApJS..128..561B"]},
		{"ascl_id":"1305.004","title":"AdaptaHOP: Subclump finder","credit":"Colombi, S.","abstract":"AdaptaHOP is a structure and substructure detector. It reads an input particle distribution file and can compute the mean square distance between each particle and its nearest neighbors or the SPH density associated to each particle + the list of its nearest neighbors. It can also read an input particle distribution and a neighbors file (output from a previous run) and output the tree of the structures in structures.","topic_id":"31313","bibcode":"2013ascl.soft05004C","views":"88","site_list":["http:\/\/www.projet-horizon.fr\/article277.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004MNRAS.352..376A"]},
		{"ascl_id":"1305.005","title":"PkdGRAV2: Parallel fast-multipole cosmological code","credit":"Stadel, Joachim","abstract":"PkdGRAV2 is a high performance N-body treecode for self-gravitating astrophysical simulations. It is designed to run efficiently in serial and on a wide variety of parallel computers including both shared memory and message passing architectures. It can spatially adapt to large ranges in particle densities, and temporally adapt to large ranges in dynamical timescales. The code uses a non-standard data structure for efficiently calculating the gravitational forces, a variant on the k-D tree, and a novel method for treating periodic boundary conditions.","topic_id":"31343","bibcode":"2013ascl.soft05005S","views":"40","site_list":["http:\/\/hpcforge.org\/projects\/pkdgrav2\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001PhDT........21S"]},
		{"ascl_id":"1305.006","title":"Pressure-Entropy SPH: Pressure-entropy smooth-particle hydrodynamics","credit":"Hopkins, Philip F.","abstract":"Pressure-Entropy SPH, a modified version of <a href=\"http:\/\/ascl.net\/0003.001\">GADGET-2<\/a>, uses the Lagrangian \u201cPressure-Entropy\u201d formulation of the SPH equations. This removes the spurious \u201csurface tension\u201d force substantially improving the treatment of fluid mixing and contact discontinuities. Pressure-Entropy SPH shows good performance in mixing experiments (e.g. Kelvin-Helmholtz & blob tests), with conservation maintained even in strong shock\/blastwave tests, where formulations without manifest conservation produce large errors. This improves the treatment of sub-sonic turbulence and lessens the need for large kernel particle numbers.","topic_id":"31344","bibcode":"2013ascl.soft05006H","views":"49","site_list":["http:\/\/www.astrosim.net\/code\/lib\/exe\/fetch.php?media=codesonline:gadget2p.tgz"],"ref_list":["http:\/\/arxiv.org\/abs\/1206.5006"]},
		{"ascl_id":"1305.007","title":"PINOCCHIO: PINpointing Orbit-Crossing Collapsed HIerarchical Objects","credit":"Monaco, Pierluigi; Theuns, Tom","abstract":"PINOCCHIO generates catalogues of cosmological dark matter halos with known mass, position, velocity and merger history. It is able to reproduce, with very good accuracy, the hierarchical formation of dark matter halos from a realization of an initial (linear) density perturbation field, given on a 3D grid. Its setup is similar to that of a conventional N-body simulation, but it is based on the powerful Lagrangian Perturbation Theory. It runs in just a small fraction of the computing time taken by an equivalent N-body simulation, producing promptly the merging histories of all halos in the catalog.","topic_id":"31355","bibcode":"2013ascl.soft05007M","views":"31","site_list":["http:\/\/adlibitum.oats.inaf.it\/monaco\/Homepage\/Pinocchio\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1305.1505M"]},
		{"ascl_id":"1305.008","title":"YNOGK: Calculating null geodesics in the Kerr spacetime","credit":"Yang, Xiaolin; Wang, Jiancheng","abstract":"YNOGK, written in Fortran, calculates the null geodesics in the Kerr spacetime. It uses Weierstrass' and Jacobi's elliptic functions to express all coordinates and affine parameters as analytical and numerical functions of a parameter $p$, which is an integral value along the geodesic. The information about the turning points do not need to be specified in advance by the user, allowing  applications such as imaging, the calculation of line profiles or the observer-emitter problem to become root finding problems. Elliptic integrations are computed by Carlson's elliptic integral method, which allows fast computation.","topic_id":"31358","bibcode":"2013ascl.soft05008Y","views":"61","site_list":["http:\/\/www1.ynao.ac.cn\/~yangxl\/yxl.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1305.1250Y"]},
		{"ascl_id":"1305.009","title":"GaussFit: Solving least squares and robust estimation problems","credit":"Jefferys, William; McArthur, Barbara; McCartney, James","abstract":"GaussFit solves least squares and robust estimation problems; written originally for reduction of NASA Hubble Space Telescope data, it includes a complete programming language designed especially to formulate estimation problems, a built-in compiler and interpreter to support the programming language, and a built-in algebraic manipulator for calculating the required partial derivatives analytically. The code can handle nonlinear models, exact constraints, correlated observations, and models where the equations of condition contain more than one observed quantity. Written in C, GaussFit includes an experimental robust estimation capability so data sets contaminated by outliers can be handled simply and efficiently.","topic_id":"31383","bibcode":"2013ascl.soft05009J","views":"52","site_list":["http:\/\/clyde.as.utexas.edu\/Software.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1987CeMec..41...39J","http:\/\/adsabs.harvard.edu\/abs\/2005AJ....129.1954J"]},
		{"ascl_id":"1305.010","title":"GILDAS: Grenoble Image and Line Data Analysis Software","credit":"Gildas Team","abstract":"GILDAS is a collection of software oriented toward (sub-)millimeter radioastronomical applications (either single-dish or interferometer). It has been adopted as the IRAM standard data reduction package and is jointly maintained by IRAM & CNRS. GILDAS contains many facilities, most of which are oriented towards spectral line mapping and many kinds of 3-dimensional data. The code, written in Fortran-90 with a few parts in C\/C++ (mainly keyboard interaction, plotting, widgets), is easily extensible.","topic_id":"31394","bibcode":"2013ascl.soft05010G","views":"139","site_list":["http:\/\/www.iram.fr\/IRAMFR\/GILDAS\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005sf2a.conf..721P"]},
		{"ascl_id":"1305.011","title":"FITDisk: Cataclysmic Variable Accretion Disk Demonstration Tool","credit":"Wood, Matthew A.; Dolence, J.","abstract":"FITDisk models accretion disk phenomena using a fully three-dimensional hydrodynamics calculation, and data can either be visualized as they are computed or stored to hard drive for later playback at a fast frame rate. Simulations are visualized using OpenGL graphics and the viewing angle can be changed interactively. Pseudo light curves of simulated systems can be plotted along with the associated Fourier amplitude spectrum. It provides an easy to use graphical user interface as well as 3-D interactive graphics. The code computes the evolution of a CV accretion disk, visualizes results in real time, records and plays back simulations, and generates and plots pseudo light curves and associated power spectra.","topic_id":"31396","bibcode":"2013ascl.soft05011W","views":"35","site_list":["http:\/\/astro.tamuc.edu\/wood\/fitdisk.html"],"ref_list":["http:\/\/www.jstor.org\/stable\/10.1086\/499574"]},
		{"ascl_id":"1305.012","title":"MapCUMBA: Multi-grid map-making algorithm for CMB experiments","credit":"Bouchet, Fran\u00e7ois R.; Dor\u00e9, Olivier; Teyssier, Romain; Vibert, Didier","abstract":"The MapCUMBA package applies a multigrid fast iterative Jacobi algorithm for map-making in the context of CMB experiments.","topic_id":"31398","bibcode":"2013ascl.soft05012B","views":"35","site_list":["http:\/\/prof.planck.fr\/article142.html"],"ref_list":["http:\/\/arxiv.org\/abs\/astro-ph\/0101112"]},
		{"ascl_id":"1305.013","title":"Non-Gaussian Realisations","credit":"Brown, Iain A.","abstract":"Non-Gaussian Realisations provides code based on a spectral distortion\/quantile transformation that generates a realization of a field on a cubic grid that has a specified probability distribution function and a specified power spectrum.","topic_id":"31354","bibcode":"2013ascl.soft05013B","views":"42","site_list":["http:\/\/sourceforge.net\/projects\/nongaussian\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013JCAP...06..003B"]},
		{"ascl_id":"1305.014","title":"TAU: 1D radiative transfer code for transmission spectroscopy of extrasolar planet atmospheres","credit":"Hollis, M. D. J.; Tessenyi, M.; Tinetti, G.","abstract":"TAU is a 1D line-by-line radiative transfer code for modeling transmission spectra of close-in extrasolar planets. The code calculates the optical path through the planetary atmosphere of the radiation from the host star and quantifies the absorption due to the modeled composition in a transmission spectrum of transit depth as a function of wavelength. The code is written in C++ and is parallelized using OpenMP.","topic_id":"31370","bibcode":"2013ascl.soft05014H","views":"49","site_list":["http:\/\/www.ucl.ac.uk\/exoplanets\/tau"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1305.2787H"]},
		{"ascl_id":"1305.015","title":"Merger Trees: Formation history of dark matter haloes","credit":"Parkinson, Hannah; Cole, Shaun; Helly, John","abstract":"Merger Trees uses a Monte Carlo algorithm to generate merger trees describing the formation history of dark matter haloes; the algorithm is implemented in Fortran. The algorithm is a modification of the algorithm of Cole et al. used in the GALFORM semi-analytic galaxy formation model based on the Extended Press\u2013Schechter theory. It should be applicable to hierarchical models with a wide range of power spectra and cosmological models. It is tuned to be in accurate agreement with the conditional mass functions found in the analysis of merger trees extracted from the \u039b cold dark matter Millennium N-body simulation. The code should be a useful tool for semi-analytic models of galaxy formation and for modelling hierarchical structure formation in general.","topic_id":"31453","bibcode":"2013ascl.soft05015P","views":"36","site_list":["http:\/\/star-www.dur.ac.uk\/~cole\/merger_trees"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008MNRAS.383..557P"]},
		{"ascl_id":"1306.001","title":"SAC: Sheffield Advanced Code","credit":"Griffiths, Mike; Fedun, Viktor; Mumford, Stuart; Gent, Frederick","abstract":"The Sheffield Advanced Code (SAC) is a fully non-linear MHD code designed for simulations of linear and non-linear wave propagation in gravitationally strongly stratified magnetized plasma. It was developed primarily for the forward modelling of helioseismological processes and for the coupling processes in the solar interior, photosphere, and corona; it is built on the well-known VAC platform that allows robust simulation of the macroscopic processes in gravitationally stratified (non-)magnetized plasmas. The code has no limitations of simulation length in time imposed by complications originating from the upper boundary, nor does it require implementation of special procedures to treat the upper boundaries. SAC inherited its modular structure from VAC, thereby allowing modification to easily add new physics.","topic_id":"31474","bibcode":"2013ascl.soft06001G","views":"37","site_list":["http:\/\/ccpforge.cse.rl.ac.uk\/gf\/project\/sac\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008A%26A...486..655S"]},
		{"ascl_id":"1306.002","title":"grmonty: Relativistic radiative transport Monte Carlo code","credit":"Dolence, Joshua C.; Gammie, Charles F.; Mocibrodzka, Monika; Leung, Po Kin","abstract":"grmonty is a Monte Carlo radiative transport code intended for calculating spectra of hot, optically thin plasmas in full general relativity. The code models hot accretion flows in the Kerr metric, it incorporates synchrotron emission and absorption and Compton scattering. grmonty can be readily generalized to account for other radiative processes and an arbitrary spacetime.","topic_id":"31475","bibcode":"2013ascl.soft06002D","views":"45","site_list":["http:\/\/rainman.astro.illinois.edu\/codelib\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009ApJS..184..387D"]},
		{"ascl_id":"1306.003","title":"Harmony: Synchrotron Emission Coefficients","credit":"Leung, Po Kin; Gammie, Charles F.; Noble, Scott C.","abstract":"Harmony is a general numerical scheme for evaluating MBS emission and absorption coefficients for both polarized and unpolarized light in a plasma with a general distribution function.","topic_id":"31476","bibcode":"2013ascl.soft06003L","views":"38","site_list":["http:\/\/rainman.astro.illinois.edu\/codelib\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ApJ...737...21L"]},
		{"ascl_id":"1306.004","title":"PROM4: 1D isothermal and isobaric modeler for solar prominences","credit":"Gouttebroze, P.; Labrosse, N.","abstract":"PROM4 computes simple models of solar prominences which consist of plane-parallel slabs standing vertically above the solar surface. Each model is defined by 5 parameters: temperature, density, geometrical thickness, microturbulent velocity and height above the solar surface. PROM4 solves the equations of radiative transfer, statistical equilibrium, ionization and pressure equilibria, and computes electron and hydrogen level populations and hydrogen line profiles. Written in Fortran 90 and with two versions available (one with text in English, one with text in French), the code needs 64-bit arithmetic for real numbers.","topic_id":"31533","bibcode":"2013ascl.soft06004G","views":"38","site_list":["http:\/\/www.ias.u-psud.fr\/medoc-OLD\/science\/codes\/rtc.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1993A%26AS...99..513G"]},
		{"ascl_id":"1306.005","title":"PROS: Multi-mission X-ray analysis software system","credit":"Conroy, M. A.; Deponte, J.; Moran, J. F.; Orszak, J. S.; Roberts, W. P.; Schmidt, D.","abstract":"PROS is a multi-mission x-ray analysis software system designed to run under IRAF.  The PROS software includes spatial, spectral, timing, data I\/O and conversion routines, plotting applications, and general algorithms for performing arithmetic operations with imaging data.","topic_id":"31534","bibcode":"2013ascl.soft06005C","views":"38","site_list":["http:\/\/hea-www.harvard.edu\/PROS\/pros.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1993ASPC...52..238C"]},
		{"ascl_id":"1306.006","title":"BEHR: Bayesian Estimation of Hardness Ratios","credit":"Park, T.; Kashyap, V. L.; Siemiginowska, A.; van Dyk, D.; Zezas, A.; Heinke, C.; Wargelin, B. J.","abstract":"BEHR is a standalone command-line C program designed to quickly estimate the hardness ratios and their uncertainties for astrophysical sources. It is especially useful in the Poisson regime of low counts, and computes the proper uncertainty regardless of whether the source is detected in both passbands or not.","topic_id":"31535","bibcode":"2013ascl.soft06006P","views":"67","site_list":["http:\/\/hea-www.cfa.harvard.edu\/astrostat\/BEHR\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ApJ...652..610P"]},
		{"ascl_id":"1306.007","title":"Tapir: A web interface for transit\/eclipse observability","credit":"Jensen, Eric","abstract":"Tapir is a set of tools, written in Perl, that provides a web interface for showing the observability of periodic astronomical events, such as exoplanet transits or eclipsing binaries. The package provides tools for creating finding charts for each target and airmass plots for each event. The code can access target lists that are stored on-line in a Google spreadsheet or in a local text file.","topic_id":"31569","bibcode":"2013ascl.soft06007J","views":"41","site_list":["https:\/\/github.com\/elnjensen\/Tapir"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1211.1031P"]},
		{"ascl_id":"1306.008","title":"MAPPINGS III: Modelling And Prediction in PhotoIonized Nebulae and Gasdynamical Shocks","credit":"Sutherland, Ralph; Dopita, Mike; Binette, Luc; Groves, Brent","abstract":"MAPPINGS III is a general purpose astrophysical plasma modelling code. It is principally intended to predict emission line spectra of medium and low density plasmas subjected to different levels of photoionization and ionization by shockwaves. MAPPINGS III tracks up to 16 atomic species in all stages of ionization, over a useful range of 102 to 108 K. It treats spherical and plane parallel geometries in equilibrium and time-dependent models. MAPPINGS III is useful for computing models of HI and HII regions, planetary nebulae, novae, supernova remnants, Herbig-Haro shocks, active galaxies, the intergalactic medium and the interstellar medium in general. The present version of MAPPINGS III is a large FORTRAN program that runs with a simple TTY interface for historical and portability reasons.","topic_id":"31612","bibcode":"2013ascl.soft06008S","views":"41","site_list":["http:\/\/www.mpia-hd.mpg.de\/~brent\/mapiii.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ApJS..178...20A"]},
		{"ascl_id":"1306.009","title":"STF: Structure Finder","credit":"Elahi, Pascal Jahan","abstract":"STF is a general structure finder designed to find halos, subhaloes, and tidal debris in N-body simulations. The current version is designed to read in \"particle data\" (that is SPH N-body data), but a simple modification of the I\/O can have it read grid data from Grid based codes.","topic_id":"31616","bibcode":"2013ascl.soft06009E","views":"34","site_list":["http:\/\/asterisk.apod.com\/library\/ASCL\/STF\/stf-1.1.tar.gz"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011MNRAS.418..320E"]},
		{"ascl_id":"1306.010","title":"MADCOW: Microwave Anisotropy Dataset Computational softWare","credit":"Hobson, M. P.; Maisinger, Klaus","abstract":"MADCOW is a set of parallelized programs written in ANSI C and Fortran 77 that perform a maximum likelihood analysis of visibility data from interferometers observing the cosmic microwave background (CMB) radiation. This software has been used to produce power spectra of the CMB with the Very Small Array (VSA) telescope.","topic_id":"31643","bibcode":"2013ascl.soft06010H","views":"36","site_list":["http:\/\/www.mrao.cam.ac.uk\/facilities\/software\/madcow\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002MNRAS.334..569H"]},
		{"ascl_id":"1306.011","title":"Pico: Parameters for the Impatient Cosmologist","credit":"Fendt, Chad; Wandelt, Benjamin","abstract":"Pico is an algorithm that quickly computes the CMB scalar, tensor and lensed power spectra, the matter transfer function and the WMAP 5 year likelihood. It is intended to accelerate parameter estimation codes; Pico can compute the CMB power spectrum and matter transfer function, as well as any computationally expensive likelihoods, in a few milliseconds. It is extremely fast and accurate over a large volume of parameter space and its accuracy can be improved by using a larger training set. More generally, Pico allows using massively parallel computing resources, including distributed computing projects such as Cosmology@Home, to speed up the slow steps in inherently sequential calculations.","topic_id":"31644","bibcode":"2013ascl.soft06011F","views":"46","site_list":["http:\/\/cosmos.astro.illinois.edu\/pico\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007ApJ...654....2F"]},
		{"ascl_id":"1306.012","title":"LRG DR7 Likelihood Software","credit":"Reid, Beth A.","abstract":"This software computes likelihoods for the Luminous Red Galaxies (LRG) data from the Sloan Digital Sky Survey (SDSS). It includes a patch to the existing <a href=\"http:\/\/ascl.net\/1102.026\">CAMB<\/a> software (the February 2009 release) to calculate the theoretical LRG halo power spectrum for various models. The code is written in Fortran 90 and has been tested with the Intel Fortran 90 and GFortran compilers.","topic_id":"31645","bibcode":"2013ascl.soft06012R","views":"31","site_list":["http:\/\/lambda.gsfc.nasa.gov\/toolbox\/lrgdr\/"],"ref_list":["http:\/\/arxiv.org\/abs\/0907.1659"]},
		{"ascl_id":"1306.013","title":"Bessel: Fast Bessel Function Jn(z) Routine for Large n,z","credit":"Leung, Po Kin; Gammie, Charles F.; Noble, Scott C.","abstract":"Bessel, written in the C programming language, uses an accurate scheme for evaluating Bessel functions of high order. It has been extensively tested against a number of other routines, demonstrating its accuracy and efficiency.","topic_id":"31477","bibcode":"2013ascl.soft06013L","views":"67","site_list":["http:\/\/rainman.astro.illinois.edu\/codelib\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ApJ...737...21L"]},
		{"ascl_id":"1306.014","title":"ZEUS-2D: Simulation of fluid dynamical flows","credit":"Stone, James M.; Norman, Michael L.","abstract":"ZEUS-2D is a hydrodynamics code based on ZEUS which adds a covariant differencing formalism and algorithms for compressible hydrodynamics, MHD, and radiation hydrodynamics (using flux-limited diffusion) in Cartesian, cylindrical, or spherical polar coordinates.","topic_id":"31692","bibcode":"2013ascl.soft06014S","views":"72","site_list":["http:\/\/www.astro.princeton.edu\/~jstone\/zeus.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1992ApJS...80..753S"]},
		{"ascl_id":"1306.015","title":"VHD: Viscous pseudo-Newtonian accretion","credit":"McKinney, Jonathan C.; Gammie, Charles F.","abstract":"VHD is a numerical study of viscous fluid accretion onto a black hole. The flow is axisymmetric and uses a pseudo-Newtonian potential to model relativistic effects near the event horizon. VHD is based on <a href=\"http:\/\/ascl.net\/1306.014\">ZEUS-2D<\/a> (Stone & Norman 1992) with the addition of an explicit scheme for the viscosity.","topic_id":"31478","bibcode":"2013ascl.soft06015M","views":"47","site_list":["http:\/\/rainman.astro.illinois.edu\/codelib\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002ApJ...573..728M"]},
		{"ascl_id":"1306.016","title":"Yaxx: Yet another X-ray extractor","credit":"Aldcroft, Tom","abstract":"Yaxx is a Perl script that facilitates batch data processing using Perl open source software and commonly available software such as CIAO\/Sherpa, S-lang, SAS, and FTOOLS. For Chandra and XMM analysis it includes automated spectral extraction, fitting, and report generation. Yaxx can be run without climbing an extensive learning curve; even so, yaxx is highly configurable and can be customized to support complex analysis. yaxx uses template files and takes full advantage of the unique Sherpa \/ S-lang environment to make much of the processing user configurable. Although originally developed with an emphasis on X-ray data analysis, yaxx evolved to be a general-purpose pipeline scripting package.","topic_id":"31651","bibcode":"2013ascl.soft06016A","views":"47","site_list":["http:\/\/cxc.harvard.edu\/contrib\/yaxx\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006HEAD....9.1358A","http:\/\/adsabs.harvard.edu\/abs\/2010ApJ...714.1582B"]},
		{"ascl_id":"1307.001","title":"DustEM: Dust extinction and emission modelling","credit":"Compi\u00e8gne, M.; Verstraete, L.; Jones, A.; Bernard, J.-P.; Boulanger, F.; Flagey, N.; Le Bourlot, J.; Paradis, D.; Ysard, N.","abstract":"DustEM computes the extinction and the emission of interstellar dust grains heated by photons. It is written in Fortran 95 and is jointly developed by IAS and CESR. The dust emission is calculated in the optically thin limit (no radiative transfer) and the default spectral range is 40 to 108 nm. The code is designed so dust properties can easily be changed and mixed and to allow for the inclusion of new grain physics.","topic_id":"31688","bibcode":"2013ascl.soft07001C","views":"38","site_list":["http:\/\/www.ias.u-psud.fr\/DUSTEM\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1010.2769"]},
		{"ascl_id":"1307.002","title":"Monte Python: Monte Carlo code for CLASS in Python","credit":"Audren, Benjamin; Lesgourgues, Julien; Benabed, Karim; Prunet, Simon","abstract":"Monte Python is a parameter inference code which combines the flexibility of the python language and the robustness of the cosmological code <a href=\"http:\/\/ascl.net\/1106.020\">CLASS<\/a> into a simple and easy to manipulate Monte Carlo Markov Chain code.","topic_id":"31689","bibcode":"2013ascl.soft07002A","views":"59","site_list":["http:\/\/montepython.net\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013JCAP...02..001A"]},
		{"ascl_id":"1307.003","title":"K3Match: Point matching in 3D space","credit":"Schellart, Pim","abstract":"K3Match is a C library with Python bindings for fast matching of points in 3D space. It uses 3-dimensional binary trees to find matches between large datasets in O(N log N) time.","topic_id":"31705","bibcode":"2013ascl.soft07003S","views":"48","site_list":["http:\/\/pschella.github.io\/k3match\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012A%26A...544A..18V"]},
		{"ascl_id":"1307.004","title":"FieldInf: Field Inflation exact integration routines","credit":"Ringeval, Christophe","abstract":"FieldInf is a collection of fast modern Fortran routines for computing exactly the background evolution and primordial power spectra of any single field inflationary models. It implements reheating without any assumptions through the \"reheating parameter\" R allowing robust inflationary parameter estimations and inference on the reheating energy scale. The underlying perturbation code actually deals with N fields minimally-coupled and\/or non-minimally coupled to gravity and works for flat FLRW only.","topic_id":"31717","bibcode":"2013ascl.soft07004R","views":"35","site_list":["http:\/\/theory.physics.unige.ch\/~ringeval\/fieldinf.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006PhRvD..73f4035R"]},
		{"ascl_id":"1307.005","title":"LENSVIEW: Resolved gravitational lens images modeling","credit":"Wayth, Randall","abstract":"Lensview models resolved gravitational lens systems based on LensMEM but using the Skilling & Bryan MEM algorithm. Though its primary purpose is to find statistically acceptable lens models for lensed images and to reconstruct the surface brightness profile of the source, LENSVIEW can also be used for more simple tasks such as projecting a given source through a lens model to generate a \u201ctrue\u201d image by conserving surface brightness. The user can specify complicated lens models based on one or more components, such as softened isothermal ellipsoids, point masses, exponential discs, and external shears; LENSVIEW generates a best-fitting source matching the observed data for each specific combination of model parameters.","topic_id":"31718","bibcode":"2013ascl.soft07005W","views":"43","site_list":["http:\/\/cira.ivec.org\/dokuwiki\/doku.php\/staff\/rwayth\/lensview"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006MNRAS.372.1187W"]},
		{"ascl_id":"1307.006","title":"im2shape: Bayesian Galaxy Shape Estimation","credit":"Bridle, S. L.; Kneib, J.-P.; Bardeau, S.","abstract":"im2shape is a Bayesian approach to the problem of accurate measurement of galaxy ellipticities for weak lensing studies, in particular cosmic shear. im2shape parameterizes galaxies as sums of Gaussians, convolved with a psf which is also a sum of Gaussians. The uncertainties in the output parameters are calculated using a Markov Chain Monte Carlo approach.","topic_id":"31719","bibcode":"2013ascl.soft07006B","views":"37","site_list":["http:\/\/www.sarahbridle.net\/im2shape\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012A%26A...540A..61S","http:\/\/adsabs.harvard.edu\/abs\/2007A%26A...470..449B"]},
		{"ascl_id":"1307.007","title":"AstroTaverna: Tool for Scientific Workflows in Astronomy","credit":"Garrido, Julian; Soiland-Reyes, Stian; Ruiz, Jose Enrique; Sanchez, Susana","abstract":"AstroTaverna is a plugin for Taverna Workbench that provides the means to build astronomy workflows using Virtual Observatory services discovery and efficient manipulation of VOTables (based on STIL tool set). It integrates SAMP-enabled software, allowing data exchange and communication among local VO tools, as well as the ability to execute Aladin scripts and macros.","topic_id":"31653","bibcode":"2013ascl.soft07007G","views":"67","site_list":["http:\/\/wf4ever.github.io\/astrotaverna\/"],"ref_list":["https:\/\/github.com\/wf4ever\/astrotaverna"]},
		{"ascl_id":"1307.008","title":"Obit: Radio Astronomy Data Handling","credit":"Cotton, Bill","abstract":"Obit is a group of software packages for handling radio astronomy data, especially interferometric and single dish OTF imaging. Obit is primarily an environment in which new data processing algorithms can be developed and tested but which can also be used for production processing of a certain range of scientific problems. The package supports both prepackaged, compiled tasks and a python interface to the major class functionality to allow rapid prototyping using python scripts; it allows access to multiple disk--resident data formats, in particular access to either AIPS disk data or FITS files. Obit applications are interoperable with Classic AIPS and the ObitTalk python interface gives access to AIPS tasks as well as Obit libraries and tasks.","topic_id":"31763","bibcode":"2013ascl.soft07008C","views":"32","site_list":["http:\/\/www.cv.nrao.edu\/~bcotton\/Obit.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008PASP..120..439C"]},
		{"ascl_id":"1307.009","title":"MAH: Minimum Atmospheric Height","credit":"Kipping, David M.; Spiegel, David S.; Sasselov, Dimitar D.","abstract":"MAH calculates the posterior distribution of the \"minimum atmospheric height\" (MAH) of an exoplanet by inputting the joint posterior distribution of the mass and radius. The code collapses the two dimensions of mass and radius into a one dimensional term that most directly speaks to whether the planet has an atmosphere or not. The joint mass-radius posteriors derived from a fit of some exoplanet data (likely using MCMC) can be used by MAH to evaluate the posterior distribution of R_MAH, from which the significance of a non-zero R_MAH (i.e. an atmosphere is present) is calculated.","topic_id":"31739","bibcode":"2013ascl.soft07009K","views":"32","site_list":["https:\/\/www.cfa.harvard.edu\/~dkipping\/mah.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1306.3221K"]},
		{"ascl_id":"1307.010","title":"cosmoxi2d: Two-point galaxy correlation function calculation","credit":"Reid, Beth","abstract":"Cosmoxi2d is written in C and computes the theoretical two-point galaxy correlation function as a function of cosmological and galaxy nuisance parameters. It numerically evaluates the model described in detail in Reid and White 2011 (arxiv:1105.4165) and Reid et al. 2012 (arxiv:1203.6641) for the multipole moments (up to ell = 4) for the observed redshift space correlation function of biased tracers as a function of cosmological (though an input linear matter power spectrum, growth rate f, and Alcock-Paczynski geometric factors alphaperp and alphapar) as well as nuisance parameters describing the tracers (bias and small scale additive velocity dispersion, isotropicdisp1d).\r\n\r\nThis model works best for highly biased tracers where the 2nd order bias term is small.  On scales larger than 100 Mpc, the code relies on 2nd order Lagrangian Perturbation theory as detailed in Matsubara 2008 (PRD 78, 083519), and uses the analytic version of Reid and White 2011 on smaller scales.","topic_id":"31816","bibcode":"2013ascl.soft07010R","views":"72","site_list":["http:\/\/www.sdss3.org\/svn\/repo\/cosmoxi2d\/trunk\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011arXiv1105.4165R"]},
		{"ascl_id":"1307.011","title":"phoSim: Photon Simulator","credit":"Peterson, John R.; Jernigan, J. Garrett","abstract":"The Photon Simulator (phoSim) is a set of fast photon Monte Carlo codes used to calculate the physics of the atmosphere, telescope, and detector by using modern numerical techniques applied to comprehensive physical models. phoSim generates images by collecting photons into pixels. The code takes the description of what astronomical objects are in the sky at a particular time (the instance catalog) as well as the description of the observing configuration (the operational parameters) and  produces a realistic data stream of images that are similar to what a real telescope would produce. phoSim was developed for large aperture wide field optical telescopes, such as the planned design of LSST. The initial version of the simulator also targeted the LSST telescope and camera design, but the code has since been broadened to include existing telescopes of a related nature. The atmospheric model, in particular, includes physical approximations that are limited to this general context.","topic_id":"31813","bibcode":"2013ascl.soft07011P","views":"37","site_list":["https:\/\/dev.lsstcorp.org\/trac\/wiki\/IS_phosim"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013MNRAS.tmp.1806C"]},
		{"ascl_id":"1307.012","title":"ITERA: IDL Tool for Emission-line Ratio Analysis","credit":"Groves, Brent; Allen, Mark","abstract":"ITERA, the IDL Tool for Emission-line Ratio Analysis, is an IDL widget tool that allows you to plot ratios of any strong atomic and ionized emission lines as determined by standard photoionization and shock models. These \"line ratio diagrams\" can then be used to determine diagnostics for nebulae excitation mechanisms or nebulae parameters such as density, temperature, metallicity, etc. ITERA can also be used to determine line sensitivities to such parameters, compare observations with the models, or even estimate unobserved line fluxes.","topic_id":"31817","bibcode":"2013ascl.soft07012G","views":"49","site_list":["http:\/\/www.mpia-hd.mpg.de\/~brent\/itera.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010NewA...15..614G"]},
		{"ascl_id":"1307.013","title":"SIMX: Event simulator","credit":"Smith, Randall","abstract":"SIMX simulates a photon-counting detector's response to an input source, including a simplified model of any telescope. The code is not a full ray-trace, but a convolution tool that uses standard descriptions of telescope PSF (via either a simple Gaussian parameter, an energy-dependent encircled-energy function, or an image of the PSF) and the detector response (using the OGIP response function) to model how sources will appear. simx uses a predefined set of PSFs, vignetting information, and instrumental responses and outputs to make the simulation. It is designed to be a 'approximation' tool to estimate issues such as source confusion, background effects, pileup, and other similar issues.","topic_id":"31818","bibcode":"2013ascl.soft07013S","views":"36","site_list":["http:\/\/hea-www.cfa.harvard.edu\/simx\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012SPIE.8443E..56"]},
		{"ascl_id":"1307.014","title":"Shapelets: Image Modelling","credit":"Massey, Richard; Refregier, Alexandre","abstract":"Shapelets are a complete, orthonormal set of 2D basis functions constructed from Laguerre or Hermite polynomials weighted by a Gaussian. A linear combination of these functions can be used to model any image, in a similar way to Fourier or wavelet synthesis. The shapelet decomposition is particularly efficient for images localized in space, and provide a high level of compression for individual galaxies in astronomical data. The basis has many elegant mathematical properties that make it convenient for image analysis and processing.","topic_id":"31780","bibcode":"2013ascl.soft07014M","views":"35","site_list":["http:\/\/www.astro.caltech.edu\/~rjm\/shapelets"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005MNRAS.363..197M","http:\/\/adsabs.harvard.edu\/abs\/2003MNRAS.338...35R"]},
		{"ascl_id":"1307.015","title":"CTI Correction Code","credit":"Massey, Richard; Stoughton, Chris; Leauthaud, Alexie; Rhodes, Jason; Koekemoer, Anton; Ellis, Richard; Shaghoulian, Edgar","abstract":"Charge Transfer Inefficiency (CTI) due to radiation damage above the Earth's atmosphere creates spurious trailing in images from Charge-Coupled Device (CCD) imaging detectors. Radiation damage also creates unrelated warm pixels, which can be used to measure CTI. This code provides pixel-based correction for CTI and has proven effective in Hubble Space Telescope Advanced Camera for Surveys raw images, successfully reducing the CTI trails by a factor of ~30 everywhere in the CCD and at all flux levels. The core is written in java for speed, and a front-end user interface is provided in IDL. The code operates on raw data by returning individual electrons to pixels from which they were unintentionally dragged during readout. Correction takes about 25 minutes per ACS exposure, but is trivially parallelisable to multiple processors.","topic_id":"31781","bibcode":"2013ascl.soft07015M","views":"47","site_list":["http:\/\/www.astro.caltech.edu\/~rjm\/acs\/CTE\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010MNRAS.401..371M"]},
		{"ascl_id":"1307.016","title":"orbfit: Orbit fitting software","credit":"Bernstein, Gary; Khushalani, Bharat","abstract":"Orbfit determines positions and orbital elements, and associated uncertainties, of outer solar system planets. The orbit-fitting procedure is greatly streamlined compared with traditional methods because acceleration can be treated as a perturbation to the inertial motion of the body. Orbfit quickly and accurately calculates orbital elements and ephemerides and their associated uncertainties for targets \u2273 10 AU from the Sun and produces positional estimates and uncertainty ellipses even in the face of the substantial degeneracies of short-arc orbit fits; the sole a priori assumption is that the orbit should be bound or nearly so.","topic_id":"31782","bibcode":"2013ascl.soft07016B","views":"44","site_list":["http:\/\/www.physics.upenn.edu\/~garyb\/#software"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000AJ....120.3323B"]},
		{"ascl_id":"1307.017","title":"NEST: Noble Element Simulation Technique","credit":"Szydagis, M.; Barry, N.; Kazkaz, K.; Mock, J.; Stolp, D.; Sweany, M.; Tripathi, M.; Uvarov, S.; Walsh, N.; Woods, M.","abstract":"NEST (Noble Element Simulation Technique) offers comprehensive, accurate, and precise simulation of the excitation, ionization, and corresponding scintillation and electroluminescence processes in liquid noble elements, useful for direct dark matter detectors, double beta decay searches, PET scans, and general radiation detection technology. Written in C++, NEST is an add-on module for the <a href=\"http:\/\/ascl.net\/1010.079\">Geant4<\/a> simulation package that incorporates more detailed physics than is currently available into the simulation of scintillation. NEST is of particular use for low-energy nuclear recoils. All available liquid xenon data on nuclear recoils and electron recoils to date have been taken into consideration in arriving at the current models. NEST also handles the magnitude of the light and charge yields of nuclear recoils, including their electric field dependence, thereby shedding light on the possibility of detection or exclusion of a low-mass dark matter WIMP by liquid xenon detectors.","topic_id":"31811","bibcode":"2013ascl.soft07017S","views":"41","site_list":["http:\/\/nest.physics.ucdavis.edu\/site\/"],"ref_list":["http:\/\/dx.doi.org\/10.1088\/1748-0221\/6\/10\/P10002","http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1307.6601S"]},
		{"ascl_id":"1307.018","title":"ETC++: Advanced Exposure-Time Calculations","credit":"Bernstein, Gary","abstract":"ETC++ is a exposure-time calculator that considers the effect of cosmic rays, undersampling, dithering, and imperfect pixel response functions. Errors on astrometry and galaxy shape measurements can be predicted as well as photometric errors.","topic_id":"31815","bibcode":"2013ascl.soft07018B","views":"37","site_list":["http:\/\/www.physics.upenn.edu\/~garyb\/#software"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002PASP..114...98B"]},
		{"ascl_id":"1307.019","title":"PURIFY: Tools for radio-interferometric imaging","credit":"Carrillo, Rafael E.; McEwen, Jason D.; Wiaux, Yves","abstract":"PURIFY is a collection of routines written in C that implements different tools for radio-interferometric imaging including file handling (for both visibilities and fits files), implementation of the measurement operator and set-up of the different optimization problems used for image deconvolution. The code calls the generic <a href=\"http:\/\/ascl.net\/1307.020\">Sparse OPTimization (SOPT)<\/a> package to solve the imaging optimization problems.","topic_id":"31820","bibcode":"2013ascl.soft07019C","views":"43","site_list":["https:\/\/github.com\/basp-group\/purify"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1307.4370C"]},
		{"ascl_id":"1307.020","title":"SOPT: Sparse OPTimisation","credit":"Carrillo, R. E.; McEwen, J. D.; Van De Ville, D.; Thiran, J.-P.; Wiaux, Y.","abstract":"SOPT (Sparse OPTimisation) is a C implementation of the Sparsity Averaging Reweighted Analysis (SARA) algorithm. The approach relies on the observation that natural images exhibit strong average sparsity; average sparsity outperforms state-of-the-art priors that promote sparsity in a single orthonormal basis or redundant frame, or that promote gradient sparsity.","topic_id":"31819","bibcode":"2013ascl.soft07020C","views":"42","site_list":["https:\/\/github.com\/basp-group\/sopt"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013ISPL...20..591C"]},
		{"ascl_id":"1308.001","title":"SMILE: Orbital analysis and Schwarzschild modeling of triaxial stellar systems","credit":"Vasiliev, Eugene","abstract":"SMILE is interactive software for studying a variety of 2D and 3D models, including arbitrary potentials represented by a basis-set expansion, a spherical-harmonic expansion with coefficients being smooth functions of radius (splines), or a set of fixed point masses. Its main features include:\r\n\r\n<ul><li>orbit integration in various 2d and 3d potentials (including N-body and basis-set representations of an arbitrary potential);<\/li><li>methods for analysis of orbital class, fundamental frequencies, regular or chaotic nature of an orbit, computation of Lyapunov exponents;<\/li><li>Poincar\u00e9 sections (in 2d) and frequency maps (in 3d) for analyzing orbital structure of potential;<\/li><li>construction of self-consistent Schwarzschild models; and<\/li><li>convenient visualization and integrated GUI environment, and a console scriptable version.<\/li><\/ul>SMILE is portable to different platforms including MS Windows, Linux and Mac.","topic_id":"31852","bibcode":"2013ascl.soft08001V","views":"37","site_list":["http:\/\/td.lpi.ru\/~eugvas\/smile\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1307.8116"]},
		{"ascl_id":"1308.002","title":"LOSSCONE: Capture rates of stars by a supermassive black hole","credit":"Vasiliev, Eugene, Merritt, David","abstract":"LOSSCONE computes the rates of capture of stars by supermassive black holes. It uses a stationary and time-dependent solutions for the Fokker-Planck equation describing the evolution of the distribution function of stars due to two-body relaxation, and works for arbitrary spherical and axisymmetric galactic models that are provided by the user in the form of M(r), the cumulative mass as a function of radius.","topic_id":"31853","bibcode":"2013ascl.soft08002V","views":"37","site_list":["http:\/\/td.lpi.ru\/~eugvas\/losscone\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1301.3150V"]},
		{"ascl_id":"1308.003","title":"MapCurvature: Map Projections","credit":"Goldberg, Dave; Gott, J. Richard, III","abstract":"MapCurvature, written in IDL, can create map projections with Goldberg-Gott indicatrices. These indicatrices measure the flexion and skewness of a map, and are useful for determining whether features are faithfully reproduced on a particular projection.","topic_id":"31863","bibcode":"2013ascl.soft08003G","views":"38","site_list":["http:\/\/www.physics.drexel.edu\/~goldberg\/projections\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006astro.ph..8501G"]},
		{"ascl_id":"1308.004","title":"LensEnt2: Maximum-entropy weak lens reconstruction","credit":"Marshall, P. J.; Hobson, M. P.; Gull, S. F.; Bridle, S. L.","abstract":"LensEnt2 is a maximum entropy reconstructor of weak lensing mass maps. The method takes each galaxy shape as an independent estimator of the reduced shear field and incorporates an intrinsic smoothness, determined by Bayesian methods, into the reconstruction. The uncertainties from both the intrinsic distribution of galaxy shapes and galaxy shape estimation are carried through to the final mass reconstruction, and the mass within arbitrarily shaped apertures are calculated with corresponding uncertainties. The input is a galaxy ellipticity catalog with each measured galaxy shape treated as a noisy tracer of the reduced shear field, which is inferred on a fine pixel grid assuming  positivity, and smoothness on scales of w arcsec where w is an input parameter. The ICF width w can be chosen by computing the evidence for it.","topic_id":"31866","bibcode":"2013ascl.soft08004M","views":"42","site_list":["http:\/\/www.slac.stanford.edu\/~pjm\/lensent\/version2\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002MNRAS.335.1037M"]},
		{"ascl_id":"1308.005","title":"APPSPACK: Asynchronous Parallel Pattern Search","credit":"Gray, Genetha A.; Kolda, Tamara G.","abstract":"APPSPACK is serial or parallel, derivative-free optimization software for solving nonlinear unconstrained, bound-constrained, and linearly-constrained optimization problems, with possibly noisy and expensive objective functions.","topic_id":"31915","bibcode":"2013ascl.soft08004G","views":"74","site_list":["https:\/\/software.sandia.gov\/appspack\/version5.0\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008JPhCS.125a2011N"]},
		{"ascl_id":"1308.006","title":"BASIN: Beowulf Analysis Symbolic INterface","credit":"Vesperini, Enrico; Goldberg, David M.; McMillan, Stephen L. W.; Dura, James; Jones, Douglas","abstract":"BASIN (Beowulf Analysis Symbolic INterface) is a flexible, integrated suite of tools for multiuser parallel data analysis and visualization that allows researchers to harness the power of Beowulf PC clusters and multi-processor machines without necessarily being experts in parallel programming. It also includes general tools for data distribution and parallel operations on distributed data for developing libraries for specific tasks.","topic_id":"31864","bibcode":"2013ascl.soft08006V","views":"69","site_list":["http:\/\/www.physics.drexel.edu\/BASIN\/"],"ref_list":["http:\/\/dx.doi.org\/10.1109\/MCSE.2009.39"]},
		{"ascl_id":"1308.007","title":"SYNAPPS: Forward-modeling of supernova spectroscopy data sets","credit":"Thomas, R. C.","abstract":"SYNAPPS is a spectrum fitter embedding a highly parameterized synthetic SN spectrum calculation within a parallel asynchronous optimizer. This open-source code is aimed primarily at the problem of systematically interpreting large sets of SN spectroscopy data.","topic_id":"31933","bibcode":"2013ascl.soft08007T","views":"36","site_list":["https:\/\/c3.lbl.gov\/es\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011PASP..123..237T"]},
		{"ascl_id":"1308.008","title":"SYN++: Standalone SN spectrum synthesis","credit":"Thomas, R. C.","abstract":"SYN++ is a standalone SN spectrum synthesis program. It is a rewrite of the original <a href=\"http:\/\/ascl.net\/1010.055\">SYNOW<\/a> code in modern C++. It offers further enhancements, a new structured input control file format, and the atomic data files have been repackaged and are more complete than those of SYNOW.","topic_id":"31934","bibcode":"2013ascl.soft08008T","views":"48","site_list":["https:\/\/c3.lbl.gov\/es\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011PASP..123..237T"]},
		{"ascl_id":"1308.009","title":"CReSyPS: Stellar population synthesis code","credit":"Cordier, D.; Lebreton, Y.; Goupil, M.-J.; Lejeune, T.; Beaulieu, J.-P.; Arenou, F.","abstract":"CReSyPS (Code Rennais de Synth\u00e8se de Populations Stellaires) is a stellar population synthesis code that determines core overshooting amount for Magellanic clouds main sequence stars.","topic_id":"31935","bibcode":"2013ascl.soft08009C","views":"45","site_list":["http:\/\/perso.utinam.cnrs.fr\/~cordier\/index.php?pw=cresyps"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002A%26A...392..169C"]},
		{"ascl_id":"1308.010","title":"GYRE: Stellar oscillation code","credit":"Townsend, R. H. D.; Teitler, S.","abstract":"GYRE is an oscillation code that solves the stellar pulsation equations (both adiabatic and non-adiabatic) using a novel Magnus Multiple Shooting numerical scheme devised to overcome certain weaknesses of the usual relaxation and shooting schemes. The code is accurate (up to 6th order in the number of grid points), robust, and makes efficient use of multiple processor cores and\/or nodes.","topic_id":"31983","bibcode":"2013ascl.soft08010T","views":"45","site_list":["https:\/\/bitbucket.org\/rhdtownsend\/gyre\/wiki\/Home"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1308.2965T"]},
		{"ascl_id":"1308.011","title":"CRUSH: Comprehensive Reduction Utility for SHARC-2 (and more...)","credit":"Kovacs, Attila","abstract":"CRUSH is an astronomical data reduction\/imaging tool for certain imaging cameras, especially at the millimeter, sub-millimeter, and far-infrared wavelengths. It supports the SHARC-2, LABOCA, SABOCA, ASZCA, p-ArTeMiS, PolKa, GISMO, MAKO and SCUBA-2 instruments. The code is written entirely in Java, allowing it to run on virtually any platform. It is normally run from the command-line with several arguments.","topic_id":"31987","bibcode":"2013ascl.soft08011K","views":"67","site_list":["http:\/\/www.submm.caltech.edu\/~sharc\/crush"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008SPIE.7020E..45K"]},
		{"ascl_id":"1308.012","title":"RADLite: Raytracer for infrared line spectra","credit":"Pontoppidan, Klaus; Dullemond, Kees","abstract":"RADLite is a raytracer that is optimized for producing infrared line spectra and images from axisymmetric density structures, originally developed to function on top of the dust radiative transfer code RADMC. RADLite can consistently deal with a wide range of velocity gradients, such as those typical for the inner regions of protoplanetary disks. The code is intended as a back-end for chemical and excitation codes, and can rapidly produce spectra of thousands of lines for grids of models for comparison with observations. It includes functionality for simulating telescopic images for optical\/IR\/midIR\/farIR telescopes. It takes advantage of multi-threaded CPUs and includes an escape-probability non-LTE module.","topic_id":"31988","bibcode":"2013ascl.soft08012P","views":"41","site_list":["http:\/\/www.stsci.edu\/~pontoppi\/Pontoppidan_web_home\/Software.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009ApJ...704.1482P"]},
		{"ascl_id":"1308.013","title":"THELI GUI: Optical, near- & mid-infrared imaging data reduction","credit":"Schirmer, Mischa","abstract":"THELI is an easy-to-use, end-to-end pipeline for the reduction of any optical, near-IR and mid-IR imaging data. It combines a variety of processing algorithms and third party software into a single, homogeneous tool. Over 90 optical and infrared instruments at observatories world-wide are pre-configured; more can be added by the user. The code's online appendix contains three walk-through examples using public data (optical, near-IR and mid-IR) and additional online documentation is available for training and troubleshooting.","topic_id":"31994","bibcode":"2013ascl.soft08013S","views":"48","site_list":["http:\/\/www.astro.uni-bonn.de\/~theli\/gui\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1308.4989S","http:\/\/adsabs.harvard.edu\/abs\/2005AN....326..432E"]},
		{"ascl_id":"1308.014","title":"SPEX: High-resolution cosmic X-ray spectra analysis","credit":"Mewe, R.; Kaastra, J. S.; Nieuwenhuijzen, H.","abstract":"SPEX is optimized for the analysis and interpretation of high-resolution cosmic X-ray spectra. The software is especially suited for fitting spectra obtained by current X-ray observatories like XMM-Newton, Chandra, and Suzaku. SPEX can fit multiple spectra with different model components simultaneously and handles highly complex models with many free parameters.","topic_id":"31998","bibcode":"2013ascl.soft08014M","views":"42","site_list":["http:\/\/www.sron.nl\/spex"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1996uxsa.coll..411K","http:\/\/adsabs.harvard.edu\/abs\/1997A%26A...320..147M"]},
		{"ascl_id":"1308.015","title":"Ceph_code: Cepheid light-curves fitting","credit":"Yoachim, Peter","abstract":"Ceph_code fits multi-band Cepheid light-curves using templates derived from OGLE observations.  The templates include short period stars (&lt;10 day) and overtone stars.","topic_id":"32000","bibcode":"2013ascl.soft08015Y","views":"48","site_list":["http:\/\/www.astro.washington.edu\/users\/yoachim\/Ceph_code.tar.gz"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009AJ....137.4697Y","http:\/\/adsabs.harvard.edu\/abs\/2009AJ....137.4707M"]},
		{"ascl_id":"1308.016","title":"JHelioviewer: Visualization software for solar physics data","credit":"Mueller, Daniel; Dimitoglou, George; Caplins, Benjamin; Garcia Ortiz, Juan Pablo; Wamsler, Benjamin; Hughitt, Keith; Alexanderian, Alen; Ireland, Jack; Amadigwe, Desmond; Fleck, Bernhard","abstract":"JHelioview is open source visualization software for solar physics data. The JHelioviewer client application enables users to browse petabyte-scale image archives; the JHelioviewer server integrates a JPIP server, metadata catalog, and an event server. JHelioview uses the JPEG 2000 image compression standard, which provides efficient access to petabyte-scale image archives; JHelioviewer also allows users to locate and manipulate specific data sets.","topic_id":"32017","bibcode":"2013ascl.soft08016Y","views":"54","site_list":["https:\/\/launchpad.net\/jhelioviewer"],"ref_list":["http:\/\/dx.doi.org\/10.1109\/MCSE.2009.142"]},
		{"ascl_id":"1308.017","title":"ChiantiPy: Python package for the CHIANTI atomic database","credit":"Dere, Ken","abstract":"ChiantiPy is an object-orient Python package for calculating astrophysical spectra using the CHIANTI atomic database for astrophysical spectroscopy. It provides access to the database and the ability to calculate various physical quantities for the interpretation of astrophysical spectra.","topic_id":"30692","bibcode":"2013ascl.soft08017D","views":"50","site_list":["http:\/\/sourceforge.net\/projects\/chiantipy\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012ApJ...744...99L","http:\/\/adsabs.harvard.edu\/abs\/2013ApJ...771...36V"]},
		{"ascl_id":"1308.018","title":"MoogStokes: Zeeman polarized radiative transfer","credit":"Dean, Casey","abstract":"MOOGStokes is a version of the <a href=\"http:\/\/ascl.net\/1202.009\">MOOG<\/a> one-dimensional local thermodynamic equilibrium radiative transfer code that incorporates a Stokes vector treatment of polarized radiation through a magnetic medium. It consists of three complementary programs that together can synthesize the disk-averaged emergent spectrum of a star with a magnetic field. The MOOGStokes package synthesizes emergent spectra of stars with magnetic fields in a familiar computational framework and produces disk-averaged spectra for all Stokes vectors ( I, Q, U, V ), normalized by the continuum.","topic_id":"32026","bibcode":"2013ascl.soft08018D","views":"42","site_list":["http:\/\/www.mpia-hd.mpg.de\/~deen\/Software\/MoogStokes\/MoogStokes.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013AJ....146...51D"]},
		{"ascl_id":"1309.001","title":"AstroImageJ: ImageJ for Astronomy","credit":"Collins, Karen; Kielkopf, John","abstract":"AstroImageJ is generic <a href=\"http:\/\/ascl.net\/1206.013\">ImageJ<\/a> (ascl:1206.013) with customizations to the base code and a packaged set of astronomy specific plugins. It reads and writes FITS images with standard headers, displays astronomical coordinates for images with WCS, supports photometry for developing color-magnitude data, offers flat field, scaled dark, and non-linearity processing, and includes tools for precision photometry that can be used during real-time data acquisition.","topic_id":"32068","bibcode":"2013ascl.soft09001C","views":"66","site_list":["http:\/\/www.astro.louisville.edu\/software\/astroimagej\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012APS..TSF.E9028R"]},
		{"ascl_id":"1309.002","title":"VAPHOT: Precision differential aperture photometry package","credit":"Deeg, Hans J.; Doyle, Laurance R.","abstract":"VAPHOT is an aperture photometry package developed to perform reliable and precise time\u2212series photometry of uncrowded fields. This package works within the <a href=\"http:\/\/ascl.net\/9911.002\">IRAF<\/a> (ascl:9911.002) environment and is built upon the standard aperture photometry task phot from IRAF. VAPHOT was designed to perform precise aperture photometry with relatively few input parameters using optimum sized apertures.","topic_id":"32070","bibcode":"2013ascl.soft09002D","views":"52","site_list":["ftp:\/\/tep:fu9dufa5@ftp.iac.es\/tepstuff\/tep_dist\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001phot.work...85D"]},
		{"ascl_id":"1309.003","title":"LOSP: Li\u00e8ge Orbital Solution Package","credit":"Sana, Hugues","abstract":"LOSP is a FORTRAN77 numerical package that computes the orbital parameters of spectroscopic binaries. The package deals with SB1 and SB2 systems and is able to adjust either circular or eccentric orbits through a weighted fit.","topic_id":"32117","bibcode":"2013ascl.soft09003S","views":"36","site_list":["http:\/\/staff.science.uva.nl\/~hsana\/losp.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009MNRAS.400.1479S"]},
		{"ascl_id":"1309.004","title":"Spherical: Geometry operations and searches on spherical surfaces","credit":"Budav\u00e1ri, Tam\u00e1s; Dobos, L\u00e1szl\u00f3; Fekete, Gy\u00f6rgy; Gray, Jim; Szalay, Alex","abstract":"The Spherical Library provides an efficient and accurate mathematical representation of shapes on the celestial sphere, such as sky coverage and footprints. Shapes of arbitrary complexity and size can be dynamically created from simple building blocks, whose exact area is also analytically computed. This methodology is also perfectly suited for censoring problematic parts of datasets, e.g., bad seeing, satelite trails or diffraction spikes of bright stars.","topic_id":"32118","bibcode":"2013ascl.soft09004B","views":"47","site_list":["http:\/\/voservices.net\/spherical\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010PASP..122.1375B"]},
		{"ascl_id":"1309.005","title":"SATMC: SED Analysis Through Monte Carlo","credit":"Johnson, Seth","abstract":"SATMC is a general purpose, MCMC-based SED fitting code written for IDL and Python. Following Bayesian statistics and Monte Carlo Markov Chain algorithms, SATMC derives the best fit parameter values and returns the sampling of parameter space used to construct confidence intervals and parameter-parameter confidence contours. The fitting may cover any range of wavelengths. The code is designed to incorporate any models (and potential priors) of the user's choice. The user's guide list all the relevant details for including observations, models and usage under both IDL and Python.","topic_id":"32152","bibcode":"2013ascl.soft09005J","views":"58","site_list":["http:\/\/asterisk.apod.com\/download\/file.php?id=10575"],"ref_list":["http:\/\/www.astro.umass.edu\/~spjohnson\/satmc.html"]},
		{"ascl_id":"1309.006","title":"VOPlot: Toolkit for Scientific Discovery using VOTables","credit":"Kale, Sonali; Vijayaraman, T. M.; Kembhavi, Ajit; Krishnan, P. R.; Navelkar, Amey, Hedge, Hrishikesh; Kulkarni, Pallavi; Balaji, K. D.","abstract":"VOPlot is a tool for visualizing astronomical data. It was developed in Java and acts on data available in VOTABLE, ASCII and FITS formats. VOPlot is available as a stand alone version, which is to be installed on the user's machine, or as a web-based version fully integrated with the VizieR database.","topic_id":"32178","bibcode":"2013ascl.soft09006K","views":"64","site_list":["http:\/\/voi.iucaa.ernet.in\/~voi\/voplot.htm"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004ASPC..314..350K","http:\/\/adsabs.harvard.edu\/abs\/2006A%26A...447...89T"]},
		{"ascl_id":"1309.007","title":"VOMegaPlot: Plotting millions of points","credit":"Urunkar, Nilesh; Kembhavi, Ajit K.; Navelkar, Ameya; Pandya, Jagruti; Moosani, Vivekananda; Nair, Prameela; Shaikh, Mohasin","abstract":"VOMegaPlot, a Java based tool, has been developed for visualizing astronomical data that is available in VOTable format. It has been specifically optimized for handling large number of points (in the range of millions). It has the same look and feel as <a href=\"http:\/\/ascl.net\/1309.006\">VOPlot<\/a> (ascl:1309.006) and both these tools have certain common functionality.","topic_id":"32179","bibcode":"2013ascl.soft09007U","views":"50","site_list":["http:\/\/voi.iucaa.ernet.in\/~voi\/vomegaplot.htm"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009ASPC..407..420D","http:\/\/adsabs.harvard.edu\/abs\/2010IJMPD..19.1049B"]},
		{"ascl_id":"1309.008","title":"VOStat: Statistical analysis of astronomical data","credit":"VOStat Development Group","abstract":"VOStat allows astronomers to use both simple and sophisticated statistical routines on large datasets. This tool uses the large public-domain statistical computing package R. Datasets can be uploaded in either ASCII or VOTABLE (preferred) format. The statistical computations are performed by the VOStat and results are returned to the user.","topic_id":"32181","bibcode":"2013ascl.soft09008V","views":"42","site_list":["http:\/\/voi.iucaa.ernet.in\/~voi\/VOStat.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009ASPC..407..420D","http:\/\/adsabs.harvard.edu\/abs\/2005ASPC..347..604M"]},
		{"ascl_id":"1310.001","title":"ORAC-DR: Astronomy data reduction pipeline","credit":"Jenness, Tim; Economou, Frossie; Cavanagh, Brad; Currie, Malcolm J.; Gibb, Andy","abstract":"ORAC-DR is a generic data reduction pipeline infrastructure; it includes specific data processing recipes for a number of instruments. It is used at the James Clerk Maxwell Telescope, United Kingdom Infrared Telescope, AAT, and LCOGT. This pipeline runs at the JCMT Science Archive hosted by CADC to generate near-publication quality data products; the code has been in use since 1998.","topic_id":"32241","bibcode":"2013ascl.soft10001J","views":"69","site_list":["https:\/\/github.com\/Starlink\/ORAC-DR"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008AN....329..295C"]},
		{"ascl_id":"1310.002","title":"PyMSES: Python modules for RAMSES","credit":"Guillet, Thomas; Chapon, Damien; Labadens, Marc","abstract":"PyMSES provides a python solution for getting data out of <a href=\"http:\/\/ascl.net\/1011.007\">RAMSES<\/a> (ascl:1011.007) astrophysical fluid dynamics simulations. It permits transparent manipulation of large simulations and interfaces with common Python libraries and existing code, and can serve as a post-processing toolbox for data analysis. It also does three-dimensional volume rendering with a specific algorithm optimized to work on RAMSES distributed data (Guillet et al. 2011 and Jones et a. 2011).","topic_id":"32573","bibcode":"2013ascl.soft10002G","views":"38","site_list":["http:\/\/irfu.cea.fr\/Projets\/PYMSES\/intro.html#documentation"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012ASPC..461..837L"]},
		{"ascl_id":"1310.003","title":"AIDA: Adaptive Image Deconvolution Algorithm","credit":"Hom, Erik; Haase, Sebastian; Marchis, Franck","abstract":"AIDA is an implementation and extension of the MISTRAL myopic deconvolution method developed by Mugnier et al. (2004) (see J. Opt. Soc. Am. A 21:1841-1854). The MISTRAL approach has been shown to yield object reconstructions with excellent edge preservation and photometric precision when used to process astronomical images. AIDA improves upon the original MISTRAL implementation. AIDA, written in Python, can deconvolve multiple frame data and three-dimensional image stacks encountered in adaptive optics and light microscopic imaging.","topic_id":"32356","bibcode":"2013ascl.soft10003H","views":"74","site_list":["https:\/\/code.google.com\/p\/aida-deconvolution\/"],"ref_list":["https:\/\/github.com\/erikhom\/aida","http:\/\/adsabs.harvard.edu\/abs\/2007JOSAA..24.1580H"]},
		{"ascl_id":"1310.004","title":"AIRY: Astronomical Image Restoration in interferometrY","credit":"Bertero, Mario; Boccacci, Patrizia; La Camera, Andrea; Carbillet, Marel; Fini, Luca; Anconelli, Barbara; Desider\u00e0, Gabriele; Salvati, Marco","abstract":"AIRY simulates optical and near-infrared interferometric observations; it can also perform subsequent image restoration or deconvolution. It is based on the <a href=\"http:\/\/ascl.net\/1106.017\">CAOS<\/a> (ascl:1106.017) Problem Solving Environment. Written in IDL, it consists of a set of specific modules, each handling a particular task.","topic_id":"32357","bibcode":"2013ascl.soft10004B","views":"78","site_list":["http:\/\/www.airyproject.eu\/docs\/AIRYpackage.aspx"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002A%26A...387..733C"]},
		{"ascl_id":"1310.005","title":"ASPRO 2: Astronomical Software to PRepare Observations","credit":"Bourg\u00e8s, Laurent; Mella, Guillaume; Lafrasse, Sylvain; Duvert, Gilles","abstract":"ASPRO 2 (Astronomical Software to PRepare Observations) is an observation preparation tool for interferometric observations with the VLTI or other interferometers such as CHARA and SUSI. It is a Java standalone program that provides a dynamic graphical interface to simulate the projected baseline evolution during observations (super-synthesis) and derive visibilities for targets (i.e., single star, binaries, user defined FITS image). It offers other useful functions such as the ability to load and save your observation settings and generate Observing Blocks.","topic_id":"32248","bibcode":"2013ascl.soft10005B","views":"67","site_list":["http:\/\/www.jmmc.fr\/aspro_page.htm",""],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ASPC..442..489D"]},
		{"ascl_id":"1310.006","title":"AIPSLite: ParselTongue extension for distributed AIPS processing","credit":"Bourke, Stephen; van Langevelde, Huib Jan; Torstensson, Karl; Golden, Aaron","abstract":"AIPSLite is an extension for <a href=\"http:\/\/www.ascl.net\/1208.020\">ParselTongue<\/a> (ascl:1208.020) that allows machines without an <a href=\"http:\/\/www.ascl.net\/9911.003\">AIPS<\/a> (ascl:9911.003) distribution to bootstrap themselves with a minimal AIPS environment. This allows deployment of AIPS routines on distributed systems, which is useful when data can be easily be split into smaller chunks and handled independently.","topic_id":"32324","bibcode":"2013ascl.soft10006B","views":"74","site_list":["http:\/\/www-astro.physics.ox.ac.uk\/~hrk\/AIPSLite.py"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013ExA....36...59B"]},
		{"ascl_id":"1310.007","title":"SMURF: SubMillimeter User Reduction Facility","credit":"Jenness, Tim; Chapin, Edward L.; Berry, David S.; Gibb, Andy G.; Tilanus, Remo P. J.; Balfour, Jennifer; Tilanus, Vincent; Currie, Malcolm J.","abstract":"SMURF reduces submillimeter single-dish continuum and heterodyne data. It is mainly targeted at data produced by the James Clerk Maxwell Telescope but data from other telescopes have been reduced using the package. SMURF is released as part of the bundle that comprises <a href=\"http:\/\/www.ascl.net\/1110.012\">Starlink<\/a> (ascl:1110.012) and most of the packages that use it. The two key commands are MAKEMAP for the creation of maps from sub millimeter continuum data and MAKECUBE for the creation of data cubes from heterodyne array instruments. The software can also convert data from legacy JCMT file formats to the modern form to allow it to be processed by MAKECUBE. SMURF is a core component of the <a href=\"http:\/\/www.ascl.net\/1310.001\">ORAC-DR<\/a> (ascl:1310.001) data reduction pipeline for JCMT.","topic_id":"32589","bibcode":"2013ascl.soft10007J","views":"42","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013MNRAS.430.2545C","http:\/\/adsabs.harvard.edu\/abs\/2011MNRAS.417..216S"]},
		{"ascl_id":"1310.008","title":"SPECX: Spectral Line Data Reduction Package","credit":"Padman, Rachael; Meyerdierks, Horst; Tilanus, Remo P. J.; Jenness, Tim","abstract":"SPECX is a general purpose line data reduction system. It can read and write FITS data cubes but has specialist support for the GSD format data from the James Clerk Maxwell Telescope. It includes commands to store and retrieve intermediate spectra in storage registers and perform the fitting and removal of polynomial, harmonic and Gaussian baselines. \n\nSPECX can filter and edit spectra and list and display spectra on a graphics terminal. It is able to perform Fourier transform and power spectrum calculations, process up to eight spectra (quadrants) simultaneously with either the same or different center, and assemble a number of reduced individual spectra into a map file and contour or greyscale any plane or planes of the resulting cube.\n\nTwo versions of SPECX are distributed. Version 6.x is the VMS and Unix version and is distributed as part of the <a href=\"http:\/\/ascl.net\/1110.012\">Starlink<\/a> software collection. Version 7.x is a complete rewrite of SPECX distributed for Windows.","topic_id":"32590","bibcode":"2013ascl.soft10008P","views":"55","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/www.mrao.cam.ac.uk\/~rachael\/specx"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1989MNRAS.237P...1M"]},
		{"ascl_id":"1311.001","title":"SciDB: Open Source DMAS for Scientific Research","credit":"SciDB Team","abstract":"SciDB is a DMAS (Data Management and Analytics Software System) optimized for data management of big data and for big analytics. SciDB is organized around multidimensional array storage, a generalization of relational tables, and is designed to be scalable up to petabytes and beyond. Complex analytics are simplified with SciDB because arrays and vectors are first-class objects with built-in optimized operations. Spatial operators and time-series analysis are easy to express. Interfaces to common scientific tools like R as well as programming languages like C++ and Python are provided.","topic_id":"32384","bibcode":"2013ascl.soft11001S","views":"40","site_list":["http:\/\/scidb.org\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012JPhCS.368a2021M"]},
		{"ascl_id":"1311.002","title":"PyCOOL: Cosmological Object-Oriented Lattice code","credit":"Sainio, Jani","abstract":"PyCOOL is a Python + CUDA program that solves the evolution of interacting scalar fields in an expanding universe. PyCOOL uses modern GPUs to solve this evolution and to make the computation much faster. The code includes numerous post-processing functions that provide useful information about the cosmological model, including various spectra and statistics of the fields.","topic_id":"32385","bibcode":"2013ascl.soft11002S","views":"33","site_list":["https:\/\/github.com\/jtksai\/PyCOOL"],"ref_list":["http:\/\/arxiv.org\/abs\/1201.5029"]},
		{"ascl_id":"1311.003","title":"AstroAsciiData: ASCII table Python module","credit":"K\u00fcmmel, Martin; Haase, Jonas","abstract":"ASCII tables continue to be one of the most popular and widely used data exchange formats in astronomy. AstroAsciiData, written in Python, imports all reasonably well-formed ASCII tables. It retains formatting of data values, allows column-first access, supports <a href=\"http:\/\/ascl.net\/1010.064\">SExtractor<\/a> style headings, performs column sorting, and exports data to other formats, including FITS, Numpy\/Numarray, and LaTeX table format. It also offers interchangeable comment character, column delimiter and null value.","topic_id":"32386","bibcode":"2013ascl.soft11003K","views":"72","site_list":["http:\/\/www.stecf.org\/software\/PYTHONtools\/astroasciidata\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007ASPC..376..547H"]},
		{"ascl_id":"1311.004","title":"PlanetPack: Radial-velocity time-series analysis tool","credit":"Baluev, Roman V.","abstract":"PlanetPack facilitates and standardizes the advanced analysis of radial velocity (RV) data for the goal of exoplanets detection, characterization, and basic dynamical N-body simulations. PlanetPack is a command-line interpreter that can run either in an interactive mode or in a batch mode of automatic script interpretation.","topic_id":"32499","bibcode":"2013ascl.soft11004B","views":"39","site_list":["http:\/\/sourceforge.net\/projects\/planetpack\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26C.....2...18B"]},
		{"ascl_id":"1311.005","title":"Spheroid: Electromagnetic Scattering by Spheroids","credit":"Martin, P. G.","abstract":"Spheroid determines the size distribution of polarizing interstellar dust grains based on electromagnetic scattering by spheroidal particles. It contains subroutines to treat the case of complex refractive indices, and also includes checks for some limiting cases.","topic_id":"32442","bibcode":"2013ascl.soft11005M","views":"41","site_list":["http:\/\/www.cita.utoronto.ca\/~pgmartin\/spheroid"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1995ApJ...444..293K","http:\/\/adsabs.harvard.edu\/abs\/1979ApJ...228..450R"]},
		{"ascl_id":"1311.006","title":"CIAO: Chandra Interactive Analysis of Observations","credit":"CIAO Development Team","abstract":"CIAO is a data analysis system written for the needs of users of the Chandra X-ray Observatory. Because Chandra data is 4-dimensional (2 spatial, time, energy) and each dimension has many independent elements, CIAO was built to handle N-dimensional data without concern about which particular axes were being analyzed. Apart from a few Chandra instrument tools, CIAO is mission independent. CIAO tools read and write several formats, including FITS images and tables (which includes event files) and IRAF imh files. CIAO is a powerful system for the analysis of many types of data.","topic_id":"32498","bibcode":"2013ascl.soft11006C","views":"50","site_list":["http:\/\/cxc.harvard.edu\/ciao\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006SPIE.6270E..60F"]},
		{"ascl_id":"1311.007","title":"CUPID: Clump Identification and Analysis Package","credit":"Berry, D. S.; Reinhold, K.; Jenness, T.; Economou, F.","abstract":"The CUPID package allows the identification and analysis of clumps of emission within 1, 2 or 3 dimensional data arrays. Whilst targeted primarily at sub-mm cubes, it can be used on any regularly gridded 1, 2 or 3D data. A variety of clump finding algorithms are implemented within CUPID, including the established <a href=\"http:\/\/ascl.net\/1107.014\">ClumpFind<\/a> (ascl:1107.014) and GaussClumps algorithms. In addition, two new algorithms called FellWalker and Reinhold are also provided. CUPID allows easy inter-comparison between the results of different algorithms; the catalogues produced by each algorithm contains a standard set of columns containing clump peak position, clump centroid position, the integrated data value within the clump, clump volume, and the dimensions of the clump. In addition, pixel masks are produced identifying which input pixels contribute to each clump. CUPID is distributed as part of the <a href=\"http:\/\/ascl.net\/1110.012\">Starlink<\/a> (ascl:1110.012) software collection.","topic_id":"32526","bibcode":"2013ascl.soft11007B","views":"210","site_list":["http:\/\/starlink.jach.hawaii.edu\/starlink\/CUPID","http:\/\/starlink.jach.hawaii.edu\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007ASPC..376..425B","http:\/\/adsabs.harvard.edu\/abs\/2011MNRAS.410.1409W"]},
		{"ascl_id":"1311.008","title":"CUPID: Customizable User Pipeline for IRS Data","credit":"Spitzer Science User Support Team; Spitzer Science Instrument Team; IRSA Science User Support Team","abstract":"Written in c, the Customizable User Pipeline for IRS Data (CUPID) allows users to run the Spitzer IRS Pipelines to re-create Basic Calibrated Data and extract calibrated spectra from the archived raw files. CUPID provides full access to all the parameters of the BCD, COADD, BKSUB, BKSUBX, and COADDX pipelines, as well as the opportunity for users to provide their own calibration files (e.g., flats or darks). CUPID is available for Mac, Linux, and Solaris operating systems.","topic_id":"32527","bibcode":"2013ascl.soft11008S","views":"52","site_list":["http:\/\/irsa.ipac.caltech.edu\/data\/SPITZER\/docs\/dataanalysistools\/tools\/cupid\/"],"ref_list":false},
		{"ascl_id":"1311.009","title":"CosmoTherm: Thermalization code","credit":"Chluba, Jens","abstract":"CosmoTherm allows precise computation of CMB spectral distortions caused by energy release in the early Universe. Different energy-release scenarios (e.g., decaying or annihilating particles) are implemented using the Green's function of the cosmological thermalization problem, allowing fast computation of the distortion signal. The full thermalization problem can be solved on a case-by-case basis for a wide range of energy-release scenarios using the full PDE solver of CosmoTherm. A simple Monte-Carlo toolkit is included for parameter estimation and forecasts using the Green's function method.","topic_id":"32525","bibcode":"2013ascl.soft11009C","views":"45","site_list":["http:\/\/www.chluba.de\/CosmoTherm"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.419.1294C"]},
		{"ascl_id":"1311.010","title":"ARPACK: Solving large scale eigenvalue problems","credit":"Lehoucq, Rich; Maschhoff, Kristi; Sorensen, Danny; Yang, Chao","abstract":"ARPACK is a collection of Fortran77 subroutines designed to solve large scale eigenvalue problems. The package is designed to compute a few eigenvalues and corresponding eigenvectors of a general n by n matrix A. It is most appropriate for large sparse or structured matrices A where structured means that a matrix-vector product w <- Av requires order n rather than the usual order n2 floating point operations. This software is based upon an algorithmic variant of the Arnoldi process called the Implicitly Restarted Arnoldi Method (IRAM). When the matrix A is symmetric it reduces to a variant of the Lanczos process called the Implicitly Restarted Lanczos Method (IRLM). These variants may be viewed as a synthesis of the Arnoldi\/Lanczos process with the Implicitly Shifted QR technique that is suitable for large scale problems. For many standard problems, a matrix factorization is not required; only the action of the matrix on a vector is needed. ARPACK is capable of solving large scale symmetric, nonsymmetric, and generalized eigenproblems from significant application areas.","topic_id":"32682","bibcode":"2013ascl.soft11010L","views":"142","site_list":["http:\/\/www.caam.rice.edu\/software\/ARPACK\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000APS..MARM19003T"]},
		{"ascl_id":"1311.011","title":"MUSIC: MUlti-Scale Initial Conditions","credit":"Hahn, Oliver; Abel, Tom","abstract":"MUSIC generates multi-scale initial conditions with multiple levels of refinements for cosmological \u2018zoom-in\u2019 simulations. The code uses an adaptive convolution of Gaussian white noise with a real-space transfer function kernel together with an adaptive multi-grid Poisson solver to generate displacements and velocities following first- (1LPT) or second-order Lagrangian perturbation theory (2LPT). MUSIC achieves rms relative errors of the order of 10\u22124 for displacements and velocities in the refinement region and thus improves in terms of errors by about two orders of magnitude over previous approaches. In addition, errors are localized at coarse-fine boundaries and do not suffer from Fourier space-induced interference ringing.","topic_id":"32683","bibcode":"2013ascl.soft11011H","views":"41","site_list":["http:\/\/www.phys.ethz.ch\/~hahn\/MUSIC\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011MNRAS.415.2101H"]},
		{"ascl_id":"1311.012","title":"ETC: Exposure Time Calculator","credit":"Hirata, Christopher M.; Gehrels, Neil; Kneib, Jean-Paul; Kruk, Jeffrey; Rhodes, Jason; Wang, Yun; Zoubian, Julien","abstract":"Written for the Wide-Field Infrared Survey Telescope (WFIRST) high-latitude survey, the exposure time calculator (ETC) works in both imaging and spectroscopic modes. In addition to the standard ETC functions (e.g. background and S\/N determination), the calculator integrates over the galaxy population and forecasts the density and redshift distribution of galaxy shapes usable for weak lensing (in imaging mode) and the detected emission lines (in spectroscopic mode). The program may be useful outside of WFIRST but no warranties are made regarding its suitability for general purposes. The software is available for download; IPAC maintains a <a href=\"http:\/\/wfirst-web.ipac.caltech.edu\/wfDepc\/wfDepc.jsp\">web interface<\/a> for those who wish to run a small number of cases without having to download the package.","topic_id":"32684","bibcode":"2013ascl.soft11012H","views":"37","site_list":["http:\/\/www.tapir.caltech.edu\/~chirata\/web\/software\/space-etc\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1204.5151","http:\/\/adsabs.harvard.edu\/abs\/2013ApJ...767..124N"]},
		{"ascl_id":"1312.001","title":"SERPent: Scripted E-merlin Rfi-mitigation PipelinE for iNTerferometry","credit":"Peck, Luke W.; Fenech, Danielle M.","abstract":"SERPent is an automated reduction and RFI-mitigation procedure that uses the SumThreshold methodology. It was originally developed for the LOFAR pipeline. SERPent is written in Parseltongue, enabling interaction with the Astronomical Image Processing Software (<a href=\"http:\/\/ascl.net\/9911.003\">AIPS<\/a>) program. Moreover, SERPent is a simple \"out of the box\" Python script, which is easy to set up and is free of compilers.","topic_id":"32555","bibcode":"2013ascl.soft12001P","views":"175","site_list":["http:\/\/www.ucl.ac.uk\/star\/research\/stars_galaxies\/cobras\/technical\/rfi\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26C.....2...54P"]},
		{"ascl_id":"1312.002","title":"WND-CHARM: Multi-purpose image classifier","credit":"Shamir, Lior; Orlov, Nikita; Eckley, D. Mark; Macura, Tomasz; Johnston, Josiah; Goldberg, Ilya","abstract":"WND-CHARM quantitatively analyzes morphologies of galaxy mergers and associate galaxies by their morphology. It computes a large set (up to ~2700) of image features for each image based on the WND-CHARM algorithm. It can then split the images into training and test sets and classify them. The software extracts the image content descriptor from raw images, image transforms, and compound image transforms. The most informative features are then selected, and the feature vector of each image is used for classification and similarity measurement using Fisher discriminant scores and a variation of Weighted Nearest Neighbor analysis. WND-CHARM's results comparable favorably to the performance of task-specific algorithms developed for tested datasets. The simple user interface allows researchers who are not knowledgeable in computer vision methods and have no background in computer programming to apply image analysis to their data.","topic_id":"32556","bibcode":"2013ascl.soft12002S","views":"50","site_list":["http:\/\/vfacstaff.ltu.edu\/lshamir\/downloads\/ImageClassifier\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26C.....2...67S"]},
		{"ascl_id":"1312.003","title":"IMCOM: IMage COMbination","credit":"Rowe, Barnaby","abstract":"IMCOM allows for careful treatment of aliasing in undersampled imaging data and can be used to test the feasibility of multi-exposure observing strategies for space-based survey missions. IMCOM can also been used to explore focal plane undersampling for an optical space mission such as Euclid.","topic_id":"32629","bibcode":"2013ascl.soft12003R","views":"36","site_list":["http:\/\/barnabyrowe.wikispaces.com\/IMCOM+public+page"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ApJ...741...46R"]},
		{"ascl_id":"1312.004","title":"BIE: Bayesian Inference Engine","credit":"Weinberg, Martin D.","abstract":"The Bayesian Inference Engine (BIE) is an object-oriented library of tools written in C++ designed explicitly to enable Bayesian update and model comparison for astronomical problems. To facilitate \"what if\" exploration, BIE provides a command line interface (written with Bison and Flex) to run input scripts. The output of the code is a simulation of the Bayesian posterior distribution from which summary statistics e.g. by taking moments, or determine confidence intervals and so forth, can be determined. All of these quantities are fundamentally integrals and the Markov Chain approach produces variates $\theta$ distributed according to $P(\theta|D)$ so moments are trivially obtained by summing of the ensemble of variates.","topic_id":"32630","bibcode":"2013ascl.soft12004W","views":"74","site_list":["http:\/\/www.astro.umass.edu\/BIE\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013MNRAS.434.1736W"]},
		{"ascl_id":"1312.005","title":"XAssist: Automatic analysis of X-ray astrophysics data","credit":"XAssist Development Team","abstract":"XAssist provides automation of X-ray astrophysics, specifically data reprocessing, source detection, and preliminary spatial, temporal and spectral analysis for each source with sufficient counts, with an emphasis on galaxies. It has been used for data from Chandra, ROSAT, XMM-Newton, and other various projects.","topic_id":"32584","bibcode":"2013ascl.soft12005X","views":"49","site_list":["http:\/\/www.xassist.org"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003ASPC..295..465P"]},
		{"ascl_id":"1312.006","title":"LTL: The Little Template Library","credit":"Drory, Niv; G\u00f6ssl, Claus A.; Snigula, Jan","abstract":"LTL provides dynamic arrays of up to 7-dimensions, subarrays and slicing, support for fixed-size vectors and matrices including basic linear algebra operations, expression templates-based evaluation, and I\/O facilities for ascii and FITS format files. Utility classes for command-line processing and configuration-file processing are provided as well.","topic_id":"32677","bibcode":"2013ascl.soft12006D","views":"36","site_list":["http:\/\/www.as.utexas.edu\/~drory\/ltl\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004ASPC..314..456G"]},
		{"ascl_id":"1312.007","title":"SkyNet: Neural network training tool for machine learning in astronomy","credit":"Graff, Philip; Feroz, Farhan","abstract":"SkyNet is an efficient and robust neural network training code for machine learning. It is able to train large and deep feed-forward neural networks, including autoencoders, for use in a wide range of supervised and unsupervised learning applications, such as regression, classification, density estimation, clustering and dimensionality reduction. SkyNet is implemented in C\/C++ and fully parallelized using MPI.","topic_id":"32585","bibcode":"2013ascl.soft12007G","views":"123","site_list":["http:\/\/ccpforge.cse.rl.ac.uk\/gf\/project\/skynet\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1309.0790"]},
		{"ascl_id":"1312.008","title":"BAMBI: Blind Accelerated Multimodal Bayesian Inference","credit":"Graff, Philip; Feroz, Farhan","abstract":"BAMBI (Blind Accelerated Multimodal Bayesian Inference) is a Bayesian inference engine that combines the benefits of SkyNet with <a href=\"http:\/\/ascl.net\/1109.006\">MultiNest<\/a>. It operated by simultaneously performing Bayesian inference using MultiNest and learning the likelihood function using <a href=\"http:\/\/ascl.net\/1312.007\">SkyNet<\/a>. Once SkyNet has learnt the likelihood to sufficient accuracy, inference finishes almost instantaneously.","topic_id":"32628","bibcode":"2013ascl.soft12008G","views":"72","site_list":["http:\/\/ccpforge.cse.rl.ac.uk\/gf\/project\/skynet\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.421..169G"]},
		{"ascl_id":"1312.009","title":"YODA: Yet another Object Detection Application","credit":"Drory, Niv","abstract":"YODA, implemented in C++, performs object detection, photometry and star-galaxy classification on astronomical images. Developed specifically to cope with the multi-band imaging data common in modern extragalactic imaging surveys, it is modular and therefore easily adaptable to specific needs. YODA works under conditions of inhomogeneous background noise across the detection frame, and performs accurate aperture photometry in image sets not sharing a common coordinate system or pixel scale as is often the case in present-day extragalactic survey work.","topic_id":"32678","bibcode":"2013ascl.soft12009D","views":"51","site_list":["http:\/\/www.as.utexas.edu\/~drory\/yoda\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003A%26A...397..371D"]},
		{"ascl_id":"1312.010","title":"GalaxyCount: Galaxy counts and variance calculator","credit":"Bland-Hawthorn, Joss; Ellis, Simon","abstract":"GalaxyCount calculates the number and standard deviation of galaxies in a magnitude limited observation of a given area. The methods to calculate both the number and standard deviation may be selected from different options. Variances may be computed for circular, elliptical and rectangular window functions.","topic_id":"32679","bibcode":"2013ascl.soft12010B","views":"36","site_list":["http:\/\/www.aao.gov.au\/astro\/GalaxyCount\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007MNRAS.377..815E"]},
		{"ascl_id":"1312.011","title":"A_phot: Photon Asymmetry","credit":"Nurgaliev, Daniyar","abstract":"Photon asymmetry is a novel robust substructure statistic for X-ray cluster observations with only a few thousand counts; it exhibits better stability than power ratios and centroid shifts and has a smaller statistical uncertainty than competing substructure parameters, allowing for low levels of substructure to be measured with confidence. A_phot computes the photon asymmetry (A_phot) parameter for morphological classification of clusters and allows quantifying substructure in samples of distant clusters covering a wide range of observational signal-to-noise ratios. The python scripts are completely automatic and can be used to rapidly classify galaxy cluster morphology for large numbers of clusters without human intervention.","topic_id":"32583","bibcode":"2013ascl.soft12011N","views":"79","site_list":["https:\/\/github.com\/ndaniyar\/aphot"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013ApJ...779..112N"]},
		{"ascl_id":"1312.012","title":"BINGO: BI-spectra and Non-Gaussianity Operator","credit":"Hazra, Dhiraj Kumar; Sriramkumar, L.; Martin, Jerome","abstract":"The BI-spectra and Non-Gaussianity Operator (BINGO) code, written in Fortran, computes the scalar bi-spectrum and the non-Gaussianity parameter fNL in single field inflationary models involving the canonical scalar field. BINGO can calculate all the different contributions to the bi-spectrum and the parameter fNL for an arbitrary triangular configuration of the wavevectors.","topic_id":"32697","bibcode":"2013ascl.soft12012H","views":"81","site_list":["http:\/\/www.physics.iitm.ac.in\/~sriram\/bingo\/bingo.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013JCAP...05..026H"]},
		{"ascl_id":"1312.013","title":"CJAM: First and second velocity moments calculations","credit":"Watkins, Laura L.; den Brok, Mark","abstract":"CJAM calculates first and second velocity moments using the Jeans Anisotropic MGE (JAM) models of Cappellari (2008) and Cappellari (2012). These models have been extended to calculate all three (x, y, z) first moments and all six (xx, yy, zz, xy, xz, yz) second moments. CJAM, written in C, is based on the IDL implementation of the line-of-sight calculations by Michele Cappellari.","topic_id":"32698","bibcode":"2013ascl.soft12013W","views":"62","site_list":["https:\/\/github.com\/lauralwatkins\/cjam"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013MNRAS.436.2598W"]},
		{"ascl_id":"1312.014","title":"SL1M: Synthesis through L1 Minimization","credit":"Hardy, Stephen J.","abstract":"SL1M deconvolves radio synthesis images based on direct inversion of the measured visibilities that can deal with the non-coplanar base line effect and can be applied to telescopes with direction dependent gains. The code is more computationally demanding than some existing methods, but is highly parallelizable and scale well to clusters of CPUs and GPUs. The algorithm is also extremely flexible, allowing the solution of the deconvolution problem on arbitrarily placed pixels.","topic_id":"32699","bibcode":"2013ascl.soft12014H","views":"36","site_list":["https:\/\/github.com\/StephenJHardy\/SL1M"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26A...557A.134H"]},
		{"ascl_id":"1401.001","title":"Kirin: N-body simulation library for GPUs","credit":"Belleman, Robert; B\u00e9dorf, Jeroen; Portegies Zwart, Simon F.","abstract":"The use of graphics processing units offers an attractive alternative to specialized hardware, like GRAPE. The Kirin library mimics the behavior of the GRAPE hardware and uses the GPU to execute the force calculations. It is compatible with the GRAPE6 library; existing code that uses the GRAPE6 library can be recompiled and relinked to use the GPU equivalents of the GRAPE6 functions. All functions in the GRAPE6 library have an equivalent GPU implementation. Kirin can be used for direct N-body simulations as well as for treecodes; it can be run with shared-time steps or with block time-steps and allows non-softened potentials. As Kirin makes use of CUDA,  it works only on NVIDIA GPUs.","topic_id":"32716","bibcode":"2014ascl.soft01001B","views":"47","site_list":["http:\/\/modesta.science.uva.nl\/Software\/src\/kirin.htm"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007NewA...12..641P","http:\/\/adsabs.harvard.edu\/abs\/2008NewA...13..103B"]},
		{"ascl_id":"1401.002","title":"SpacePy: Python-Based Tools for the Space Science Community","credit":"Morley, Steve; Koller, Josef; Welling, Dan; Larsen, Brian; Niehof, Jon","abstract":"SpacePy provides data analysis and visualization tools for the space science community. Written in Python, it builds on the capabilities of the NumPy and MatPlotLib packages to make basic data analysis, modeling and visualization easier. It contains modules for handling many complex time formats, obtaining data from the OMNI database, and accessing the powerful Onera library. It contains a library of commonly used empirical relationships, performs association analysis, coordinate transformations, radiation belt modeling, and CDF reading, and creates publication quality plots.","topic_id":"32717","bibcode":"2014ascl.soft01002M","views":"37","site_list":["http:\/\/spacepy.lanl.gov\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012GMD.....5..277W"]},
		{"ascl_id":"1401.003","title":"PyMidas: Interface from Python to Midas","credit":"Maisala, Sami; Oittinen, Tero","abstract":"PyMidas is an interface between Python and MIDAS, the major ESO legacy general purpose data processing system. PyMidas allows a user to exploit both the rich legacy of MIDAS software and the power of Python scripting in a unified interactive environment. PyMidas also allows the usage of other Python-based astronomical analysis systems such as <a href=\"http:\/\/ascl.net\/1207.011\">PyRAF<\/a>.","topic_id":"32749","bibcode":"2014ascl.soft01003M","views":"37","site_list":["http:\/\/www.eso.org\/sci\/software\/sampo\/pymidas\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ASPC..351..343H","http:\/\/adsabs.harvard.edu\/abs\/2010MNRAS.405.1203M"]},
		{"ascl_id":"1401.004","title":"Reflex: Graphical workflow engine for data reduction","credit":"ESO Reflex development Team","abstract":"Reflex provides an easy and flexible way to reduce VLT\/VLTI science data using the ESO pipelines. It allows graphically specifying the sequence in which the data reduction steps are executed, including conditional stops, loops and conditional branches. It eases inspection of the intermediate and final data products and allows repetition of selected processing steps to optimize the data reduction. The data organization necessary to reduce the data is built into the system and is fully automatic; advanced users can plug their own modules and steps into the data reduction sequence. Reflex supports the development of data reduction workflows based on the ESO Common Pipeline Library. Reflex is based on the concept of a scientific workflow, whereby the data reduction cascade is rendered graphically and data seamlessly flow from one processing step to the next. It is distributed with a number of complete test datasets so users can immediately start experimenting and familiarize themselves with the system.","topic_id":"32750","bibcode":"2014ascl.soft01004E","views":"35","site_list":["http:\/\/www.eso.org\/sci\/software\/reflex\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ASPC..394..638H","http:\/\/adsabs.harvard.edu\/abs\/2011ASPC..442..261B"]},
		{"ascl_id":"1401.005","title":"PyDrizzle: Python version of Drizzle","credit":"Hack, Warren; Blakeslee, John; Meurer, Gerhardt; Hook, Richard","abstract":"PyDrizzle provides a semi-automated interface for computing the parameters necessary for running <a href=\"http:\/\/ascl.net\/1212.011\">Drizzle<\/a>. PyDrizzle performs the task of determining the parameters necessary for aligning images based on the WCS information in the input image headers, as well as any supplemental alignment information provided in shift files, and combines the images onto the same WCS. Though it does not identify cosmic rays, it has the ability to ignore pixels flagged as bad, such as pixels identified by other programs as affected by cosmic rays.","topic_id":"32751","bibcode":"2014ascl.soft01005H","views":"32","site_list":["https:\/\/pypi.python.org\/pypi\/pydrizzle"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002ASPC..281..197H"]},
		{"ascl_id":"1401.006","title":"convolve_image.pro: Common-Resolution Convolution Kernels for Space- and Ground-Based Telescopes","credit":"Aniano, Gonzalo J.","abstract":"The IDL package convolve_image.pro transforms images between different instrumental point spread functions (PSFs). It can load an image file and corresponding kernel and return the convolved image, thus preserving the colors of the astronomical sources. Convolution kernels are available for images from Spitzer (IRAC MIPS), Herschel (PACS SPIRE), GALEX (FUV NUV), WISE (W1 - W4), Optical PSFs (multi- Gaussian and Moffat functions), and Gaussian PSFs; they allow the study of the Spectral Energy Distribution (SED) of extended objects and preserve the characteristic SED in each pixel.","topic_id":"32777","bibcode":"2014ascl.soft01006A","views":"62","site_list":["http:\/\/www.astro.princeton.edu\/~ganiano\/Kernels.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011PASP..123.1218A"]},
		{"ascl_id":"1401.007","title":"abundance: High Redshift Cluster Abundance","credit":"Mortonson, Michael; Hu, Wayne; Huterer, Dragan","abstract":"abundance, written in Fortran, provides driver and fitting routines to compute the predicted number of clusters in a \u039bCDM cosmology that agrees with CMB, SN, BAO, and H0 measurements (up to 2010) at some specified parameter confidence and the mass that would rule out that cosmology at some specified sample confidence. It also computes the expected number of such clusters in the light cone and the Eddington bias factor that must be applied to observed masses.","topic_id":"32780","bibcode":"2014ascl.soft01007M","views":"86","site_list":["http:\/\/background.uchicago.edu\/abundance\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011PhRvD..83b3015M"]},
		{"ascl_id":"1401.008","title":"massconvert: Halo Mass Conversion","credit":"Hu, Wayne; Kravtsov, Andrey","abstract":"massconvert, written in Fortran, provides driver and fitting routines for converting halo mass definitions from one spherical overdensity to another assuming an NFW density profile. In surveys that probe ever lower cluster masses and temperatures, sample variance is generally comparable to or greater than shot noise and thus cannot be neglected in deriving precision cosmological constraints; massconvert offers an accurate fitting formula for the conversion between different definitions of halo mass.","topic_id":"32781","bibcode":"2014ascl.soft01008H","views":"43","site_list":["http:\/\/background.uchicago.edu\/mass_convert\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003ApJ...584..702H"]},
		{"ascl_id":"1401.009","title":"PPF module for CAMB","credit":"Fang, Wenjuan; Hu, Wayne; Lewis, Antony","abstract":"The main <a href=\"http:\/\/ascl.net\/1102.026\">CAMB<\/a> code supports smooth dark energy models with constant equation of state and sound speed of one, or a quintessence model based on a potential. This modified code generalizes it to support a time-dependent equation of state w(a) that is allowed to cross the phantom divide, i.e. w=-1 multiple times by implementing a Parameterized Post-Friedmann(PPF) prescription for the dark energy perturbations.","topic_id":"32782","bibcode":"2014ascl.soft01009F","views":"46","site_list":["http:\/\/background.uchicago.edu\/ppf\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007PhRvD..76j4043H"]},
		{"ascl_id":"1401.010","title":"SunPy: Python for Solar Physicists","credit":"SunPy Development Team","abstract":"SunPy is a community-developed free and open-source software package for solar physics and is an alternative to the <a href=\"http:\/\/ascl.net\/1208.013\">SolarSoft<\/a> data analysis environment. SunPy provides data structures for representing the most common solar data types (images, lightcurves, and spectra) and integration with the Virtual Solar Observatory (VSO) and the Heliophysics Event Knowledgebase (HEK) for data acquisition.","topic_id":"32814","bibcode":"2014ascl.soft01010S","views":"41","site_list":["http:\/\/sunpy.org\/"],"ref_list":["http:\/\/conference.scipy.org\/proceedings\/scipy2013\/mumford.html","http:\/\/adsabs.harvard.edu\/abs\/2012AAS...22020117I"]},
		{"ascl_id":"1402.001","title":"Vissage: ALMA VO Desktop Viewer","credit":"Kawasaki, Wataru","abstract":"Vissage (VISualisation Software for Astronomical Gigantic data cubEs) is a FITS browser primarily targeting FITS data cubes obtained from ALMA. Vissage offers basic functionality for viewing three-dimensional data cubes, integrated intensity map, flipbook, channel map, and P-V diagram. It has several color sets and color scales available, offers panning and zooming, and can connect with the ALMA WebQL system and the JVO Subaru Image Cutout Service.","topic_id":"32859","bibcode":"2014ascl.soft02001K","views":"50","site_list":["http:\/\/jvo.nao.ac.jp\/download\/Vissage\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1211.3790"]},
		{"ascl_id":"1402.002","title":"Glue: Linked data visualizations across multiple files","credit":"Beaumont, Chris; Robitaille, Thomas; Borkin, Michelle","abstract":"Glue, written in Python, links visualizations of scientific datasets across many files, allowing for interactive, linked statistical graphics of multiple files. It supports many file formats including common image formats (jpg, tiff, png), ASCII tables, astronomical image and table formats (FITS, VOT, IPAC), and HDF5. Custom data loaders can also be easily added. Glue is highly scriptable and extendable.","topic_id":"32860","bibcode":"2014ascl.soft02002B","views":"46","site_list":["https:\/\/github.com\/glue-viz\/glue"],"ref_list":["http:\/\/conference.scipy.org\/proceedings\/scipy2013\/beaumont.html"]},
		{"ascl_id":"1402.003","title":"astroplotlib: Astronomical library of plots","credit":"Ubeda, Leonardo; Davis, Matt; Diaz, Rosa; Hammer, Derek; Philippe-Lajoie, Charles; Le Blanc, Tommy; Lim, Pey-Lian; Viana, Alex","abstract":"Astropoltlib is a multi-language astronomical library of plots, a collection of templates useful for creating paper-quality figures. Most of the codes for producing the plots are written in IDL and\/or Python; a very few are written in Mathematica. Any plot can be downloaded and customized to one's own needs.","topic_id":"32861","bibcode":"2014ascl.soft02003U","views":"103","site_list":["http:\/\/astroplotlib.stsci.edu\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013AAS...22124007U"]},
		{"ascl_id":"1402.004","title":"PyVO: Python access to the Virtual Observatory","credit":"Graham, Matthew; Plante, Ray; Tody, Doug; Fitzpatrick, Mike","abstract":"PyVO provides access to remote data and services of the Virtual observatory (VO) using Python. It allows archive searches for data of a particular type or related to a particular topic and query submissions to obtain data to a particular archive to download selected data products. PyVO supports querying the VAO registry; simple data access services (DAL) to access images (SIA), source catalog records (Cone Search), spectra (SSA), and spectral line emission\/absorption data (SLAP); and object name resolution (for converting names of objects in the sky into positions). PyVO requires both <a href=\"http:\/\/ascl.net\/1304.002\">AstroPy<\/a> and NumPy.","topic_id":"32853","bibcode":"2014ascl.soft02004G","views":"45","site_list":["http:\/\/dev.usvao.org\/vao\/wiki\/Products\/PyVO"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014AAS...22325304P"]},
		{"ascl_id":"1402.005","title":"Aladin Lite: Lightweight sky atlas for browsers","credit":"Boch, Thomas","abstract":"Aladin Lite is a lightweight version of the <a href=\"http:\/\/ascl.net\/1112.019\">Aladin<\/a> tool, running in the browser and geared towards simple visualization of a sky region. It allows visualization of image surveys (JPEG multi-resolution HEALPix all-sky surveys) and permits superimposing tabular (VOTable) and footprints (STC-S) data. Aladin Lite is powered by HTML5 canvas technology and is easily embeddable on any web page and can also be controlled through a Javacript API.","topic_id":"32864","bibcode":"2014ascl.soft02005B","views":"93","site_list":["http:\/\/aladin.u-strasbg.fr\/AladinLite\/"],"ref_list":false},
		{"ascl_id":"1402.006","title":"Munipack: General astronomical image processing software","credit":"Hroch, Filip","abstract":"Munipack provides easy-to-use tools for all astronomical astrometry and photometry, access to Virtual Observatory as well as FITS files operations and a simple user interface along with a powerful processing engine. Its many features include a FITS images viewer that allows for basic (astronomical) operations with frames, advanced image processor supporting an infinite dynamic range and advanced color management, and astrometric calibration of images. The astrometry module uses robust statistical estimators and algorithms. The photometry module provides the classical method detection of stars and implements the aperture photometry, calibrated on the basis of photon statistics, and allows for the automatic detection and aperture photometry of stars; calibration on absolute fluxes is possible. The software also provides a standard way to correct for all the bias, dark and flat-field frames, and many other features.","topic_id":"32865","bibcode":"2014ascl.soft02006H","views":"40","site_list":["http:\/\/munipack.physics.muni.cz\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008OEJV...95...21C"]},
		{"ascl_id":"1402.007","title":"SPLAT: Spectral Analysis Tool","credit":"Draper, Peter W.","abstract":"SPLAT is a graphical tool for displaying, comparing, modifying and analyzing astronomical spectra stored in NDF, FITS and TEXT files as well as in NDX format. It can read in many spectra at the same time and then display these as line plots. Display windows can show one or several spectra at the same time and can be interactively zoomed and scrolled, centered on specific wavelengths, provide continuous coordinate readout, produce printable hardcopy and be configured in many ways. Analysis facilities include the fitting of a polynomial to selected parts of a spectrum, the fitting of Gaussian, Lorentzian and Voigt profiles to emission and absorption lines and the filtering of spectra using average, median and line-shape window functions as well as wavelet denoising. SPLAT also supports a full range of coordinate systems for spectra, which allows coordinates to be displayed and aligned in many different coordinate systems (wavelength, frequency, energy, velocity) and transformed between these and different standards of rest (topocentric, heliocentric, dynamic and kinematic local standards of rest, etc). SPLAT is distributed as part of the <a href=\"http:\/\/ascl.net\/1110.012\">Starlink<\/a> (ascl:1110.012) software collection.","topic_id":"32866","bibcode":"2014ascl.soft02007D","views":"74","site_list":["http:\/\/star-www.dur.ac.uk\/~pdraper\/splat\/splat.html"],"ref_list":false},
		{"ascl_id":"1402.008","title":"SPLAT-VO: Spectral Analysis Tool for the Virtual Observatory","credit":"Castro-Neves, Margarida; Draper, Peter W.","abstract":"SPLAT-VO is an extension of the <a href=\"http:\/\/ascl.net\/1402.007\">SPLAT<\/a> (Spectral Analysis Tool, ascl:1402.007) graphical tool for displaying, comparing, modifying and analyzing astronomical spectra; it includes facilities that allow it to work as part of the Virtual Observatory (VO). SPLAT-VO comes in two different forms, one for querying and downloading spectra from SSAP servers and one for interoperating with VO tools, such as <a href=\"http:\/\/ascl.net\/1101.010\">TOPCAT<\/a> (ascl:1101.010).","topic_id":"32867","bibcode":"2014ascl.soft02008C","views":"50","site_list":["http:\/\/star-www.dur.ac.uk\/~pdraper\/splat\/splat-vo\/splat-vo.html"],"ref_list":false},
		{"ascl_id":"1402.009","title":"GalSim: Modular galaxy image simulation toolkit","credit":"Rowe, Barney; Jarvis, Mike; Mandelbaum, Rachel","abstract":"GalSim is a fast, modular software package for simulation of astronomical images. Though its primary purpose is for tests of weak lensing analysis methods, it can be used for other purposes. GalSim allows galaxies and PSFs to be represented in a variety of ways, and can apply shear, magnification, dilation, or rotation to a galaxy profile including lensing-based models from a power spectrum or NFW halo profile. It can write images in regular FITS files, FITS data cubes, or multi-extension FITS files. It can also compress the output files using various compressions including gzip, bzip2, and rice. The user interface is in python or via configuration scripts, and the computations are done in C++ for speed.","topic_id":"31914","bibcode":"2014ascl.soft02009R","views":"58","site_list":["https:\/\/github.com\/GalSim-developers\/GalSim"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1308.4982M"]},
		{"ascl_id":"1402.010","title":"CPL: Common Pipeline Library","credit":"ESO CPL Development Team","abstract":"The Common Pipeline Library (CPL) is a set of ISO-C libraries that provide a comprehensive, efficient and robust software toolkit to create automated astronomical data reduction pipelines. Though initially developed as a standardized way to build VLT instrument pipelines, the CPL may be more generally applied to any similar application. The code also provides a variety of general purpose image- and signal-processing functions, making it an excellent framework for the creation of more generic data handling packages. The CPL handles low-level data types (images, tables, matrices, strings, property lists, etc.) and medium-level data access methods (a simple data abstraction layer for FITS files). It also provides table organization and manipulation, keyword\/value handling and management, and support for dynamic loading of recipe modules (using programs such as EsoRex).","topic_id":"32850","bibcode":"2014ascl.soft02010E","views":"52","site_list":["http:\/\/www.eso.org\/sci\/software\/cpl\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004ASPC..314..392B","http:\/\/adsabs.harvard.edu\/abs\/2011A%26A...536A.105V"]},
		{"ascl_id":"1402.011","title":"KROME: Chemistry package for astrophysical simulations","credit":"Grassi, Tommaso; Bovino, Stefano; Prieto, Joaqu\u00edn; Seifried, Daniel; Simoncini, Eugenio; Gianturco, Francesco; Schleicher, Dominik","abstract":"KROME, given a chemical network (in CSV format), automatically generates all the routines needed to solve the kinetics of the system modeled as a system of coupled Ordinary Differential Equations. It provides a large set of physical processes connected to chemistry, including photochemistry, cooling, heating, dust treatment, and reverse kinetics. KROME is flexible and can be used for a wide range of astrophysical simulations. The package contains a network for primordial chemistry, a small metal network appropriate for the modeling of low metallicities environments, a detailed network for the modeling of molecular clouds, and a network for planetary atmospheres as well as a framework for the modelling of the dust grain population.","topic_id":"32890","bibcode":"2014ascl.soft02011G","views":"54","site_list":["http:\/\/kromepackage.org\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1311.1070G","http:\/\/adsabs.harvard.edu\/abs\/2014A%26A...561A..13B"]},
		{"ascl_id":"1402.012","title":"QUICKCV: Cosmic variance calculator","credit":"Newman, Jeffrey A.; Moster, Benjamin P.","abstract":"QUICKCV is an IDL sample variance\/cosmic variance calculator for some geometry.","topic_id":"32901","bibcode":"2014ascl.soft02012N","views":"42","site_list":["http:\/\/www.phyast.pitt.edu\/%7Ejanewman\/quickcv\/quickcv.tar.gz","http:\/\/www.phyast.pitt.edu\/~janewman\/Jeffrey_A._Newmans_home_page\/Welcome.html","http:\/\/www.mpa-garching.mpg.de\/~moster\/download.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002ApJ...564..567N","http:\/\/adsabs.harvard.edu\/abs\/2011ApJ...731..113M"]},
		{"ascl_id":"1402.013","title":"CASSIS: Interactive spectrum analyzer","credit":"Cassis Team At Cesr\/Irap","abstract":"CASSIS (Centre d'Analyse Scientifique de Spectres Infrarouges et Submillimetriques), written in Java, is suited for broad-band spectral surveys to speed up the scientific analysis of high spectral resolution observations. It uses a local spectroscopic database made of the two molecular spectroscopic databases JPL and CDMS, as well as the atomic spectroscopic database NIST. Its tools include a LTE model and the RADEX model connected to the LAMDA molecular collisional database. CASSIS can build a line list fitting the various transitions of a given species and to directly produce rotational diagrams from these lists. CASSIS is fully integrated into <a href=\"http:\/\/ascl.net\/1111.001\">HIPE<\/a>, the Herschel Interactive Processing Environment, as a plug-in.","topic_id":"32902","bibcode":"2014ascl.soft02013C","views":"58","site_list":["http:\/\/cassis.irap.omp.eu\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011IAUS..280P.120C"]},
		{"ascl_id":"1402.014","title":"ARTIST: Adaptable Radiative Transfer Innovations for Submillimeter Telescopes","credit":"J\u00f8rgensen, Jes; Brinch, Christian; Girart, Josep Miquel; Padovani, Marco; Frau, Pau; Schaaf, Reinhold; Kuiper, Rolf; Bertoldi, Frank; Hogerheijde, Michiel; Juhasz, Attila; Vlemmings, Wouter","abstract":"ARTIST is a suite of tools for comprehensive multi-dimensional radiative transfer calculations of dust and line emission, as well as their polarization, to help interpret observations from submillimeter telescopes. The ARTIST package consists of <a href=\"http:\/\/ascl.net\/1107.012\">LIME<\/a>, a radiative transfer code that uses adaptive gridding allowing simulations of sources with arbitrary multi-dimensional (1D, 2D, 3D) and time-dependent structures, thus ensuring rapid convergence; the DustPol and LinePol tools for modeling the polarization of the line and dust emission; and an interface run from Python scripts that manages the interaction between a general model library and LIME, and a graphical interface to simulate images.","topic_id":"32927","bibcode":"2014ascl.soft02014J","views":"83","site_list":["http:\/\/youngstars.nbi.dk\/artist\/Welcome.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011IAUS..270..451P"]},
		{"ascl_id":"1402.015","title":"BF_dist: Busy Function fitting","credit":"Westmeier, Tobias; Jurek, Russell; Obreschkow, Danail; Koribalski, B\u00e4rbel S.; Staveley-Smith, Lister","abstract":"The \"busy function\" accurately describes the characteristic double-horn HI profile of many galaxies. Implemented in a C\/C++ library and Python module called BF_dist, it is a continuous, differentiable function that consists of only two basic functions, the error function, erf(x), and a polynomial, |x|^n, of degree n &gt;= 2. BF_dist offers great flexibility in fitting a wide range of HI profiles from the Gaussian profiles of dwarf galaxies to the broad, asymmetric double-horn profiles of spiral galaxies, and can be used to parametrize observed HI spectra of galaxies and the construction of spectral templates for simulations and matched filtering algorithms accurately and efficiently.","topic_id":"32929","bibcode":"2014ascl.soft02015W","views":"76","site_list":["http:\/\/code.google.com\/p\/busy-function-fitting\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014MNRAS.438.1176W"]},
		{"ascl_id":"1402.016","title":"FAMA: Fast Automatic MOOG Analysis","credit":"Magrini, Laura; Randich, Sofia; Friel, Eileen; Spina, Lorenzo; Jacobson, Heather; Cantat-Gaudin, Tristan; Donati, Paolo; Baglioni, Roberto; Maiorca, Enrico; Bragaglia, Angela; Sordo, Rosanna; Vallenari, Antonella","abstract":"FAMA (Fast Automatic MOOG Analysis), written in Perl, computes the atmospheric parameters and abundances of a large number of stars using measurements of equivalent widths (EWs) automatically and independently of any subjective approach. Based on the widely-used <a href=\"http:\/\/ascl.net\/1202.009\">MOOG<\/a> code, it simultaneously searches for three equilibria, excitation equilibrium, ionization balance, and the relationship between logn(FeI) and the reduced EWs. FAMA also evaluates the statistical errors on individual element abundances and errors due to the uncertainties in the stellar parameters. Convergence criteria are not fixed \"a priori\" but instead are based on the quality of the spectra.","topic_id":"32928","bibcode":"2014ascl.soft02016M","views":"52","site_list":["http:\/\/cdsarc.u-strasbg.fr\/viz-bin\/qcat?J\/A+A\/558\/A38"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26A...558A..38M"]},
		{"ascl_id":"1402.017","title":"UVMULTIFIT: Fitting astronomical radio interferometric data","credit":"Marti-Vidal, I.; Vlemmings, W. H. T.; Muller, S.; Casey, S.","abstract":"UVMULTIFIT, written in Python, is a versatile library for fitting models directly to visibility data. These models can depend on frequency and fitting parameters in an arbitrary algebraic way. The results from the fit to the visibilities of sources with sizes smaller than the diffraction limit of the interferometer are superior to the output obtained from a mere analysis of the deconvolved images. Though UVMULTIFIT is based on the <a href=\"http:\/\/ascl.net\/1107.013\">CASA<\/a> package, it can be easily adapted to other analysis packages that have a Python API.","topic_id":"32934","bibcode":"2014ascl.soft02017M","views":"43","site_list":["http:\/\/nordic-alma.se\/support\/software-tools"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1401.4984M"]},
		{"ascl_id":"1402.018","title":"TARDIS: Temperature And Radiative Diffusion In Supernovae","credit":"Kerzendorf, Wolfgang E.; Sim, Stuart A.","abstract":"TARDIS creates synthetic spectra for supernova ejecta and is sufficiently fast to allow exploration of the complex parameter spaces of models for SN ejecta. TARDIS uses Monte Carlo methods to obtain a self-consistent description of the plasma state and to compute a synthetic spectrum. It is written in Python with a modular design that facilitates the implementation of a range of physical approximations that can be compared to assess both accuracy and computational expediency; this allows users to choose a level of sophistication appropriate for their application.","topic_id":"32935","bibcode":"2014ascl.soft02018K","views":"46","site_list":["https:\/\/github.com\/tardis-sn\/tardis"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1401.5469K"]},
		{"ascl_id":"1402.019","title":"ANAigm: Analytic model for attenuation by the intergalactic medium","credit":"Inoue, Akio K.; Shimizu, Ikkoh; Iwata, Ikuru","abstract":"ANAigm offers an updated version of the Madau model for the attenuation by the intergalactic neutral hydrogen against the radiation from distant objects. This new model is written in Fortran90 and predicts, for some redshifts, more than 0.5--1 mag different attenuation magnitudes through usual broad-band filters relative to the original Madau model.","topic_id":"32938","bibcode":"2014ascl.soft02019I","views":"88","site_list":["http:\/\/www.las.osaka-sandai.ac.jp\/~inoue\/ANAIGM\/ANAIGM.tar.gz"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1402.0677I"]},
		{"ascl_id":"1402.020","title":"XNS: Axisymmetric equilibrium configuration of neutron stars","credit":"Bucciantini, N.; Pili, A. G.; Del Zanna, L.","abstract":"XNS solves for the axisymmetric equilibrium configuration of neutron stars in general relativity. It can model differentially rotating and magnetic fields that are either purely toroidal, purely poloidal or in the mixed twisted torus configuration. Einsten's equations are solved using the XCFC approximation for the metric in spherical coordinates.","topic_id":"32939","bibcode":"2014ascl.soft02020B","views":"58","site_list":["http:\/\/www.arcetri.astro.it\/science\/ahead\/XNS\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1401.3101B"]},
		{"ascl_id":"1402.021","title":"PyGFit: Python Galaxy Fitter","credit":"Mancone, Conor L.; Gonzalez, Anthony H.; Moustakas, Leonidas A.; Price, Andrew","abstract":"PyGFit measures PSF-matched photometry from images with disparate pixel scales and PSF sizes; its primary purpose is to extract robust spectral energy distributions (SEDs) from crowded images. It fits blended sources in crowded, low resolution images with models generated from a higher resolution image, thus minimizing the impact of crowding and also yielding consistently measured fluxes in different filters which minimizes systematic uncertainty in the final SEDs.","topic_id":"32941","bibcode":"2014ascl.soft02021M","views":"48","site_list":["http:\/\/www.baryons.org\/pygfit\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013PASP..125.1514M"]},
		{"ascl_id":"1402.022","title":"DexM: Semi-numerical simulations for very large scales","credit":"Mesinger, Andrei; Furlanetto, Steven","abstract":"DexM (Deus ex Machina) efficiently generates density, halo, and ionization fields on very large scales and with a large dynamic range through seminumeric simulation. These properties are essential for reionization studies, especially those involving rare, massive QSOs, since one must be able to statistically capture the ionization field. DexM can also generate ionization fields directly from the evolved density field to account for the ionizing contribution of small halos. Semi-numerical simulations use more approximate physics than numerical simulations, but independently generate 3D cosmological realizations. DexM is portable and fast, and allows for explorations of wide swaths of astrophysical parameter space and an unprecedented dynamic range.","topic_id":"32950","bibcode":"2014ascl.soft02022M","views":"49","site_list":["http:\/\/homepage.sns.it\/mesinger\/DexM___21cmFAST.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007ApJ...669..663M","http:\/\/adsabs.harvard.edu\/abs\/2010MNRAS.407.1328M"]},
		{"ascl_id":"1402.024","title":"QuickReduce: Data reduction pipeline for the WIYN One Degree Imager","credit":"Kotulla, Ralf","abstract":"QuickReduce quickly reduces data for ODI and is optimized for a first data inspection during acquisition at the the telescope. When installed on the ODI observer's interface, QuickReduce, coded in Python, performs all basic reduction steps as well as more advanced corrections for pupil-ghost removal, fringe correction and masking of persistent pixels and is capable enough for science-quality data reductions. It can also add an accurate astrometric WCS solution based on the 2MASS reference system as well as photometric zeropoint calibration for frames covered by the SDSS foot-print. The pipeline makes use of multiple CPU-cores wherever possible, resulting in an execution time of only a few seconds per frame, thus offering the ODI observer a convenient way to closely monitor data quality.","topic_id":"32940","bibcode":"2014ascl.soft02024K","views":"46","site_list":["http:\/\/members.galev.org\/rkotulla\/research\/podi-pipeline\/","http:\/\/portal.odi.iu.edu\/index\/front"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1310.5046K"]},
		{"ascl_id":"1402.025","title":"BAOlab: Baryon Acoustic Oscillations software","credit":"Labatie, Antoine; Starck, Jean-Luc; Lachi\u00e8ze-Rey, Marc","abstract":"Using the 2-point correlation function, BAOlab aids the study of Baryon Acoustic Oscillations (BAO). The code generates a model-dependent covariance matrix which can change the results both for BAO detection and for parameter constraints.","topic_id":"32942","bibcode":"2014ascl.soft02025L","views":"73","site_list":["http:\/\/www.cosmostat.org\/baolab.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010arXiv1009.1232L","http:\/\/adsabs.harvard.edu\/abs\/2012ApJ...760...97L"]},
		{"ascl_id":"1402.026","title":"athena: Tree code for second-order correlation functions","credit":"Kilbinger, Martin; Bonnett, Christopher; Coupon, Jean","abstract":"athena is a 2d-tree code that estimates second-order correlation functions from input galaxy catalogues. These include shear-shear correlations (cosmic shear), position-shear (galaxy-galaxy lensing) and position-position (spatial angular correlation). Written in C, it includes a power-spectrum estimator implemented in Python; this script also calculates the aperture-mass dispersion. A test data set is available.","topic_id":"32943","bibcode":"2014ascl.soft02026K","views":"106","site_list":["http:\/\/www.cosmostat.org\/athena.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002A%26A...396....1S"]},
		{"ascl_id":"1402.027","title":"Darth Fader: Galaxy catalog cleaning method for redshift estimation","credit":"Machado, D. P.; Leonard, A.; Starck, J.-L.; Abdalla, F. B.; Jouvel, S.","abstract":"Darth Fader is a wavelet-based method for extracting spectral features from very noisy spectra. Spectra for which a reliable redshift cannot be measured are identified and removed from the input data set automatically, resulting in a clean catalogue that gives an extremely low rate of catastrophic failures even when the spectra have a very low S\/N. This technique may offer a significant boost in the number of faint galaxies with accurately determined redshifts.","topic_id":"32944","bibcode":"2014ascl.soft02027M","views":"64","site_list":["http:\/\/www.cosmostat.org\/darth_fader.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26A...560A..83M"]},
		{"ascl_id":"1402.028","title":"Commander 2: Bayesian CMB component separation and analysis","credit":"Bull, Phil; Eriksen, Hans Kristian; Gjerl\u00f8w, Eirik; Gorski, Krzysztof; Jewell, Jeff; Seljebotn, Dag Sverre; Wehus, Ingunn","abstract":"Commander 2 is a Gibbs sampling code for joint CMB estimation and component separation. The Commander framework uses a parametrized physical model of the sky to perform statistically-rigorous analyses of multi-frequency, multi-resolution CMB data on the full and partial (flat) sky, as well as cross-correlation analyses with large-scale structure datasets.","topic_id":"33006","bibcode":"2014ascl.soft02028B","views":"59","site_list":["http:\/\/commander.bitbucket.org\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014ApJS..210...24S"]},
		{"ascl_id":"1402.029","title":"wssa_utils: WSSA 12 micron dust map utilities","credit":"Meisner, Aaron M.; Finkbeiner, Douglas P.","abstract":"wssa_utils contains utilities for accessing the full-sky, high-resolution maps of the WSSA 12 micron data release. Implementations in both Python and IDL are included. The code allows users to sample values at (longitude, latitude) coordinates of interest with ease, transparently mapping coordinates to WSSA tiles and performing interpolation. The wssa_utils software also serves to define a unique WSSA 12 micron flux at every location on the sky.","topic_id":"33007","bibcode":"2014ascl.soft02029M","views":"139","site_list":["http:\/\/wise.skymaps.info\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014ApJ...781....5M"]},
		{"ascl_id":"1402.031","title":"gyrfalcON: N-body code","credit":"Dehnen, Walter","abstract":"gyrfalcON (GalaxY simulatoR using falcON) is a full-fledged N-body code using Dehnen\u2019s force algorithm of complexity O(N) (falcON); this algorithm is approximately 10 times faster than an optimally coded tree code. The code features individual adaptive time steps and individual (but fixed) softening lengths. gyrfalcON is included in and requires <a href=http:\/\/ascl.net\/1010.051>NEMO<\/a> to run.","topic_id":"32984","bibcode":"2014ascl.soft02031D","views":"75","site_list":["http:\/\/carma.astro.umd.edu\/nemo\/","http:\/\/carma.astro.umd.edu\/nemo\/man_html\/gyrfalcON.1.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002JCoPh.179...27D","http:\/\/adsabs.harvard.edu\/abs\/2000ApJ...536L..39D"]},
		{"ascl_id":"1402.032","title":"HALOFIT: Nonlinear distribution of cosmological mass and galaxies","credit":"Peacock, J. A.; Smith, R. E.","abstract":"HALOFIT provides an explanatory framework for galaxy bias and clustering and has been incorporated into CMB packages such as <a href=\"http:\/\/ascl.net\/9909.004\">CMBFAST<\/a> and <a href=\"http:\/\/ascl.net\/1102.026\">CAMB<\/a>. It attains a reasonable level of precision, though the halo model does not match N-body data perfectly. The code is written in Fortran 77. HALOFIT tends to underpredict the power on the smallest scales in standard LCDM universes (although HALOFIT was designed to work for a much wider range of power spectra); its accuracy can be improved by using a supplied correction.","topic_id":"21726","bibcode":"2014ascl.soft02032P","views":"79","site_list":["http:\/\/www.roe.ac.uk\/~jap\/haloes\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003MNRAS.341.1311S"]},
		{"ascl_id":"1402.033","title":"libsharp: Library for spherical harmonic transforms","credit":"Reinecke, Martin","abstract":"Libsharp is a collection of algorithms for efficient conversion between maps on the sphere and their spherical harmonic coefficients. It supports a wide range of pixelisations (including HEALPix, GLESP, and ECP). This library is a successor of <a href=\"http:\/\/ascl.net\/1010.020\">libpsht<\/a>; it adds MPI support for distributed memory systems and SHTs of fields with arbitrary spin, and also supports new developments in CPU instruction sets like the Advanced Vector Extensions (AVX) or fused multiply-accumulate (FMA) instructions. libsharp is written in portable C99; it provides an interface accessible to other programming languages such as C++, Fortran, and Python.","topic_id":"32977","bibcode":"2014ascl.soft02033R","views":"45","site_list":["http:\/\/sourceforge.net\/projects\/libsharp\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26A...554A.112R"]},
		{"ascl_id":"1402.034","title":"PyWiFeS: Wide Field Spectrograph data reduction pipeline","credit":"Childress, Michael; Vogt, Fr\u00e9d\u00e9ric; Nielsen, Jon; Sharp, Rob","abstract":"PyWiFeS is a Python-based data reduction pipeline for the Wide Field Spectrograph (WiFeS). Its core data processing routines are built on standard scientific Python packages commonly used in astronomical applications. It includes an implementation of a global optical model of the spectrograph which provides wavelengths solutions accurate to \u02dc0.05 \u00c5 (RMS) across the entire detector. Through scripting, PyWiFeS can enable batch processing of large quantities of data.","topic_id":"32979","bibcode":"2014ascl.soft02034C","views":"51","site_list":["http:\/\/www.mso.anu.edu.au\/pywifes\/doku.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013Ap%26SS.tmp..406C"]},
		{"ascl_id":"1402.035","title":"MGHalofit: Modified Gravity extension of Halofit","credit":"Zhao, Gong-Bo","abstract":"MGHalofit is a modified gravity extension of the fitting formula for the matter power spectrum of <a href=\"http:\/\/ascl.net\/1402.032\">HALOFIT<\/a> and its improvement by Takahashi et al. MGHalofit is implemented in <a href=\"http:\/\/ascl.net\/1106.013\">MGCAMB<\/a>, which is based on <a href=\"http:\/\/ascl.net\/1102.026\">CAMB<\/a>. MGHalofit calculates the nonlinear matter power spectrum P(k) for the Hu-Sawicki model. Comparing MGHalofit predictions at various redshifts (z&lt;=1) to the f(R) simulations, the accuracy on P(k) is 6% at k&lt;1 h\/Mpc and 12% at 1&lt;k&lt;10 h\/Mpc respectively.","topic_id":"32989","bibcode":"2014ascl.soft02035Z","views":"53","site_list":["http:\/\/icosmology.info\/website\/MGHalofit.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013arXiv1312.1291Z"]},
		{"ascl_id":"1403.001","title":"GPU-D: Generating cosmological microlensing magnification maps","credit":"Thompson, A. C.; Vernardos, G.; Fluke, C. J.; Barsdell, B. R.","abstract":"GPU-D is a GPU-accelerated implementation of the inverse ray-shooting technique used to generate cosmological microlensing magnification maps. These maps approximate the source plane magnification patterns created by an ensemble of stellar-mass compact objects within a foreground macrolens galaxy. Unlike other implementations, GPU-D solves the gravitational lens equation without any approximation. Due to the high computational intensity and high degree of parallelization inherent in the algorithm, it is ideal for brute-force implementation on GPUs. GPU-D uses CUDA for GPU acceleration and require NVIDIA devices to run.","topic_id":"33034","bibcode":"2014ascl.soft03001T","views":"48","site_list":["http:\/\/gerlumph.swin.edu.au\/GPUD\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010NewA...15...16T"]},
		{"ascl_id":"1403.002","title":"pyExtinction: Atmospheric extinction","credit":"Buton, Cl\u00e9ment; Copin, Yannick","abstract":"The Python script\/package pyExtinction computes and plots total atmospheric extinction from decomposition into physical components (Rayleigh attenuation, ozone absorption, aerosol extinction). Its default extinction parameters are adapted to mean Mauna Kea summit conditions.","topic_id":"32537","bibcode":"2014ascl.soft03002B","views":"49","site_list":["http:\/\/snfactory.in2p3.fr\/soft\/atmosphericExtinction\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26A...549A...8B"]},
		{"ascl_id":"1403.003","title":"MLZ: Machine Learning for photo-Z","credit":"Carrasco Kind, Matias; Brunner, Robert","abstract":"The parallel Python framework MLZ (Machine Learning and photo-Z) computes fast and robust photometric redshift PDFs using Machine Learning algorithms. It uses a supervised technique with prediction trees and random forest through <a href=\"http:\/\/ascl.net\/1304.011\">TPZ<\/a> that can be used for a regression or a classification problem, or a unsupervised methods with self organizing maps and random atlas called SOMz. These machine learning implementations can be efficiently combined into a more powerful one resulting in robust and accurate probability distributions for photometric redshifts.","topic_id":"32766","bibcode":"2014ascl.soft03003C","views":"62","site_list":["http:\/\/lcdm.astro.illinois.edu\/static\/code\/mlz\/MLZ-1.0\/doc\/html\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1403.0044C"]},
		{"ascl_id":"1403.004","title":"Lightcone: Light-cone generating script","credit":"Bernyk, Max","abstract":"Lightcone works with simulated galaxy data stored in a relational database to rearrange the data in a shape of a light-cone; simulated galaxy data is expected to be in a box volume. The light-cone constructing script works with output from the SAGE semi-analytic model, but will work with any other model that has galaxy positions (and other properties) saved per snapshots of the simulation volume distributed in time. The database configuration file is set up for PostgreSQL RDBMS, but can be modified for use with any other SQL database.","topic_id":"33089","bibcode":"2014ascl.soft03004B","views":"52","site_list":["https:\/\/github.com\/maxbernyk\/lightcone"],"ref_list":false},
		{"ascl_id":"1403.005","title":"GRay: Massive parallel ODE integrator","credit":"Chan, Chi-kwan; Psaltis, Dimitrios; Ozel, Feryal","abstract":"GRay is a massive parallel ordinary differential equation integrator that employs the \"stream processing paradigm.\" It is designed to efficiently integrate billions of photons in curved spacetime according to Einstein's general theory of relativity. The code is implemented in CUDA C\/C++.","topic_id":"31010","bibcode":"2014ascl.soft03005C","views":"56","site_list":["https:\/\/github.com\/chanchikwan\/gray"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013ApJ...777...13C"]},
		{"ascl_id":"1403.006","title":"CHIMERA: Core-collapse supernovae simulation code","credit":"Mezzacappa, Anthony; Hix, Raph; Messor, Bronson; Lentz, Eric; Chertkow, Merek Austin; Parete-Koon, Suzanne; Lingerfelt, Eric","abstract":"CHIMERA simulates core collapse supernovas; it is three-dimensional and accounts for the differing energies of neutrinos. This massively parallel multiphysics code conserves total energy (gravitational, internal, kinetic, and neutrino) to within  0.5 B, given a conservative gravitational potential. CHIMERA has three main components: a hydro component, a neutrino transport component, and a nuclear reaction network component. It also includes a Poisson solver for the gravitational potential and a sophisticated equation of state.","topic_id":"33014","bibcode":"2014ascl.soft03006M","views":"75","site_list":["https:\/\/sites.google.com\/site\/utkastro\/splash\/chimera"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009JPhCS.180a2018B"]},
		{"ascl_id":"1403.007","title":"Unified EOS for neutron stars","credit":"Chamel, Nicolas; Potekhin, Alexander","abstract":"The equation of state (EOS) of dense matter is a crucial input for the neutron-star structure calculations. This Fortran code can obtain a \"unified EOS\" in the many-body calculations based on a single effective nuclear Hamiltonian, and is valid in all regions of the neutron star interior. For unified EOSs, the transitions between the outer crust and the inner crust and between the inner crust and the core are obtained as a result of many-body calculations.","topic_id":"33015","bibcode":"2014ascl.soft03007C","views":"64","site_list":["http:\/\/www.ioffe.ru\/astro\/NSG\/BSk\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26A...560A..48P"]},
		{"ascl_id":"1403.008","title":"SURF: Submm User Reduction Facility","credit":"Jenness, Tim; Lightfoot, John","abstract":"SURF reduces data from the SCUBA instrument from the James Clerk Maxwell Telescope. Facilities are provided for reducing all the SCUBA observing modes including jiggle, scan and photometry modes. SURF uses the <a href=\"http:\/\/ascl.net\/1110.012\">Starlink<\/a> environment (ascl:1110.012).","topic_id":"33134","bibcode":"2014ascl.soft03008J","views":"54","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/www.adsabs.harvard.edu\/abs\/1998ASPC..145..216J","http:\/\/www.adsabs.harvard.edu\/abs\/2013MNRAS.435..289R"]},
		{"ascl_id":"1403.009","title":"ISAP: ISO Spectral Analysis Package","credit":"Ali, Babar; Bauer, Otto; Brauher, Jim; Buckley, Mark; Harwood, Andrew; Hur, Min; Khan, Iffat; Li, Jing; Lord, Steve; Lutz, Dieter; Mazzarella, Joe; Molinari, Sergio; Morris, Pat; Narron, Bob; Seidenschwang, Karla; Sidher, Sunil; Sturm, Eckhard; Swinyard, Bruce; Unger, Sarah; Verstraete, Laurent; Vivares, Florence; Wieprecht, Ecki","abstract":"ISAP, written in IDL, simplifies the process of visualizing, subsetting, shifting, rebinning, masking, combining scans with weighted means or medians, filtering, and smoothing Auto Analysis Results (AARs) from post-pipeline processing of the Infrared Space Observatory's (ISO) Short Wavelength Spectrometer (SWS) and Long Wavelength Spectrometer (LWS) data. It can also be applied to PHOT-S and CAM-CVF data, and data from practically any spectrometer. The result of a typical ISAP session is expected to be a \"simple spectrum\" (single-valued spectrum which may be resampled to a uniform wavelength separation if desired) that can be further analyzed and measured either with other ISAP functions, native IDL functions, or exported to other analysis package (e.g., <a href=\"http:\/\/www.ascl.net\/9911.002\">IRAF<\/a>, <a href=\"http:\/\/www.ascl.net\/1302.017\">MIDAS<\/a>) if desired. ISAP provides many tools for further analysis, line-fitting, and continuum measurements, such as routines for unit conversions, conversions from wavelength space to frequency space, line and continuum fitting, flux measurement, synthetic photometry and models such as a zodiacal light model to predict and subtract the dominant foreground at some wavelengths.","topic_id":"33057","bibcode":"2014ascl.soft03009A","views":"55","site_list":["http:\/\/www.ipac.caltech.edu\/iso\/isap\/isap.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1998ASPC..145..161S"]},
		{"ascl_id":"1403.010","title":"Inverse Beta: Inverse cumulative density function (CDF) of a Beta distribution","credit":"Kipping, David","abstract":"The Beta Inverse code solves the inverse cumulative density function (CDF) of a Beta distribution, allowing one to sample from the Beta prior directly. The Beta distribution is well suited as a prior for the distribution of the orbital eccentricities of extrasolar planets; imposing a Beta prior on orbital eccentricity is valuable for any type of observation of an exoplanet where eccentricity can affect the model parameters (e.g. transits, radial velocities, microlensing, direct imaging). The Beta prior is an excellent description of the current, empirically determined distribution of orbital eccentricities and thus employing it naturally incorporates an observer\u2019s prior experience of what types of orbits are probable or improbable. The default parameters in the code are currently set to the Beta distribution which best describes the entire population of exoplanets with well-constrained orbits.","topic_id":"33058","bibcode":"2014ascl.soft03010K","views":"54","site_list":["https:\/\/www.cfa.harvard.edu\/~dkipping\/betaprior.html"],"ref_list":["http:\/\/arxiv.org\/abs\/1306.4982"]},
		{"ascl_id":"1403.011","title":"RMHB: Hierarchical Reverberation Mapping","credit":"Brewer, Brendon J.; Elliott, Tom M.","abstract":"RMHB is a hierarchical Bayesian code for reverberation mapping (RM) that combines results of a sparsely sampled broad line region (BLR) light curve and a large sample of active galactic nuclei (AGN) to infer properties of the sample of the AGN. The key idea of RM is to measure the time lag \u03c4 between variations in the continuum emission from the accretion disc and subsequent response of the broad line region (BLR). The measurement of \u03c4 is typically used to estimate the physical size of the BLR and is combined with other measurements to estimate the black hole mass MBH. A major difficulty with RM campaigns is the large amount of data needed to measure \u03c4. RMHB allows a clear interpretation of a posterior distribution for hyperparameters describing the sample of AGN.","topic_id":"32988","bibcode":"2014ascl.soft03011B","views":"50","site_list":["https:\/\/github.com\/eggplantbren\/RMHB"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014MNRAS.tmpL...8B"]},
		{"ascl_id":"1403.012","title":"YNOGKM: Time-like geodesics in the Kerr-Newmann Spacetime calculations","credit":"Yang, Xiao-lin; Wang, Jian-cheng","abstract":"YNOGKM (Yun-Nan observatories geodesic in a Kerr-Newman spacetime for massive particles) performs fast calculation of time-like geodesics in the Kerr-Newman (K-N) spacetime; it is a direct extension of <a hred=\"http:\/\/www.ascl.net\/1305.008\">YNOGK<\/a> (Yun-Nan observatories geodesic Kerr) calculating null geodesics in a Kerr spacetime. The four Boyer-Lindquis coordinates and proper time are expressed as functions of a parameter p semi-analytically by using the Weierstrass' and Jacobi's elliptic functions and integrals. The elliptic integrals are computed by Carlson's elliptic integral method, which guarantees the fast speed of the code. The source Fortran file ynogkm.f90 contains three modules: constants, rootfind, ellfunction, and blcoordinates.","topic_id":"33137","bibcode":"2014ascl.soft03012Y","views":"70","site_list":["http:\/\/www1.ynao.ac.cn\/~yangxl\/yxl.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014A%26A...561A.127Y"]},
		{"ascl_id":"1403.013","title":"BAOlab: Image processing program","credit":"Larsen, S\u00f8ren S.","abstract":"BAOlab is an image processing package written in C that should run on nearly any UNIX system with just the standard C libraries. It reads and writes images in standard FITS format; 16- and 32-bit integer as well as 32-bit floating-point formats are supported. Multi-extension FITS files are currently not supported. Among its tools are ishape for size measurements of compact sources, mksynth for generating synthetic images consisting of a background signal including Poisson noise and a number of pointlike sources, imconvol for convolving two images (a \u201csource\u201d and a \u201ckernel\u201d) with each other using fast fourier transforms (FFTs) and storing the output as a new image, and kfit2d for fitting a two-dimensional King model to an image.","topic_id":"33143","bibcode":"2014ascl.soft03013L","views":"83","site_list":["http:\/\/baolab.astroduo.org\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1999A%26AS..139..393L"]},
		{"ascl_id":"1403.014","title":"T(dust) as a function of sSFR","credit":"Magnelli, Benjamin","abstract":"This IDL code returns the dust temperature of a galaxy from its redshift, SFR and stellar mass; it can also predict the observed monochromatic fluxes of the galaxy. These monochromatic fluxes correspond to those of a DH SED template with the appropriate dust temperature and the appropriate normalization. Dust temperatures and fluxes predictions are only valid and provided in the redshift, stellar mass, SSFR and wavelength ranges 0 &lt;  z &lt;  2.5, Mstar&gt; 10^10 Msun, 10^-11 &lt; SSFR[yr-1]&lt;  10^-7 and 30um &lt;  lambda_rest &lt;  2mm.","topic_id":"33146","bibcode":"2014ascl.soft03014M","views":"59","site_list":["http:\/\/www.mpe.mpg.de\/ir\/Research\/PEP\/Tdust_sSFR"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014A%26A...561A..86M"]},
		{"ascl_id":"1403.015","title":"computePk: Power spectrum computation","credit":"L'Huillier, Benjamin","abstract":"ComputePk computes the power spectrum in cosmological simulations. It is MPI parallel and has been tested up to a 4096^3 mesh. It uses the FFTW library. It can read Gadget-3 and GOTPM outputs, and computes the dark matter component. The user may choose between NGP, CIC, and TSC for the mass assignment scheme.","topic_id":"33159","bibcode":"2014ascl.soft03015L","views":"75","site_list":["http:\/\/aramis.obspm.fr\/~lhuillier\/codes.php"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014NewA...30...79L"]},
		{"ascl_id":"1403.016","title":"Viewpoints: Fast interactive linked plotting of large multivariate data sets","credit":"Levit, Creon; Gazis, Paul R.; Way, Michael J.","abstract":"Viewpoints is an interactive tool for exploratory visual analysis of large high-dimensional (multivariate) data. It uses linked scatterplots to find relations in a few seconds that can take much longer with other plotting tools. Its features include linked scatter plots with brushing, dynamic histograms, normalization, and outlier detection\/removal.","topic_id":"33162","bibcode":"2014ascl.soft03016L","views":"59","site_list":["https:\/\/www.assembla.com\/wiki\/show\/viewpoints"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011ApJ...734L...9W","http:\/\/adsabs.harvard.edu\/abs\/2010PASP..122.1518G"]},
		{"ascl_id":"1403.017","title":"MGE_FIT_SECTORS: Multi-Gaussian Expansion fits to galaxy images","credit":"Cappellari, Michele","abstract":"MGE_FIT_SECTORS performs Multi-Gaussian Expansion (MGE) fits to galaxy images. The MGE parameterizations are useful in the construction of realistic dynamical models of galaxies, PSF deconvolution of images, the correction and estimation of dust absorption effects, and galaxy photometry. The algorithm is well suited for use with multiple-resolution images (e.g. Hubble Space Telescope (HST) and ground-based images).","topic_id":"33125","bibcode":"2014ascl.soft03017C","views":"79","site_list":["http:\/\/www-astro.physics.ox.ac.uk\/~mxc\/software\/#mge"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002MNRAS.333..400C"]},
		{"ascl_id":"1403.018","title":"JAM: Jeans Anisotropic MGE modeling method","credit":"Cappellari, Michele","abstract":"The Jeans Anisotropic MGE (JAM) modeling method uses the Multi-Gaussian Expansion parameterization for the galaxy surface brightness. The code allows for orbital anisotropy (three-integrals distribution function) and also provides the full second moment tensor, including proper motions and radial velocities.","topic_id":"33126","bibcode":"2014ascl.soft03018C","views":"65","site_list":["http:\/\/www-astro.physics.ox.ac.uk\/~mxc\/software\/#jam"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008MNRAS.390...71C"]},
		{"ascl_id":"1403.019","title":"KINEMETRY: Analysis of 2D maps of kinematic moments of LOSVD","credit":"Krajnovi\u0107, Davor","abstract":"KINEMETRY, written in IDL, analyzes 2D maps of the moments of the line-of-sight velocity distribution (LOSVD). It generalizes the surface photometry to all moments of the LOSVD. It performs harmonic expansion of 2D maps of observed moments (surface brightness, velocity, velocity dispersion, h3, h4, etc.) along the best fitting ellipses (either fixed or free to change along the radii) to robustly quantify maps of the LOSVD moments, describe trends in structures, and detect morphological and kinematic sub-components.","topic_id":"33130","bibcode":"2014ascl.soft03019K","views":"54","site_list":["http:\/\/davor.krajnovic.org\/idl\/#kinemetry"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006MNRAS.366..787K"]},
		{"ascl_id":"1403.020","title":"disc2vel: Tangential and radial velocity components derivation","credit":"Krajnovi\u0107, Davor; Maciejewski, Witold","abstract":"Disc2vel derives tangential and radial velocity components in the equatorial plane of a barred stellar disc from the observed line-of-sight velocity, assuming geometry of a thin disc. The code is written in IDL, and the method assumes that the bar is close to steady state (i.e. does not evolve fast) and that both morphology and kinematics are symmetrical with respect to the major axis of the bar.","topic_id":"33131","bibcode":"2014ascl.soft03020K","views":"58","site_list":["http:\/\/davor.krajnovic.org\/idl\/#disc2vel"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.427.3427M"]},
		{"ascl_id":"1403.021","title":"CCDPACK: CCD Data Reduction Package","credit":"Warren-Smith, Rodney F.; Draper, Peter W.; Taylor, Mark; Allan, Alasdair","abstract":"CCDPACK contains programs to debias, remove dark current, flatfield, register, resample and normalize data from single- or multiple-CCD instruments. The basic reduction stages can be set up using an X based GUI that controls an automated reduction system so one can to start working without any detailed knowledge of the package (or indeed of CCD reduction). Registration is performed using graphical, script based or automated techniques that keep the amount of work to a minimum. CCDPACK uses the <a href=\"http:\/\/ascl.net\/1110.012\">Starlink<\/a> environment (ascl:1110.012).","topic_id":"33203","bibcode":"2014ascl.soft03021W","views":"95","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1993ESOC...47...33D","http:\/\/adsabs.harvard.edu\/abs\/2013MNRAS.430.3397B\/"]},
		{"ascl_id":"1403.022","title":"KAPPA: Kernel Applications Package","credit":"Currie, Malcolm J.; Berry, David S.","abstract":"KAPPA comprising about 180 general-purpose commands for image processing, data visualization, and manipulation of the standard Starlink data format--the NDF. It works with Starlink's various specialized packages; in addition to the NDF, KAPPA can also process data in other formats by using the \"on-the-fly\" conversion scheme. Many commands can process data arrays of arbitrary dimension, and others work on both spectra and images. KAPPA operates from both the UNIX C-shell and the ICL command language. KAPPA uses the <a href=\"http:\/\/ascl.net\/1110.012\">Starlink<\/a> environment (ascl:1110.012).","topic_id":"33204","bibcode":"2014ascl.soft03022C","views":"78","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1993MNRAS.263..655K\/","http:\/\/adsabs.harvard.edu\/abs\/2014MNRAS.437.2894C\/"]},
		{"ascl_id":"1403.023","title":"ASTERIX: X-ray Data Processing System","credit":"Peden, Jim; Allan, David J.; Ponman, Trevor; Saxton, Richard; Andrews, Phillip; Beard, Richard; Vallance, Bob","abstract":"ASTERIX is a general purpose X-ray data reduction package optimized for ROSAT data reduction. ASTERIX uses the <a href=\"http:\/\/ascl.net\/1110.012\">Starlink<\/a> software environment (ascl:1110.012).","topic_id":"33205","bibcode":"2014ascl.soft03023P","views":"82","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1995MNRAS.277L...5P\/","http:\/\/adsabs.harvard.edu\/abs\/2007MNRAS.378.1217R\/"]},
		{"ascl_id":"1403.024","title":"GAIA: Graphical Astronomy and Image Analysis Tool","credit":"Draper, Peter W.; Gray, Norman; Berry, David S.; Taylor, Mark","abstract":"GAIA is an image and data-cube display and analysis tool for astronomy. It provides the usual facilities of image display tools, plus more astronomically useful ones such as aperture and optimal photometry, contouring, source detection, surface photometry, arbitrary region analysis, celestial coordinate readout, calibration and modification, grid overlays, blink comparison, defect patching and the ability to query on-line catalogues and image servers. It can also display slices from data-cubes, extract and visualize spectra as well as perform full 3D rendering. GAIA uses the <a href=\"http:\/\/www.ascl.net\/1110.012\">Starlink<\/a> software environment (ascl:1110.012) and is derived from the ESO <a href=\"http:\/\/www.ascl.net\/1109.019\">SkyCat tool<\/a> (ascl:1109.019).","topic_id":"33206","bibcode":"2014ascl.soft03024D","views":"95","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009ASPC..411..575D","http:\/\/adsabs.harvard.edu\/abs\/2013A%26A...556A..20F"]},
		{"ascl_id":"1403.025","title":"SLALIB: A Positional Astronomy Library","credit":"Wallace, Patrick T.","abstract":"SLALIB is a library of routines that make accurate and reliable positional-astronomy applications easier to write. Most SLALIB routines are concerned with astronomical position and time, but a number have wider trigonometrical, numerical or general applications. A Fortran implementation of SLALIB under GPL licensing is available as part of <a href=\"http:\/\/www.ascl.net\/1110.012\">Starlink<\/a> (ascl:1110.012).","topic_id":"33209","bibcode":"2014ascl.soft03025W","views":"189","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1997ApJ...488L.153C\/","http:\/\/adsabs.harvard.edu\/abs\/2013PASJ...65...78O\/"]},
		{"ascl_id":"1403.026","title":"SOFA: Standards of Fundamental Astronomy","credit":"IAU SOFA Center","abstract":"SOFA (Standards Of Fundamental Astronomy) is a collection of subprograms, in source-code form, that implement official IAU algorithms for fundamental astronomy computations. SOFA offers more than 160 routines for fundamental astronomy, including time scales (including dealing with leap seconds), Earth rotation, sidereal time, precession, nutation, polar motion, astrometry and transforms between various reference systems (e.g. BCRS, ICRS, GCRS, CIRS, TIRS, ITRS). The subprograms are supported by 55 vector\/matrix routines, and are available in both Fortran77 and C implementations.","topic_id":"33207","bibcode":"2014ascl.soft03026I","views":"106","site_list":["http:\/\/www.iausofa.org\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012A%26A...548A..50L","http:\/\/adsabs.harvard.edu\/abs\/1996ASPC..101..207W"]},
		{"ascl_id":"1404.001","title":"LTS_LINEFIT & LTS_PLANEFIT: LTS fit of lines or planes","credit":"Cappellari, Michele","abstract":"LTS_LINEFIT and LTS_PLANEFIT are IDL programs to robustly fit lines and planes to data with intrinsic scatter. The code combines the Least Trimmed Squares (LTS) robust technique, proposed by Rousseeuw (1984) and optimized in Rousseeuw & Driessen (2006), into a least-squares fitting algorithm which allows for intrinsic scatter. This method makes the fit converge to the correct solution even in the presence of a large number of catastrophic outliers, where the much simpler \u03c3-clipping approach can converge to the wrong solution.","topic_id":"33265","bibcode":"2014ascl.soft04001C","views":"51","site_list":["http:\/\/www-astro.physics.ox.ac.uk\/~mxc\/software\/#lts"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013MNRAS.432.1709C"]},
		{"ascl_id":"1404.002","title":"ZDCF: Z-Transformed Discrete Correlation Function","credit":"Alexander, Tal","abstract":"The cross-correlation function (CCF) is commonly employed in the study of AGN, where it is used to probe the structure of the broad line region by line reverberation, to study the continuum emission mechanism by correlating multi-waveband light curves and to seek correlations between the variability and other AGN properties. The z -transformed discrete correlation function (ZDCF) is a method for estimating the CCF of sparse, unevenly sampled light curves. Unlike the commonly used interpolation method, it does not assume that the light curves are smooth and it does provide errors on its estimates.","topic_id":"33266","bibcode":"2014ascl.soft04002A","views":"71","site_list":["http:\/\/www.weizmann.ac.il\/weizsites\/tal\/research\/software\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1997ASSL..218..163A","http:\/\/adsabs.harvard.edu\/abs\/2008ApJ...677..884L"]},
		{"ascl_id":"1404.003","title":"macula: Model of rotational modulations of a spotted star","credit":"Kipping, David","abstract":"Macula models the rotational modulations in the photometry of a spotted star, assuming N circular, grey starspots with differential rotation, and starspot evolution. It also provides the partial derivatives of the inputted parameters with respect to the flux, plus the temporal derivatives of the flux.","topic_id":"33267","bibcode":"2014ascl.soft04003K","views":"45","site_list":["https:\/\/www.cfa.harvard.edu\/~dkipping\/macula.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.427.2487K"]},
		{"ascl_id":"1404.004","title":"SAS: Science Analysis System for XMM-Newton observatory","credit":"SAS development team","abstract":"The Science Analysis System (SAS) is an extensive suite of software tasks developed to process the data collected by the XMM-Newton Observatory. The SAS extracts standard (spectra, light curves) and\/or customized science products, and allows reproductions of the reduction pipelines run to get the PPS products from the ODFs files. SAS includes a powerful and extensive suite of FITS file manipulation packages based on the Data Access Layer library.","topic_id":"33268","bibcode":"2014ascl.soft04004S","views":"48","site_list":["http:\/\/xmm.esac.esa.int\/sas\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004ASPC..314..759G","http:\/\/adsabs.harvard.edu\/abs\/2004MNRAS.351..989B"]},
		{"ascl_id":"1404.005","title":"SER: Subpixel Event Repositioning Algorithms","credit":"Li, Dylan","abstract":"Subpixel Event Repositioning (SER) techniques significantly improve the already unprecedented spatial resolution of Chandra X-ray imaging with the Advanced CCD Imaging Spectrometer (ACIS). Chandra CCD SER techniques are based on the premise that the impact position of events can be refined, based on the distribution of charge among affected CCD pixels. Unlike ACIS SER models that are restricted to corner split (3- and 4-pixel) events and assume that such events take place at the split pixel corners, this IDL code uses two-pixel splits as well, and incorporates more realistic estimates of photon impact positions.","topic_id":"33269","bibcode":"2014ascl.soft04005L","views":"55","site_list":["http:\/\/www.cis.rit.edu\/people\/faculty\/kastner\/SER\/ser.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003ApJ...590..586L"]},
		{"ascl_id":"1404.006","title":"TORUS: Radiation transport and hydrodynamics code","credit":"Harries, Tim","abstract":"TORUS is a flexible radiation transfer and radiation-hydrodynamics code. The code has a basic infrastructure that includes the AMR mesh scheme that is used by several physics modules including atomic line transfer in a moving medium, molecular line transfer, photoionization, radiation hydrodynamics and radiative equilibrium. TORUS is useful for a variety of problems, including magnetospheric accretion onto T Tauri stars, spiral nebulae around Wolf-Rayet stars, discs around Herbig AeBe stars, structured winds of O supergiants and Raman-scattered line formation in symbiotic binaries, and dust emission and molecular line formation in star forming clusters. The code is written in Fortran 2003 and is compiled using a standard Gnu makefile. The code is parallelized using both MPI and OMP, and can use these parallel sections either separately or in a hybrid mode.","topic_id":"33270","bibcode":"2014ascl.soft04006H","views":"76","site_list":["http:\/\/www.astro.ex.ac.uk\/people\/th2\/torus_html\/homepage.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.422..241A","http:\/\/adsabs.harvard.edu\/abs\/2000MNRAS.315..722H"]},
		{"ascl_id":"1404.007","title":"AMBIG: Automated Ambiguity-Resolution Code","credit":"Leka, K.D.; Barnes, G.; Crouch, A.","abstract":"AMBIG is a fast, automated algorithm for resolving the 180\u00b0 ambiguity in vector magnetic field data, including those data from Hinode\/Spectropolarimeter. The Fortran-based code is loosely based on the Minimum Energy Algorithm, and is distributed to provide ambiguity-resolved data for the general user community.","topic_id":"33271","bibcode":"2014ascl.soft04007L","views":"82","site_list":["http:\/\/www.cora.nwra.com\/AMBIG\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009ASPC..415..365L","http:\/\/adsabs.harvard.edu\/abs\/2014A%26A...564A..91J"]},
		{"ascl_id":"1404.008","title":"Comet: Multifunction VOEvent broker","credit":"Swinbank, John","abstract":"Comet is a Python implementation of the VOEvent Transport Protocol (VTP). VOEvent is the IVOA system for describing transient celestial events. Details of transients detected by many projects, including Fermi, Swift, and the Catalina Sky Survey, are currently made available as VOEvents, which is also the standard alert format by future facilities such as LSST and SKA. The core of Comet is a multifunction VOEvent broker, capable of receiving events either by subscribing to one or more remote brokers or by direct connection from authors; it can then both process those events locally and forward them to its own subscribers. In addition, Comet provides a tool for publishing VOEvents to the global VOEvent backbone.","topic_id":"33272","bibcode":"2014ascl.soft04008S","views":"77","site_list":["https:\/\/github.com\/jdswinbank\/Comet","http:\/\/comet.transientskp.org\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013MNRAS.428.3114S"]},
		{"ascl_id":"1404.009","title":"carma_pack: MCMC sampler for Bayesian inference","credit":"Kelly, Brandon C.; Becker, Andrew","abstract":"carma_pack is an MCMC sampler for performing Bayesian inference on continuous time autoregressive moving average models. These models may be used to model time series with irregular sampling. The MCMC sampler utilizes an adaptive Metropolis algorithm combined with parallel tempering.","topic_id":"33273","bibcode":"2014ascl.soft04009K","views":"82","site_list":["https:\/\/github.com\/bckelly80\/carma_pack"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1402.5978K"]},
		{"ascl_id":"1404.010","title":"VictoriaReginaModels: Stellar evolutionary tracks","credit":"VandenBerg, Don A.; Bergbusch, Peter A.; Dowler, Patrick D.","abstract":"The Victoria\u2013Regina stellar models are comprised of seventy-two grids of stellar evolutionary tracks accompanied by complementary zero-age horizontal branches and are presented in \u201cequivalent evolutionary phase\u201d (.eep) files. This Fortran 77 software interpolates isochrones, isochrone population functions, luminosity functions, and color functions of stellar evolutionary tracks.","topic_id":"33274","bibcode":"2014ascl.soft04010V","views":"74","site_list":["http:\/\/www1.cadc-ccda.hia-iha.nrc-cnrc.gc.ca\/community\/VictoriaReginaModels\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ApJS..162..375V"]},
		{"ascl_id":"1404.011","title":"CAP_LOESS_1D & CAP_LOESS_2D: Recover mean trends from noisy data","credit":"Cappellari, Michele","abstract":"The IDL programs CAP_LOESS_1D and CAP_LOESS_2D provide improved implementations of the one-dimensional (Clevelend 1979) and two-dimensional (Cleveland & Devlin 1988) Locally Weighted Regression (LOESS) methods to recover the mean trends of the population from noisy data in one or two dimensions. They include a robust approach to deal with outliers (bad data).","topic_id":"33275","bibcode":"2014ascl.soft04011C","views":"56","site_list":["http:\/\/www-astro.physics.ox.ac.uk\/~mxc\/software\/#loess"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013MNRAS.432.1862C"]},
		{"ascl_id":"1404.012","title":"RegPT: Regularized cosmological power spectrum","credit":"Taruya, Atsushi","abstract":"RegPT computes the power spectrum in flat wCDM class models based on the RegPT treatment when provided with either of transfer function or matter power spectrum. It then gives the multiple-redshift outputs for power spectrum, and optionally provides correlation function data. The Fortran code has two major options for power spectrum calculations; -fast, which quickly computes the power spectrum at two-loop level (typically a few seconds) using the pre-computed data set of PT kernels for fiducial cosmological models, and -direct, in which the code first applies the fast method, and then follows the regularized expression for power spectrum to directly evaluate the multi-dimensional integrals. The output results are the power spectrum of direct calculation and difference of the results between fast and direct method. The code also gives the data set of PT diagrams necessary for power spectrum calculations from which the power spectrum can be constructed.","topic_id":"33276","bibcode":"2014ascl.soft04012T","views":"55","site_list":["http:\/\/www2.yukawa.kyoto-u.ac.jp\/~atsushi.taruya\/regpt_code.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012PhRvD..86j3528T"]},
		{"ascl_id":"1404.013","title":"WFC3UV_GC: WFC3 UVIS geometric-distortion correction","credit":"Bellini, Andrea; Anderson, Jay; Bedin, L.R.","abstract":"WFC3UV_GC is an improved geometric-distortion solution for the Hubble Space Telescope UVIS channel of Wide Field Camera 3 for ten broad-band filters. The solution is made up of three parts:\n\n<ol><li>a 3rd-order polynomial to deal with the general optical distortion<\/li><li>a table of residuals that accounts for both chip-related anomalies and fine-structure introduced by the filter<\/li><li>a linear transformation to put the two chips into a convenient master frame<\/li>\n<\/ol>","topic_id":"33277","bibcode":"2014ascl.soft04013B","views":"61","site_list":["http:\/\/www.stsci.edu\/~jayander\/WFC3\/WFC3UV_GC\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011PASP..123..622B"]},
		{"ascl_id":"1404.014","title":"SpecPro: Astronomical spectra viewer and analyzer","credit":"Masters, Dan; Capak, Peter","abstract":"SpecPro is an interactive program for viewing and analyzing spectra, particularly in the context of modern imaging surveys. In addition to displaying the 1D and 2D spectrum, SpecPro can simultaneously display available stamp images as well as the spectral energy distribution of a source. This extra information can help significantly in assessing a spectrum.","topic_id":"33278","bibcode":"2014ascl.soft04014M","views":"70","site_list":["http:\/\/specpro.caltech.edu\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011PASP..123..638M"]},
		{"ascl_id":"1404.015","title":"TTVFast: Transit timing inversion","credit":"Deck, Katherine; Agol, Eric; Holman, Matt; Nesvorny, David","abstract":"TTVFast efficiently calculates transit times for n-planet systems and the corresponding radial velocities. The code uses a symplectic integrator with a Keplerian interpolator for the calculation of transit times (Nesvorny et al. 2013); it is available in both C and Fortran.","topic_id":"33279","bibcode":"2014ascl.soft04015D","views":"63","site_list":["http:\/\/github.com\/kdeck\/TTVFast"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1403.1895D"]},
		{"ascl_id":"1404.016","title":"AST: World Coordinate Systems in Astronomy","credit":"Berry, David S.; Warren-Smith, Rodney F.","abstract":"The AST library provides a comprehensive range of facilities for attaching world coordinate systems to astronomical data, for retrieving and interpreting that information in a variety of formats, including FITS-WCS, and for generating graphical output based on it. Core projection algorithms are provided by <a href=\"http:\/\/ascl.net\/1108.003\">WCSLIB<\/a> (ascl:1108.003) and astrometry is provided by the PAL and <a href=\"http:\/\/ascl.net\/1403.026\">SOFA<\/a> (ascl:1403.026) libraries. AST bindings are available in Python (pyast), Java (JNIAST) and Perl (Starlink::AST). AST is used as the plotting and astrometry library in DS9 and GAIA, and is distributed separately and as part of the Starlink software collection.","topic_id":"33280","bibcode":"2014ascl.soft04016B","views":"100","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/starlink.jach.hawaii.edu\/starlink\/AST"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A%26A...558A..33A","http:\/\/adsabs.harvard.edu\/abs\/2005ASPC..347..491S\/"]},
		{"ascl_id":"1404.017","title":"Spextool: Spectral EXtraction tool","credit":"Cushing, Michael; Vacca, Bill; Rayner, John","abstract":"Spextool (Spectral EXtraction tool) is an IDL-based data reduction package for SpeX, a medium resolution near-infrared spectrograph on the NASA IRTF. It performs all of the steps necessary to produce spectra ready for analysis and publication including non-linearity corrections, flat fielding, wavelength calibration, telluric correction, flux calibration, and order merging.","topic_id":"33281","bibcode":"2014ascl.soft04017C","views":"65","site_list":["http:\/\/irtfweb.ifa.hawaii.edu\/~spex\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004PASP..116..362C","http:\/\/adsabs.harvard.edu\/abs\/2004PASP..116..352V"]},
		{"ascl_id":"1405.003","title":"The Hammer: An IDL Spectral Typing Suite","credit":"Covey, Kevin R.; West, Andrew A.; Bochanski, John J.; Hawley, Suzanne L.","abstract":"The Hammer can classify spectra in a variety of formats with targets spanning the MK spectral sequence. It processes a list of input spectra by automatically estimating each object's spectral type and measuring activity and metallicity tracers in late type stars. Once automatic processing is complete, an interactive interface allows the user to manually tweak the final assigned spectral type through visual comparison with a set of templates.","topic_id":"33296","bibcode":"2014ascl.soft05003C","views":"67","site_list":["http:\/\/www.astro.washington.edu\/users\/slh\/hammer\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007AJ....134.2398C"]},
		{"ascl_id":"1405.004","title":"Defringeflat: Fringe pattern removal","credit":"Rojo, Patricio; Harrington; Joseph","abstract":"The IDL package Defringeflat identifies and removes fringe patterns from images such as spectrograph flat fields. It uses a wavelet transform to calculate the frequency spectrum in a region around each point of a one-dimensional array. The wavelet transform amplitude is reconstructed from (smoothed) parameters obtaining the fringe's wavelet transform, after which an inverse wavelet transform is performed to obtain the computed fringe pattern which is then removed from the flat.","topic_id":"33297","bibcode":"2014ascl.soft05004R","views":"67","site_list":["http:\/\/physics.ucf.edu\/~jh\/ast\/software.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ApJ...649..553R"]},
		{"ascl_id":"1405.005","title":"HIIPHOT: Automated Photometry of H II Regions","credit":"Thilker, David A.; Braun, Robert; Walterbos, Ren\u00e9 A. M.","abstract":"HIIPHOT enables accurate photometric characterization of H II regions while permitting genuine adaptivity to irregular source morphology. It makes a first guess at the shapes of all sources through object recognition techniques; it then allows for departure from such idealized \"seeds\" through an iterative growing procedure and derives photometric corrections for spatially coincident diffuse emission from a low-order surface fit to the background after exclusion of all detected sources.","topic_id":"33298","bibcode":"2014ascl.soft05005T","views":"53","site_list":["http:\/\/dolomiti.pha.jhu.edu\/dthilker\/HIIphot_code\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000AJ....120.3070T"]},
		{"ascl_id":"1405.002","title":"TelFit: Fitting the telluric absorption spectrum","credit":"Gullikson, Kevin","abstract":"TelFit calculates the best-fit telluric absorption spectrum in high-resolution optical and near-IR spectra. The best-fit model can then be divided out to remove the telluric contamination. Written in Python, TelFit is essentially a wrapper to <a href=\"http:\/\/www.ascl.net\/1405.001\">LBLRTM<\/a>, the Line-By-Line Radiative Transfer Model, and simplifies the process of generating a telluric model.","topic_id":"33299","bibcode":"2014ascl.soft05002G","views":"66","site_list":["http:\/\/www.as.utexas.edu\/~kgulliks\/projects.html","https:\/\/github.com\/kgullikson88\/Telluric-Fitter"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014AJ....148...53G","http:\/\/adsabs.harvard.edu\/abs\/2013AJ....145....3G"]},
		{"ascl_id":"1405.001","title":"LBLRTM: Line-By-Line Radiative Transfer Model","credit":"Clough, Shepard A.; Iacono, Michael J.; Moncet, Jean-Luc","abstract":"LBLRTM (Line-By-Line Radiative Transfer Model) is an accurate line-by-line model that is efficient and highly flexible. LBLRTM attributes provide spectral radiance calculations with accuracies consistent with the measurements against which they are validated and with computational times that greatly facilitate the application of the line-by-line approach to current radiative transfer applications. LBLRTM has been extensively validated against atmospheric radiance spectra from the ultra-violet to the sub-millimeter. \n\nLBLRTM's heritage is in FASCODE [Clough et al., 1981, 1992].","topic_id":"33300","bibcode":"2014ascl.soft05001C","views":"80","site_list":["http:\/\/rtweb.aer.com\/lblrtm.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1992JGR....9715761C","http:\/\/adsabs.harvard.edu\/abs\/2005JQSRT..91..233C","http:\/\/adsabs.harvard.edu\/abs\/2013AJ....145....3G"]},
		{"ascl_id":"1405.006","title":"PROPER: Optical propagation routines","credit":"Krist, John E.","abstract":"PROPER simulates the propagation of light through an optical system using Fourier transform algorithms (Fresnel, angular spectrum methods). Distributed as IDL source code, it includes routines to create complex apertures, aberrated wavefronts, and deformable mirrors. It is especially useful for the simulation of high contrast imaging telescopes (extrasolar planet imagers like TPF).","topic_id":"33301","bibcode":"2014ascl.soft05006K","views":"57","site_list":["http:\/\/www.openchannelsoftware.com\/projects\/PROPER"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007SPIE.6675E..23K","http:\/\/adsabs.harvard.edu\/abs\/2012A%26A...541A..83M"]},
		{"ascl_id":"1405.007","title":"FORWARD: Forward modeling of coronal observables","credit":"Gibson, Sarah E.; Kucera, Therese A.; Casini, Roberto; Dove, James; Forland, Blake; Judge, Philip; Rachmeler, Laurel","abstract":"FORWARD forward models various coronal observables and can access and compare existing data. Given a coronal model, it can produce many different synthetic observables (including Stokes polarimetry), as well as plots of model plasma properties (density, magnetic field, etc.). It uses the <a href=\"http:\/\/www.ascl.net\/9911.004\">CHIANTI<\/a> database and CLE polarimetry synthesis code, works with numerical model datacubes, interfaces with the PFSS module of <a href=\"http:\/\/www.ascl.net\/1208.013\">SolarSoft<\/a>, includes several analytic models, and connects to the Virtual Solar Observatory for downloading data in a format directly comparable to model predictions.","topic_id":"33302","bibcode":"2014ascl.soft05007G","views":"65","site_list":["http:\/\/people.hao.ucar.edu\/sgibson\/FORWARD\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013AGUSMSH51A..02F","http:\/\/adsabs.harvard.edu\/abs\/2014IAUS..300..414F"]},
		{"ascl_id":"1405.008","title":"TRIPP: Time Resolved Imaging Photometry Package","credit":"Geckeler, Ralf D.; Schuh, Sonja; Dreizler, Stefan; Deetjen, Jochen; Gleissner, Thomas; Risse, Patrick; Rauch, Thomas; G\u00f6hler, Eckart; H\u00fcgelmeyer, Simon; Husser, Tim-Oliver; Israel, Holger; Benlloch-Garcia, Sara; Pottschmidt, Katja; Wilms, J\u00f6rn","abstract":"Written in IDL, TRIPP performs CCD time series reduction and analysis. It provides an on-line check of the incoming frames, performs relative aperture photometry and provides a set of time series tools, such as calculation of periodograms including false alarm probability determination, epoc folding, sinus fitting, and light curve simulations.","topic_id":"33303","bibcode":"2014ascl.soft05008G","views":"82","site_list":["http:\/\/astro.uni-tuebingen.de\/~schuh\/tripp\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2003BaltA..12..167S"]},
		{"ascl_id":"1405.009","title":"ATV: Image display tool","credit":"Barth, Aaron J.; Schlegel, David; Finkbeiner, Doug; Colley, Wesley; Liu, Mike; Brauher, Jim; Cunningham, Nathaniel; Perrin, Marshall; Roe, Henry; Weaver, Hal","abstract":"ATV displays and analyses astronomical images using the IDL image-processing language. It allows interactive control of the image scaling, color table, color stretch, and zoom, with support for world coordinate systems. It also does point-and-click aperture photometry, simple spectral extractions, and can produce publication-quality postscript output images.","topic_id":"33304","bibcode":"2014ascl.soft05009B","views":"105","site_list":["http:\/\/www.physics.uci.edu\/~barth\/atv\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001ASPC..238..385B","http:\/\/adsabs.harvard.edu\/abs\/2013ApJS..208....5N","http:\/\/adsabs.harvard.edu\/abs\/2014ApJ...781..122W"]},
		{"ascl_id":"1405.010","title":"FLUXES: Position and flux density of planets","credit":"Jenness, Tim; Privett, Grant; Matthews, Henry; Hohenkerk, Catherine; Barnard, Vicki; Tilanus, Remo; Watt, Graeme; Emerson, Jim","abstract":"FLUXES calculates approximate topocentric positions of the planets and also integrated flux densities of five of them at several wavelengths. These provide calibration information at the effective frequencies and beam-sizes employed by the UKT14, SCUBA and SCUBA-2 receivers on the JCMT telescope based on Mauna Kea, Hawaii. FLUXES is part of the bundle that comprises the <a href=\"http:\/\/www.ascl.net\/1110.012\">Starlink multi-purpose astronomy software package<\/a> (ascl:1110.012).","topic_id":"33305","bibcode":"2014ascl.soft05010J","views":"79","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013MNRAS.430.2534D","http:\/\/adsabs.harvard.edu\/abs\/2012ApJ...744..169S","http:\/\/adsabs.harvard.edu\/abs\/1991MNRAS.248...91L"]},
		{"ascl_id":"1405.011","title":"DATACUBE: A datacube manipulation package","credit":"Allan, Alasdair; Currie, Malcolm J.","abstract":"DATACUBE is a command-line package for manipulating and visualizing data cubes. It was designed for integral field spectroscopy but has been extended to be a generic data cube tool, used in particular for sub-millimeter data cubes from the James Clerk Maxwell Telescope. It is part of the Starlink software collection (ascl:1110.012).","topic_id":"33307","bibcode":"2014ascl.soft05011A","views":"71","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/www.adsabs.harvard.edu\/abs\/2012MNRAS.426..389C","http:\/\/www.adsabs.harvard.edu\/abs\/2008ASPC..394..650C"]},
		{"ascl_id":"1405.012","title":"PISA: Position Intensity and Shape Analysis","credit":"Draper, Peter W.; Eaton, Nicholas; Irwin, Mike","abstract":"PISA (Position, Intensity and Shape Analysis) routines deal with the location and parameterization of objects on an image frame. The core of this package is the routine PISAFIND which performs image analysis on a 2-dimensional data frame. The program searches the data array for objects that have a minimum number of connected pixels above a given threshold and extracts the image parameters (position, intensity, shape) for each object. The image parameters can be determined using thresholding techniques or an analytical stellar profile can be used to fit the objects. In crowded regions deblending of overlapping sources can be performed. PISA is distributed as part of the Starlink software collection (ascl:1110.012).","topic_id":"33308","bibcode":"2014ascl.soft05012D","views":"56","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/www.starlink.ac.uk\/docs\/sun109.htx\/sun109.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2000MNRAS.317..801W","http:\/\/adsabs.harvard.edu\/abs\/1998MNRAS.297..839K","http:\/\/adsabs.harvard.edu\/abs\/1995AJ....109..935B"]},
		{"ascl_id":"1405.013","title":"PHOTOM: Photometry of digitized images","credit":"Eaton, Nicholas; Draper, Peter W.; Allan, Alasdair; Naylor, Tim; Mukai, Koji; Currie, Malcolm J.; McCaughrean, Mark","abstract":"PHOTOM performs photometry of digitized images. It has two basic modes of operation: using an interactive display to specify the positions for the measurements, or obtaining those positions from a file. In both modes of operation PHOTOM performs photometry using either the traditional aperture method or via optimal extraction. When using the traditional aperture extraction method the target aperture can be circular or elliptical and its size and shape can be varied interactively on the display, or by entering values from the keyboard. Both methods allow the background sky level to be either sampled interactively by the manual positioning of an aperture, or automatically from an annulus surrounding the target object. PHOTOM is the photometry backend for the GAIA tool (ascl:1403.024) and is part of the Starlink software collection (ascl:1110.012).","topic_id":"33309","bibcode":"2014ascl.soft05013E","views":"76","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/www.starlink.ac.uk\/docs\/sun45.htx\/sun45.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013A&A...559A..36G","http:\/\/adsabs.harvard.edu\/abs\/1998ApJ...501..522B","http:\/\/adsabs.harvard.edu\/abs\/1989ESOC...31...93E"]},
		{"ascl_id":"1405.014","title":"POLPACK: Imaging polarimetry reduction package","credit":"Berry, David S.; Gledhill, Tim M.","abstract":"POLPACK maps the linear or circular polarization of extended astronomical objects, either in a single waveband, or in multiple wavebands (spectropolarimetry). Data from both single and dual beam polarimeters can be processed. It is part of the Starlink software collection (ascl:1110.012).","topic_id":"33310","bibcode":"2014ascl.soft05014B","views":"53","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/www.starlink.ac.uk\/docs\/sun223.htx\/sun223.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009ApJS..182..143M","http:\/\/adsabs.harvard.edu\/abs\/2005ASPC..343...71B"]},
		{"ascl_id":"1405.015","title":"CURSA: Catalog and Table Manipulation Applications","credit":"Davenhall, A.C.","abstract":"The CURSA package manipulates astronomical catalogs and similar tabular datasets. It provides facilities for browsing or examining catalogs; selecting subsets from a catalog; sorting and copying catalogs; pairing two catalogs; converting catalog coordinates between some celestial coordinate systems; and plotting finding charts and photometric calibration. It can also extract subsets from a catalog in a format suitable for plotting using other Starlink packages such as PONGO. CURSA can access catalogs held in the popular FITS table format, the Tab-Separated Table (TST) format or the Small Text List (STL) format.  Catalogs in the STL and TST formats are simple ASCII text files.  CURSA also includes some facilities for accessing remote on-line catalogs via the Internet. It is part of the Starlink software collection (ascl:1110.012).","topic_id":"33311","bibcode":"2014ascl.soft05015D","views":"61","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/www.starlink.ac.uk\/docs\/sun190.htx\/sun190.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009ApJS..182..143M","http:\/\/adsabs.harvard.edu\/abs\/2001ASPC..232..314D"]},
		{"ascl_id":"1405.016","title":"DIPSO: Spectrum analysis code","credit":"Howarth, I. D.; Murray, J.; Mills, D.; Berry, David S.","abstract":"DIPSO plots spectroscopic data rapidly and combines analysis and high-quality graphical output in a simple command-line driven interactive environment. It can be used, for example, to fit emission lines, measure equivalent widths and fluxes, do Fourier analysis, and fit models to spectra. A macro facility allows convenient execution of regularly used sequences of commands, and a simple Fortran interface permits \"personal\" software to be integrated with the program. DIPSO is part of the Starlink software collection (ascl:1110.012).","topic_id":"33312","bibcode":"2014ascl.soft05016H","views":"73","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/www.starlink.ac.uk\/docs\/sun50.htx\/sun50.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014ApJ...784...16M","http:\/\/adsabs.harvard.edu\/abs\/1998A&A...332..479V","http:\/\/adsabs.harvard.edu\/abs\/1986A%26A...155..113B"]},
		{"ascl_id":"1406.001","title":"ASURV: Astronomical SURVival Statistics","credit":"Feigelson, E. D.; Nelson, P. I.; Isobe, T.; LaValley, M.","abstract":"ASURV (Astronomical SURVival Statistics) provides astronomy survival analysis for right- and left-censored data including the maximum-likelihood Kaplan-Meier estimator and several univariate two-sample tests, bivariate correlation measures, and linear regressions. ASURV is written in FORTRAN 77, and is stand-alone and does not call any specialized libraries.","topic_id":"33334","bibcode":"2014ascl.soft06001F","views":"86","site_list":["http:\/\/astrostatistics.psu.edu\/statcodes\/asurv"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1985ApJ...293..192F","http:\/\/adsabs.harvard.edu\/abs\/2014ApJ...787..153K","http:\/\/adsabs.harvard.edu\/abs\/2014ApJ...787...42C"]},
		{"ascl_id":"1406.002","title":"PAMELA: Optimal extraction code for long-slit CCD spectroscopy","credit":"Marsh, Thomas R.","abstract":"PAMELA is an implementation of the optimal extraction algorithm for long-slit CCD spectroscopy and is well suited for time-series spectroscopy. It properly implements the optimal extraction algorithm for curved spectra, including on-the-fly cosmic ray rejection as well as proper calculation and propagation of the errors. The software is distributed as part of the Starlink software collection (ascl:1110.012).","topic_id":"33335","bibcode":"2014ascl.soft06002M","views":"57","site_list":["http:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1989PASP..101.1032M","http:\/\/adsabs.harvard.edu\/abs\/2011A&A...536A..43N","http:\/\/adsabs.harvard.edu\/abs\/2001A&A...376L..17S"]},
		{"ascl_id":"1405.017","title":"ESP: Extended Surface Photometry","credit":"Privett, Grant; Taylor, Mark; Gray, Norman; Draper, Peter W.; Jenness, Tim","abstract":"ESP (Extended Surface Photometry) determines the photometric properties of galaxies and other extended objects. It has applications that detect flatfielding faults, remove cosmic rays, median filter images, determine image statistics and local background values, perform galaxy profiling, fit 2-D Gaussian profiles to galaxies, generate pie slice cross-sections of galaxies, and display profiling results. It is distributed as part of the Starlink software collection (ascl:1110.012)","topic_id":"33315","bibcode":"2014ascl.soft05017P","views":"69","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/www.starlink.ac.uk\/docs\/sun180.htx\/sun180.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005ApJ...624..680K","http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.420.3412S"]},
		{"ascl_id":"1405.018","title":"ECHOMOP: Echelle data reduction package","credit":"Mills, Dave; Webb, John; Clayton, Martin; Gray, Norman","abstract":"ECHOMOP extracts spectra from 2-D data frames. These data can be single-order spectra or multi-order echelle spectra. A substantial degree of automation is provided, particularly in the traditionally manual functions for cosmic-ray detection and wavelength calibration; manual overrides are available. Features include robust and flexible order tracing, optimal extraction, support for variance arrays, and 2-D distortion fitting and extraction. ECHOMOP is distributed as part of the Starlink software collection (ascl:1110.012).","topic_id":"33316","bibcode":"2014ascl.soft05018M","views":"84","site_list":["http:\/\/github.com\/Starlink\/starlink","http:\/\/www.starlink.ac.uk\/docs\/sun152.htx\/sun152.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014MNRAS.439.3094B","http:\/\/adsabs.harvard.edu\/abs\/1995MNRAS.277.1145U"]},
		{"ascl_id":"1406.005","title":"PERIOD: Time-series analysis package","credit":"Dhillon, V. S.; Privett, G. J.; Duffey, K. P.","abstract":"PERIOD searches for periodicities in data. It is distributed within the Starlink software collection (ascl:1110.012).","topic_id":"33342","bibcode":"2014ascl.soft06005D","views":"65","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/www.starlink.ac.uk\/docs\/sun167.htx\/sun167.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012MNRAS.419..330M","http:\/\/adsabs.harvard.edu\/abs\/2010A&A...511A..84S"]},
		{"ascl_id":"1406.006","title":"FROG: Time-series analysis","credit":"Allan, Alasdair","abstract":"FROG performs time series analysis and display. It provides a simple user interface for astronomers wanting to do time-domain astrophysics but still offers the powerful features found in packages such as PERIOD (ascl:1406.005). FROG includes a number of tools for manipulation of time series. Among other things, the user can combine individual time series, detrend series (multiple methods) and perform basic arithmetic functions. The data can also be exported directly into the TOPCAT (ascl:1101.010) application for further manipulation if needed.","topic_id":"33343","bibcode":"2014ascl.soft06006A","views":"74","site_list":["https:\/\/github.com\/Starlink\/starjava"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010ApJ...720..337S","http:\/\/adsabs.harvard.edu\/abs\/2005ASPC..347..370A"]},
		{"ascl_id":"1406.007","title":"RV: Radial Components of Observer's Velocity","credit":"Wallace, Patrick T.; Clayton, Chris A","abstract":"The RV program produces a report listing the components, in a given direction, of the observer's velocity on a given date.  This allows an observed radial velocity to be referred to an appropriate standard of rest -- typically either the Sun or an LSR.\n\nAs a secondary function, RV computes light time components to the Sun, thus allowing the times of phenomena observed from a terrestrial observatory to be referred to a heliocentric frame of reference. n.b. It will of course, in addition, be necessary to express the observations in the appropriate timescale as well as applying light time corrections.  In particular, it is likely that an observed UTC will need to be converted to TDB as well as being corrected to the Sun.)\n\nRV is distributed with the Starlink software collection (ascl:1110.012) and uses SLALIB (ascl:1403.025).","topic_id":"33344","bibcode":"2014ascl.soft06007W","views":"59","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/www.starlink.ac.uk\/docs\/sun78.htx\/sun78.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008A&A...490..125M","http:\/\/adsabs.harvard.edu\/abs\/2006MNRAS.370..597L"]},
		{"ascl_id":"1406.008","title":"ASTROM: Basic astrometry program","credit":"Wallace, Patrick T.; Gray, Norman","abstract":"ASTROM performs \"plate reductions\" by taking user-provided star positions and the (x,y) coordinates of the corresponding star images and establishes the relationship between (x,y) and (ra,dec), thus enabling the coordinates of unknown stars to be determined. ASTROM is distributed with the Starlink software (ascl:1110.012) and uses SLALIB (ascl:1403.025).","topic_id":"33345","bibcode":"2014ascl.soft06008W","views":"90","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/www.starlink.ac.uk\/docs\/sun5.htx\/sun5.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006MNRAS.369...97H","http:\/\/adsabs.harvard.edu\/abs\/2002MNRAS.330..737S"]},
		{"ascl_id":"1406.004","title":"Autoastrom: Autoastrometry for Mosaics","credit":"Cavanagh, Brad; Gray, Norman","abstract":"Autoastrom performs automated astrometric corrections on an astronomical image by automatically detecting objects in the frame, retrieving a reference catalogue, cross correlating the catalog with CCDPACK (ascl:1403.021) or MATCH, and using the ASTROM application to calculate a correction. It is distributed as part of the Starlink software collection (ascl:1110.012).","topic_id":"33341","bibcode":"2014ascl.soft06004C","views":"79","site_list":["https:\/\/github.com\/Starlink\/perl-Starlink-Autoastrom","http:\/\/www.astro.gla.ac.uk\/~norman\/star\/autoastrom\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008MNRAS.390.1517C","http:\/\/adsabs.harvard.edu\/abs\/2011MNRAS.412.2071C"]},
		{"ascl_id":"1406.010","title":"MATCH: A program for matching star lists","credit":"Richmond, Michael W.","abstract":"MATCH matches up items in two different lists, which can have two different systems of coordinates. The program allows the two sets of coordinates to be related by a linear, quadratic, or cubic transformation. MATCH was designed and written to work on lists of stars and other astronomical objects but can be applied to other types of data. In order to match two lists of N points, the main algorithm calls for O(N^6) operations; though not the most efficient choice, it does allow for arbitrary translation, rotation, and scaling.","topic_id":"33347","bibcode":"2014ascl.soft06010R","views":"56","site_list":["http:\/\/spiff.rit.edu\/match\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006PASP..118.1666D","http:\/\/adsabs.harvard.edu\/abs\/2010PASJ...62...91R"]},
		{"ascl_id":"1407.001","title":"The Starfish Diagram: Statistical visualization tool","credit":"Konstantopoulos, Iraklis S.","abstract":"The Starfish Diagram is a statistical visualization tool that simultaneously displays the properties of an individual and its parent sample through a series of histograms. The code is useful for large datasets for which one needs to understand the standing or significance of a single entry.","topic_id":"33358","bibcode":"2014ascl.soft07001K","views":"254","site_list":["https:\/\/bitbucket.org\/iraklis_k\/starfish"],"ref_list":["http:\/\/arxiv.org\/abs\/1407.5619"]},
		{"ascl_id":"1406.011","title":"TSP: Time-Series\/Polarimetry Package","credit":"Bailey, Jeremy","abstract":"TSP is an astronomical data reduction package that handles time series data and polarimetric data from a variety of different instruments, and is distributed as part of the Starlink software collection (ascl:1110.012).","topic_id":"33348","bibcode":"2014ascl.soft06011B","views":"72","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006MNRAS.373.1641P","http:\/\/adsabs.harvard.edu\/abs\/1996MNRAS.283L...1Y","http:\/\/adsabs.harvard.edu\/abs\/1993MNRAS.263..895I"]},
		{"ascl_id":"1406.012","title":"POLMAP: Interactive data analysis package for linear spectropolarimetry","credit":"Harries, T. J.","abstract":"POLMAP provides routines for displaying and analyzing spectropolarimetry data that are not available in the complementary TSP package. Commands are provided to read and write TSP (ascl:1406.011) polarization spectrum format files from within POLMAP. This code is distributed as part of the Starlink software collection (ascl:1110.012).","topic_id":"33349","bibcode":"2014ascl.soft06012H","views":"62","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1999MNRAS.304L...1A","http:\/\/adsabs.harvard.edu\/abs\/2009A&A...505..743V"]},
		{"ascl_id":"1406.013","title":"CGS4DR: Automated reduction of data from CGS4","credit":"Daly, Phil N.; Beard, Steven M; Lightfoot, John, L.; Bridger, Alan","abstract":"CGS4DR is data reduction software for the CGS4 instrument at UKIRT. The software can be used offline to reprocess CGS4 data. CGS4DR allows a wide variety of data reduction configurations, and can interlace oversampled data frames; reduce known bias, dark, flat, arc, object and sky frames; remove the sky, residual sky OH-lines (\u03bb < 2.3 \u03bcm) and thermal emission (\u03bb \u2265 2.3 \u03bcm) from data; and add data into groups for improved signal-to-noise. It can also extract and de-ripple a spectrum and offers a variety of ways to plot data, in addition to other useful features. CGS4DR is distributed as part of the Starlink software collection (ascl:1110.012).","topic_id":"33350","bibcode":"2014ascl.soft06013D","views":"68","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1992ESOC...41..117P","http:\/\/adsabs.harvard.edu\/abs\/1995MNRAS.272L...5E","http:\/\/adsabs.harvard.edu\/abs\/2004ApJ...613..770M"]},
		{"ascl_id":"1406.014","title":"IRAS90: IRAS Data Processing","credit":"Berry, David S.; Parsons, Diana C.; Gong, Wei; Currie, Malcolm J.; Warren-Smith, Rodney F.; Morris, Huw","abstract":"IRAS90 is a suite of programs for processing IRAS data. It takes advantage of Starlink's (ascl:1110.012) ADAM environment, which provides multi-platform availability of both data and the programs to process it, and the user friendly interface of the parameter entry system. The suite can determine positions in astrometric coordinates, draw grids, and offers other functions for standard astronomical measurement and standard projections.","topic_id":"33351","bibcode":"2014ascl.soft06014B","views":"57","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1997A&A...325..542C"]},
		{"ascl_id":"1406.015","title":"IRCAMDR: IRCAM3 Data Reduction Software","credit":"Aspin, Colin; McCaughrean, Mark; Bridger, Alan B.; Baines, Dave; Beard, Steven; Chan, S.; Giddings, Jack; Hartley, K. F.; Horsfield, A.P.; Kelly, B. D.; Emerson, J. P.; Currie, Malcolm J.; Economou, Frossie","abstract":"The UKIRT IRCAM3 data reduction and analysis software package, IRCAMDR (formerly ircam_clred) analyzes and displays any 2D data image stored in the standard Starlink (ascl:1110.012) NDF data format. It reduces and analyzes IRCAM1\/2 data images of 62x58 pixels and IRCAM3 images of 256x256 size. Most of the applications will work on NDF images of any physical (pixel) dimensions, for example, 1024x1024 CCD images can be processed.","topic_id":"33352","bibcode":"2014ascl.soft06015A","views":"77","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1999MNRAS.305L..49H","http:\/\/adsabs.harvard.edu\/abs\/1997MNRAS.290L..65F","http:\/\/adsabs.harvard.edu\/abs\/1992MNRAS.255P...6C"]},
		{"ascl_id":"1406.016","title":"IUEDR: IUE Data Reduction package","credit":"Giddings, Jack; Rees, Paul; Mills, Dave; Clayton, Martin","abstract":"IUEDR reduces IUE data. It addresses the problem of working from the IUE Guest Observer tape or disk file through to a calibrated spectrum that can be used in scientific analysis and is a complete system for IUE data reduction. IUEDR was distributed as part of the Starlink software collection (ascl:1110.012).","topic_id":"33353","bibcode":"2014ascl.soft06016G","views":"73","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002ApJS..140...37F","http:\/\/adsabs.harvard.edu\/abs\/1998A&A...338.1057J","http:\/\/adsabs.harvard.edu\/abs\/1992ApJ...390..266P"]},
		{"ascl_id":"1406.019","title":"JCMTDR: Applications for reducing JCMT continuum data in GSD format","credit":"Lightfoot, John F.; Harrison, Paul A.; Meyerdierks, Horst; Jenness, Tim","abstract":"JCMTDR reduces continuum on-the-fly mapping data obtained with UKT14 or the heterodyne instruments using the IFD on the James Clerk Maxwell Telescope. This program reduces archive data and heterodyne beam maps and was distributed as part of the Starlink software collection (ascl:1110.012).","topic_id":"33355","bibcode":"2014ascl.soft06019L","views":"142","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1996MNRAS.281..294B","http:\/\/adsabs.harvard.edu\/abs\/1997MNRAS.288L..45L"]},
		{"ascl_id":"1406.020","title":"STARMAN: Stellar photometry and image\/table handling","credit":"Penny, Alan J.","abstract":"STARMAN is a stellar photometry package designed for the reduction of data from imaging systems. Its main components are crowded-field photometry programs, aperture photometry programs, a star finding program, and a CCD reduction program.\n\nImage and table handling are served by a large number of programs which have a general use in photometry and other types of work. The package is a coherent whole, for use in the entire process of stellar photometry from raw images to the final standard-system magnitudes and their plotting as color-magnitude and color-color diagrams. It was distributed as part of the Starlink software collection (ascl:1110.012).","topic_id":"33356","bibcode":"2014ascl.soft06020P","views":"166","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001MNRAS.325.1205T","http:\/\/adsabs.harvard.edu\/abs\/1995MNRAS.274..407F","http:\/\/adsabs.harvard.edu\/abs\/1986MNRAS.220..845P"]},
		{"ascl_id":"1407.003","title":"SPECDRE: Spectroscopy Data Reduction","credit":"Meyerdierks, Horst","abstract":"Specdre performs spectroscopy data reduction and analysis. General features of the package include data cube manipulation, arc line calibration, resampling and spectral fitting. Particular care is taken with error propagation, including tracking covariance. SPECDRE is distributed as part of the Starlink software collection (<a href=\"http:\/\/ascl.net\/1110.012\">ascl:1110.012<\/a>).","topic_id":"33360","bibcode":"2014ascl.soft07003M","views":"191","site_list":["https:\/\/github.com\/Starlink\/starlink"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004NewA....9..537K","http:\/\/adsabs.harvard.edu\/abs\/1996MNRAS.280...77J","http:\/\/adsabs.harvard.edu\/abs\/1992ESOC...41...47M"]},
		{"ascl_id":"1406.003","title":"CoREAS: CORSIKA-based Radio Emission from Air Showers simulator","credit":"Huege, Tim","abstract":"CoREAS is a Monte Carlo code for the simulation of radio emission from extensive air showers. It implements the endpoint formalism for the calculation of electromagnetic radiation directly in CORSIKA (<a href=\"www.ascl.net\/1202.006\">ascl:1202.006<\/a>). As such, it is parameter-free, makes no assumptions on the emission mechanism for the radio signals, and takes into account the complete complexity of the electron and positron distributions as simulated by CORSIKA.","topic_id":"33338","bibcode":"2014ascl.soft06003H","views":"48","site_list":["http:\/\/www.timhuege.de\/coreas"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013AIPC.1535..128H","http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1402.3677P"]},
		{"ascl_id":"1407.009","title":"Period04: Statistical analysis of large astronomical time series","credit":"Lenz, Patrick; Breger, Michel","abstract":"Period04 statistically analyzes large astronomical time series containing gaps. It calculates formal uncertainties, can extract the individual frequencies from the multiperiodic content of time series, and provides a flexible interface to perform multiple-frequency fits with a combination of least-squares fitting and the discrete Fourier transform algorithm. Period04, written in Java\/C++, supports the SAMP communication protocol to provide interoperability with other applications of the Virtual Observatory. It is a reworked and extended version of Period98 (Sperl 1998) and PERIOD\/PERDET (Breger 1990).","topic_id":"33374","bibcode":"2014ascl.soft07009L","views":"105","site_list":["http:\/\/www.univie.ac.at\/tops\/Period04\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004IAUS..224..786L","http:\/\/adsabs.harvard.edu\/abs\/2014AJ....147..107S","http:\/\/adsabs.harvard.edu\/abs\/2005CoAst.146...53L"]},
		{"ascl_id":"1407.017","title":"e-MERLIN data reduction pipeline","credit":"Argo, Megan","abstract":"Written in Python and utilizing ParselTongue (<a href=\"http:\/\/www.ascl.net\/1208.020\">ascl:1208.020<\/a>) to interface with AIPS (<a href=\"http:\/\/www.ascl.net\/9911.003\">ascl:9911.003<\/a>), the e-MERLIN data reduction pipeline processes, calibrates and images data from the UK's radio interferometric array (Multi-Element Remote-Linked Interferometer Network). Driven by a plain text input file, the pipeline is modular and can be run in stages. The software includes options to load raw data, average in time and\/or frequency, flag known sources of interference, flag more comprehensively with SERPent (<a href=\"http:\/\/www.ascl.net\/1312.001\">ascl:1312.001<\/a>), carry out some or all of the calibration procedures (including self-calibration), and image in either normal or wide-field mode. It also optionally produces a number of useful diagnostic plots at various stages so data quality can be assessed.","topic_id":"33384","bibcode":"2014ascl.soft07017A","views":"278","site_list":["https:\/\/github.com\/mkargo\/pipeline","http:\/\/www.e-merlin.ac.uk\/observe\/pipeline\/"],"ref_list":false},
		{"ascl_id":"1406.018","title":"GAUSSCLUMPS: Gaussian-shaped clumping from a spectral map","credit":"Stutzki, J.","abstract":"GAUSSCLUMPS decomposes a spectral map into Gaussian-shape clumps. The clump-finding algorithm decomposes a spectral data cube by iteratively removing 3-D Gaussians as representative clumps. GAUSSCLUMPS was originally a separate code distribution but is now a contributed package in GILDAS (ascl:1305.010). A reimplementation can also be found in CUPID (ascl:1311.007).","topic_id":"33354","bibcode":"2014ascl.soft06018S","views":"154","site_list":["http:\/\/www.iram.fr\/~gildas\/dist\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1990ApJ...356..513S","http:\/\/adsabs.harvard.edu\/abs\/1994MNRAS.266..972H"]},
		{"ascl_id":"1406.017","title":"COCO: Conversion of Celestial Coordinates","credit":"Wallace, Patrick","abstract":"The COCO program converts star coordinates from one system to another. Both the improved IAU system, post-1976, and the old pre-1976 system are supported. COCO can perform accurate transformations between multiple coordinate systems. COCO\u2019s user-interface is spartan but efficient and the program offers control over report resolution. All input is free-format, and defaults are provided where this is meaningful. COCO uses SLALIB (ascl:1403.025) and is distributed as part of the Starlink software collection (ascl:1110.012).","topic_id":"33337","bibcode":"2014ascl.soft06017W","views":"149","site_list":["https:\/\/github.com\/Starlink\/starlink","http:\/\/www.starlink.ac.uk\/docs\/sun56.htx\/sun56.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1993ApJ...417..706H","http:\/\/adsabs.harvard.edu\/abs\/1987MNRAS.225..761F"]},
		{"ascl_id":"1407.008","title":"Exopop: Exoplanet population inference","credit":"Foreman-Mackey, Daniel","abstract":"Exopop is a general hierarchical probabilistic framework for making justified inferences about the population of exoplanets. Written in python, it requires that the occurrence rate density be a smooth function of period and radius (employing a Gaussian process) and takes survey completeness and observational uncertainties into account. Exopop produces more accurate estimates of the whole population than standard procedures based on weighting by inverse detection efficiency.","topic_id":"33373","bibcode":"2014ascl.soft07008F","views":"284","site_list":["https:\/\/github.com\/dfm\/exopop"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1406.3020F"]},
		{"ascl_id":"1407.010","title":"CLE: Coronal line synthesis","credit":"Judge, Philip G.; Casini, Roberto","abstract":"CLE, written in Fortran 77, synthesizes Stokes profiles of forbidden lines such as Fe XIII 1074.7nm, formed in magnetic dipole transitions under coronal conditions. The lines are assumed to be optically thin, excited by (anisotropic) photospheric radiation and thermal particle collisions.","topic_id":"33375","bibcode":"2014ascl.soft07010J","views":"99","site_list":["http:\/\/people.hao.ucar.edu\/judge\/homepage\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2001ASPC..236..503J","http:\/\/adsabs.harvard.edu\/abs\/2011ApJ...731L...1D"]},
		{"ascl_id":"1407.011","title":"kungifu: Calibration and reduction of fiber-fed IFU astronomical spectroscopy","credit":"Bolton, Adam S.; Burles, Scott","abstract":"kungifu is a set of IDL software routines designed for the calibration and reduction of fiber-fed integral-field unit (IFU) astronomical spectroscopy. These routines can perform optimal extraction of IFU data and allow relative and absolute wavelength calibration to within a few hundredths of a pixel (for unbinned data) across 1200-2000 fibers. kungifu does nearly Poisson-limited sky subtraction, even in the I band, and can rebin in wavelength. The Princeton <a href=\"http:\/\/spectro.princeton.edu\/idlspec2d_install.html\">IDLUTILS and IDLSPEC2D packages<\/a> must be installed for kungifu to run.","topic_id":"33376","bibcode":"2014ascl.soft07011B","views":"157","site_list":["http:\/\/www.physics.utah.edu\/~bolton\/kungifu\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2007NJPh....9..443B"]},
		{"ascl_id":"1407.012","title":"PINGSoft2: Integral Field Spectroscopy Software","credit":"Rosales-Ortega, F. F.","abstract":"PINGSoft2 visualizes, manipulates and analyzes integral field spectroscopy (IFS) data based on either 3D cubes or Raw Stacked Spectra (RSS) format. Any IFS data can be adapted to work with PINGSoft2, regardless of the original data format and the size\/shape of the spaxel. Written in IDL, PINGSoft2 is optimized for fast visualization rendering; it also includes various routines useful for generic astronomy and spectroscopy tasks.","topic_id":"33378","bibcode":"2014ascl.soft07012R","views":"165","site_list":["http:\/\/centeotl.inaoep.mx\/~frosales\/pings\/html\/software\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2011NewA...16..220R"]},
		{"ascl_id":"1408.002","title":"LIA: LWS Interactive Analysis","credit":"Infrared Space Observatory (ISO) Development Team","abstract":"The Long Wavelength Spectrometer (LWS) was one of two complementary spectrometers on the Infrared Space Observatory (ISO). LIA (LWS Interactive Analysis) is used for processing data from the LWS. It provides access to the different processing steps, including visualization of intermediate products and interactive manipulation of the data at each stage.","topic_id":"33393","bibcode":"2014ascl.soft08002I","views":"77","site_list":["http:\/\/iso.esac.esa.int\/archive\/software\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2002SPIE.4847..435L"]},
		{"ascl_id":"1408.003","title":"PIA: ISOPHOT Interactive Analysis","credit":"Gabriel, Carlos; Acosta, Jose; Heinrichsen, Ingolf; Skaley, Detlef; Tai, Wai Ming; Morris, Huw; Merluzzi, Paola","abstract":"ISOPHOT is one of the instruments on board the Infrared Space Observatory (ISO). ISOPHOT Interactive Analysis (PIA) is a scientific and calibration interactive data analysis tool for ISOPHOT data reduction. Written in IDL under Xwindows, PIA offers a full context sensitive graphical interface for retrieving, accessing and analyzing ISOPHOT data. It is available in two nearly identical versions; a general observers version omits the calibration sequences.","topic_id":"33394","bibcode":"2014ascl.soft08003G","views":"74","site_list":["http:\/\/iso.esac.esa.int\/manuals\/PHT\/pia\/pia.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1997ASPC..125..108G"]},
		{"ascl_id":"1407.013","title":"VStar: Variable star data visualization and analysis tool","credit":"VStar Team","abstract":"VStar is a multi-platform, easy-to-use variable star data visualization and analysis tool. Data for a star can be read from the AAVSO (American Association of Variable Star Observers) database or from CSV and TSV files. VStar displays light curves and phase plots, can produce a mean curve, and analyzes time-frequency with Weighted Wavelet Z-Transform. It offers tools for period analysis, filtering, and other functions.","topic_id":"33379","bibcode":"2014ascl.soft07013V","views":"201","site_list":["http:\/\/www.aavso.org\/vstar-overview","http:\/\/sourceforge.net\/projects\/vstar\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012JAVSO..40..852B"]},
		{"ascl_id":"1406.009","title":"VADER: Viscous Accretion Disk Evolution Resource","credit":"Krumholz, Mark R.; Forbes, John C.","abstract":"VADER is a flexible, general code that simulates the time evolution of thin axisymmetric accretion disks in time-steady potentials. VADER handles arbitrary viscosities, equations of state, boundary conditions, and source and sink terms for both mass and energy.","topic_id":"33346","bibcode":"2014ascl.soft06009K","views":"51","site_list":["https:\/\/bitbucket.org\/krumholz\/vader\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1406.6691K"]},
		{"ascl_id":"1407.004","title":"MCMAC: Monte Carlo Merger Analysis Code","credit":"Dawson, William A.","abstract":"Monte Carlo Merger Analysis Code (MCMAC) aids in the study of merging clusters. It takes observed priors on each subcluster's mass, radial velocity, and projected separation, draws randomly from those priors, and uses them in a analytic model to get posterior PDF's for merger dynamic properties of interest (e.g. collision velocity, time since collision).","topic_id":"33361","bibcode":"2014ascl.soft07004D","views":"266","site_list":["https:\/\/github.com\/MCTwo\/MCMAC\/tree\/v0.1","http:\/\/dx.doi.org\/10.5281\/zenodo.10242"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013ApJ...772..131D"]},
		{"ascl_id":"1407.005","title":"MATLAB package for astronomy and astrophysics","credit":"Ofek, Eran O.","abstract":"The MATLAB package for astronomy and astrophysics is a collection of software tools and modular functions for astronomy and astrophysics, written in the MATLAB environment. It includes over 700 MATLAB functions and a few tens of data files and astronomical catalogs. The scripts cover a wide range of subjects including: astronomical image processing, ds9 control, astronomical spectra, optics and diffraction phenomena, catalog retrieval and searches, celestial maps and projections, Solar System ephemerides, planar and spherical geometry, time and coordinates conversion and manipulation, cosmology, gravitational lensing, function fitting, general utilities, plotting utilities, statistics, and time series analysis.","topic_id":"33369","bibcode":"2014ascl.soft07005O","views":"322","site_list":["http:\/\/www.weizmann.ac.il\/home\/eofek\/matlab\/"],"ref_list":false},
		{"ascl_id":"1407.007","title":"ASTRORAY: General relativistic polarized radiative transfer code","credit":"Shcherbakov, Roman V.","abstract":"ASRORAY employs a method of ray tracing and performs polarized radiative transfer of (cyclo-)synchrotron radiation. The radiative transfer is conducted in curved space-time near rotating black holes described by Kerr-Schild metric. Three-dimensional general relativistic magneto hydrodynamic (3D GRMHD) simulations, in particular performed with variations of the HARM code, serve as an input to ASTRORAY. The code has been applied to reproduce the sub-mm synchrotron bump in the spectrum of Sgr A*, and to test the detectability of quasi-periodic oscillations in its light curve. ASTRORAY can be readily applied to model radio\/sub-mm polarized spectra of jets and cores of other low-luminosity active galactic nuclei. For example, ASTRORAY is uniquely suitable to self-consistently model Faraday rotation measure and circular polarization fraction in jets.","topic_id":"33372","bibcode":"2014ascl.soft07007S","views":"116","site_list":["http:\/\/astroman.org\/code\/ASTRORAY\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013ApJ...774L..22S"]},
		{"ascl_id":"1407.006","title":"SAMI: Sydney-AAO Multi-object Integral field spectrograph pipeline","credit":"Allen, J. T.; Green, A. W.; Fogarty, L. M. R.; Sharp, R.; Nielsen, J.; Konstantopoulos, I.; Taylor, E. N.; Scott, N.; Cortese, L.; Richards, S. N.; Croom, S.; Owers, M. S.; Bauer, A. E.; Sweet, S. M.; Bryant, J. J.","abstract":"The SAMI (Sydney-AAO Multi-object Integral field spectrograph) pipeline reduces data from the Sydney-AAO Multi-object Integral field spectrograph (SAMI) for the SAMI Galaxy Survey. The python code organizes SAMI data and, along with the AAO 2dfdr package, carries out all steps in the data reduction, from raw data to fully calibrated datacubes. The principal steps are: data management, use of 2dfdr to produce row-stacked spectra, flux calibration, correction for telluric absorption, removal of atmospheric dispersion, alignment of dithered exposures, and drizzling onto a regular output grid. Variance and covariance information is tracked throughout the pipeline. Some quality control routines are also included.","topic_id":"33370","bibcode":"2014ascl.soft07006A","views":"358","site_list":["https:\/\/bitbucket.org\/james_t_allen\/sami-package\/"],"ref_list":false},
		{"ascl_id":"1407.014","title":"VIDE: The Void IDentification and Examination toolkit","credit":"Sutter, P. M.; Lavaux, Guilhem; Hamaus, Nico; Pisani, Alice; Wandelt, Benjamin D.; Warren, Michael S.; Villaescusa-Navarro, Francisco; Zivick, Paul; Mao, Qingqing; Thompson, Benjamin B.","abstract":"The Void IDentification and Examination toolkit (VIDE) identifies voids using a modified version of the parameter-free void finder ZOBOV (<a href=\"http:\/\/ascl.net\/1304.005\">ascl:1304.005<\/a>); a Voronoi tessellation of the tracer particles is used to estimate the density field followed by a watershed algorithm to group Voronoi cells into zones and subsequently voids. Output is a summary of void properties in plain ASCII; a Python API is provided for analysis tasks, including loading and manipulating void catalogs and particle members, filtering, plotting, computing clustering statistics, stacking, comparing catalogs, and fitting density profiles.","topic_id":"33380","bibcode":"2014ascl.soft07014S","views":"176","site_list":["http:\/\/bitbucket.org\/cosmicvoids\/vide_public","http:\/\/www.cosmicvoids.net"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1406.1191S"]},
		{"ascl_id":"1407.015","title":"BayesFlare: Bayesian method for detecting stellar flares","credit":"Pitkin, M.; Williams, D.; Fletcher, L.; Grant, S. D. T.","abstract":"BayesFlare identifies flaring events in light curves released by the Kepler mission; it identifies even weak events by making use of the flare signal shape. The package contains functions to perform Bayesian hypothesis testing comparing the probability of light curves containing flares to that of them containing noise (or non-flare-like) artifacts. BayesFlare includes functions in its amplitude-marginalizer suite to account for underlying sinusoidal variations in light curve data; it includes such variations in the signal model, and then analytically marginalizes over them.","topic_id":"33381","bibcode":"","views":"205","site_list":["https:\/\/github.com\/BayesFlare\/bayesflare\/releases\/tag\/v1.0.0"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1406.1712P"]},
		{"ascl_id":"1407.016","title":"Brut: Automatic bubble classifier","credit":"Beaumont, Christopher; Goodman, Alyssa; Williams, Jonathan; Kendrew, Sarah; Simpson, Robert","abstract":"Brut, written in Python, identifies bubbles in infrared images of the Galactic midplane; it uses a database of known bubbles from the Milky Way Project and Spitzer images to build an automatic bubble classifier. The classifier is based on the Random Forest algorithm, and uses the WiseRF implementation of this algorithm.","topic_id":"33382","bibcode":"","views":"196","site_list":["https:\/\/github.com\/ChrisBeaumont\/brut"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1406.2692B"]},
		{"ascl_id":"1407.019","title":"EZ_Ages: Stellar population age calculator","credit":"Graves, Genevieve J.","abstract":"EZ_Ages is an IDL code package that computes the mean, light-weighted stellar population age, [Fe\/H], and abundance enhancements [Mg\/Fe], [C\/Fe], [N\/Fe], and [Ca\/Fe] for unresolved stellar populations. This is accomplished by comparing Lick index line strengths between the data and the stellar population models of Schiavon (2007), using a method described in Graves & Schiavon (2008). The algorithm uses the inversion of index-index model grids to determine ages and abundances, and exploits the sensitivities of the various Lick indices to measure Mg, C, N, and Ca enhancements over their solar abundances with respect to Fe.","topic_id":"33387","bibcode":"","views":"247","site_list":["http:\/\/astro.berkeley.edu\/~graves\/ez_ages.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008ApJS..177..446G","http:\/\/adsabs.harvard.edu\/abs\/2007ApJS..171..146S"]},
		{"ascl_id":"1407.018","title":"AstroML: Machine learning and data mining in astronomy","credit":"VanderPlas, Jacob; Fouesneau, Morgan; Taylor, Julia","abstract":"Written in Python, AstroML is a library of statistical and machine learning routines for analyzing astronomical data in python, loaders for several open astronomical datasets, and a large suite of examples of analyzing and visualizing astronomical datasets. An optional companion library, astroML_addons, is available; it requires a C compiler and contains faster and more efficient implementations of certain algorithms in compiled code.","topic_id":"33386","bibcode":"","views":"220","site_list":["http:\/\/www.astroml.org\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012cidu.conf...47V","http:\/\/adsabs.harvard.edu\/abs\/2014AAS...22325301V","http:\/\/adsabs.harvard.edu\/abs\/2014AJ....147...76B"]},
		{"ascl_id":"1407.020","title":"Halogen: Multimass spherical structure models for N-body simulations","credit":"Zemp, Marcel","abstract":"Halogen, written in C, generates multimass spherically symmetric initial conditions for N-body simulations. A large family of radial density profiles is supported. The initial conditions are sampled from the full distribution function.","topic_id":"33388","bibcode":"2014ascl.soft07020Z","views":"304","site_list":["https:\/\/github.com\/mzemp\/halogen"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2008MNRAS.386.1543Z","http:\/\/dx.doi.org\/10.1111\/j.1365-2966.2008.13126.x"]},
		{"ascl_id":"1408.011","title":"GALAPAGOS-C: Galaxy Analysis over Large Areas","credit":"Hiemer, Andreas; Kelvin, Lee S.","abstract":"GALAPAGOS-C is a C implementation of the IDL code GALAPAGOS (ascl:1203.002). It processes a complete set of survey images through automation of source detection via SExtractor (ascl:1010.064), postage stamp cutting, object mask preparation, sky background estimation and complex two-dimensional light profile S\u00e9rsic modelling via GALFIT (ascl:1104.010). GALAPAGOS-C uses MPI-parallelization, thus allowing quick processing of large data sets. The code can fit multiple S\u00e9rsic profiles to each galaxy, each representing distinct galaxy components (e.g. bulge, disc, bar), and optionally can fit asymmetric Fourier mode distortions.","topic_id":"33389","bibcode":"2014ascl.soft08011H","views":"148","site_list":["http:\/\/astro-staff.uibk.ac.at\/~andi\/"],"ref_list":false},
		{"ascl_id":"1408.004","title":"HEAsoft: Unified Release of FTOOLS and XANADU","credit":"NASA High Energy Astrophysics Science Archive Research Center (HEASARC)","abstract":"HEASOFT combines XANADU, high-level, multi-mission software for X-ray astronomical spectral, timing, and imaging data analysis tasks, and FTOOLS (ascl:9912.002), general and mission-specific software to manipulate FITS files, into one package. The source code for the software can be downloaded; precompiled executables for the most widely used computer platforms are also available for download. As an additional service, HEAsoft tasks can be directly from a web browser via &lt;a href=\"http:\/\/heasarc.gsfc.nasa.gov\/webHera\/\"&gt;WebHera&lt;\/a&gt;.","topic_id":"33395","bibcode":"2014ascl.soft08004N","views":"72","site_list":["http:\/\/heasarc.nasa.gov\/lheasoft\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2005xrrc.procE6.01D","http:\/\/adsabs.harvard.edu\/abs\/2014ApJ...790...52M"]},
		{"ascl_id":"1408.001","title":"Imfit: A Fast, Flexible Program for Astronomical Image Fitting","credit":"Erwin, Peter","abstract":"Imift is an open-source astronomical image-fitting program specialized for galaxies but potentially useful for other sources, which is fast, flexible, and highly extensible. Its object-oriented design allows new types of image components (2D surface-brightness functions) to be easily written and added to the program. Image functions provided with Imfit include Sersic, exponential, and Gaussian galaxy decompositions along with Core-Sersic and broken-exponential profiles, elliptical rings, and three components that perform line-of-sight integration through 3D luminosity-density models of disks and rings seen at arbitrary inclinations.\n\nAvailable minimization algorithms include Levenberg-Marquardt, Nelder-Mead simplex, and Differential Evolution, allowing trade-offs between speed and decreased sensitivity to local minima in the fit landscape. Minimization can be done using the standard chi^2 statistic (using either data or model values to estimate per-pixel Gaussian errors, or else user-supplied error images) or the Cash statistic; the latter is particularly appropriate for cases of Poisson data in the low-count regime.\n\nThe C++ source code for Imfit is available under the GNU Public License.","topic_id":"33392","bibcode":"2014ascl.soft08001E","views":"100","site_list":["http:\/\/www.mpe.mpg.de\/~erwin\/code\/imfit\/"],"ref_list":["http:\/\/arxiv.org\/abs\/1408.1097"]},
		{"ascl_id":"1408.005","title":"POET: Planetary Orbital Evolution due to Tides","credit":"Penev, Kaloyan","abstract":"POET (Planetary Orbital Evolution due to Tides) calculates the orbital evolution of a system consisting of a single star with a single planet in orbit under the influence of tides. The following effects are The evolutions of the semimajor axis of the orbit due to the tidal dissipation in the star and the angular momentum of the stellar convective envelope by the tidal coupling are taken into account. In addition, the evolution includes the transfer of angular momentum between the stellar convective and radiative zones, effect of the stellar evolution on the tidal dissipation efficiency, and stellar core and envelope spins and loss of stellar convective zone angular momentum to a magnetically launched wind. POET can be used out of the box, and can also be extended and modified.","topic_id":"33396","bibcode":"","views":"77","site_list":["http:\/\/www.astro.princeton.edu\/~kpenev\/tidal_orbital_evolution\/index.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014PASP..126..553P"]},
		{"ascl_id":"1408.006","title":"SPAM: Source Peeling and Atmospheric Modeling","credit":"Intema, Huib T.","abstract":"SPAM is a extension to AIPS for reducing high-resolution, low-frequency radio interferometric observations. Direction-dependent ionospheric calibration and image-plane ripple suppression are among the features that help to make high-quality sub-GHz images. Data reductions are captured in well-tested Python scripts that execute AIPS tasks directly (mostly during initial data reduction steps), call high-level functions that make multiple AIPS or ParselTongue calls, and require few manual operations.","topic_id":"33397","bibcode":"2014ascl.soft08006I","views":"77","site_list":["https:\/\/safe.nrao.edu\/wiki\/bin\/view\/Main\/HuibIntemaSpam"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1402.4889I","http:\/\/adsabs.harvard.edu\/abs\/2014MNRAS.442.2867W"]},
		{"ascl_id":"1408.007","title":"Skycorr: Sky emission subtraction for observations without plain sky information","credit":"Noll, S.; Kausch, W.; Kimeswenger, S.; Barden, M.; Jones, A. M.; Modigliani, A.; Szyszka, C.; Taylor, J.","abstract":"Skycorr is an instrument-independent sky subtraction code that uses physically motivated line group scaling in the reference sky spectrum by a fitting approach for an improved sky line removal in the object spectrum. Possible wavelength shifts between both spectra are corrected by fitting Chebyshev polynomials and advanced rebinning without resolution decrease. For the correction, the optimized sky line spectrum and the automatically separated sky continuum (without scaling) is subtracted from the input object spectrum. Tests show that Skycorr performs well (per cent level residuals) for data in different wavelength regimes and of different resolution, even in the cases of relatively long time lags between the object and the reference sky spectrum. Lower quality results are mainly restricted to wavelengths not dominated by airglow lines or pseudo continua by unresolved strong emission bands.","topic_id":"33398","bibcode":"2014ascl.soft08007N","views":"85","site_list":["http:\/\/www.eso.org\/sci\/software\/pipelines\/skytools\/skycorr"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014A%26A...567A..25N"]},
		{"ascl_id":"1408.008","title":"GALIC: Galaxy initial conditions construction","credit":"Yurin, Denis; Springel, Volker","abstract":"GalIC (GALaxy Initial Conditions) is an implementation of an iterative method to construct steady state composite halo-disk-bulge galaxy models with prescribed density distribution and velocity anisotropy that can be used as initial conditions for N-body simulations. The code is parallelized for distributed memory based on MPI. While running, GalIC produces \"snapshot files\" that can be used as initial conditions files. GalIC supports the three file formats ('type1' format, the slightly improved 'type2' format, and an HDF5 format) of the GADGET (ascl:0003.001) code for its output snapshot files.","topic_id":"33399","bibcode":"2014ascl.soft08008Y","views":"87","site_list":["http:\/\/www.h-its.org\/english\/research\/tap\/galic\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014MNRAS.444...62Y"]},
		{"ascl_id":"1408.012","title":"LightcurveMC: An extensible lightcurve simulation program","credit":"Findeisen, Krzysztof","abstract":"LightcurveMC is a versatile and easily extended simulation suite for testing the performance of time series analysis tools under controlled conditions. It is designed to be highly modular, allowing new lightcurve types or new analysis tools to be introduced without excessive development overhead. The statistical tools are completely agnostic to how the lightcurve data is generated, and the lightcurve generators are completely agnostic to how the data will be analyzed. The use of fixed random seeds throughout guarantees that the program generates consistent results from run to run.\n\nLightcurveMC can generate periodic light curves having a variety of shapes and stochastic light curves having a variety of correlation properties. It features two error models (Gaussian measurement and signal injection using a randomized sample of base light curves), testing of C1 shape statistic, periodograms, \u0394m\u0394t plots, autocorrelation function plots, peak-finding plots, and Gaussian process regression. The code is written in C++ and R.","topic_id":"33406","bibcode":"2014ascl.soft08012F","views":"142","site_list":["https:\/\/github.com\/kfindeisen\/LightcurveMC\/releases\/"],"ref_list":false},
		{"ascl_id":"1408.013","title":"NumCosmo: Numerical Cosmology","credit":"Dias Pinto Vitenti, Sandro; Penna-Lima, Mariana","abstract":"NumCosmo is a free software C library whose main purposes are to test cosmological models using observational data and to provide a set of tools to perform cosmological calculations. The software implements three different probes: cosmic microwave background (CMB), supernovae type Ia (SNeIa) and large scale structure (LSS) information, such as baryonic acoustic oscillations (BAO) and galaxy cluster abundance. The code supports a joint analysis of these data and the parameter space can include cosmological and phenomenological parameters. NumCosmo matter power spectrum and CMB codes were written independent of other implementations such as CMBFAST (ascl:9909.004), CAMB (ascl:1102.026), etc.\n\nThe library structure simplifies the inclusion of non-standard cosmological models. Besides the functions related to cosmological quantities, this library also implements mathematical and statistical tools. The former were developed to enable the inclusion of other probes and\/or theoretical models and to optimize the codes. The statistical framework comprises algorithms which define likelihood functions, minimization, Monte Carlo, Fisher Matrix and profile likelihood methods.","topic_id":"33407","bibcode":"2014ascl.soft08013D","views":"191","site_list":["https:\/\/savannah.nongnu.org\/projects\/numcosmo\/","http:\/\/www.nongnu.org\/numcosmo\/","https:\/\/github.com\/NumCosmo\/NumCosmo"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014JCAP...05..039P"]},
		{"ascl_id":"1408.014","title":"pieflag: CASA task to efficiently flag bad data","credit":"Hales, C. A.; Middelberg, E.","abstract":"pieflag compares bandpass-calibrated data to a clean reference channel and identifies and flags essentially all bad data. pieflag compares visibility amplitudes in each frequency channel to a 'reference' channel that is rfi-free (or manually ensured to be rfi-free). pieflag performs this comparison independently for each correlation on each baseline, but will flag all correlations if threshold conditions are met. To operate effectively, pieflag must be supplied with bandpass-calibrated data. pieflag has two core modes of operation (static and dynamic flagging) with an additional extend mode; the type of data largely determines which mode to choose. Instructions for pre-processing data and selecting the mode of operation are provided in the help file. Once pre-processing and selecting the mode of operation are done, pieflag should work well 'out of the box' with its default parameters.","topic_id":"33408","bibcode":"2014ascl.soft08014H","views":"139","site_list":["https:\/\/github.com\/chrishales\/pieflag"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006PASA...23...64M"]},
		{"ascl_id":"1408.009","title":"IIPImage: Large-image visualization","credit":"Pillay, Ruven","abstract":"IIPImage is an advanced high-performance feature-rich image server system that enables online access to full resolution floating point (as well as other bit depth) images at terabyte scales. Paired with the VisiOmatic (ascl:1408.010) celestial image viewer, the system can comfortably handle gigapixel size images as well as advanced image features such as both 8, 16 and 32 bit depths, CIELAB colorimetric images and scientific imagery such as multispectral images. Streaming is tile-based, which enables viewing, navigating and zooming in real-time around gigapixel size images. Source images can be in either TIFF or JPEG2000 format. Whole images or regions within images can also be rapidly and dynamically resized and exported by the server from a single source image without the need to store multiple files in various sizes.","topic_id":"33404","bibcode":"2014ascl.soft08009P","views":"73","site_list":["http:\/\/iipimage.sourceforge.net\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1403.6025B","http:\/\/www.sciencedirect.com\/science\/article\/pii\/S0169755298000622"]},
		{"ascl_id":"1408.010","title":"VisiOmatic: Celestial image viewer","credit":"Bertin, Emmanuel; Marmo, Chiara; Pillay, Ruven","abstract":"VisiOmatic is a web client for IIPImage (ascl:1408.009) and is used to visualize and navigate through large science images from remote locations. It requires STIFF (ascl:1110.006), is based on the Leaflet Javascript library, and works on both touch-based and mouse-based devices.","topic_id":"33405","bibcode":"2014ascl.soft08010B","views":"72","site_list":["http:\/\/www.astromatic.net\/software\/visiomatic","https:\/\/github.com\/astromatic\/visiomatic\/releases"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1403.6025B"]},
		{"ascl_id":"1408.018","title":"CosmoPhotoz: Photometric redshift estimation using generalized linear models","credit":"de Souza, Rafael S.; Elliott, Jonathan; Krone-Martins, Alberto; Ishida, Emille E. O.; Hilbe, Joseph; Cameron, Ewan","abstract":"CosmoPhotoz determines photometric redshifts from galaxies utilizing their magnitudes. The method uses generalized linear models which reproduce the physical aspects of the output distribution. The code can adopt gamma or inverse gaussian families, either from a frequentist or a Bayesian perspective. A set of publicly available libraries and a web application are available. This software allows users to apply a set of GLMs to their own photometric catalogs and generates publication quality plots with no involvement from the user. The code additionally provides a Shiny application providing a simple user interface.","topic_id":"33413","bibcode":"2014ascl.soft08018D","views":"275","site_list":["https:\/\/github.com\/COINtoolbox\/CosmoPhotoz","http:\/\/cointoolbox.github.io\/CosmoPhotoz\/","http:\/\/algollabs.shinyapps.io\/glmPhotoZ-2\/","http:\/\/cosmophotoz.readthedocs.org\/en\/latest\/"],"ref_list":false},
		{"ascl_id":"1408.015","title":"VPFIT: Voigt profile fitting program","credit":"Carswell, R. F.; Webb, J. K.","abstract":"The VPFIT program fits multiple Voigt profiles (convolved with the instrument profiles) to spectroscopic data that is in FITS or an ASCII file. It requires CFITSIO (ascl:1010.001) and PGPLOT (ascl:1103.002); the tarball includes RDGEN (ascl:1408.017), which can be used with VPFIT to set up the fits, fit the profiles, and examine the result in interactive mode for setting up initial guesses; vpguess (ascl:1408.016) can also be used to set up an initial file.","topic_id":"33412","bibcode":"2014ascl.soft08015C","views":"116","site_list":["http:\/\/www.ast.cam.ac.uk\/~rfc\/vpfit.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013ApJ...779...38P"]},
		{"ascl_id":"1408.016","title":"vpguess: Fitting multiple Voigt profiles to spectroscopic data","credit":"Liske, Jochen","abstract":"vpguess facilitates the fitting of multiple Voigt profiles to spectroscopic data. It is a graphical interface to VPFIT (ascl:1408.015). Originally meant to simplify the process of setting up first guesses for a subsequent fit with VPFIT, it has developed into a full interface to VPFIT. It may also be used independently of VPFIT for displaying data, playing around with data and models, \"chi-by-eye\" fits, displaying the result of a proper fit, pretty plots, etc. vpguess is written in C, and the graphics are based on PGPLOT (ascl:1103.002).","topic_id":"33411","bibcode":"2014ascl.soft08016L","views":"116","site_list":["http:\/\/www.eso.org\/~jliske\/vpguess\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013ApJ...779...38P"]},
		{"ascl_id":"1408.017","title":"RDGEN: Routines for data handling, display, and adjusting","credit":"Carswell, R.F.; Webb, J. K.; Cooke, A. J.; Irwin, M. J.","abstract":"RDGEN is a collection of routines for data handling, display, and adjusting, with a facility which helps to set up files for using with VPFIT (ascl:1408.015); it is included in the VPFIT distribution file. It is useful for setting region boundaries and initial guesses for VPFIT, for displaying the accumulated results, for examining by eye particular redshift systems and fits to them, testing that the error array is a true reflection of the rms scatter in the data, comparing spectra and generally examining and even modifying the data.","topic_id":"33410","bibcode":"2014ascl.soft08017C","views":"114","site_list":["http:\/\/www.ast.cam.ac.uk\/~rfc\/rdgen.html","http:\/\/www.ast.cam.ac.uk\/~rfc\/vpfit.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2004ApJ...615..323S"]},
		{"ascl_id":"1408.019","title":"O<sub>2<\/sub>scl: Object-oriented scientific computing library","credit":"Steiner, Andrew W.","abstract":"O<sub>2<\/sub>scl is an object-oriented library for scientific computing in C++ useful for solving, minimizing, differentiating, integrating, interpolating, optimizing, approximating, analyzing, fitting, and more. Many classes operate on generic function and vector types; it includes classes based on GSL and CERNLIB. O<sub>2<\/sub>scl also contains code for computing the basic thermodynamic integrals for fermions and bosons, for generating almost all of the most common equations of state of nuclear and neutron star matter, and for solving the TOV equations. O<sub>2<\/sub>scl can be used on Linux, Mac and Windows (Cygwin) platforms and has extensive documentation.","topic_id":"33416","bibcode":"2014ascl.soft08019S","views":"169","site_list":["http:\/\/github.com\/awsteiner\/o2scl","http:\/\/o2scl.sourceforge.net"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2010ApJ...722...33S"]},
		{"ascl_id":"1408.020","title":"bamr: Bayesian analysis of mass and radius observations","credit":"Steiner, Andrew W.","abstract":"bamr is an MPI implementation of a Bayesian analysis of neutron star mass and radius data that determines the mass versus radius curve and the equation of state of dense matter. Written in C++, bamr provides some EOS models. This code requires O<sub>2<\/sub>scl (ascl:1408.019) be installed before compilation.","topic_id":"33417","bibcode":"2014ascl.soft08020S","views":"157","site_list":["http:\/\/github.com\/awsteiner\/bamr","http:\/\/bamr.sourceforge.net\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2013ApJ...765L...5S"]},
		{"ascl_id":"1408.021","title":"APS: Active Parameter Searching","credit":"Daniel, Scott F.; Connolly, Andrew J.; Schneider, Jeff","abstract":"APS finds Frequentist confidence limits on high-dimensional parameter spaces by using Gaussian Process interpolation to identify regions of parameter space for which chisquared is less than or equal to some specified limit. The code is written in C++, is robust against multi-modal chisquared functions and converges comparably fast to Monte Carlo methods. Code is also provided to draw Bayesian credible limits using the outputs of APS, though this code does not converge as well. APS requires the linear algebra libraries LAPACK, BLAS, and ARPACK (ascl:1311.010) to run.","topic_id":"33419","bibcode":"2014ascl.soft08021D","views":"143","site_list":["https:\/\/github.com\/uwssg\/APS"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2012arXiv1205.2708D"]},
		{"ascl_id":"1408.022","title":"PhotoRApToR: PHOTOmetric Research APplication TO Redshifts","credit":"Brescia, Massimo","abstract":"PhotoRApToR (PHOTOmetric Research APplication TO Redshifts) solves regression and classification problems and is specialized for photo-z estimation. PhotoRApToR offers data table manipulation capabilities and 2D and 3D graphics tools for data visualization; it also provides a statistical report for both classification and regression experiments. The code is written in Java; the machine learning model is in C++ to increase the core execution speed.","topic_id":"33420","bibcode":"2014ascl.soft08022B","views":"171","site_list":["http:\/\/dame.dsf.unina.it\/dame_photoz.html#photoraptor"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1406.3192C"]},
		{"ascl_id":"1408.023","title":"WSClean: Widefield interferometric imager","credit":"Offringa, A. R.; McKinley, B.; Hurley-Walker, N.; Briggs, F. H.; Wayth, R. B.; Kaplan, D. L.; Bell, M. E.; Feng, L.; Neben, A. R.; Hughes, J. D.; Rhee, J.; Murphy, T.; Bhat, N. D. R.; Bernardi, G.; Bowman, J. D.; Cappallo, R. J.; Corey, B. E.; Deshpande, A. A.; Emrich, D.; Ewall-Wice, A.; Gaensler, B. M.; Goeke, R.; Greenhill, L. J.; Hazelton, B. J.; Hindson, L.; Johnston-Hollitt, M.; Jacobs, D. C.; Kasper, J. C.; Kratzenberg, E.; Lenc, E.; Lonsdale, C. J.; Lynch, M. J.; McWhirter, S. R.; Mitchell, D. A.; Morales, M. F.; Morgan, E.; Kudryavtseva, N.; Oberoi, D.; Ord, S. M.; Pindor, B.; Procopio, P.; Prabu, T.; Riding, J.; Roshi, D. A.; Shankar, N. Udaya; Srivani, K. S.; Subrahmanyan, R.; Tingay, S. J.; Waterson, M.; Webster, R. L.; Whitney, A. R.; Williams, A.; Williams, C. L.","abstract":"WSClean (w-stacking clean) is a fast generic widefield imager. It uses the w-stacking algorithm and can make use of the w-snapshot algorithm. It supports full-sky imaging and proper beam correction for homogeneous dipole arrays such as the MWA. WSClean allows Hogbom and Cotton-Schwab cleaning, and can clean polarizations joinedly. All operations are performed on the CPU; it is not specialized for GPUs.","topic_id":"33421","bibcode":"2014ascl.soft08023O","views":"168","site_list":["http:\/\/sourceforge.net\/projects\/wsclean\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014MNRAS.444..606O"]},
		{"ascl_id":"1409.004","title":"IFSRED: Data Reduction for Integral Field Spectrographs","credit":"Rupke, David S. N.","abstract":"IFSRED is a general-purpose library for reducing data from integral field spectrographs (IFSs). For a general IFS data cube, it contains IDL routines to: (1) find and apply a zero-point shift in a wavelength solution on a spaxel-by-spaxel basis, using sky lines; (2) find the spatial coordinates of a flux peak; (3) empirically correct for differential atmospheric refraction; (4) mosaic dithered exposures; (5) (integer) rebin; and (6) apply a telluric correction. A sky-subtraction routine for data from the Gemini Multi-Object Spectrograph and Imager (GMOS) that can be easily modified for any instrument is also included. IFSRED also contains additional software specific to reducing data from GMOS and the Gemini Near-Infrared Integral Field Spectrograph (NIFS).","topic_id":"33427","bibcode":"2014ascl.soft09004R","views":"50","site_list":["https:\/\/github.com\/drupke\/ifsred"],"ref_list":false},
		{"ascl_id":"1409.001","title":"mixT: single-temperature fit for a multi-component thermal plasma","credit":"Vikhlinin, Alexey","abstract":"mixT accurately predicts T derived from a single-temperature fit for a multi-component thermal plasma. It can be applied in the deprojection analysis of objects with the temperature and metallicity gradients, for correction of the PSF effects, for consistent comparison of numerical simulations of galaxy clusters and groups with the X-ray observations, and for estimating how emission from undetected components can bias the global X-ray spectral analysis.","topic_id":"33424","bibcode":"2014ascl.soft09001V","views":"44","site_list":["http:\/\/hea-www.harvard.edu\/~alexey\/mixT\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2006ApJ...640..710V"]},
		{"ascl_id":"1409.005","title":"IFSFIT: Spectral Fitting for Integral Field Spectrographs","credit":"Rupke, David S. N.","abstract":"IFSFIT is a general-purpose IDL library for fitting the continuum, emission lines, and absorption lines in integral field spectra. It uses PPXF (ascl:1210.002) to find the best fit stellar continuum (using a user-defined library of stellar templates and including additive polynomials), or optionally a user-defined method to find the best fit continuum. It uses MPFIT (ascl:1208.019) to simultaneously fit Gaussians to any number of emission lines and emission line velocity components. It will also fit the NaI D feature using analytic absorption and\/or emission-line profiles.","topic_id":"33428","bibcode":"2014ascl.soft09005R","views":"52","site_list":["https:\/\/github.com\/drupke\/ifsfit"],"ref_list":false},
		{"ascl_id":"1409.003","title":"LANL*: Radiation belt drift shell modeling","credit":"Yu, Yiqun; Koller, Josef","abstract":"LANL* calculates the magnetic drift invariant L*, used for modeling radiation belt dynamics and other space weather applications, six orders of magnitude (~ one million times) faster than convectional approaches that require global numerical field lines tracing and integration. It is based on a modern machine learning technique (feed-forward artificial neural network) by supervising a large data pool obtained from the IRBEM library, which is the traditional source for numerically calculating the L* values. The pool consists of about 100,000 samples randomly distributed within the magnetosphere (r: [1.03, 11.5] Re) and within a whole solar cycle from 1\/1\/1994 to 1\/1\/2005. There are seven LANL* models, each corresponding to its underlying magnetic field configuration that is used to create the data sample pool. This model has applications to real-time radiation belt forecasting, analysis of data sets involving tens of satellite-years of observations, and other problems in space weather.","topic_id":"33426","bibcode":"2014ascl.soft09003Y","views":"36","site_list":["http:\/\/ccmc.gsfc.nasa.gov\/models\/modelinfo.php?model=LANL","http:\/\/www.lanlstar.lanl.gov\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2009GMD.....2..113K"]},
		{"ascl_id":"1409.002","title":"Tsyganenko Geomagnetic Field Models","credit":"Tsyganenko, Nikolai","abstract":"The Tsyganenko models are semi-empirical best-fit representations for the magnetic field, based on a large number of satellite observations (IMP, HEOS, ISEE, POLAR, Geotail, GOES, etc). The models include the contributions from major external magnetospheric sources: ring current, magnetotail current system, magnetopause currents, and large-scale system of field-aligned currents.","topic_id":"33425","bibcode":"2014ascl.soft09002T","views":"43","site_list":["http:\/\/ccmc.gsfc.nasa.gov\/models\/modelinfo.php?model=Tsyganenko%20Magnetic%20Field","http:\/\/geo.phys.spbu.ru\/~tsyganenko\/modeling.html"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/1995JGR...100.5599T"]},
		{"ascl_id":"1409.006","title":"iSpec: Stellar atmospheric parameters and chemical abundances","credit":"Blanco-Cuaresma, S.; Soubiran, C.; Heiter, U.; Jofr\u00e9, P.","abstract":"iSpec is an integrated software framework written in Python for the treatment and analysis of stellar spectra and abundances. Spectra treatment functions include cosmic rays removal, continuum normalization, resolution degradation, and telluric lines identification. It can also perform radial velocity determination and correction and resampling. iSpec can also determine atmospheric parameters (i.e effective temperature, surface gravity, metallicity, micro\/macroturbulence, rotation) and individual chemical abundances by using either the synthetic spectra fitting technique or equivalent widths method. The synthesis is performed with SPECTRUM (ascl:9910.002).","topic_id":"33429","bibcode":"2014ascl.soft09006B","views":"5","site_list":["http:\/\/www.blancocuaresma.com\/s\/iSpec\/"],"ref_list":["http:\/\/adsabs.harvard.edu\/abs\/2014arXiv1407.2608B"]}
	]
}